<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>k8s学习（10）：RS、Deployment控制器</title>
    <url>/2020/01/05/10_RS%E3%80%81Deployment-%E6%8E%A7%E5%88%B6%E5%99%A8/</url>
    <content><![CDATA[<h2 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h2><p>RC(ReplicationController)主要的作用是确保容器应用的副本数始终保持在用户定义的副本数。</p>
<p>k8s官方建议使用RS（ReplicaSet）替代RC，两者功能一样，但RS支持集合式的selector</p>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">dns</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看标签</span></span><br><span class="line">kubectl get pod --show-labels</span><br><span class="line"><span class="meta">#</span><span class="bash"> 尝试修改标签，看看会不会自动创建新的pod</span></span><br><span class="line">kubectl label pod frontend-xxx tier=frontend1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 会提示需要加--overwrite is <span class="literal">false</span></span></span><br><span class="line">kubectl label pod frontend-xxx tier=frontend1 --overwrite=True</span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次get看pod状态</span></span><br><span class="line">kubectl get pods --show-labels</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除RS，此时不会删除之前修改过label的pod</span></span><br><span class="line">kubectl delete rs frontend</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod,此时只剩下一个pod</span></span><br><span class="line">kubectl get pod </span><br></pre></td></tr></table></figure>

<p><strong>RS会通过matchLabels匹配template.metadata.labels对应的数值</strong></p>
<p>如果修改pod的标签，会重新创建新的pod；如果删除旧的pod，也会重新创建pod</p>
<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><p><img src="/assets/image-20200131012425977.png" alt="image-20200131012425977"></p>
<p>Deployment为Pod和ReplicaSet提供了一个声明式定义（declarative）方法，用来替代以前的RC来方便管理应用，典型应用：</p>
<ul>
<li><p><strong>定义Deployment来创建Pod和RS</strong></p>
</li>
<li><p><strong>滚动升级和回滚应用</strong></p>
</li>
<li><p><strong>扩容和缩容</strong></p>
</li>
<li><p><strong>暂停和继续Deployment</strong></p>
</li>
</ul>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建deployment，通过添加record参数可以记录命令，后续可以查看revision的变化</span></span><br><span class="line">kubectl create -f nginx-deployment.yaml --record</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看deployment</span></span><br><span class="line">kubectl get deploy</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看rs</span></span><br><span class="line">kubectl get rs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">kubectl get pods</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看label</span></span><br></pre></td></tr></table></figure>

<ul>
<li>labels需要写在<strong>spec.template.metadata.labels</strong>这个位置</li>
</ul>
<p>这里个人理解一下：</p>
<p>rs有matchLabels和labels相对应，deployment只有labels，应该是deployment省略了</p>
<h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl scale deployment nginx-deployment --replicas=10</span><br></pre></td></tr></table></figure>



<h3 id="如果集群支持horizontal-pod-autoscaling的话，还可以为Deployment设置自动扩展"><a href="#如果集群支持horizontal-pod-autoscaling的话，还可以为Deployment设置自动扩展" class="headerlink" title="如果集群支持horizontal pod autoscaling的话，还可以为Deployment设置自动扩展"></a>如果集群支持horizontal pod autoscaling的话，还可以为Deployment设置自动扩展</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80</span><br></pre></td></tr></table></figure>



<h3 id="更新镜像"><a href="#更新镜像" class="headerlink" title="更新镜像"></a>更新镜像</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl set image deployment/nginx-deployment nginx=wangyanglinux/myapp:v2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod，发现旧的pod被删除，新的pod被创建</span></span><br><span class="line">kubectl get pods</span><br><span class="line"><span class="meta">#</span><span class="bash"> 此时查看rs，会发现多一个rs</span></span><br><span class="line">kubectl get rs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod IP</span></span><br><span class="line">kubectl get pod -o wide</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod版本</span></span><br><span class="line">curl ip</span><br></pre></td></tr></table></figure>



<h3 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl rollout undo deployment/nginx-deployment</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看rs和pod</span></span><br><span class="line">kubectl get pods -o wide</span><br><span class="line">kubectl get rs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod版本</span></span><br><span class="line">curl ip</span><br></pre></td></tr></table></figure>



<h3 id="Deployment更新策略"><a href="#Deployment更新策略" class="headerlink" title="Deployment更新策略"></a>Deployment更新策略</h3><p>Deployment可以保证在升级时只有一定数量的Pod是down。默认的，它会确保至少有比期望的Pod数量少一个是up状态（最多一个不可用）</p>
<p>Deployment同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的，它会确保最多比期望的Pod数量多一个的Pod是up的（最多一个surge）</p>
<p>未来的k8s版本中，将从1-1变成25%-25%</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl describe deployment</span><br></pre></td></tr></table></figure>



<h3 id="Rollver-多个rollout并行"><a href="#Rollver-多个rollout并行" class="headerlink" title="Rollver(多个rollout并行)"></a>Rollver(多个rollout并行)</h3><p>假如你创建了一个有5个replicas的<code>nginx:1.7.9</code>的Deployment，但是当还只有3个pod被创建出来的时候就开始更新nginx至<code>nginx:1.9.1</code>，在这种情况下，Deployment会立即杀掉已创建的3个的<code>nginx:1.7.9</code>的pod，并开始创建<code>nginx:1.9.1</code>的pod。它不会等到所有的5个<code>nginx:1.7.9</code>的Pod都创建完成后才开始改变航道。</p>
<h3 id="回退Deployment"><a href="#回退Deployment" class="headerlink" title="回退Deployment"></a>回退Deployment</h3><p>只要Deployment的rollout被出发就会创建一个revision。也就是说当且仅当Deployment的Pod template（如‘.spec.template’）被更改，例如更新template中的label和容器镜像时，就会创建出一个新的revision。其他的更新，如扩容，则不会创建revision。当回退历史revision时，只会回退template，数量不会回退。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line">kubectl rollout status deployments nginx-deployment</span><br><span class="line">kubectl get pods</span><br><span class="line">kubectl rollout history deployment/nginx-deployment</span><br><span class="line">kubectl rollout undo deployment/nginx-deployment</span><br><span class="line">kubectl rollout undo deployment/nginx-deployment --to-revision=2 ## 指定历史版本</span><br><span class="line">kubectl rollout pause deployment/nginx-deployment ## 暂停deployment的更新</span><br></pre></td></tr></table></figure>

<p>可以用<code>kubectl rollout status</code>命令查看Deployment是否完成。如果rollout完成，则返回一个0值的Exit Code</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout status deploy/nginx</span></span><br><span class="line">Waiting for rollout to finish:2 of 3 updated replicas are available...</span><br><span class="line">deployment &quot;nginx&quot; successfully rolled out</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> $?</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure>



<h3 id="清理Policy"><a href="#清理Policy" class="headerlink" title="清理Policy"></a>清理Policy</h3><p>可以通过设置<code>.spce.revisionHistoryLimit</code>项来指定deployment最多保留多少revision历史记录。默认的会保留所有的revision；如果将该项设置为0，就不允许回退</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（11）：DaemonSet控制器</title>
    <url>/2020/01/05/11_DaemonSet%E6%8E%A7%E5%88%B6%E5%99%A8/</url>
    <content><![CDATA[<h2 id="什么是DaemonSet"><a href="#什么是DaemonSet" class="headerlink" title="什么是DaemonSet"></a>什么是DaemonSet</h2><p>DaemonSet确保全部（或者一些）Node上运行一个Pod的副本。当有Node加入集群时，也会为他们新增一个Pod。当有Node从集群移除时，这些Pod也会被回收。删除DaemonSet将会删除他创建的所有Pod</p>
<p>典型用法：</p>
<ul>
<li><strong>运行集群存储daemon，例如在每个Node上运行glusterd、ceph-mon</strong></li>
<li><strong>在每个Node上运行日志收集daemon，例如fluentd、logstash</strong></li>
<li><strong>在每个Node上运行监控daemon，例如Prometheus Node Exporter、colletcd、Datadog代理、New Relic代理、Ganglia gmond</strong></li>
</ul>
<h2 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">daemonset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">    <span class="attr">template:</span></span><br><span class="line">      <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">labels:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br></pre></td></tr></table></figure>

<p>视频上说，metadata.labels和spec.selector.matchLabels要对应</p>
<p>实际上我两者写不一样，也是可以创建成功，只有当spec内的matchLabels和spec内的labels对应才能创建成功</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（12）：Job、CronJob控制器</title>
    <url>/2020/01/05/12_Job%E3%80%81CronJob%E6%8E%A7%E5%88%B6%E5%99%A8/</url>
    <content><![CDATA[<p>Job负责批处理任务，即仅执行一次的任务，他保证批处理任务的一个或多个Pod成功结束</p>
<p><strong>特殊说明</strong></p>
<ul>
<li><strong>spec.templage格式同Pod</strong></li>
<li><strong>RestartPolicy仅支持Never或OnFailure</strong></li>
<li><strong>单个Pod时，默认Pod成功运行后Job即结束</strong></li>
<li><strong><code>.spec.completions</code>标志Job结束需要成功运行的Pod个数，默认为1</strong></li>
<li><strong><code>.spec.parallelism</code>标志并行运行的Pod的个数，默认为1</strong></li>
<li><strong><code>.spec.activeDeadlineSeconds</code>标志失败Pod的重试最大时间，超过这个时间不会继续重试</strong></li>
</ul>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;perl&quot;</span>, <span class="string">&quot;-Mbignum=bpi&quot;</span>, <span class="string">&quot;-wle&quot;</span>, <span class="string">&quot;print bpi(2000)&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看job</span></span><br><span class="line">kubectl get job</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod</span></span><br><span class="line">kubectl get pod</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod <span class="built_in">log</span></span></span><br><span class="line">kubectl log pi-xxx</span><br></pre></td></tr></table></figure>



<h2 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h2><p>cronJob管理基于时间的Job，即：</p>
<ul>
<li><strong>在给定时间点只运行一次</strong></li>
<li><strong>周期性地在给定时间点运行</strong></li>
</ul>
<p>使用条件：k8s集群版本&gt;=1.8</p>
<p><strong>典型用法：</strong></p>
<ul>
<li><strong>在给定的时间点调度Job运行</strong></li>
<li><strong>创建周期性运行的Job，例如：数据库备份、发送邮件</strong></li>
</ul>
<h3 id="CronJob-Spec"><a href="#CronJob-Spec" class="headerlink" title="CronJob Spec"></a>CronJob Spec</h3><p>spec.template格式同Pod</p>
<p>RestartPolicy仅支持Never或OnFailure</p>
<p>单个Pod时，默认Pod成功后Job即结束</p>
<p><code>.spec.completions</code>标志Job结束需要成功运行的Pod个数，默认为1</p>
<p><code>.spec.parallelism</code>标志并行运行的Pod的个数，默认为1</p>
<p><code>.spec.activeDeadlineSeconds</code>标志失败Pod的重试最大时间，超过这个时间不会继续重试</p>
<h3 id="CronJob-Spec-1"><a href="#CronJob-Spec-1" class="headerlink" title="CronJob Spec"></a>CronJob Spec</h3><ul>
<li><code>**.spec.schedule</code>：调度，必须字段，指定任务运行周期，格式同Cron**</li>
<li><strong><code>.spec.jobTemplate</code>：Job模板，必须字段，指定需要运行的任务，格式同Job</strong></li>
<li><strong><code>.spec.startingDeadlineSeconds</code>：启动Job的期限（秒级别），该字段可选。如果因为任何原因而错过了呗调度的时间，name错过执行时间的Job将被认为是失败的。如果没有指定，则没有期限</strong></li>
<li><strong><code>.spec.concurrencyPolicy</code>：并发策略，该字段可选。它指定了如何处理CronJob创建的Job的并发执行方式。只允许指定下面策略中的一种</strong></li>
</ul>
<blockquote>
<p><strong><code>Allow</code>(默认)：允许并发运行Job</strong></p>
<p><strong><code>Forbid</code>：禁止并发运行，如果前一个还没有完成，则直接跳过下一个</strong></p>
<p>*<code>Replace</code>：取消当前正在运行的Job，用一个新的来替换**</p>
</blockquote>
<p><code>.spec.suspend</code>：挂起，该字段可选。如果设置为true，后续所有执行都会被挂起。它对已经开始执行的Job不起作用。默认值为<code>false</code>。</p>
<p><code>.spec.successfulJobsHistoryLimit</code>和<code>.spec.failedJobsHistoryLimit</code>：历史限制。可选字段。他们制定了可以保存多少完成和失败的Job。默认情况下，它们分别设置为<code>3</code>和<code>1</code>。设置为<code>0</code>时，相关类型的job完成后将不会被保留。</p>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cronjob</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;*/1 * * * *&quot;</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cronjob-container</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">            <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">            <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">date;</span> <span class="string">echo</span> <span class="string">Hello</span> <span class="string">from</span> <span class="string">k8s</span> <span class="string">cluster</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br></pre></td></tr></table></figure>



<h3 id="CronJob本身的一些限制"><a href="#CronJob本身的一些限制" class="headerlink" title="CronJob本身的一些限制"></a>CronJob本身的一些限制</h3><p>创建Job操作应该是幂等的</p>
<p>CronJob不会判断job是否成功，只会定期的去创建job</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>提高Job执行效率</p>
<p>1 设置restartPolicy=OnFailure</p>
<p>2 completions<code>和</code>parallelism<code>，默认值均为 </code>1，每次运行<code>parallelism</code>个pod，直到总共有<code>completions</code>个Pod完成</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（13）：Service定义</title>
    <url>/2020/01/06/13_Service%E5%AE%9A%E4%B9%89/</url>
    <content><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>在kubernetes中，<code>Service</code>定义了这样一种抽象：一个Pod的逻辑分组，一种可以访问它们的策略–通常称为微服务。这一组Pod能够被<code>Service</code>访问到，通常是通过Label Selector</p>
<p>Service能提供负载均衡的能力，但是在使用上有以下限制：</p>
<ul>
<li><p><strong>只提供4层负载均衡能力，而没有7层功能，即不能通过主机名或域名方案去负载，但有时我们可能需要更多的匹配规则来转发请求，这点4层负载均衡是不支持的。（7层可以通过ingress去支持）</strong></p>
</li>
<li><p><strong>负载均衡方式：RR（轮询）</strong></p>
</li>
</ul>
<p><img src="/assets/image-20200201010345630.png" alt="image-20200201010345630"></p>
<h2 id="Service的类型"><a href="#Service的类型" class="headerlink" title="Service的类型"></a>Service的类型</h2><p>Service在k8s中有以下4中类型：</p>
<ul>
<li><p><strong>ClusterIP：默认，自动分配一个仅Cluster内部可以访问的虚拟IP</strong></p>
</li>
<li><p><strong>NodePort：在ClusterIP基础上为Service在每台机器上绑定一个端口，可以通过NodeIP:NodePort来访问该服务</strong></p>
</li>
<li><p><strong>LoadBalancer：在NodePort的基础上，借助cloudprovider创建一个外部负载均衡器，并将请求转发NodeIP:NodePort</strong></p>
</li>
<li><p><strong>ExternalName：把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何代理类型被创建，在k8s版本&gt;=1.7支持</strong></p>
</li>
</ul>
<p><img src="/assets/image-20200201012138497.png" alt="image-20200201012138497"></p>
<h2 id="VIP和Service代理"><a href="#VIP和Service代理" class="headerlink" title="VIP和Service代理"></a>VIP和Service代理</h2><p>在k8s集群中，每个Node运行一个<code>kube-proxy</code>进程。<code>kube-proxy</code>负责为<code>Service</code>实现了一种VIP的形式，而不是<code>ExternalName</code>的形式。</p>
<ul>
<li><strong>k8s v1.0版本，代理是完全是userspace</strong></li>
<li><strong>k8s v1.1版本，新增了iptables代理</strong></li>
<li><strong>k8s v1.2版本，默认为iptables代理</strong></li>
<li><strong>k8s v1,8,0-beta.0版本，添加了ipvs代理</strong></li>
<li><strong>k8s v1.14版本开始，默认使用ipvs代理</strong></li>
</ul>
<p>在k8s v1.0版本，<code>Service</code>是4层（TCP/UDP over IP）概念，在k8s v1.1版本新增了<code>Ingress</code>API（beta版），用来标识7层（HTTP）服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">问题： 为何不使用round-robin DNS？</span><br><span class="line">原因是DNS会在客户端里进行缓存</span><br></pre></td></tr></table></figure>



<h2 id="代理模式的分类"><a href="#代理模式的分类" class="headerlink" title="代理模式的分类"></a>代理模式的分类</h2><h3 id="1-userspace代理模式"><a href="#1-userspace代理模式" class="headerlink" title="1 userspace代理模式"></a>1 userspace代理模式</h3><p><img src="/assets/image-20200201013210254.png" alt="image-20200201013210254"></p>
<h3 id="2-iptables代理模式"><a href="#2-iptables代理模式" class="headerlink" title="2 iptables代理模式"></a>2 iptables代理模式</h3><p><img src="/assets/image-20200201013340246.png" alt="image-20200201013340246"></p>
<h3 id="3-ipvs代理模式"><a href="#3-ipvs代理模式" class="headerlink" title="3 ipvs代理模式"></a>3 ipvs代理模式</h3><p>这种模式，<code>kube-proxy</code>会监视Kubernetes<code>Service</code>对象和<code>Endpoints</code>，调用<code>netlink</code>接口以响应地创建ipvs规则并定期与Kubernetes<code>Service</code>对象和<code>Endpoints</code>对象同步ipvs规则，以确保ipvs状态与期望一致。访问服务时，流量将被重定向到其中一个后端Pod</p>
<p>与iptables类似，ipvs于netfilter的hook功能，但使用哈希表作为底层数据结构并在内核空间工作。这意味着ipvs可以更快地重定向流量，并且在同步代理规则时具有更好的性能。此外，ipvs为负载均衡算法提供了更多选项，例如：</p>
<ul>
<li><strong><code>rr</code>：轮询调度</strong></li>
<li><strong><code>lc</code>：最小连接数</strong></li>
<li><strong><code>dh</code>：目标哈希</strong></li>
<li><strong><code>sh</code>：源哈希</strong></li>
<li><strong><code>sed</code>：最短期望延迟</strong></li>
<li><strong><code>nq</code>：不排队调度</strong></li>
</ul>
<!--注意： ipvs模式假定在运行kube-proxy之前在节点上都已经安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点是否暗转该IPVS模块，如果未安装，则回退到iptables代理模式-->

<p><img src="/assets/image-20200201013438178.png" alt="image-20200201013438178"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 查看负载状态</span><br><span class="line">ipvsadm -Ln</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（14）：Service实例</title>
    <url>/2020/01/06/14_Service%E5%AE%9E%E4%BE%8B/</url>
    <content><![CDATA[<h2 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h2><p>ClusterIP主要在每个Node节点使用iptables（在我们现在的环境是IPVS），将发向ClusterIP对应端口的数据，转发到<code>kube-proxy</code>中。然后<code>kube-proxy</code>自己内部实现有负载均衡的方法，并可以查询到这个<code>Service</code>下对应Pod的地址和端口，进而把数据转发给度踹常能的Pod的地址和端口</p>
<p><img src="/assets/image-20200201141409970.png" alt="image-20200201141409970"></p>
<p>为了实现图上的功能，主要需要以下几个组件的协同工作：</p>
<ul>
<li><strong>apiServer    用户通过kubectl命令向apiserver发送创建service的命令，apiserver接收到请求后将数据存储到etcd中</strong></li>
<li><strong>kube-proxy    kubernetes的每个节点中都有一个叫做kube-proxy的进程，这个进程负责感知service，pod的变化，并将变化的信息写入本地的iptables规则中</strong></li>
<li><strong>iptables    使用NAT等技术将virtualIP的流量转至endpoint中</strong></li>
</ul>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><p>首先创建deployment</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="string">name:myapp-deploy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">      <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">        <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">        <span class="attr">env:</span> <span class="string">test</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>接着创建Service</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> pod查看</span></span><br><span class="line">kubectl get pod</span><br><span class="line"><span class="meta">#</span><span class="bash"> deployment查看</span></span><br><span class="line">kubectl get deployment</span><br><span class="line"><span class="meta">#</span><span class="bash"> svc查看</span></span><br><span class="line">kubectl get svc</span><br><span class="line"><span class="meta">#</span><span class="bash"> ipvs查看</span></span><br><span class="line">ipvsadm -Ln</span><br><span class="line"><span class="meta">#</span><span class="bash"> 访问IP</span></span><br><span class="line">curl x.x.x./hostname.html</span><br></pre></td></tr></table></figure>

<p><strong>deployment的selector需要加matchLabels</strong></p>
<p><strong>svc直接在selector下加标签即可</strong></p>
<h2 id="Headless-Service"><a href="#Headless-Service" class="headerlink" title="Headless Service"></a>Headless Service</h2><p>有时不需要或不想要负载均衡，以及单独的Service IP。遇到这种情况，可以通过制定Cluster IP<code>spec.clusterIP</code>的值为<code>None</code>来创建Headless Service。这类Service并不会分配ClusterIP，kube-proxy不会处理它们，而且平台也不会为它们进行负载均衡和路由</p>
<p>通俗来讲：就是创建一个没有IP的ClusterIP服务 ，但是可以通过coreDNS的域名方式进行访问</p>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">env:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  </span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装dig</span></span><br><span class="line">yum install -y bind-utils</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看kube-dns的ClusterIP的IP地址</span></span><br><span class="line">kubectl get svc -n kube-system</span><br><span class="line">NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span><br><span class="line">kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   4d</span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试coreDNS域名访问</span></span><br><span class="line">dig -t A myapp-headless.default.svc.cluster.local. @10.96.0.10</span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; -t A myapp-headless.default.svc.cluster.local. @10.96.0.10</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; WARNING: .local is reserved for Multicast DNS</span><br><span class="line">;; You are currently testing what happens when an mDNS query is leaked to DNS</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 38148</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;myapp-headless.default.svc.cluster.local. IN A</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">myapp-headless.default.svc.cluster.local. 30 IN	A 10.244.2.156</span><br><span class="line">myapp-headless.default.svc.cluster.local. 30 IN	A 10.244.2.157</span><br><span class="line">myapp-headless.default.svc.cluster.local. 30 IN	A 10.244.1.101</span><br><span class="line"></span><br><span class="line">;; Query time: 1 msec</span><br><span class="line">;; SERVER: 10.96.0.10#53(10.96.0.10)</span><br><span class="line">;; WHEN: Sat Feb 01 16:53:08 +08 2020</span><br><span class="line">;; MSG SIZE  rcvd: 237</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 上面例子是通过kube-dns的IP，也就是svc来访问的</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 也可以通过pod的IP来访问</span></span><br><span class="line">kubectl get pods -n kube-system -o wide</span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE   IP                NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">coredns-5c98db65d4-gh2qc             1/1     Running   3          4d    10.244.0.7        k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">coredns-5c98db65d4-pczm8             1/1     Running   3          4d    10.244.0.6        k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">etcd-k8s-master                      1/1     Running   3          4d    192.168.128.140   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-apiserver-k8s-master            1/1     Running   3          4d    192.168.128.140   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-controller-manager-k8s-master   1/1     Running   6          4d    192.168.128.140   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-amd64-2lrvk          1/1     Running   3          4d    192.168.128.142   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-amd64-bst48          1/1     Running   3          4d    192.168.128.140   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-flannel-ds-amd64-jdqq8          1/1     Running   3          4d    192.168.128.141   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-dm5p6                     1/1     Running   2          4d    192.168.128.140   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-dwdvl                     1/1     Running   3          4d    192.168.128.141   k8s-node01   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-proxy-qhst5                     1/1     Running   3          4d    192.168.128.142   k8s-node02   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-scheduler-k8s-master            1/1     Running   5          4d    192.168.128.140   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 测试coreDNS域名访问</span></span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.11.4-P2-RedHat-9.11.4-9.P2.el7 &lt;&lt;&gt;&gt; -t A myapp-headless.default.svc.cluster.local. @10.96.0.10</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; WARNING: .local is reserved for Multicast DNS</span><br><span class="line">;; You are currently testing what happens when an mDNS query is leaked to DNS</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 38148</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;myapp-headless.default.svc.cluster.local. IN A</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">myapp-headless.default.svc.cluster.local. 30 IN	A 10.244.2.156</span><br><span class="line">myapp-headless.default.svc.cluster.local. 30 IN	A 10.244.2.157</span><br><span class="line">myapp-headless.default.svc.cluster.local. 30 IN	A 10.244.1.101</span><br><span class="line"></span><br><span class="line">;; Query time: 1 msec</span><br><span class="line">;; SERVER: 10.96.0.10#53(10.96.0.10)</span><br><span class="line">;; WHEN: Sat Feb 01 16:53:08 +08 2020</span><br><span class="line">;; MSG SIZE  rcvd: 237</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">myapp-headless.default.svc.cluster.local.</span><br><span class="line">myapp-headless：svc名称</span><br><span class="line">default：名称空间名称</span><br><span class="line">svc.cluster.local：集群的域名</span><br></pre></td></tr></table></figure>



<h2 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h2><p>NodePort的原理在于在node上开了一个端口，将向该端口的流量导入到kube-proxy，然后由kube-proxy进一步到给对应的pod</p>
<h3 id="举个栗子-2"><a href="#举个栗子-2" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-nodeport</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">sector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看svc给的随机端口</span></span><br><span class="line">kubectl get svc</span><br><span class="line"><span class="meta">#</span><span class="bash"> curl验证</span></span><br><span class="line">curl NodeIP:NodePort</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询规则</span></span><br><span class="line">iptables -t nat -nvL</span><br><span class="line">	KUBE-NODEPORTS</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果是ipvs</span></span><br><span class="line">ipvsadm -Ln</span><br></pre></td></tr></table></figure>



<h2 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h2><p>LoadBalancer和NodePort其实是同一种方式。区别在于LoadBalancer比NodePort多了一步，就是可以调用cloud provider去创建LB来向节点导流</p>
<p><img src="/assets/image-20200201173438372.png" alt="image-20200201173438372"></p>
<p><strong>这东西要花钱</strong></p>
<h2 id="ExternalName"><a href="#ExternalName" class="headerlink" title="ExternalName"></a>ExternalName</h2><p>这种类型的Service通过返回CNAME和它的值，可以将服务映射到externalName字段的内容（例如：hub.test.com）。ExternalName Service是Service的特例，它没有selector，也没有定义任何的端口和Endpoint。相反的，对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-servie-1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ExternalName</span></span><br><span class="line">  <span class="attr">externalName:</span> <span class="string">hub.test.com</span>   <span class="comment"># 也可以是IP地址</span></span><br></pre></td></tr></table></figure>

<p>当查询主机my-service-1.default.svc.cluster.local(SVC_NAME.NAMESPACE.svc.cluster.local)时，集群的DNS服务将返回一个值my.database.example.com的CNAME记录。访问这个服务的工作方式和其他的相同，唯一不同的是重定向发生在DNS层，而且不会进行代理或转发。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig -t A my-service-1.default.svc.cluster.local @x.x.x.x</span><br></pre></td></tr></table></figure>





<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>1 可以通过<code>iptables-save</code>命令打印出当前接待你的iptables规则</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（15）：Ingress-负载均衡</title>
    <url>/2020/01/06/15_Ingress/</url>
    <content><![CDATA[<p>Ingress-nginx github地址： <a href="https://github.com/kubernetes/ingress-nginx">https://github.com/kubernetes/ingress-nginx</a></p>
<p>Ingress-nginx 官方网站： <a href="https://kubernetes.github.io/ingress-nginx">https://kubernetes.github.io/ingress-nginx</a></p>
<p><img src="/assets/image-20200201175404733.png" alt="image-20200201175404733"></p>
<p>这里依然是NodePort方式</p>
<p><img src="/assets/image-20200201175657978.png" alt="image-20200201175657978"></p>
<h2 id="部署Ingress-Nginx"><a href="#部署Ingress-Nginx" class="headerlink" title="部署Ingress Nginx"></a>部署Ingress Nginx</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载资源清单配置文件</span></span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.28.0/deploy/static/mandatory.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 国内无法访问quay.io地址，可以修改成国内源</span></span><br><span class="line">sed -i &#x27;s#quay.io#quay-mirror.qiniu.com#g&#x27; mandatory.yaml</span><br><span class="line">kubectl apply -f mandatory.yaml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 以NodePort方式暴露出来</span></span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.28.0/deploy/static/provider/baremetal/service-nodeport.yaml</span><br><span class="line">kubectl apply -f service-nodeport.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress pod</span></span><br><span class="line">kubectl get pod -n ingress-nginx</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress svc</span></span><br><span class="line">kubectl get svc -n ingress-nginx</span><br></pre></td></tr></table></figure>



<h2 id="Ingress-HTTP代理访问"><a href="#Ingress-HTTP代理访问" class="headerlink" title="Ingress HTTP代理访问"></a>Ingress HTTP代理访问</h2><p>deployment、Service、Ingress yaml文件</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deploy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-container</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPolicy</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">          <span class="attr">backend:</span></span><br><span class="line">            <span class="attr">serviceName:</span> <span class="string">nginx-svc</span>   <span class="comment"># 这里的nginx-svc链接的是Service的名称：nginx-svc</span></span><br><span class="line">            <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress</span></span><br><span class="line">kubectl get ingress</span><br><span class="line">NAME            HOSTS          ADDRESS   PORTS   AGE</span><br><span class="line">nginx-ingress   www.test.com             80      9s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress端口</span></span><br><span class="line">kubectl get svc -n ingress-nginx</span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.111.109.71   &lt;none&gt;        80:30153/TCP,443:31846/TCP   3h15m</span><br><span class="line"><span class="meta">#</span><span class="bash"> 首先在本机添加映射</span></span><br><span class="line">- Linux： /etc/hosts</span><br><span class="line">- Windows：C:\Windows\System32\drivers\etc\hosts</span><br><span class="line"><span class="meta">#</span><span class="bash"> 访问www.test.com:30153</span></span><br><span class="line">curl www.test.com:30153</span><br><span class="line">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>



<h2 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h2><h3 id="Ingress虚拟主机-virtual-host"><a href="#Ingress虚拟主机-virtual-host" class="headerlink" title="Ingress虚拟主机 virtual-host"></a>Ingress虚拟主机 virtual-host</h3><p>第一个deployment、svc</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deploy-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">deploy-1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deploy-1</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">svc-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">deploy-1</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>第二个deployment、svc</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deploy-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">deploy-2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">deploy-2</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v2</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">svc-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">deploy-2</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看pod是否running</span></span><br><span class="line">kubectl get pods</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看svcIP地址</span></span><br><span class="line">kubectl get svc </span><br><span class="line">NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP   4d8h</span><br><span class="line">svc-1        ClusterIP   10.98.201.103   &lt;none&gt;        80/TCP    11m</span><br><span class="line">svc-2        ClusterIP   10.98.22.123    &lt;none&gt;        80/TCP    10m</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证svc是否正确链接到pod</span></span><br><span class="line">[root@k8s-master ingress-vh]# curl 10.98.201.103</span><br><span class="line">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br><span class="line">[root@k8s-master ingress-vh]# curl 10.98.22.123</span><br><span class="line">Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>

<p>Ingress rule 规则创建</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test1.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">          <span class="attr">backend:</span></span><br><span class="line">            <span class="attr">serviceName:</span> <span class="string">svc-1</span></span><br><span class="line">            <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test2.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">          <span class="attr">backend:</span></span><br><span class="line">            <span class="attr">serviceName:</span> <span class="string">svc-2</span></span><br><span class="line">            <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress，这里需要等待ADDRESS地址出来之后才能正常访问</span></span><br><span class="line">kubectl get ingress</span><br><span class="line">NAME        HOSTS           ADDRESS         PORTS   AGE</span><br><span class="line">ingress-1   www.test1.com   10.111.109.71   80      48s</span><br><span class="line">ingress-2   www.test2.com   10.111.109.71   80      94s</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress端口</span></span><br><span class="line">kubectl get svc -n ingress-nginx</span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.111.109.71   &lt;none&gt;        80:30153/TCP,443:31846/TCP   3h51m</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证是否能够访问</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> curl www.test1.com:30153</span></span><br><span class="line">Hello MyApp | Version: v1 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> curl www.test2.com:30153</span></span><br><span class="line">Hello MyApp | Version: v2 | &lt;a href=&quot;hostname.html&quot;&gt;Pod Name&lt;/a&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/assets/image-20200202012014428.png" alt="image-20200202012014428"></p>
<p><img src="/assets/image-20200202012021522.png" alt="image-20200202012021522"></p>
<h2 id="Ingress-HTTPS代理访问"><a href="#Ingress-HTTPS代理访问" class="headerlink" title="Ingress HTTPS代理访问"></a>Ingress HTTPS代理访问</h2><p>创建证书，以及cert存储方式</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj &quot;/CN=nginxsvc/0=nginxsvc&quot;</span><br><span class="line">kubectl create secert tls tls-secert --key tls.key --cert tls.crt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 secret</span></span><br><span class="line">kubectl get secret</span><br></pre></td></tr></table></figure>

<p>创建deployment、svc</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-3</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-3</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v3</span> </span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">svc-3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-3</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f nginx-3.yaml</span><br><span class="line">kubectl get pods</span><br><span class="line">kubectl get svc</span><br><span class="line">curl ClusterIP</span><br></pre></td></tr></table></figure>

<p>创建ingress https</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-https</span><br><span class="line">spec:</span><br><span class="line">  tls:</span><br><span class="line">    - hosts:</span><br><span class="line">      - www.test3.com</span><br><span class="line">      secretName: tls-secret</span><br><span class="line">  rules:</span><br><span class="line">    - host: www.test3.com</span><br><span class="line">      http:</span><br><span class="line">        paths:</span><br><span class="line">        - path: &#x2F;</span><br><span class="line">          backend:</span><br><span class="line">            serviceName: svc-3</span><br><span class="line">            servicePort: 80</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress，等待ADDRESS出来</span></span><br><span class="line">kubectl get ingress</span><br><span class="line">NAME          HOSTS           ADDRESS         PORTS     AGE</span><br><span class="line">nginx-https   www.test3.com   10.111.109.71   80, 443   65s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看端口</span></span><br><span class="line">kubectl get svc -n ingress-svc</span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.111.109.71   &lt;none&gt;        80:30153/TCP,443:31846/TCP   4h22m</span><br><span class="line"><span class="meta">#</span><span class="bash"> 浏览器访问</span></span><br></pre></td></tr></table></figure>

<p><img src="/assets/image-20200202011945503.png" alt="image-20200202011945503"></p>
<h2 id="Nginx进行BasicAuth"><a href="#Nginx进行BasicAuth" class="headerlink" title="Nginx进行BasicAuth"></a>Nginx进行BasicAuth</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install httpd</span><br><span class="line">htpasswd -c auth foo</span><br><span class="line">kubectl create secret generic basic-auth --from-file&#x3D;auth</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ingress</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-with-auth</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/auth-type:</span> <span class="string">basic</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/auth-secret:</span> <span class="string">basic-auth</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/auth-realm:</span> <span class="string">&#x27;Authentication Required - foo&#x27;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">www.test4.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">          <span class="attr">backend:</span></span><br><span class="line">            <span class="attr">serviceName:</span> <span class="string">svc-1</span></span><br><span class="line">            <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看ingress</span></span><br><span class="line">kubectl get pods</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看svc端口</span></span><br><span class="line">kubectl get svc -n ingress-nginx</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加hosts映射信息</span></span><br></pre></td></tr></table></figure>

<p><img src="/assets/image-20200202013336313.png" alt="image-20200202013336313"></p>
<p><img src="/assets/image-20200202014205832.png" alt="image-20200202014205832"></p>
<h2 id="Nginx进行重写"><a href="#Nginx进行重写" class="headerlink" title="Nginx进行重写"></a>Nginx进行重写</h2><p><img src="/assets/image-20200202013508869.png" alt="image-20200202013508869"></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-rewrite</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">https://www.test3.com:31846</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www.test5.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">          <span class="attr">backend:</span></span><br><span class="line">            <span class="attr">serviceName:</span> <span class="string">svc-1</span></span><br><span class="line">            <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>这里输入<a href="http://www.test5.com:30135会跳转到https://www.test3.com:31846">http://www.test5.com:30135会跳转到https://www.test3.com:31846</a></p>
<p>而且后面写的serviceName: svc-1不起作用</p>
<p><img src="/assets/image-20200202015216510.png" alt="image-20200202015216510"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（16）：configMap-配置映射</title>
    <url>/2020/01/07/16_configMap/</url>
    <content><![CDATA[<h2 id="ConfigMap描述"><a href="#ConfigMap描述" class="headerlink" title="ConfigMap描述"></a>ConfigMap描述</h2><p>ConfigMap功能在k8s1.2版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap API给我们提供了向容器中注入配置信息的机制，ConfigMap可以被用来保存单个属性，也可以用来保存整个配置文件或JSON二进制大对象</p>
<h2 id="ConfigMap的创建"><a href="#ConfigMap的创建" class="headerlink" title="ConfigMap的创建"></a>ConfigMap的创建</h2><h3 id="1-使用目录创建"><a href="#1-使用目录创建" class="headerlink" title="1 使用目录创建"></a>1 使用目录创建</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir configmap</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash">cat configmap/game.properties</span></span><br><span class="line">enemies=aliens</span><br><span class="line">lives=3</span><br><span class="line">enemies.cheat=true</span><br><span class="line">enemies.cheat.level=noGoodRotten</span><br><span class="line">secret.code.passphrase=UUDDLRLRBABAS</span><br><span class="line">secret.code.allowed=true</span><br><span class="line">secret.code.lives=30</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat config/ui.properties</span></span><br><span class="line">color.good=purple</span><br><span class="line">color.bad=yellow</span><br><span class="line">allow.textmode=true</span><br><span class="line">how.nice.to.look=fairlyNice</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create configmap game-config --from-file=configmap/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看ConfigMap</span></span><br><span class="line">kubectl get cm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看具体信息</span></span><br><span class="line">kubectl get cm game-config -o yaml</span><br><span class="line">kubecctl describe cm game-config</span><br></pre></td></tr></table></figure>

<p><code>--from-file</code>指定在目录下的所有文件都会被用在ConfigMap里面创建一个键值对，其中：</p>
<ul>
<li><strong>键的名字就是文件名</strong></li>
<li><strong>键的值就是文件的内容</strong></li>
</ul>
<h3 id="2-使用文件创建"><a href="#2-使用文件创建" class="headerlink" title="2 使用文件创建"></a>2 使用文件创建</h3><p>只要指定为一个文件就可以从单个文件中创建ConfigMap</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create configmap game-config-2 --from-file=configmap/game.properties</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get configmaps game-config-2 -o yaml</span></span><br></pre></td></tr></table></figure>

<p><code>--from-file</code>这个参数可以使用多次，可以使用两次分别指定上个实例中的那两个配置文件，效果就跟指定整个目录是一样的</p>
<h3 id="3-使用字面值创建"><a href="#3-使用字面值创建" class="headerlink" title="3 使用字面值创建"></a>3 使用字面值创建</h3><p>使用文字值创建，利用<code>--from-literal</code>参数传递配置信息，该参数可以使用多次，格式如下</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get configmaps special-config -o yaml</span></span><br></pre></td></tr></table></figure>



<h2 id="Pod中使用ConfigMap"><a href="#Pod中使用ConfigMap" class="headerlink" title="Pod中使用ConfigMap"></a>Pod中使用ConfigMap</h2><h3 id="1-使用ConfigMap来替代环境变量"><a href="#1-使用ConfigMap来替代环境变量" class="headerlink" title="1 使用ConfigMap来替代环境变量"></a>1 使用ConfigMap来替代环境变量</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadta:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">env-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">log_level:</span> <span class="string">INFO</span> </span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dapi-test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">comman:</span> [<span class="string">&quot;/bin/sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;env&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_LEVEL_KEY</span></span><br><span class="line">            <span class="attr">valueFrom:</span></span><br><span class="line">              <span class="attr">configMapKeyRef:</span></span><br><span class="line">                <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">                <span class="attr">key:</span> <span class="string">special.how</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_TYPE_KEY</span></span><br><span class="line">            <span class="attr">valueFrom:</span></span><br><span class="line">              <span class="attr">configMapKeyRef:</span></span><br><span class="line">                <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">                <span class="attr">key:</span> <span class="string">special.type</span></span><br><span class="line">        <span class="attr">envFrom:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">configMapRef:</span></span><br><span class="line">              <span class="string">name:env-config</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>



<h3 id="2-用ConfigMap设置命令行参数"><a href="#2-用ConfigMap设置命令行参数" class="headerlink" title="2 用ConfigMap设置命令行参数"></a>2 用ConfigMap设置命令行参数</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dapi-test-pod2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)&#x27;</span>]</span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_LEVEL_KEY</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">special.how</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_TYPE_KEY</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">special.type</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>



<h3 id="3-通过数据卷插件使用ConfigMap"><a href="#3-通过数据卷插件使用ConfigMap" class="headerlink" title="3 通过数据卷插件使用ConfigMap"></a>3 通过数据卷插件使用ConfigMap</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>

<p>在数据卷里面使用个ConfigMap，有不同的选项。最基本的就是将文件填入数据卷，在这个文件中，键就是文件名，键值就是文件内容</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dapi-test-pod3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;cat /etc/config/special.how&#x27;</span>]</span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/config</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">      <span class="attr">configMap:</span></span><br><span class="line">       <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>



<h2 id="ConfigMap的热更新"><a href="#ConfigMap的热更新" class="headerlink" title="ConfigMap的热更新"></a>ConfigMap的热更新</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">log-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">log_level:</span> <span class="string">INFO</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">my-nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/config</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">log-config</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> my-nginx-74f99c7fd8-knsl9 cat /etc/config/log_level</span></span><br><span class="line">INFO</span><br></pre></td></tr></table></figure>

<p><strong>接下来进行热更新，修改ConfigMap，将INFO改成DEBUG</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl edit configmaps log-config</span></span><br></pre></td></tr></table></figure>

<p><strong>查看修改是否成功</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> my-nginx-74f99c7fd8-knsl9 cat /etc/config/log_level</span></span><br><span class="line">DEBUG</span><br></pre></td></tr></table></figure>

<!--!!!特别注意，ConfigMap如果以ENV的方式挂载至容器，修改ConfigMap并不会实现热更新-->

<p><strong>ConfigMap更新后滚动更新Pod</strong></p>
<p>更新ConfigMap目前并不会触发相关Pod的滚动更新，可以通过修改pod annotations的方式强制触发滚动更新</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl patch deployment my-nginx --patch <span class="string">&#x27;&#123;&quot;spec&quot;: &#123;&quot;template&quot;: &#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;: &#123;&quot;version/config&quot;: &quot;20190411&quot;&#125;&#125;&#125;&#125;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure>

<p>这个例子里我们在<code>.spec.template.metadata.annotations</code>中添加<code>version/config</code>，每次通过修改<code>version/config</code>来触发滚动更新</p>
<p>！！！更新ConfigMap后：</p>
<p>使用该ConfigMap挂载的Env不会同步更新</p>
<p>使用该ConfigMap挂载的Volume中的数据需要一段时间（10s左右）才能同步更新</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（17）：secret-秘钥</title>
    <url>/2020/01/07/17_secret/</url>
    <content><![CDATA[<h2 id="Secret存在意义"><a href="#Secret存在意义" class="headerlink" title="Secret存在意义"></a>Secret存在意义</h2><p>Secret解决了密码、token、秘钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者Pod spec中。Secret可以以Volume或者环境变量的方式使用</p>
<p>Secret有三种类型：</p>
<ul>
<li><p><strong><code>Service Account</code>：用来访问Kubernetes API，由Kubernetes自动创建，并且会自动挂载到<code>/run/secrets/kubernetes.io/serviceaccount</code>目录中</strong></p>
</li>
<li><p><strong><code>Opaque</code>：base64编码格式的Secret，用来存储密码、秘钥等</strong></p>
</li>
<li><p><strong><code>kubernetes.io/dockerconfigjson</code>：用来存储私有docker registry的认证信息</strong></p>
</li>
</ul>
<h2 id="Service-Account"><a href="#Service-Account" class="headerlink" title="Service Account"></a>Service Account</h2><p>Service Account用来访问kubernetes API，由kubernetes自动创建，并且会自动挂载到pod的<code>/run/secrets/kubernetes.io/serviceaccount</code>目录中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl run nginx --image nginx</span></span><br><span class="line">deployemnt &quot;nginx&quot; create</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> nginx-xxxx ls /run/secrets/kubernetes.io/service</span></span><br></pre></td></tr></table></figure>

<p>这里会进/bin/sh会发现没有这个目录，因为他没有和kubernetes API进行交互</p>
<p>可以进<code>-n kube-system</code>名称空间的pod看</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pods -n kube-system</span></span><br><span class="line">NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">coredns<span class="literal">-5c98db65d4</span><span class="literal">-gh2qc</span>             <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">coredns<span class="literal">-5c98db65d4</span><span class="literal">-pczm8</span>             <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">etcd<span class="literal">-k8s</span><span class="literal">-master</span>                      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-apiserver</span><span class="literal">-k8s</span><span class="literal">-master</span>            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-controller</span><span class="literal">-manager</span><span class="literal">-k8s</span><span class="literal">-master</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">11</span>         <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-flannel</span><span class="literal">-ds</span><span class="literal">-amd64</span><span class="literal">-2lrvk</span>          <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">6</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-flannel</span><span class="literal">-ds</span><span class="literal">-amd64</span><span class="literal">-bst48</span>          <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-flannel</span><span class="literal">-ds</span><span class="literal">-amd64</span><span class="literal">-jdqq8</span>          <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-proxy</span><span class="literal">-dm5p6</span>                     <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">4</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-proxy</span><span class="literal">-dwdvl</span>                     <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-proxy</span><span class="literal">-qhst5</span>                     <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">5</span>          <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">kube<span class="literal">-scheduler</span><span class="literal">-k8s</span><span class="literal">-master</span>            <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">10</span>         <span class="number">5</span>d6<span class="built_in">h</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl exec kube-proxy-dm5p6 -n kube-system ls /run/secrets/kubernetes.io/serviceaccount</span></span><br><span class="line">ca.crt</span><br><span class="line">namespace</span><br><span class="line">token</span><br></pre></td></tr></table></figure>

<p><strong>Service Account不常用</strong></p>
<h2 id="Opaque-Secret"><a href="#Opaque-Secret" class="headerlink" title="Opaque Secret"></a>Opaque Secret</h2><h3 id="1-创建说明"><a href="#1-创建说明" class="headerlink" title="1 创建说明"></a>1 创建说明</h3><p>Opaque类型的数据是一个map类型，要求value是base64编码格式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> -n <span class="string">&quot;admin&quot;</span> | base64</span></span><br><span class="line">YWRtaW4=</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> -n <span class="string">&quot;1f2d1e2e67df&quot;</span> | base64</span></span><br><span class="line">MWYyZDFlMmU2N2Rm</span><br></pre></td></tr></table></figure>

<p>base64加密只是表面加密，可以用<code>echo -n &quot;YWRtaW4=&quot; | base64 -d</code>**解密</p>
<p><strong>secrets.yaml</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">MWYyZDFlMmU2N2Rm</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">YWRtaW4=</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建</span></span><br><span class="line">[root@k8s-master ~]# kubectl apply -f secrets.yaml </span><br><span class="line">secret/mysecret created</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line">[root@k8s-master ~]# kubectl get secret</span><br><span class="line">NAME                  TYPE                                  DATA   AGE</span><br><span class="line">basic-auth            Opaque                                1      22h</span><br><span class="line">default-token-89jrq   kubernetes.io/service-account-token   3      5d7h</span><br><span class="line">mysecret              Opaque                                2      3s</span><br><span class="line">tls-secret            kubernetes.io/tls                     2      22h</span><br></pre></td></tr></table></figure>

<p><strong>默认情况下，每个namespace都有一个default-token</strong></p>
<h3 id="2-使用方式"><a href="#2-使用方式" class="headerlink" title="2 使用方式"></a>2 使用方式</h3><h4 id="a-将Secret挂载到Volume中"><a href="#a-将Secret挂载到Volume中" class="headerlink" title="a 将Secret挂载到Volume中"></a>a 将Secret挂载到Volume中</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">secret-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secrets</span></span><br><span class="line">    <span class="attr">secret:</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">mysecret</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">db</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secrets</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">&quot;/etc/secrets&quot;</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建</span></span><br><span class="line">[root@k8s-master secret]# kubectl create -f pod.yaml </span><br><span class="line">pod/secret-test created</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看</span></span><br><span class="line">[root@k8s-master secret]# kubectl get pods</span><br><span class="line">NAME          READY   STATUS    RESTARTS   AGE</span><br><span class="line">secret-test   1/1     Running   0          3s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进容器查看</span></span><br><span class="line">[root@k8s-master secret]# kubectl exec -it secret-test -- /bin/sh</span><br><span class="line">/ # cd /etc/secrets/</span><br><span class="line">/etc/secrets # ls</span><br><span class="line">password  username</span><br><span class="line">/etc/secrets # cat *</span><br><span class="line">1f2d1e2e67dfadmin</span><br></pre></td></tr></table></figure>

<p><strong>在创建的时候时候的base64加密，但是在容器中使用的是解密后的数据</strong></p>
<h4 id="b-将Secret导出到环境变量中"><a href="#b-将Secret导出到环境变量中" class="headerlink" title="b 将Secret导出到环境变量中"></a>b 将Secret导出到环境变量中</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span> </span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-deploy</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">pod-deploy</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-1</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TEST_USER</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">username</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TEST_PASSWORD</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">secretKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">password</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">secret</span>]<span class="comment"># kubectl apply -f deploy-env.yaml </span></span><br><span class="line">deployment.extensions/deploy<span class="literal">-test</span> created</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">secret</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE</span><br><span class="line">deploy<span class="literal">-test</span><span class="literal">-869f8f7bc4</span><span class="literal">-d8ltv</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">secret<span class="literal">-test</span>                    <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">secret</span>]<span class="comment"># kubectl exec deploy-test-869f8f7bc4-d8ltv -it -- /bin/sh</span></span><br><span class="line">/ <span class="comment"># echo $PASSWORD $USERNAME</span></span><br><span class="line"><span class="number">1</span>f2d1e2e67df admin</span><br></pre></td></tr></table></figure>



<h2 id="kubernetes-io-dockerconfigjson"><a href="#kubernetes-io-dockerconfigjson" class="headerlink" title="kubernetes.io/dockerconfigjson"></a>kubernetes.io/dockerconfigjson</h2><p>使用<code>kubectl</code>创建docker registry认证的secret</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create secret docker-registry myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL</span></span><br><span class="line">secret &quot;myregistrykey&quot; created.</span><br></pre></td></tr></table></figure>

<p>在创建Pod的时候，通过<code>imagePullSecrets</code>来引用刚创建的<code>myregistrykey</code></p>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create secret docker-registry myregistrykey --docker-server=hub.test.com --docker-username=admin --docker-password=Harbor12345 --docker-email=admin@123.com</span></span><br></pre></td></tr></table></figure>

<p><strong>设置harbor仓库为私有</strong></p>
<p><img src="/assets/image-20200203004924734.png" alt="image-20200203004924734"></p>
<p><strong>创建pod.yaml</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">foo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">foo</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/private/myapp:v1</span></span><br><span class="line">  <span class="attr">imagePullSecrets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myregistrykey</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">registry</span>]<span class="comment"># kubectl create -f pod.yaml </span></span><br><span class="line">pod/pod<span class="literal">-registry</span><span class="literal">-test</span> created</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（18）：volume-卷</title>
    <url>/2020/01/07/18_volume/</url>
    <content><![CDATA[<p> 容器磁盘上的文件的声明周期是短暂的，这就使得容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，<code>kubelet</code>会重启它，但是容器中的文件将丢失–容器以干净的状态（镜像最初的状态）重新启动。其次，在<code>pod</code>中同时运行多个容器时，这些容器之间通常需要共享文件。kubernetes中的<code>volume</code>抽象就很好的解决了这些问题</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>kubernetes中的卷有明确的寿命–与封装它的pod相同。所以，卷的生命比pod中的所有容器都长，当这个容器重启时数据仍然得以保存。当然，当pod不再存在时，卷也将不复存在。也许更重要的是，kubernetes支持多种类型的卷，pod可以同时使用任意数量的卷</p>
<h2 id="卷的类型"><a href="#卷的类型" class="headerlink" title="卷的类型"></a>卷的类型</h2><p>kubernetes支持以下类型的卷：</p>
<p><img src="/assets/image-20200203013115393.png" alt="image-20200203013115393"></p>
<h2 id="emptyDir"><a href="#emptyDir" class="headerlink" title="emptyDir"></a>emptyDir</h2><p>当pod被分配给节点时，首先创建<code>emptyDir</code>卷，并且只要该Pod在该节点上运行，该卷就会存在。正如卷的名字所述，它最初是空的。Pod中的容器可以读取和写入<code>emptyDir</code>卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当处于任何原因从节点中删除Pod时，<code>emptyDir</code>中的数据将被永久删除。</p>
<!--注意：容器崩溃不会从节点中移除Pod，因此emptyDir卷中的数据在容器崩溃时是安全的-->

<p><code>emptyDir</code>的用法：</p>
<ul>
<li><strong>暂存空间，例如用于基于磁盘的合并排序</strong></li>
<li><strong>用作长时间计算崩溃恢复时的检查点</strong></li>
<li><strong>Web服务器容器提供数据时，保存内容管理器容器提取的文件</strong></li>
</ul>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-vol</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">c1</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">c2</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;sleep 600&#x27;</span>]</span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/html</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html-volume</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># kubectl apply -f pod.yaml </span></span><br><span class="line">pod/pod<span class="literal">-vol</span> created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod<span class="literal">-registry</span><span class="literal">-test</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">53</span>m</span><br><span class="line">pod<span class="literal">-vol</span>             <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">pod<span class="literal">-registry</span><span class="literal">-test</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">53</span>m   <span class="number">10.244</span>.<span class="number">2.189</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod<span class="literal">-vol</span>             <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">0</span>          <span class="number">15</span>s   <span class="number">10.244</span>.<span class="number">2.190</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># curl 10.244.2.190 </span></span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;<span class="number">403</span> Forbidden&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body bgcolor=<span class="string">&quot;white&quot;</span>&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;<span class="number">403</span> Forbidden&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/<span class="number">1.12</span>.<span class="number">2</span>&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># kubectl exec -it pod-vol -c c2 -- /bin/sh</span></span><br><span class="line">/html <span class="comment"># date &gt; index.html</span></span><br><span class="line">/html <span class="comment"># exit</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># curl 10.244.2.190 </span></span><br><span class="line">Sun Feb  <span class="number">2</span> <span class="number">17</span>:<span class="number">56</span>:<span class="number">42</span> UTC <span class="number">2020</span></span><br></pre></td></tr></table></figure>



<h2 id="hostPath"><a href="#hostPath" class="headerlink" title="hostPath"></a>hostPath</h2><p><code>hostPath</code>卷将主机节点的文件系统中的文件或目录挂载到集群中</p>
<p><code>hostPath</code>用途：</p>
<ul>
<li><strong>运行需要访问Docker内部的容器；使用<code>/var/lib/docker</code>的<code>hostPath</code></strong></li>
<li><strong>在容器中运行cAdvisor；使用<code>/dev/cgroups</code>的<code>hostPath</code></strong></li>
</ul>
<p>CAdvisor：谷歌的一个docker监控服务</p>
<p>除了所需的<code>path</code>属性之外，用户还可以为<code>hostPath</code>指定<code>type</code></p>
<p><img src="/assets/image-20200203020648565.png" alt="image-20200203020648565"></p>
<p>使用这种卷类型时请注意：</p>
<ul>
<li><strong>由于每个节点上的文件都不通，具有相同配置（例如从podTemplate创建的）的Pod在不同节点上的行为可能会有所不同</strong></li>
<li><strong>当Kubernetes按照计划添加资源感知调度时，将无法考虑<code>hostPath</code>使用的资源</strong><ul>
<li><strong>在底层主机上创建的文件或目录只能由root写入。需要在特权容器中以root身份运行进程，或修改主机上的文件权限以便写入<code>hostPath</code>卷</strong></li>
</ul>
</li>
</ul>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">c1</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/test</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="comment"># directory location on host</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/data</span></span><br><span class="line">      <span class="comment"># this field is optional</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">Directory</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># kubectl create -f pod-hostpath.yaml </span></span><br><span class="line">pod/pod created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># kubectl get pods  -o wide</span></span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">pod                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">80</span>s   <span class="number">10.244</span>.<span class="number">2.191</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># curl 10.244.2.191</span></span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;<span class="number">403</span> Forbidden&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">&lt;body bgcolor=<span class="string">&quot;white&quot;</span>&gt;</span><br><span class="line">&lt;center&gt;&lt;h1&gt;<span class="number">403</span> Forbidden&lt;/h1&gt;&lt;/center&gt;</span><br><span class="line">&lt;hr&gt;&lt;center&gt;nginx/<span class="number">1.12</span>.<span class="number">2</span>&lt;/center&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"><span class="comment"># 此时由于当前node02节点的目录为空，所以curl访问失败</span></span><br><span class="line"><span class="comment"># 在node02节点新建index.html文件</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">node02</span> <span class="type">test</span>]<span class="comment"># echo hello &gt; /opt/test/index.html</span></span><br><span class="line"><span class="comment"># 访问该pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">volume</span>]<span class="comment"># curl 10.244.2.191</span></span><br><span class="line">hello</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（19）：PV、PVC-持久化存储</title>
    <url>/2020/01/07/19_PV-PVC/</url>
    <content><![CDATA[<p>个人理解：PVC绑定PV</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p><strong><code>PersistentVolume</code>（PV）持久卷</strong></p>
<p>是由管理员设置的存储，它是集群的一部分。就像节点是集群中的资源一样，PV也是集群中的资源。PV是Volume之类的卷插件，但是具有独立于使用PV的Pod的生命周期。此API对向包含存储实现的细节，即NFS、ISCSI或特定于云供应商的存储系统</p>
<p><strong><code>PersistentVolumeClaim</code>(PVC)持久卷声明</strong></p>
<p>是用户存储的请求。他与Pod相似。Pod消耗节点资源，PVC消耗PV资源。Pod可以请求特定级别的资源（CPU和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或只读多次模式挂载）</p>
<p>静态<strong>PV</strong></p>
<p>集群管理员创建一些PV。它们带有可供集群用户使用的实际存储的细节。它们存在于kubernetes API中，可用于消费</p>
<p><strong>动态</strong></p>
<p>当管理员创建的静态PV都不匹配用户的<code>PersistentVolumeClaim</code>时，集群可能会尝试动态的为PVC创建卷。此配置基于<code>StorageClasses</code>：PVC必须请求[存储类]，并且管理员必须创建并配置该类才能进行动态创建。生米功能该类为<code>&quot;&quot;</code>可以有效地禁用其动态配置</p>
<p>要启用基于存储级别的动态存储配置，集群管理员需要启用API server的<code>DefaultStorageClass</code>[准入控制器]。例如，通过确保<code>DefaultStorageClass</code>位于API server组件的<code>--admission-control</code>标志，使用逗号分隔的有序值列表中，可以完成此操作</p>
<p><strong>绑定</strong></p>
<p>master中的控制环路监视新的PVC，寻找匹配的PV（如果可能），并将它们绑定在一起。如果为新的PVC动态调配PV，则该环路将始终将该PV绑定到PVC。否则，用户总会得到他们所请求的存储，但是容量可能超出要求的数量。一旦PV和PVC绑定后，`PersistentVolumeCalaim·绑定是排他性的，不管它们是如何绑定的。PVC跟PV绑定是一对一的映射。</p>
<h2 id="持久化卷声明的保护"><a href="#持久化卷声明的保护" class="headerlink" title="持久化卷声明的保护"></a>持久化卷声明的保护</h2><p>PVC保护的目的是确保由Pod正在使用的PVC不会从系统中移除，因为如果被移除的话可能会导致数据丢失</p>
<!--注意：当pod状态为‘pending’并且pod已经分配给节点或pod为‘running’状态时，PPVC处于活动状态-->

<p>当启用PVC保护alpha功能时，如果用户删除了一个pod正在使用的PVC，则该PVC不会被立刻删除。PVC的删除将被推迟，直到PVC不再被任何Pod使用。</p>
<h2 id="持久化卷类型"><a href="#持久化卷类型" class="headerlink" title="持久化卷类型"></a>持久化卷类型</h2><p><code>PersistentVolume</code>类型以插件形式实现。kubernetes目前支持以下插件类型：</p>
<p><img src="/assets/image-20200203181947841.png" alt="image-20200203181947841"></p>
<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv-nfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">mountOptions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hard</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nfsvers=4.1</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.32</span></span><br></pre></td></tr></table></figure>



<h2 id="PV访问模式"><a href="#PV访问模式" class="headerlink" title="PV访问模式"></a>PV访问模式</h2><p><code>PersistentVolume</code>可以以资源提供者支持的任何方式挂载到主机上。如下表所示，供应商具有不同的功能，每个PV的访问模式都将被设置为改卷支持的特定模式。例如，NFS可以支持多个读/写客户端，但特定的NFS PV可能以制度方式导出到服务器上。每个PV都有一套自己的用来描述特定功能的访问模式</p>
<ul>
<li><strong><code>ReadWriteOnce</code>：该卷可以被单个节点以读/写模式挂载</strong></li>
<li><strong><code>ReadOnlyMany</code>：改卷可以被多个节点以只读模式挂载</strong></li>
<li><strong><code>ReadWriteMany</code>：该卷可以被多个节点以读/写模式挂载</strong></li>
</ul>
<p>在命令行中，访问模式缩写为：</p>
<ul>
<li><strong><code>RWO</code>-<code>ReadWriteOnly</code></strong></li>
<li><strong><code>ROX</code>-<code>ReadOnlyMany</code></strong></li>
<li><strong><code>RWX</code>-<code>ReadWriteMany</code></strong></li>
</ul>
<!--一个卷一次只能使用一种访问模式挂载，即使它支持很多访问模式。例如：GCEPersistentDisk可以由单个节点作为ReadWriteOnce模式挂载，或由多个节点以ReadOnlyMany模式挂载，但不能同时挂载-->

<p><img src="/assets/image-20200203184006744.png" alt="image-20200203184006744"></p>
<p><img src="/assets/image-20200203184132638.png" alt="image-20200203184132638"></p>
<h2 id="回收策略"><a href="#回收策略" class="headerlink" title="回收策略"></a>回收策略</h2><ul>
<li><strong>Retain(保留)–手动回收</strong></li>
<li><strong>Recycle(回收)–基本擦除(<code>rm -rf /thevolume/*</code>)</strong></li>
<li><strong>Delete(删除)–关联的存储资产(例如AWS EBS、GCE PD、Azure Disk和OpenStack Cinder卷)将被删除</strong></li>
</ul>
<p>当前，只有NFS和HostPath支持策略。AWS EBS、GCE PD、Azure Disk和Cinder卷支持删除策略</p>
<h2 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h2><p>卷可以处于以下的某种状态：</p>
<ul>
<li>Available(可用)–一块空闲资源还没有被任何声明绑定</li>
<li>Bound(已绑定)–卷已经被声明绑定</li>
<li>Released(已释放)–声明被删除，但是资源还未被集群重新声明</li>
<li>Failed(失败)–该卷的自动回收失败</li>
</ul>
<p>命令行显示绑定到PV的PVC的名称</p>
<h2 id="持久化演示说明-NFS"><a href="#持久化演示说明-NFS" class="headerlink" title="持久化演示说明-NFS"></a>持久化演示说明-NFS</h2><h3 id="1-安装NFS"><a href="#1-安装NFS" class="headerlink" title="1 安装NFS"></a>1 安装NFS</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y nfs-common nfs-utils rpcbind</span><br><span class="line">mkdir /nfsdata</span><br><span class="line">chmod 666 /nfsdata</span><br><span class="line">chown nfsnobody /nfsdata</span><br><span class="line">cat /etc/exports</span><br><span class="line">/nfsdata *(rw,no_root_squash,no_all_squash,sync)</span><br><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl start nfs</span><br></pre></td></tr></table></figure>

<h3 id="2-部署PV"><a href="#2-部署PV" class="headerlink" title="2 部署PV"></a>2 部署PV</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersisentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfspv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfs</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.32</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfspv2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfsv2</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/zfspool/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.32</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfspv3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadOnlyMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfs</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/zfspool/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.32</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfspv4</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfs</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/zfspool/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.32</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pv</span></span><br><span class="line">NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE</span><br><span class="line">nfspv1   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Recycle          Available           nfs                     <span class="number">20</span><span class="built_in">h</span></span><br><span class="line">nfspv2   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Available           nfsv2                   <span class="number">20</span><span class="built_in">h</span></span><br><span class="line">nfspv3   <span class="number">10</span><span class="built_in">Gi</span>       ROX            Retain           Available           nfs                     <span class="number">2</span>m24s</span><br><span class="line">nfspv4   <span class="number">10</span><span class="built_in">Gi</span>       RWX            Retain           Available           nfs                     <span class="number">58</span>s</span><br></pre></td></tr></table></figure>

<h3 id="3-创建服务并使用PVC"><a href="#3-创建服务并使用PVC" class="headerlink" title="3 创建服务并使用PVC"></a>3 创建服务并使用PVC</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">none</span>    <span class="comment"># 想要建立一个StatefulSet，必须先建立一个无头服务</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&quot;nginx&quot;</span>    <span class="comment"># 使用的svc名称</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> [<span class="string">&quot;ReadWriteOnce&quot;</span>]</span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">&quot;nfs&quot;</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl apply -f pod.yaml </span></span><br><span class="line">service/nginx created</span><br><span class="line">statefulset.apps/web created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get svc</span></span><br><span class="line">NAME         <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   <span class="number">10.96</span>.<span class="number">0.1</span>       &lt;none&gt;        <span class="number">443</span>/TCP   <span class="number">7</span>d</span><br><span class="line">nginx        ClusterIP   <span class="number">10.102</span>.<span class="number">85.247</span>   &lt;none&gt;        <span class="number">80</span>/TCP    <span class="number">9</span>s</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">38</span><span class="built_in">h</span></span><br><span class="line">pod<span class="literal">-registry</span><span class="literal">-test</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">39</span><span class="built_in">h</span></span><br><span class="line">pod<span class="literal">-vol</span>             <span class="number">2</span>/<span class="number">2</span>     Running   <span class="number">231</span>        <span class="number">38</span><span class="built_in">h</span></span><br><span class="line">web<span class="literal">-0</span>               <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>s</span><br><span class="line">web<span class="literal">-1</span>               <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">1</span>s</span><br><span class="line"><span class="comment">## replicas设置的是3，但是在第2个的时候就卡死了，查看一下web-1卡在哪里</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl describe pod web-1</span></span><br><span class="line">Name:           web<span class="literal">-1</span></span><br><span class="line">Namespace:      default</span><br><span class="line">Priority:       <span class="number">0</span></span><br><span class="line">Node:           &lt;none&gt;</span><br><span class="line">Labels:         app=nginx</span><br><span class="line">                controller<span class="literal">-revision</span><span class="literal">-hash</span>=web<span class="literal">-59c46fbcb8</span></span><br><span class="line">                statefulset.kubernetes.io/pod<span class="literal">-name</span>=web<span class="literal">-1</span></span><br><span class="line">Annotations:    &lt;none&gt;</span><br><span class="line">Status:         Pending</span><br><span class="line">IP:             </span><br><span class="line">Controlled By:  StatefulSet/web</span><br><span class="line">Containers:</span><br><span class="line">  nginx:</span><br><span class="line">    Image:        hub.test.com/library/myapp:v1</span><br><span class="line">    Port:         <span class="number">80</span>/TCP</span><br><span class="line">    Host Port:    <span class="number">0</span>/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /usr/share/nginx/html from www (rw)</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default<span class="literal">-token</span><span class="literal">-89jrq</span> (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  <span class="built_in">Type</span>           Status</span><br><span class="line">  PodScheduled   False </span><br><span class="line">Volumes:</span><br><span class="line">  www:</span><br><span class="line">    <span class="built_in">Type</span>:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim <span class="keyword">in</span> the same namespace)</span><br><span class="line">    ClaimName:  www<span class="literal">-web</span><span class="literal">-1</span></span><br><span class="line">    ReadOnly:   false</span><br><span class="line">  default<span class="literal">-token</span><span class="literal">-89jrq</span>:</span><br><span class="line">    <span class="built_in">Type</span>:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default<span class="literal">-token</span><span class="literal">-89jrq</span></span><br><span class="line">    Optional:    false</span><br><span class="line">QoS <span class="class"><span class="keyword">Class</span>:       <span class="title">BestEffort</span></span></span><br><span class="line"><span class="class"><span class="title">Node</span>-<span class="title">Selectors</span>:  &lt;<span class="title">none</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">Tolerations</span>:     <span class="title">node</span>.<span class="title">kubernetes</span>.<span class="title">io</span>/<span class="title">not</span>-<span class="title">ready</span>:<span class="title">NoExecute</span> <span class="title">for</span> 300<span class="title">s</span></span></span><br><span class="line"><span class="class">                 <span class="title">node</span>.<span class="title">kubernetes</span>.<span class="title">io</span>/<span class="title">unreachable</span>:<span class="title">NoExecute</span> <span class="title">for</span> 300<span class="title">s</span></span></span><br><span class="line"><span class="class"><span class="title">Events</span>:</span></span><br><span class="line"><span class="class">  <span class="title">Type</span>     <span class="title">Reason</span>            <span class="title">Age</span>                <span class="title">From</span>               <span class="title">Message</span></span></span><br><span class="line"><span class="class">  ----     ------            ----               ----               -------</span></span><br><span class="line"><span class="class">  <span class="title">Warning</span>  <span class="title">FailedScheduling</span>  43<span class="title">s</span> (<span class="title">x2</span> <span class="title">over</span> 43<span class="title">s</span>)  <span class="title">default</span>-<span class="title">scheduler</span>  <span class="title">pod</span> <span class="title">has</span> <span class="title">unbound</span> <span class="title">immediate</span> <span class="title">PersistentVolumeClaims</span> (<span class="title">repeated</span> 2 <span class="title">times</span>)</span></span><br><span class="line"><span class="class">## 发现没有<span class="title">volume</span>绑定，查看<span class="title">pv</span>，发现只有一个<span class="title">pv</span>符合要求</span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# <span class="title">kubectl</span> <span class="title">get</span> <span class="title">pv</span></span></span><br><span class="line"><span class="class"><span class="title">NAME</span>     <span class="title">CAPACITY</span>   <span class="title">ACCESS</span> <span class="title">MODES</span>   <span class="title">RECLAIM</span> <span class="title">POLICY</span>   <span class="title">STATUS</span>      <span class="title">CLAIM</span>               <span class="title">STORAGECLASS</span>   <span class="title">REASON</span>   <span class="title">AGE</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv1</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">Recycle</span>          <span class="title">Bound</span>       <span class="title">default</span>/<span class="title">www</span>-<span class="title">web</span>-0   <span class="title">nfs</span>                     20<span class="title">h</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv2</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">Retain</span>           <span class="title">Available</span>                       <span class="title">nfsv2</span>                   20<span class="title">h</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv3</span>   10<span class="title">Gi</span>       <span class="title">ROX</span>            <span class="title">Retain</span>           <span class="title">Available</span>                       <span class="title">nfs</span>                     11<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv4</span>   10<span class="title">Gi</span>       <span class="title">RWX</span>            <span class="title">Retain</span>           <span class="title">Available</span>                       <span class="title">nfs</span>                     9<span class="title">m39s</span></span></span><br><span class="line"><span class="class">## 创建多2个<span class="title">PV</span>，模板使用刚刚的模板</span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# <span class="title">cat</span> <span class="title">pv3</span>.<span class="title">yaml</span> </span></span><br><span class="line"><span class="class"><span class="title">apiVersion</span>: <span class="title">v1</span></span></span><br><span class="line"><span class="class"><span class="title">kind</span>: <span class="title">PersistentVolume</span></span></span><br><span class="line"><span class="class"><span class="title">metadata</span>:</span></span><br><span class="line"><span class="class">  <span class="title">name</span>: <span class="title">nfspv5</span></span></span><br><span class="line"><span class="class"><span class="title">spec</span>:</span></span><br><span class="line"><span class="class">  <span class="title">capacity</span>:</span></span><br><span class="line"><span class="class">    <span class="title">storage</span>: 10<span class="title">Gi</span></span></span><br><span class="line"><span class="class">  <span class="title">accessModes</span>:</span></span><br><span class="line"><span class="class">  - <span class="title">ReadWriteOnce</span></span></span><br><span class="line"><span class="class">  <span class="title">persistentVolumeReclaimPolicy</span>: <span class="title">Retain</span></span></span><br><span class="line"><span class="class">  <span class="title">storageClassName</span>: <span class="title">nfs</span></span></span><br><span class="line"><span class="class">  <span class="title">nfs</span>:</span></span><br><span class="line"><span class="class">    <span class="title">path</span>: /<span class="title">zfspool</span>/<span class="title">nfs</span></span></span><br><span class="line"><span class="class">    <span class="title">server</span>: 192.168.128.32</span></span><br><span class="line"><span class="class">---</span></span><br><span class="line"><span class="class"><span class="title">apiVersion</span>: <span class="title">v1</span></span></span><br><span class="line"><span class="class"><span class="title">kind</span>: <span class="title">PersistentVolume</span></span></span><br><span class="line"><span class="class"><span class="title">metadata</span>:</span></span><br><span class="line"><span class="class">  <span class="title">name</span>: <span class="title">nfspv6</span></span></span><br><span class="line"><span class="class"><span class="title">spec</span>:</span></span><br><span class="line"><span class="class">  <span class="title">capacity</span>:</span></span><br><span class="line"><span class="class">    <span class="title">storage</span>: 10<span class="title">Gi</span></span></span><br><span class="line"><span class="class">  <span class="title">accessModes</span>:</span></span><br><span class="line"><span class="class">  - <span class="title">ReadWriteOnce</span></span></span><br><span class="line"><span class="class">  <span class="title">persistentVolumeReclaimPolicy</span>: <span class="title">Retain</span></span></span><br><span class="line"><span class="class">  <span class="title">storageClassName</span>: <span class="title">nfs</span></span></span><br><span class="line"><span class="class">  <span class="title">nfs</span>:</span></span><br><span class="line"><span class="class">    <span class="title">path</span>: /<span class="title">zfspool</span>/<span class="title">nfs</span></span></span><br><span class="line"><span class="class">    <span class="title">server</span>: 192.168.128.32</span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# <span class="title">kubectl</span> <span class="title">create</span> -<span class="title">f</span> <span class="title">pv3</span>.<span class="title">yaml</span> </span></span><br><span class="line"><span class="class"><span class="title">persistentvolume</span>/<span class="title">nfspv5</span> <span class="title">created</span></span></span><br><span class="line"><span class="class"><span class="title">persistentvolume</span>/<span class="title">nfspv6</span> <span class="title">created</span></span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# <span class="title">kubectl</span> <span class="title">get</span> <span class="title">pods</span></span></span><br><span class="line"><span class="class"><span class="title">NAME</span>    <span class="title">READY</span>   <span class="title">STATUS</span>    <span class="title">RESTARTS</span>   <span class="title">AGE</span></span></span><br><span class="line"><span class="class"><span class="title">web</span>-0   1/1     <span class="title">Running</span>   0          9<span class="title">s</span></span></span><br><span class="line"><span class="class"><span class="title">web</span>-1   1/1     <span class="title">Running</span>   0          7<span class="title">s</span></span></span><br><span class="line"><span class="class"><span class="title">web</span>-2   1/1     <span class="title">Running</span>   0          5<span class="title">s</span></span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# <span class="title">kubectl</span> <span class="title">get</span> <span class="title">pv</span></span></span><br><span class="line"><span class="class"><span class="title">NAME</span>     <span class="title">CAPACITY</span>   <span class="title">ACCESS</span> <span class="title">MODES</span>   <span class="title">RECLAIM</span> <span class="title">POLICY</span>   <span class="title">STATUS</span>      <span class="title">CLAIM</span>               <span class="title">STORAGECLASS</span>   <span class="title">REASON</span>   <span class="title">AGE</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv1</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">Recycle</span>          <span class="title">Bound</span>       <span class="title">default</span>/<span class="title">www</span>-<span class="title">web</span>-0   <span class="title">nfs</span>                     20<span class="title">h</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv2</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">Retain</span>           <span class="title">Available</span>                       <span class="title">nfsv2</span>                   20<span class="title">h</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv3</span>   10<span class="title">Gi</span>       <span class="title">ROX</span>            <span class="title">Retain</span>           <span class="title">Available</span>                       <span class="title">nfs</span>                     34<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv4</span>   10<span class="title">Gi</span>       <span class="title">RWX</span>            <span class="title">Retain</span>           <span class="title">Available</span>                       <span class="title">nfs</span>                     33<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv5</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">Retain</span>           <span class="title">Bound</span>       <span class="title">default</span>/<span class="title">www</span>-<span class="title">web</span>-2   <span class="title">nfs</span>                     21<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">nfspv6</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">Retain</span>           <span class="title">Bound</span>       <span class="title">default</span>/<span class="title">www</span>-<span class="title">web</span>-1   <span class="title">nfs</span>                     21<span class="title">m</span></span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# <span class="title">kubectl</span> <span class="title">get</span> <span class="title">pvc</span></span></span><br><span class="line"><span class="class"><span class="title">NAME</span>        <span class="title">STATUS</span>   <span class="title">VOLUME</span>   <span class="title">CAPACITY</span>   <span class="title">ACCESS</span> <span class="title">MODES</span>   <span class="title">STORAGECLASS</span>   <span class="title">AGE</span></span></span><br><span class="line"><span class="class"><span class="title">www</span>-<span class="title">web</span>-0   <span class="title">Bound</span>    <span class="title">nfspv1</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">nfs</span>            57<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">www</span>-<span class="title">web</span>-1   <span class="title">Bound</span>    <span class="title">nfspv6</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">nfs</span>            57<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">www</span>-<span class="title">web</span>-2   <span class="title">Bound</span>    <span class="title">nfspv5</span>   10<span class="title">Gi</span>       <span class="title">RWO</span>            <span class="title">nfs</span>            46<span class="title">m</span></span></span><br><span class="line"><span class="class">[<span class="title">root</span>@<span class="title">k8s</span>-<span class="title">master</span> <span class="title">pv</span>]# </span></span><br></pre></td></tr></table></figure>

<p>查看pod的详细信息，验证能否访问，需要先在nfs上有index.html文件</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pod -o wide</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE     IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">web<span class="literal">-0</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m23s   <span class="number">10.244</span>.<span class="number">2.197</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web<span class="literal">-1</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m21s   <span class="number">10.244</span>.<span class="number">1.115</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m19s   <span class="number">10.244</span>.<span class="number">2.198</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">/nfs<span class="comment"># echo `date`&gt;index.html</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># curl 10.244.2.197</span></span><br><span class="line">Tue Feb <span class="number">4</span> <span class="number">17</span>:<span class="number">10</span>:<span class="number">32</span> CST <span class="number">2020</span></span><br></pre></td></tr></table></figure>

<p>删除web-0的pod，再次查看</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl delete pod web-0</span></span><br><span class="line">pod <span class="string">&quot;web-0&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">web<span class="literal">-0</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">web<span class="literal">-1</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span>m</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">web<span class="literal">-0</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">8</span>s    <span class="number">10.244</span>.<span class="number">2.199</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web<span class="literal">-1</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span>m   <span class="number">10.244</span>.<span class="number">1.115</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">12</span>m   <span class="number">10.244</span>.<span class="number">2.198</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># curl  10.244.2.199</span></span><br><span class="line">Tue Feb <span class="number">4</span> <span class="number">17</span>:<span class="number">10</span>:<span class="number">32</span> CST <span class="number">2020</span></span><br></pre></td></tr></table></figure>

<p>会创建一个相同名称的pod</p>
<h2 id="关于StatefulSet"><a href="#关于StatefulSet" class="headerlink" title="关于StatefulSet"></a>关于StatefulSet</h2><ul>
<li><strong>匹配Pod name（网络标识）的模式为：(statefulSet名称)-(序号)，比如上面的示例：web-0，web-1，web-2</strong></li>
<li><strong>StatefulSet为每个Pod副本创建了一个DNS域名，这个域名的格式为：$(podname).(headless  server name)，也就是意味着服务间是通过Pod域名来通信而非Pod IP，因为当Pod所在节点发生故障时，Pod会被漂移到其他节点上，Pod IP会发生变化，但是Pod与敏感不会有变化</strong></li>
<li><strong>StatefulSet使用Headless服务来控制Pod的域名，这个域名的FQDN为：(servicename).(namespace).svc.cluster.local，其中，”cluster.local”指的是集群的域名</strong></li>
<li><strong>根据volumeClaimTemplates，为每个Pod创建创建一个PVC，PVC的命名规则为：(volumeClaimTemplates.name)-(pod_name)，比如上面的volumeMounts.name=www，Pod Name=web-[0-2]，因此创建出来的PVC是www-web-0、www-web-1、www-web-2</strong></li>
<li><strong>删除Pod不会删除其PVC，手动删除PVC将自动释放PV</strong></li>
</ul>
<p>StatefulSet的启停顺序：</p>
<ul>
<li>有序部署：部署StatefulSet时，如果有多个Pod副本，他们会被顺序的创建（从0到N-1），并且在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态</li>
<li>有序删除：当Pod被删除时，他们被终止的顺序是从N-1到0</li>
<li>有序扩展：当对Pod执行扩展操作时，与部署一样，它前面的Pod必须都处于Running和Ready状态。</li>
</ul>
<p>StatefulSet使用场景：</p>
<ul>
<li>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现。</li>
<li>稳定的网络标识符，即Pod重新调度后其PodName和HostName不变</li>
<li>有序部署，有序扩展，基于init Container来实现</li>
<li>有序收缩</li>
</ul>
<h3 id="通过DNS访问：示例"><a href="#通过DNS访问：示例" class="headerlink" title="通过DNS访问：示例"></a>通过DNS访问：示例</h3><p>新建pod.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br></pre></td></tr></table></figure>

<p>创建pod</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod.yaml </span></span><br><span class="line">pod/myapp created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">myapp   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">web<span class="literal">-0</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">40</span>m</span><br><span class="line">web<span class="literal">-1</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">40</span>m</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">40</span>m</span><br></pre></td></tr></table></figure>

<p>通过此pod访问web-0</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl exec -it myapp -- /bin/sh</span></span><br><span class="line">/ <span class="comment"># ping web-0.nginx</span></span><br><span class="line">PING web<span class="literal">-0</span>.nginx (<span class="number">10.244</span>.<span class="number">2.200</span>): <span class="number">56</span> <span class="keyword">data</span> bytes</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">10.244</span>.<span class="number">2.200</span>: seq=<span class="number">0</span> ttl=<span class="number">64</span> time=<span class="number">0.114</span> ms</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">10.244</span>.<span class="number">2.200</span>: seq=<span class="number">1</span> ttl=<span class="number">64</span> time=<span class="number">0.085</span> ms</span><br><span class="line">^C</span><br><span class="line">--- web<span class="literal">-0</span>.nginx ping statistics ---</span><br><span class="line"><span class="number">2</span> packets transmitted, <span class="number">2</span> packets received, <span class="number">0</span>% packet loss</span><br><span class="line">round<span class="literal">-trip</span> min/avg/max = <span class="number">0.085</span>/<span class="number">0.099</span>/<span class="number">0.114</span> ms</span><br></pre></td></tr></table></figure>

<p>删除web-0之后，再次访问</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">/ <span class="comment"># exit</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl delete pod web-0</span></span><br><span class="line">pod <span class="string">&quot;web-0&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">myapp   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">2</span>m34s</span><br><span class="line">web<span class="literal">-0</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">web<span class="literal">-1</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">43</span>m</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">43</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl exec -it myapp -- /bin/sh</span></span><br><span class="line">/ <span class="comment"># ping web-0.nginx</span></span><br><span class="line">PING web<span class="literal">-0</span>.nginx (<span class="number">10.244</span>.<span class="number">2.203</span>): <span class="number">56</span> <span class="keyword">data</span> bytes</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">10.244</span>.<span class="number">2.203</span>: seq=<span class="number">0</span> ttl=<span class="number">64</span> time=<span class="number">0.085</span> ms</span><br><span class="line"><span class="number">64</span> bytes from <span class="number">10.244</span>.<span class="number">2.203</span>: seq=<span class="number">1</span> ttl=<span class="number">64</span> time=<span class="number">0.113</span> ms</span><br><span class="line">^C</span><br><span class="line">--- web<span class="literal">-0</span>.nginx ping statistics ---</span><br><span class="line"><span class="number">2</span> packets transmitted, <span class="number">2</span> packets received, <span class="number">0</span>% packet loss</span><br><span class="line">round<span class="literal">-trip</span> min/avg/max = <span class="number">0.085</span>/<span class="number">0.099</span>/<span class="number">0.113</span> ms</span><br></pre></td></tr></table></figure>



<h2 id="删除PV与PVC的绑定"><a href="#删除PV与PVC的绑定" class="headerlink" title="删除PV与PVC的绑定"></a>删除PV与PVC的绑定</h2><p>查看pod、PV、PVC</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">myapp   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">31</span>m</span><br><span class="line">web<span class="literal">-0</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">29</span>m</span><br><span class="line">web<span class="literal">-1</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">72</span>m</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">72</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pv</span></span><br><span class="line">NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   REASON   AGE</span><br><span class="line">nfspv1   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Recycle          Bound       default/www<span class="literal">-web</span><span class="literal">-0</span>   nfs                     <span class="number">22</span><span class="built_in">h</span></span><br><span class="line">nfspv2   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Available                       nfsv2                   <span class="number">22</span><span class="built_in">h</span></span><br><span class="line">nfspv3   <span class="number">10</span><span class="built_in">Gi</span>       ROX            Retain           Available                       nfs                     <span class="number">121</span>m</span><br><span class="line">nfspv4   <span class="number">10</span><span class="built_in">Gi</span>       RWX            Retain           Available                       nfs                     <span class="number">119</span>m</span><br><span class="line">nfspv5   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Bound       default/www<span class="literal">-web</span><span class="literal">-2</span>   nfs                     <span class="number">107</span>m</span><br><span class="line">nfspv6   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Bound       default/www<span class="literal">-web</span><span class="literal">-1</span>   nfs                     <span class="number">107</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pvc</span></span><br><span class="line">NAME        STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">www<span class="literal">-web</span><span class="literal">-0</span>   Bound    nfspv1   <span class="number">10</span><span class="built_in">Gi</span>       RWO            nfs            <span class="number">112</span>m</span><br><span class="line">www<span class="literal">-web</span><span class="literal">-1</span>   Bound    nfspv6   <span class="number">10</span><span class="built_in">Gi</span>       RWO            nfs            <span class="number">112</span>m</span><br><span class="line">www<span class="literal">-web</span><span class="literal">-2</span>   Bound    nfspv5   <span class="number">10</span><span class="built_in">Gi</span>       RWO            nfs            <span class="number">102</span>m</span><br></pre></td></tr></table></figure>

<p>删除StatefulSet</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl delete -f pod.yaml </span></span><br><span class="line">service <span class="string">&quot;nginx&quot;</span> deleted</span><br><span class="line">statefulset.apps <span class="string">&quot;web&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pod</span></span><br><span class="line">NAME    READY   STATUS        RESTARTS   AGE</span><br><span class="line">myapp   <span class="number">1</span>/<span class="number">1</span>     Running       <span class="number">0</span>          <span class="number">32</span>m</span><br><span class="line">web<span class="literal">-2</span>   <span class="number">0</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">73</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get statefulset</span></span><br><span class="line">No resources found.</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pv</span></span><br><span class="line">NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   REASON   AGE</span><br><span class="line">nfspv1   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Recycle          Bound       default/www<span class="literal">-web</span><span class="literal">-0</span>   nfs                     <span class="number">22</span><span class="built_in">h</span></span><br><span class="line">nfspv2   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Available                       nfsv2                   <span class="number">22</span><span class="built_in">h</span></span><br><span class="line">nfspv3   <span class="number">10</span><span class="built_in">Gi</span>       ROX            Retain           Available                       nfs                     <span class="number">122</span>m</span><br><span class="line">nfspv4   <span class="number">10</span><span class="built_in">Gi</span>       RWX            Retain           Available                       nfs                     <span class="number">121</span>m</span><br><span class="line">nfspv5   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Bound       default/www<span class="literal">-web</span><span class="literal">-2</span>   nfs                     <span class="number">108</span>m</span><br><span class="line">nfspv6   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Bound       default/www<span class="literal">-web</span><span class="literal">-1</span>   nfs                     <span class="number">108</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pvc</span></span><br><span class="line">NAME        STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">www<span class="literal">-web</span><span class="literal">-0</span>   Bound    nfspv1   <span class="number">10</span><span class="built_in">Gi</span>       RWO            nfs            <span class="number">114</span>m</span><br><span class="line">www<span class="literal">-web</span><span class="literal">-1</span>   Bound    nfspv6   <span class="number">10</span><span class="built_in">Gi</span>       RWO            nfs            <span class="number">114</span>m</span><br><span class="line">www<span class="literal">-web</span><span class="literal">-2</span>   Bound    nfspv5   <span class="number">10</span><span class="built_in">Gi</span>       RWO            nfs            <span class="number">103</span>m</span><br></pre></td></tr></table></figure>

<p>删除PVC</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl delete pvc --all</span></span><br><span class="line">persistentvolumeclaim <span class="string">&quot;www-web-0&quot;</span> deleted</span><br><span class="line">persistentvolumeclaim <span class="string">&quot;www-web-1&quot;</span> deleted</span><br><span class="line">persistentvolumeclaim <span class="string">&quot;www-web-2&quot;</span> deleted</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pvc</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>

<p>查看pv，发现pv还是绑定状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@k8s-master pv]# kubectl get pv</span><br><span class="line">NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   REASON   AGE</span><br><span class="line">nfspv1   10Gi       RWO            Recycle          Released    default&#x2F;www-web-0   nfs                     22h</span><br><span class="line">nfspv2   10Gi       RWO            Retain           Available                       nfsv2                   22h</span><br><span class="line">nfspv3   10Gi       ROX            Retain           Available                       nfs                     129m</span><br><span class="line">nfspv4   10Gi       RWX            Retain           Available                       nfs                     127m</span><br><span class="line">nfspv5   10Gi       RWO            Retain           Released    default&#x2F;www-web-2   nfs                     115m</span><br><span class="line">nfspv6   10Gi       RWO            Retain           Released    default&#x2F;www-web-1   nfs                     115m</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>查看pv详细信息</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pv nfspv1 -o yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    pv.kubernetes.io/bound<span class="literal">-by</span><span class="literal">-controller</span>: <span class="string">&quot;yes&quot;</span></span><br><span class="line">  creationTimestamp: <span class="string">&quot;2020-02-03T12:27:09Z&quot;</span></span><br><span class="line">  finalizers:</span><br><span class="line">  - kubernetes.io/pv<span class="literal">-protection</span></span><br><span class="line">  name: nfspv1</span><br><span class="line">  resourceVersion: <span class="string">&quot;931314&quot;</span></span><br><span class="line">  selfLink: /api/v1/persistentvolumes/nfspv1</span><br><span class="line">  uid: <span class="number">96885487</span><span class="literal">-396e</span><span class="literal">-432a</span><span class="literal">-bbc7</span><span class="literal">-4a175f4d008a</span></span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  capacity:</span><br><span class="line">    storage: <span class="number">10</span><span class="built_in">Gi</span></span><br><span class="line">  claimRef:</span><br><span class="line">    apiVersion: v1</span><br><span class="line">    kind: PersistentVolumeClaim</span><br><span class="line">    name: www<span class="literal">-web</span><span class="literal">-0</span></span><br><span class="line">    namespace: default</span><br><span class="line">    resourceVersion: <span class="string">&quot;931311&quot;</span></span><br><span class="line">    uid: <span class="number">4285</span>e38c<span class="literal">-9dd9</span><span class="literal">-49f3</span><span class="literal">-9737</span><span class="literal">-dac799397c13</span></span><br><span class="line">  nfs:</span><br><span class="line">    path: /zfspool/nfs</span><br><span class="line">    server: <span class="number">192.168</span>.<span class="number">128.32</span></span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle</span><br><span class="line">  storageClassName: nfs</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">status:</span><br><span class="line">  phase: Bound</span><br></pre></td></tr></table></figure>

<p>发现该pv的<code>spec.claimRef</code>有绑定信息，使用<code>kubectl edit pv nfspv1</code>将其删除</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">[<span class="string">root@k8s-master</span> <span class="string">pv</span>]<span class="comment"># kubectl edit pv nfspv1 </span></span><br><span class="line"><span class="comment"># Please edit the object below. Lines beginning with a &#x27;#&#x27; will be ignored,</span></span><br><span class="line"><span class="comment"># and an empty file will abort the edit. If an error occurs while saving this file will be</span></span><br><span class="line"><span class="comment"># reopened with the relevant failures.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">pv.kubernetes.io/bound-by-controller:</span> <span class="string">&quot;yes&quot;</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2020-02-03T12:27:09Z&quot;</span></span><br><span class="line">  <span class="attr">finalizers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">kubernetes.io/pv-protection</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfspv1</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">&quot;931314&quot;</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">/api/v1/persistentvolumes/nfspv1</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="number">96885487</span><span class="string">-396e-432a-bbc7-4a175f4d008a</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/zfspool/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.32</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfs</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">phase:</span> <span class="string">Bound</span></span><br></pre></td></tr></table></figure>

<p>查看pv，nfspv1的状态已经编程Available</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pv</span>]<span class="comment"># kubectl get pv</span></span><br><span class="line">NAME     CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   REASON   AGE</span><br><span class="line">nfspv1   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Recycle          Available                       nfs                     <span class="number">22</span><span class="built_in">h</span></span><br><span class="line">nfspv2   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Available                       nfsv2                   <span class="number">22</span><span class="built_in">h</span></span><br><span class="line">nfspv3   <span class="number">10</span><span class="built_in">Gi</span>       ROX            Retain           Available                       nfs                     <span class="number">129</span>m</span><br><span class="line">nfspv4   <span class="number">10</span><span class="built_in">Gi</span>       RWX            Retain           Available                       nfs                     <span class="number">128</span>m</span><br><span class="line">nfspv5   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Released    default/www<span class="literal">-web</span><span class="literal">-2</span>   nfs                     <span class="number">115</span>m</span><br><span class="line">nfspv6   <span class="number">10</span><span class="built_in">Gi</span>       RWO            Retain           Released    default/www<span class="literal">-web</span><span class="literal">-1</span>   nfs                     <span class="number">115</span>m</span><br></pre></td></tr></table></figure>



<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>1 emptyDir和hostPath类型的Volume很方便，但可持久性不强，k8s支持多种外部存储的volume</p>
<p>2 PV和PVC是分离了管理员和普通用户的职责，更适合生产环境</p>
<p>3 通过StorageClass实现更高效的动态供给</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（1）：kubernetes-v1.15.1 部署安装</title>
    <url>/2020/01/04/1_kubernetes-1.15.1%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><table>
<thead>
<tr>
<th align="center">节点名</th>
<th align="center">系统</th>
<th align="center">IP</th>
</tr>
</thead>
<tbody><tr>
<td align="center">master</td>
<td align="center">CentOS7.6</td>
<td align="center">192.168.128.140</td>
</tr>
<tr>
<td align="center">node01</td>
<td align="center">CentOS7.6</td>
<td align="center">192.168.128.141</td>
</tr>
<tr>
<td align="center">node02</td>
<td align="center">CentOS7.6</td>
<td align="center">192.168.128.142</td>
</tr>
</tbody></table>
<h2 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># master节点</span></span><br><span class="line">hostnamectl set-hostname master</span><br><span class="line"><span class="comment"># node01节点</span></span><br><span class="line">hostnamectl set-hostname node01</span><br><span class="line"><span class="comment"># node02节点</span></span><br><span class="line">hostnamectl set-hostname node02</span><br></pre></td></tr></table></figure>



<h2 id="设置host文件"><a href="#设置host文件" class="headerlink" title="设置host文件"></a>设置host文件</h2><p>所有节点编辑/etc/hosts，添加以下内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/hosts,</span><br><span class="line">192.168.128.140 master</span><br><span class="line">192.168.128.141 node01</span><br><span class="line">192.168.128.142 node02</span><br></pre></td></tr></table></figure>



<h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 设置阿里yum源</span></span><br><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">yum install -y conntrack ntpdate ntp ipvsadm ipset jq iptables curl sysstat libseccomp wget vim net-tools git</span><br></pre></td></tr></table></figure>



<h2 id="设置防火墙为iptables，并清空规则"><a href="#设置防火墙为iptables，并清空规则" class="headerlink" title="设置防火墙为iptables，并清空规则"></a>设置防火墙为iptables，并清空规则</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld &amp;&amp; systemctl disable firewalld</span><br><span class="line">yum -y install iptables-services</span><br><span class="line">systemctl start iptables &amp;&amp; systemctl enable iptables</span><br><span class="line">iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -Z &amp;&amp; service iptables save</span><br></pre></td></tr></table></figure>



<h2 id="关闭Selinux"><a href="#关闭Selinux" class="headerlink" title="关闭Selinux"></a>关闭Selinux</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setenforce 0 &amp;&amp; sed -i &#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27; /etc/selinux/config </span><br></pre></td></tr></table></figure>



<h2 id="关闭swap"><a href="#关闭swap" class="headerlink" title="关闭swap"></a>关闭swap</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sed -i &#x27;/ swap / s/^\(.*\)$/#\1/g&#x27; /etc/fstab</span><br></pre></td></tr></table></figure>



<h2 id="调整内核参数，对于K8S"><a href="#调整内核参数，对于K8S" class="headerlink" title="调整内核参数，对于K8S"></a>调整内核参数，对于K8S</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.ipv4.tcp_tw_recycle=0</span><br><span class="line">vm.swappiness=0 # 禁止使用swap空间，只有当系统OOM时才允许使用它</span><br><span class="line">vm.overcommit_memory=1 # 不检查物理内存是否够用</span><br><span class="line">vm.panic_on_oom=0 # 开启OOM</span><br><span class="line">fs.inotify.max_user_instances=8192</span><br><span class="line">fs.inotify.max_user_watches=1048576</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line">EOF</span><br><span class="line">sysctl -p /etc/sysctl.conf</span><br></pre></td></tr></table></figure>



<h2 id="调整系统时区"><a href="#调整系统时区" class="headerlink" title="调整系统时区"></a>调整系统时区</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置系统时区为 中国/上海</span></span><br><span class="line">timedatectl set-timezone Asia/Shanghai</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将当前的UTC时间写入硬件时钟</span></span><br><span class="line">timedatectl set-local-rtc 0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启依赖于系统时间的服务</span></span><br><span class="line">systemctl restart rsyslog</span><br><span class="line">systemctl restart crond</span><br></pre></td></tr></table></figure>



<h2 id="关闭系统不需要的服务"><a href="#关闭系统不需要的服务" class="headerlink" title="关闭系统不需要的服务"></a>关闭系统不需要的服务</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl stop postfix &amp;&amp; systemctl disable postfix</span><br></pre></td></tr></table></figure>



<h2 id="设置rsyslogd和systemd-journald"><a href="#设置rsyslogd和systemd-journald" class="headerlink" title="设置rsyslogd和systemd journald"></a>设置rsyslogd和systemd journald</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /var/log/journal # 持久化保存日志的目录</span><br><span class="line">mkdir /etc/systemd/journald.conf.d</span><br><span class="line">cat &gt; /etc/systemd/journald.conf.d/99-prophet.conf &lt;&lt;EOF</span><br><span class="line">[Journal]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 持久化保存到磁盘</span></span><br><span class="line">Storage=persistent</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 压缩历史日志</span></span><br><span class="line">Compress=yes</span><br><span class="line"></span><br><span class="line">SyncIntervalSec=5m</span><br><span class="line">RateLimitInterval=30s</span><br><span class="line">RateLimitBurst=1000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 最大占用空间10G</span></span><br><span class="line">SystemMaxUse=10G</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 单日志文件最大200M</span></span><br><span class="line">SystemMaxFileSize=200M</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 日志保存时间2周</span></span><br><span class="line">MaxRetentionSec=2week</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 不将日志转发到syslog</span></span><br><span class="line">ForwardToSyslog=no</span><br><span class="line">EOF</span><br><span class="line">systemctl restart systemd-journald</span><br></pre></td></tr></table></figure>



<h2 id="升级系统内核为4-4"><a href="#升级系统内核为4-4" class="headerlink" title="升级系统内核为4.4"></a>升级系统内核为4.4</h2><p>CentOS7.x系统自带的3.10.x内核存在一些Bugs，导致运行的Docker、kubernetes不稳定</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装完成后检查/boot/grub2/grub.cfg中对应内核menuentry中是否包含initrd16配置，如果没有，再安装一次 egrep -i initrd /boot/grub2/grub.cfg</span></span><br><span class="line">yum --enablerepo=elrepo-kernel install -y kernel-lt</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看可用内核</span></span></span><br><span class="line">cat /boot/grub2/grub.cfg |grep menuentry</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置开机从新内核启动</span></span><br><span class="line">grub2-set-default &quot;CentOS Linux (4.4.221-1.el7.elrepo.x86_64) 7 (Core)&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看内核启动项</span></span></span><br><span class="line">grub2-editenv list</span><br><span class="line">reboot</span><br><span class="line">uname -r</span><br></pre></td></tr></table></figure>

<h2 id="kube-proxy开启ipvs的前置条件"><a href="#kube-proxy开启ipvs的前置条件" class="headerlink" title="kube-proxy开启ipvs的前置条件"></a>kube-proxy开启ipvs的前置条件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">modprobe br_netfilter</span><br><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash">! /bin/bash</span></span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules</span><br><span class="line">bash /etc/sysconfig/modules/ipvs.modules</span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack_ipv4 # 检查是否生效</span><br></pre></td></tr></table></figure>



<h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 阿里云</span></span></span><br><span class="line">sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 国外</span></span></span><br><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看docker可安装版本</span></span><br><span class="line">yum list docker-ce.x86_64  --showduplicates |sort -r</span><br><span class="line"></span><br><span class="line">yum update -y &amp;&amp; yum install -y docker-ce[-xxx] ## 最新版本会用到overlay的驱动引擎</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># yum install http://ftp.riken.jp/Linux/cern/centos/7/extras/x86_64/Packages/container-selinux-2.10-2.el7.noarch.rpm</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 创建docker目录</span></span></span><br><span class="line">mkdir /etc/docker</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 配置daemon</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># CentOS有两个cgroup：cgroupfs、cgroup-systemd</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 并设置log-driver，可以在/var/log下查找日志</span></span></span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class="line">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class="line">  &quot;log-opts&quot;: &#123;</span><br><span class="line">    &quot;max-size&quot;: &quot;100m&quot;,</span><br><span class="line">    &quot;max-file&quot;: &quot;3&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">  &quot;storage-opts&quot;: [</span><br><span class="line">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://uyah70su.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line"><span class="meta">#</span><span class="bash">重启docker服务</span></span><br><span class="line">systemctl daemon-reload &amp;&amp; systemctl start docker &amp;&amp; systemctl enable docker</span><br></pre></td></tr></table></figure>



<h2 id="安装Kubeadm（主从配置）"><a href="#安装Kubeadm（主从配置）" class="headerlink" title="安装Kubeadm（主从配置）"></a>安装Kubeadm（主从配置）</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line">yum install -y kubelet-1.15.1 kubeadm-1.15.1 kubectl-1.15.1</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure>



<h2 id="初始化主节点"><a href="#初始化主节点" class="headerlink" title="初始化主节点"></a>初始化主节点</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## 这里需要下载Google的镜像，可以提前下载好(阿里云有，叫google_containers)</span><br><span class="line">kubeadm config images list</span><br><span class="line"></span><br><span class="line"># 阿里云</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">image_aliyun&#x3D;(kube-apiserver-amd64:v1.15.1 kube-controller-manager-amd64:v1.15.1 kube-scheduler-amd64:v1.15.1 kube-proxy-amd64:v1.15.1 pause-amd64:3.1 etcd-amd64:3.3.10 coredns:1.3.1)</span><br><span class="line">for image in $&#123;image_aliyun[@]&#125;</span><br><span class="line">do</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;$image</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;$image k8s.gcr.io&#x2F;$&#123;image&#x2F;-amd64&#x2F;&#125;</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;$image</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">kubeadm config print init-defaults &gt; kubeadm-config.yaml</span><br><span class="line">## 修改此模板的配置</span><br><span class="line">	localAPIEndpoint:</span><br><span class="line">		advertiseAddress: 192.168.128.140</span><br><span class="line">	kubernetesVersion: v1.15.1</span><br><span class="line">	networking:</span><br><span class="line">		podSubnet: &quot;10.244.0.0&#x2F;16&quot;</span><br><span class="line">		serviceSubnet: 10.96.0.0&#x2F;12</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io&#x2F;v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">featureGates:</span><br><span class="line">	SupportIPVSProxyMode: true</span><br><span class="line">mode: ipvs</span><br><span class="line">kubeadm init --config&#x3D;kubeadm-config.yaml --experimental-upload-certs | tee kubeadm-init.log</span><br><span class="line"></span><br><span class="line"># root用户添加KUBECONFIG</span><br><span class="line">cat &lt;&lt; EOF &gt;&gt; ~&#x2F;.bashrc</span><br><span class="line">export KUBECONFIG&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;admin.conf</span><br><span class="line">EOF</span><br><span class="line">source ~&#x2F;.bashrc</span><br><span class="line"></span><br><span class="line"># 普通用户执行以下命令才能使用kubectl</span><br><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br><span class="line"></span><br><span class="line"># 查看集群状态</span><br><span class="line">kubectl get nodes</span><br><span class="line">kubectl get pod -n kube-system</span><br><span class="line">kubectl get cs</span><br><span class="line">## 由于未安装网络插件，coredns处于pending状态，node处于notready状态</span><br></pre></td></tr></table></figure>



<h2 id="部署网络"><a href="#部署网络" class="headerlink" title="部署网络"></a>部署网络</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 此时kubectl get node，master的状态是NotReady</span></span></span><br><span class="line">kubectl apply -f \</span><br><span class="line">https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 外网不通的情况下，可以使用我的配置文件</span></span></span><br><span class="line">sed -i &#x27;s#quay.io#quay-mirror.qiniu.com#g&#x27; kube-flannel.yml</span><br><span class="line">kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure>

<p>flannel配置文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">policy/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodSecurityPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">psp.flannel.unprivileged</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">seccomp.security.alpha.kubernetes.io/allowedProfileNames:</span> <span class="string">docker/default</span></span><br><span class="line">    <span class="attr">seccomp.security.alpha.kubernetes.io/defaultProfileName:</span> <span class="string">docker/default</span></span><br><span class="line">    <span class="attr">apparmor.security.beta.kubernetes.io/allowedProfileNames:</span> <span class="string">runtime/default</span></span><br><span class="line">    <span class="attr">apparmor.security.beta.kubernetes.io/defaultProfileName:</span> <span class="string">runtime/default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">configMap</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">secret</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">emptyDir</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hostPath</span></span><br><span class="line">  <span class="attr">allowedHostPaths:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">&quot;/etc/cni/net.d&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">&quot;/etc/kube-flannel&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">&quot;/run/flannel&quot;</span></span><br><span class="line">  <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Users and groups</span></span><br><span class="line">  <span class="attr">runAsUser:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">supplementalGroups:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">fsGroup:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="comment"># Privilege Escalation</span></span><br><span class="line">  <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">defaultAllowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Capabilities</span></span><br><span class="line">  <span class="attr">allowedCapabilities:</span> [<span class="string">&#x27;NET_ADMIN&#x27;</span>]</span><br><span class="line">  <span class="attr">defaultAddCapabilities:</span> []</span><br><span class="line">  <span class="attr">requiredDropCapabilities:</span> []</span><br><span class="line">  <span class="comment"># Host namespaces</span></span><br><span class="line">  <span class="attr">hostPID:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">hostIPC:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPorts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">min:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">max:</span> <span class="number">65535</span></span><br><span class="line">  <span class="comment"># SELinux</span></span><br><span class="line">  <span class="attr">seLinux:</span></span><br><span class="line">    <span class="comment"># SELinux is unused in CaaSP</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">&#x27;RunAsAny&#x27;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&#x27;extensions&#x27;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&#x27;podsecuritypolicies&#x27;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&#x27;use&#x27;</span>]</span><br><span class="line">    <span class="attr">resourceNames:</span> [<span class="string">&#x27;psp.flannel.unprivileged&#x27;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">pods</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">nodes/status</span></span><br><span class="line">    <span class="attr">verbs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">cni-conf.json:</span> <span class="string">|</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;:</span> <span class="string">&quot;cbr0&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;cniVersion&quot;:</span> <span class="string">&quot;0.3.1&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;plugins&quot;:</span> [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;delegate&quot;:</span> &#123;</span><br><span class="line">            <span class="attr">&quot;hairpinMode&quot;:</span> <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">&quot;isDefaultGateway&quot;:</span> <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">&quot;type&quot;:</span> <span class="string">&quot;portmap&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;capabilities&quot;:</span> &#123;</span><br><span class="line">            <span class="attr">&quot;portMappings&quot;:</span> <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="attr">net-conf.json:</span> <span class="string">|</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;Network&quot;:</span> <span class="string">&quot;10.244.0.0/16&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;Backend&quot;:</span> &#123;</span><br><span class="line">        <span class="attr">&quot;Type&quot;:</span> <span class="string">&quot;vxlan&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-ds-amd64</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/os</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">linux</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/arch</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">amd64</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">flannel</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install-cni</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay-mirror.qiniu.com/coreos/flannel:v0.11.0-amd64</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cp</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-f</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/kube-flannel/cni-conf.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/cni/net.d/10-flannel.conflist</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-amd64</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">            <span class="attr">add:</span> [<span class="string">&quot;NET_ADMIN&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-ds-arm64</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/os</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">linux</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/arch</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">arm64</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">flannel</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install-cni</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-arm64</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cp</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-f</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/kube-flannel/cni-conf.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/cni/net.d/10-flannel.conflist</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-arm64</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">             <span class="attr">add:</span> [<span class="string">&quot;NET_ADMIN&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-ds-arm</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/os</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">linux</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/arch</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">arm</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">flannel</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install-cni</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-arm</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cp</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-f</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/kube-flannel/cni-conf.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/cni/net.d/10-flannel.conflist</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-arm</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">             <span class="attr">add:</span> [<span class="string">&quot;NET_ADMIN&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-ds-ppc64le</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/os</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">linux</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/arch</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">ppc64le</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">flannel</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install-cni</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-ppc64le</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cp</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-f</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/kube-flannel/cni-conf.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/cni/net.d/10-flannel.conflist</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-ppc64le</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">             <span class="attr">add:</span> [<span class="string">&quot;NET_ADMIN&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-flannel-ds-s390x</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">node</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">flannel</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">affinity:</span></span><br><span class="line">        <span class="attr">nodeAffinity:</span></span><br><span class="line">          <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">            <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/os</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">linux</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">beta.kubernetes.io/arch</span></span><br><span class="line">                    <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                    <span class="attr">values:</span></span><br><span class="line">                      <span class="bullet">-</span> <span class="string">s390x</span></span><br><span class="line">      <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">flannel</span></span><br><span class="line">      <span class="attr">initContainers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">install-cni</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-s390x</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cp</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">-f</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/kube-flannel/cni-conf.json</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/etc/cni/net.d/10-flannel.conflist</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kube-flannel</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/coreos/flannel:v0.11.0-s390x</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/opt/bin/flanneld</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--ip-masq</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">--kube-subnet-mgr</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">&quot;100m&quot;</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        <span class="attr">securityContext:</span></span><br><span class="line">          <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">          <span class="attr">capabilities:</span></span><br><span class="line">             <span class="attr">add:</span> [<span class="string">&quot;NET_ADMIN&quot;</span>]</span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAMESPACE</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/kube-flannel/</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">run</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/run/flannel</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cni</span></span><br><span class="line">          <span class="attr">hostPath:</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">/etc/cni/net.d</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">flannel-cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">kube-flannel-cfg</span></span><br></pre></td></tr></table></figure>



<h2 id="加入主节点以及其余工作节点"><a href="#加入主节点以及其余工作节点" class="headerlink" title="加入主节点以及其余工作节点"></a>加入主节点以及其余工作节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">执行安装日志中的加入命令即可</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 可通过kubectl get pod -n kube-system -o wide 查看对应节点进度</span></span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（20）：集群调度</title>
    <url>/2020/01/08/20_%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Scheduler是kubernetes的调度器，主要的任务是把定义的Pod分配到集群的节点上。听起来非常简单，但是有很多要考虑的问题：</p>
<ul>
<li><strong>公平：如何保证每个节点都能被分配资源</strong></li>
<li><strong>资源高效利用：季芹所有资源最大化被使用</strong></li>
<li><strong>效率：调度的性能要好，能够尽快地对大批量的Pod完成调度工作</strong></li>
<li><strong>灵活：允许用户根据自己的需求烤制调度的逻辑</strong></li>
</ul>
<p>Scheduler是作为单独的程序运行的，启动之后会一直监听API Server，获取<code>spec.Nodename</code>为空的pod，对每个pod都会创建一个binding，表明该pod应该放到哪个节点上</p>
<h2 id="调度过程"><a href="#调度过程" class="headerlink" title="调度过程"></a>调度过程</h2><p>调度氛围几个部分：首先是过滤掉不满足条件的节点，这个过程称为<code>predicate</code>(预选)；然后对通过的节点按照优先级排序，这个是<code>priority</code>；最后从中选择优先级最高的节点。如果中间任何一个步骤有问题，就直接返回错误。</p>
<p>Predicate有一系列的算法可以使用：</p>
<ul>
<li><code>PodFitsResources</code>：节点上剩余的资源是否大于Pod请求的资源</li>
<li><code>PodFitsHost</code>：如果Pod指定了NodeName，检查节点名称和NodeName匹配</li>
<li><code>PodFitsHostPorts</code>：节点上已经使用的Port是否和Pod申请的Port冲突</li>
<li><code>PodSelectorMatches</code>：过滤掉和Pod指定的label不匹配的节点</li>
<li><code>NoDiskConflict</code>：已经mount的volume和Pod指定的volume不冲突，除非他们都是只读</li>
</ul>
<p>如果在predicate过程中没有合适的节点，pod会一直在<code>pending</code>状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续priorities过程：按照优先级大小进行排序</p>
<p>优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括：</p>
<ul>
<li><strong><code>LeastRequestedPriority</code>：通过计算CPU和Memory的使用率来决定权重，使用率越低，权重越高。换句话说，这个优先级制表倾向于资源使用比例更低的节点</strong></li>
<li><strong><code>BalancedResourceAllocation</code>：节点上CPU和Memo而已使用率越接近，权重越高。这个应该和上面的一起使用，不应该单独使用</strong></li>
<li><strong><code>ImageLocalityPriority</code>：倾向于已经有要使用镜像的节点，镜像镜像总大小值越大，权重越高</strong></li>
</ul>
<p>通过算法对所有的优先级项目和权重进行计算，得出最终的结果</p>
<h2 id="自定义调度器"><a href="#自定义调度器" class="headerlink" title="自定义调度器"></a>自定义调度器</h2><p>除了kubernetes自带的调度器，你也可以编写自己的调度器。通过<code>spec:schedulername</code>参数指定调度器名字，可以为pod选择某个调度器进行调度。比如下面的pod选择<code>my-scheduler</code>进行调度，而不是默认的<code>default-scheduler</code>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">annotation-second-scheduler</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">multischeduler-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedulername:</span> <span class="string">my-scheduler</span></span><br><span class="line">  <span class="attr">container:</span> <span class="string">pod-with-second-annotatinon-container</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">gcr.oio/google_containers/pause:2.0</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（21）：调度亲和性</title>
    <url>/2020/01/08/21_%E8%B0%83%E5%BA%A6%E4%BA%B2%E5%92%8C%E6%80%A7/</url>
    <content><![CDATA[<h2 id="节点亲和性"><a href="#节点亲和性" class="headerlink" title="节点亲和性"></a>节点亲和性</h2><p><code>pod.spec.nodeAffinity</code></p>
<ul>
<li><strong>preferredDuringSchedulingIgnoredDuringExecution：软策略</strong>   (百度翻译：优先执行计划)</li>
<li><strong>requiredDuringSchedulingIgnoredDuringExecution：硬策略</strong>（百度翻译：执行期间要求的预定计划）</li>
</ul>
<p>老师讲解：</p>
<ul>
<li>软策略：有更优的节点就选择更优的节点</li>
<li>硬策略：必须选择我指定的将节点</li>
</ul>
<h3 id="requiredDuringSchedulingIgnoredDuringExecution"><a href="#requiredDuringSchedulingIgnoredDuringExecution" class="headerlink" title="requiredDuringSchedulingIgnoredDuringExecution"></a>requiredDuringSchedulingIgnoredDuringExecution</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span>  <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">node-affinity-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span>  <span class="comment">#key就是节点的标签，使用`kubectl get node --show-labels`</span></span><br><span class="line">              <span class="attr">operator:</span> <span class="string">NotIn</span></span><br><span class="line">              <span class="attr">values:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">k8s-node02</span>     <span class="comment">## node节点不为node02</span></span><br></pre></td></tr></table></figure>

<p>键值运算关系</p>
<ul>
<li>In：label的值在某个列表中</li>
<li>NotIn：label的值不在某个列表中</li>
<li>Gt：label的值大于某个值</li>
<li>Lt：label的值小于某个值</li>
<li>Exists：某个label存在</li>
<li>DoesNotExist：某个label不存在</li>
</ul>
<!--如果`nodeSelectorTerms`下面有多个选项的话，满足任何一个条件就可以了；如果`matchExpressions`有多个选项的话，必须同时满足这些条件才能正常调度Pod-->

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">kubectl create <span class="operator">-f</span> pod.yaml</span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME           READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">affinity<span class="literal">-pod</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">45</span>s   <span class="number">10.244</span>.<span class="number">1.117</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<h3 id="PreferredDuringSchedulingIgnoredDuringExectuion"><a href="#PreferredDuringSchedulingIgnoredDuringExectuion" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExectuion"></a>PreferredDuringSchedulingIgnoredDuringExectuion</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity-preferred</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">node-affinity-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span>			<span class="comment">## 权重，如果有多个，则优先选择权重高的</span></span><br><span class="line">        <span class="attr">preference:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">              <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">              <span class="attr">values:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">k8s-node03</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl create -f pod2.yaml </span></span><br><span class="line">pod/affinity<span class="literal">-preferred</span> created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">affinity<span class="literal">-pod</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">19</span>m   <span class="number">10.244</span>.<span class="number">1.117</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">7</span>s    <span class="number">10.244</span>.<span class="number">2.208</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="同时使用软策略和硬策略"><a href="#同时使用软策略和硬策略" class="headerlink" title="同时使用软策略和硬策略"></a>同时使用软策略和硬策略</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">faainity-multi</span></span><br><span class="line">  <span class="attr">app:</span> <span class="string">node-affinity-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoreDuringExecution:</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">NotIn</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">k8s-node02</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoreDuringExecution:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">preference:</span></span><br><span class="line">        <span class="attr">matchExpressions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">source</span></span><br><span class="line">          <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">qikaiak</span></span><br></pre></td></tr></table></figure>





<h2 id="Pod亲和性"><a href="#Pod亲和性" class="headerlink" title="Pod亲和性"></a>Pod亲和性</h2><p><code>Pod.spec.affinity.podAffinity/podAntiAffinity</code> 亲和性/反亲和性</p>
<p>preferredDuringSchedulingIgnoredDuringExection：软策略</p>
<p>requiredDruingSchedulingIgnoredDuringExecution：硬策略</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-3</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">pod-3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-3</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">podAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchdeulingIgnoredDuringExecution:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">pod-1</span></span><br><span class="line">        <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span>    <span class="comment">## 拓扑域</span></span><br><span class="line">    <span class="attr">podAntiAffinity:</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">podAffinityTerm:</span></span><br><span class="line">          <span class="attr">labelSelector:</span></span><br><span class="line">            <span class="attr">matchExpressions:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">              <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">              <span class="attr">values:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">pod-2</span></span><br><span class="line">          <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure>

<p>这里的podAffinityTerm和nodeSelectorTerms，一个有s，一个没有</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl create -f pod3.yaml </span></span><br><span class="line">pod/affinity<span class="literal">-pod</span><span class="literal">-3</span> created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">affinity<span class="literal">-pod</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">115</span>m</span><br><span class="line">affinity<span class="literal">-pod</span><span class="literal">-3</span>       <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">5</span>s</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">96</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide --show-labels</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE    IP             NODE         NOMINATED NODE   READINESS GATES   LABELS</span><br><span class="line">affinity<span class="literal">-pod</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">116</span>m   <span class="number">10.244</span>.<span class="number">1.117</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;            app=node<span class="literal">-affinity</span><span class="literal">-pod</span></span><br><span class="line">affinity<span class="literal">-pod</span><span class="literal">-3</span>       <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">18</span>s    &lt;none&gt;         &lt;none&gt;       &lt;none&gt;           &lt;none&gt;            &lt;none&gt;</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">96</span>m    <span class="number">10.244</span>.<span class="number">2.208</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;            &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>可以看到pod-3是pending状态</p>
<p>修改其中一个pod的标签app=pod-1</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl label pod affinity-pod app=pod-1 --overwrite=true</span></span><br><span class="line">pod/affinity<span class="literal">-pod</span> labeled</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide --show-labels</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE    IP             NODE         NOMINATED NODE   READINESS GATES   LABELS</span><br><span class="line">affinity<span class="literal">-pod</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">136</span>m   <span class="number">10.244</span>.<span class="number">1.117</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;            app=pod<span class="literal">-1</span></span><br><span class="line">affinity<span class="literal">-pod</span><span class="literal">-3</span>       <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">21</span>m    <span class="number">10.244</span>.<span class="number">1.118</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;            &lt;none&gt;</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">117</span>m   <span class="number">10.244</span>.<span class="number">2.208</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;            &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>此时pod-3的状态就变成Running状态</p>
<p>这里的含义就是：判断在<code>kubernetes.io/hostname</code>下，app必须包含pod-1，可选不包含pod-2</p>
<p>亲和性/反亲和性调度策略比较如下：</p>
<p><img src="/assets/image-20200204211100740.png" alt="image-20200204211100740"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（22）：调度器-污点</title>
    <url>/2020/01/08/22_%E8%B0%83%E5%BA%A6%E5%99%A8-%E6%B1%A1%E7%82%B9/</url>
    <content><![CDATA[<h2 id="Taint和Toleration（污点和容忍）"><a href="#Taint和Toleration（污点和容忍）" class="headerlink" title="Taint和Toleration（污点和容忍）"></a>Taint和Toleration（污点和容忍）</h2><p>节点亲和性，是Pod的一种属性(偏好或硬性要求)，它使Pod被吸引到一类特定的节点。Taint则相反，它使节点能够排斥一类特定的Pod</p>
<p>Taint和Toleration相互配合，可以用来避免Pod被分配到不合适的节点上。每个节点上都可以应用一个或多个taint，这表示对于那些不能容忍这些taint的pod，是不会被该节点接受的。如果将toleration应用于pod上，则表示这些pod可以（但不要求）被调度到具有匹配taint的节点上。</p>
<h2 id="污点（Taint）"><a href="#污点（Taint）" class="headerlink" title="污点（Taint）"></a>污点（Taint）</h2><h3 id="1-污点（taint）的组成"><a href="#1-污点（taint）的组成" class="headerlink" title="1 污点（taint）的组成"></a>1 污点（taint）的组成</h3><p>使用<code>kubectl taint</code>命令可以给某个Node节点设置污点，Node被设置上污点之后就和Pod之间存在一种互斥的关系，可以让Node拒绝Pod的调度执行，甚至将Node已经存在的Pod驱逐出去</p>
<p>每个污点的组成如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">key=value:effect</span><br></pre></td></tr></table></figure>



<p>每个污点有一个key和value作为污点的标签，其中value可以为空，effect描述污点的作用。当前taint effect支持如下三个选项：</p>
<ul>
<li><strong><code>NoSchedule</code>：表示k8s不会将Pod调度到具有该污点的Node上</strong></li>
<li><strong><code>PreferNoSchedule</code>：表示k8s尽量避免将Pod调度到具有该污点的Node上</strong></li>
<li><strong><code>Noexecute</code>：表示k8s不会将Pod调度到具有该污点的Node上，同时会将Node上已经存在的Pod驱逐出去</strong></li>
</ul>
<p>master天生就被设置为污点<code>NoSchedule</code></p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl describe node k8s-master|grep Taints</span></span><br><span class="line">Taints:             node<span class="literal">-role</span>.kubernetes.io/master:NoSchedule</span><br></pre></td></tr></table></figure>



<h3 id="2-污点的设置、查看和去除"><a href="#2-污点的设置、查看和去除" class="headerlink" title="2 污点的设置、查看和去除"></a>2 污点的设置、查看和去除</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置污点</span></span><br><span class="line">kubectl taint nodes node1 key1=value1:NoSchedule</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点说明中，查找Taints字段</span></span><br><span class="line">kubectl describe pod pod-name </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 去除污点</span></span><br><span class="line">kubectl taint nodes node1 key1:NoSchedule-</span><br></pre></td></tr></table></figure>



<h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><p>查看该节点上的pod所在的节点，然后设置该节点为NoExecute，可以看到该节点的Pod自动被删除</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE    IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">affinity<span class="literal">-pod</span>         <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">174</span>m   <span class="number">10.244</span>.<span class="number">1.117</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="literal">-pod</span><span class="literal">-3</span>       <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">58</span>m    <span class="number">10.244</span>.<span class="number">1.118</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">155</span>m   <span class="number">10.244</span>.<span class="number">2.208</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl taint nodes k8s-node01 check=test:NoExecute</span></span><br><span class="line">node/k8s<span class="literal">-node01</span> tainted</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME                 READY   STATUS    RESTARTS   AGE    IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">155</span>m   <span class="number">10.244</span>.<span class="number">2.208</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>查看node01的taint</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl describe node k8s-node01</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Taints:             check=test:NoExecute</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>



<h2 id="容忍（Tolerations）"><a href="#容忍（Tolerations）" class="headerlink" title="容忍（Tolerations）"></a>容忍（Tolerations）</h2><p>设置了污点的Node将根据taint的effect：NoSchedule、PreferNoschedule、NoExecute和Pod之间产生的互斥欢喜，Pod将一定程度上不会调度到Node上。但我们可以在Pod上设置容忍（Toleration），意思是设置了容忍的Pod将可以容忍污点的存在，可以被调度到存在污点的Node上</p>
<p>pod.spec.tolerations</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key1&quot;</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span></span><br><span class="line">  <span class="attr">value:</span> <span class="string">&quot;value1&quot;</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></span><br><span class="line">  <span class="attr">tolerationSeconds:</span> <span class="number">3600</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key1&quot;</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span></span><br><span class="line">  <span class="attr">value:</span> <span class="string">&quot;value1&quot;</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="string">&quot;NoExecute&quot;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key2&quot;</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br><span class="line">  <span class="attr">effect:</span> <span class="string">&quot;NoSchedule&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>其中可以，value，effect要与Node上设置的taint保持一致</strong></li>
<li><strong>operator的值为Exists将会忽略value的值</strong></li>
<li><strong>tolerationSeconds用于描述当Pod需要被驱逐时可以在Pod上继续保留运行的时间</strong></li>
</ul>
<h3 id="举个栗子-1"><a href="#举个栗子-1" class="headerlink" title="举个栗子"></a>举个栗子</h3><p>给node02也打上污点</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl taint nodes k8s-node02 check=test:NoExecute</span></span><br><span class="line">node/k8s<span class="literal">-node02</span> tainted</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                 READY   STATUS        RESTARTS   AGE</span><br><span class="line">affinity<span class="literal">-preferred</span>   <span class="number">0</span>/<span class="number">1</span>     Terminating   <span class="number">0</span>          <span class="number">166</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">affinity</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>

<p>创建pod，可以看到pod处于pending状态，因为所有节点都有污点</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># cat pod.yaml </span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: app</span><br><span class="line">    image: hub.test.com/library/myapp:v1</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod.yaml </span></span><br><span class="line">pod/myapp created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME    READY   STATUS    RESTARTS   AGE</span><br><span class="line">myapp   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">5</span>s</span><br></pre></td></tr></table></figure>



<h3 id="其他属性"><a href="#其他属性" class="headerlink" title="其他属性"></a><strong>其他属性</strong></h3><h4 id="1-当不指定key值时，表示容忍所有的污点key："><a href="#1-当不指定key值时，表示容忍所有的污点key：" class="headerlink" title="1 当不指定key值时，表示容忍所有的污点key："></a>1 当不指定key值时，表示容忍所有的污点key：</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="2-当不指定effect值时，表示容忍所有的污点作用"><a href="#2-当不指定effect值时，表示容忍所有的污点作用" class="headerlink" title="2 当不指定effect值时，表示容忍所有的污点作用"></a>2 当不指定effect值时，表示容忍所有的污点作用</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;key&quot;</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">&quot;Exists&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="3-有多个Master存在时，防止资源浪费，可以如下设置"><a href="#3-有多个Master存在时，防止资源浪费，可以如下设置" class="headerlink" title="3 有多个Master存在时，防止资源浪费，可以如下设置"></a>3 有多个Master存在时，防止资源浪费，可以如下设置</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl taint nodes Node-Name node-role.kubernetes.io&#x2F;master&#x3D;:PreferNoSchedule</span><br></pre></td></tr></table></figure>



<h4 id="举个栗子-2"><a href="#举个栗子-2" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>新建Pod</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-taint-toleration</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">&quot;check&quot;</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">&quot;Equal&quot;</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">&quot;test&quot;</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">&quot;NoExecute&quot;</span></span><br><span class="line">    <span class="attr">tolerationSeconds:</span> <span class="number">3600</span></span><br></pre></td></tr></table></figure>

 <figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl create -f pod.yaml </span></span><br><span class="line">pod/pod<span class="literal">-taint</span><span class="literal">-toleration</span> created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">myapp                  <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">12</span>m</span><br><span class="line">pod<span class="literal">-taint</span><span class="literal">-toleration</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s</span><br></pre></td></tr></table></figure>



<p>如果某个node节点需要维护，可以打上NoExecute污点，待所有pod驱逐之后，即可进入维护</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（23）：固定节点调度</title>
    <url>/2020/01/08/23_%E5%9B%BA%E5%AE%9A%E8%8A%82%E7%82%B9%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="指定调度节点"><a href="#指定调度节点" class="headerlink" title="指定调度节点"></a>指定调度节点</h2><h3 id="1-Pod-spec-nodeName将Pod直接调度到指定的Node节点上，会跳过Scheduler的调度策略，该匹配规则是强制匹配"><a href="#1-Pod-spec-nodeName将Pod直接调度到指定的Node节点上，会跳过Scheduler的调度策略，该匹配规则是强制匹配" class="headerlink" title="1 Pod.spec.nodeName将Pod直接调度到指定的Node节点上，会跳过Scheduler的调度策略，该匹配规则是强制匹配"></a>1 <code>Pod.spec.nodeName</code>将Pod直接调度到指定的Node节点上，会跳过Scheduler的调度策略，该匹配规则是强制匹配</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">7</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeName:</span> <span class="string">k8s-node01</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>运行一下看看效果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl apply -f deploy.yaml </span></span><br><span class="line">deployment.extensions/myweb created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                     READY   STATUS              RESTARTS   AGE</span><br><span class="line">myapp                    <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">25</span>m</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-4wbpm</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-5m24f</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-8z6dh</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-9gdlp</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-9vnnz</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-rzckd</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-s49tp</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-td6kn</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-vrpsn</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-w7568</span>   <span class="number">0</span>/<span class="number">1</span>     ContainerCreating   <span class="number">0</span>          <span class="number">2</span>s</span><br><span class="line">pod<span class="literal">-taint</span><span class="literal">-toleration</span>     <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">13</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl get pods -o wide</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">myapp                    <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">25</span>m   <span class="number">10.244</span>.<span class="number">1.120</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-4wbpm</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.123</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-5m24f</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.128</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-8z6dh</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.130</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-9gdlp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.121</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-9vnnz</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.122</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-rzckd</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.124</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-s49tp</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.127</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-td6kn</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.125</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-vrpsn</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.129</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">myweb<span class="literal">-7bff67bccc</span><span class="literal">-w7568</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">6</span>s    <span class="number">10.244</span>.<span class="number">1.126</span>   k8s<span class="literal">-node01</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">pod<span class="literal">-taint</span><span class="literal">-toleration</span>     <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">13</span>m   <span class="number">10.244</span>.<span class="number">2.210</span>   k8s<span class="literal">-node02</span>   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>可以看到，所有的Pod被调度到k8s-node01节点上</p>
<h3 id="2-Pod-spec-nodeSelector：通过kubernetes的label-selector机制选择节点，由调度器调度策略匹配label，而后调度Pod到目标节点，该匹配规则属于强制约束"><a href="#2-Pod-spec-nodeSelector：通过kubernetes的label-selector机制选择节点，由调度器调度策略匹配label，而后调度Pod到目标节点，该匹配规则属于强制约束" class="headerlink" title="2 Pod.spec.nodeSelector：通过kubernetes的label-selector机制选择节点，由调度器调度策略匹配label，而后调度Pod到目标节点，该匹配规则属于强制约束"></a>2 <code>Pod.spec.nodeSelector</code>：通过kubernetes的label-selector机制选择节点，由调度器调度策略匹配label，而后调度Pod到目标节点，该匹配规则属于强制约束</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myweb-2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">disk:</span> <span class="string">ssd</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myweb-2</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>运行该deploy</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl apply -f deploy2.yaml </span></span><br><span class="line">deployment.extensions/myweb created</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">myweb<span class="literal">-689f546447</span><span class="literal">-8tftj</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">myweb<span class="literal">-689f546447</span><span class="literal">-xsdz4</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">3</span>s</span><br><span class="line">myweb<span class="literal">-689f546447</span><span class="literal">-z2zp9</span>   <span class="number">0</span>/<span class="number">1</span>     Pending   <span class="number">0</span>          <span class="number">3</span>s</span><br></pre></td></tr></table></figure>

<p>设置node label为<code>disk=ssd</code>，可以看到pod成功被调度到node上</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl label node k8s-node01 disk=ssd</span></span><br><span class="line">node/k8s<span class="literal">-node01</span> labeled</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">node</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                     READY   STATUS    RESTARTS   AGE</span><br><span class="line">myweb<span class="literal">-689f546447</span><span class="literal">-8tftj</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">60</span>s</span><br><span class="line">myweb<span class="literal">-689f546447</span><span class="literal">-xsdz4</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">60</span>s</span><br><span class="line">myweb<span class="literal">-689f546447</span><span class="literal">-z2zp9</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">60</span>s</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（24）：集群安全-认证</title>
    <url>/2020/01/09/24_%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8-%E8%AE%A4%E8%AF%81/</url>
    <content><![CDATA[<h2 id="机制说明"><a href="#机制说明" class="headerlink" title="机制说明"></a>机制说明</h2><p>kubernetes作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。API server是集群内部各个组件通信的中介，也是外部控制的入口。所以kubernetes的安全机制基本就是围绕保护API server来设计的。kubernetes使用了<strong>认证（Authentication）</strong>、<strong>鉴权（Authorization）</strong>、<strong>准入控制（Admission Control）</strong>三步来保证API Server的安全</p>
<h2 id="Authentication"><a href="#Authentication" class="headerlink" title="Authentication"></a>Authentication</h2><ul>
<li><p><strong>HTTP Token认证：通过一个Token来识别合法用户</strong></p>
<ul>
<li><strong>HTTP Token的认证是用一个很长的特殊编码方式并且很难以被模仿的字符串-Token来表达客户的一种方式。Token的认证是一个很长很复杂的字符串，每一个Token对应一个用户名存储在API server能访问的文件中。当客户端发起API调用请求时，需要在HTTP Header里放入Token</strong></li>
</ul>
</li>
<li><p><strong>HTTP Base认证：通过用户名+密码的方式认证</strong></p>
<ul>
<li><strong>用户名+密码：用BASE64算法进行编码后的字符串放在HTTP Request中的Header Authorization域里发送给服务端，服务端收到后进行编码，获取用户名及密码</strong></li>
</ul>
</li>
<li><p><strong>最严格的的HTTPS证书认证：基于CA根证书签名的客户端身份认证方式</strong></p>
</li>
</ul>
<h3 id="1-HTTPS证书认证"><a href="#1-HTTPS证书认证" class="headerlink" title="1 HTTPS证书认证"></a>1 HTTPS证书认证</h3><p><img src="/assets/image-20200205003528539.png" alt="image-20200205003528539"></p>
<h3 id="2-需要认证的节点"><a href="#2-需要认证的节点" class="headerlink" title="2 需要认证的节点"></a>2 需要认证的节点</h3><p><img src="/assets/image-20200205003718595.png" alt="image-20200205003718595"></p>
<p>两种类型：</p>
<ul>
<li><strong>kubernetes组件对API Server的访问：kubectl、Controller Manager、Scheduler、kubetlet、kube-proxy</strong></li>
<li><strong>kubernetes管理的Pod对容器的访问：Pod（dashboard也是以Pod形式运行）</strong></li>
</ul>
<p>安全性说明</p>
<ul>
<li><strong>Controller Manager、Scheduler与API Server在同一台机器，所以直接使用API Server的非安全接口访问，<code>--insecure-bind-address=127.0.0.1</code></strong></li>
<li><strong>kubectl、kubelet、kube-proxy访问API Server就都需要证书进行HTTPS双向认证</strong></li>
</ul>
<p>证书颁发</p>
<p>手动签发：通过K8s集群的跟CA进行签发HTTPS证书</p>
<p>自动签发：kubelet首次访问API Server时，使用token做认证，通过后，Controller Manager会为kubelet生成一个证书，以后的访问都是用证书做认证了</p>
<h3 id="3-kubeconfig"><a href="#3-kubeconfig" class="headerlink" title="3 kubeconfig"></a>3 kubeconfig</h3><p>kubeconfig文件包含集群参数（CA证书、API Server地址），客户端参数（上面生成的证书和私钥），集群context信息（集群名称、用户名）。kubernetes组件通过启动时指定不同的kubeconfig文件可以切换不同的集群</p>
<h3 id="4-ServiceAccount"><a href="#4-ServiceAccount" class="headerlink" title="4 ServiceAccount"></a>4 ServiceAccount</h3><p>Pod中的容器访问API Server。因为Pod的创建、销毁是动态的，所以要为它手动生成证书就不可行了。kubernetes使用了Service Account解决了Pod访问API Server的认证问题</p>
<h3 id="5-Secret与SA的关系"><a href="#5-Secret与SA的关系" class="headerlink" title="5 Secret与SA的关系"></a>5 Secret与SA的关系</h3><p>Kubernetes设计了一种资源对象叫做Secret，分为两类，一种是用于ServiceAccount的service-account-token，另一种是用于保存用户自定义保密信息的Opaque。ServiceAccount中用到包含三个部分：Token、ca,crt、namespace</p>
<ul>
<li><strong>token是使用API Server私钥签名的JWT。用于访问API Server时，API Server端认证</strong></li>
<li><strong>ca.crt，根证书。用于Client端验证API Server发送的证书</strong></li>
<li><strong>namespace，表示这个service-account-token的作用域名空间</strong></li>
</ul>
<!--Json web token(JWT)，是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准（[RFC 7519]），该token被设计为紧凑且安全的，特别适合用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密-->

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get secret --all-namespaces</span><br><span class="line">kubectl describe secret default-token -xxx --namespeca=kube-system</span><br></pre></td></tr></table></figure>

<p>默认情况下，每个namespace都会有一个ServiceAccount，如果Pod在创建时没有指定ServiceAccount，就会使用Pod所属的namespace的ServiceAccount</p>
<!--默认挂载目录： /run/secrets/kubernetes.io/serviceaccount/-->



<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="/assets/image-20200205010502453.png" alt="image-20200205010502453"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（25）：集群安全-鉴权</title>
    <url>/2020/01/09/25_%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8-%E9%89%B4%E6%9D%83/</url>
    <content><![CDATA[<p>!–<a href="https://kubernetes.io/docs/tasks/--">https://kubernetes.io/docs/tasks/--</a></p>
<h2 id="Authorization"><a href="#Authorization" class="headerlink" title="Authorization"></a>Authorization</h2><p>上面认证过程，只是确认通信的双方都确认了对方是可信的，可以互相通信。而鉴权是确定请求方有哪些资源权限。API Server目前支持以下几种授权策略（通过API Server的启动参数”–authorization-mode”设置）</p>
<ul>
<li><strong>AlwaysDeny：表示拒绝所有的请求，一般用于测试</strong></li>
<li><strong>AlwaysAllow：允许接收所有请求，如果集群不需要授权流程，则可以采用该策略</strong></li>
<li><strong>ABAC(Attribute-Based Access Control)：基于属性的访问控制，表示使用用户配置的授权规对用户请求进行匹配和控制（老版本中用的，需要配置多个规则，不能及时修改生效，已经淘汰）</strong></li>
<li><strong>Webbook：通过调用外部REST服务队用户进行授权</strong></li>
<li><strong>RBAC（Role-Based Access Control）：基于角色的访问控制，现行默认规则</strong></li>
</ul>
<h2 id="RBAC授权模式"><a href="#RBAC授权模式" class="headerlink" title="RBAC授权模式"></a>RBAC授权模式</h2><p>RBAC（Role-Based Access Control）基于角色的访问控制，在kubernetes1.5中引入，现行版本称为默认标准。相对其它访问控制方法，拥有以下优势：</p>
<ul>
<li><strong>对集群中的资源和非资源均拥有完整非覆盖</strong></li>
<li><strong>整个RBAC完全由几个API对象完成，同其它API对象一样，可以用kubectl或API进行操作</strong></li>
<li><strong>可以在运行时进行调整，无需重启API Server</strong></li>
</ul>
<h3 id="1-RBAC的API资源对象说明"><a href="#1-RBAC的API资源对象说明" class="headerlink" title="1 RBAC的API资源对象说明"></a>1 RBAC的API资源对象说明</h3><p>RBAC引入了4个新的顶级资源对象：Role、ClusterRole、RoleBinding、ClusterRoleBinding，4种对象类型均可以通过kubectl与API操作</p>
<p><img src="/assets/image-20200205120031518.png" alt="image-20200205120031518"></p>
<p>需要注意的是Kubernetes并不会提供用户管理，那么User、Group、ServiceAccount指定的用户又是从哪里来的呢？kubernetes组件（kubectl、kube-proxy）或是其他自定义的用户在向CA申请证书时，需要提供一个证书请求文件</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;CN&quot;</span>: <span class="string">&quot;admin&quot;</span>, </span><br><span class="line">    <span class="attr">&quot;hosts&quot;</span>: [],</span><br><span class="line">    <span class="attr">&quot;key&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;algo&quot;</span>: <span class="string">&quot;rsa&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;size&quot;</span>: <span class="number">2048</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;names&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;c&quot;</span>: <span class="string">&quot;CN&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;ST&quot;</span>: <span class="string">&quot;HangZhou&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;L&quot;</span>: <span class="string">&quot;XS&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;O&quot;</span>: <span class="string">&quot;system:masters&quot;</span>, </span><br><span class="line">            <span class="attr">&quot;OU&quot;</span>: <span class="string">&quot;System&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>API Server会把客户端证书的<code>CN</code>字段作为User，吧<code>names.O</code>字段作为Group</p>
<p>kubelet使用TLS Bootstraping认证时，API Server可以使用BootStrap token或token authentication file验证=token，无论是哪一种，kubernetes都会为token绑定一个默认的User和Group</p>
<p>Pod使用ServiceAccount认证时，service-account-token中的JWT会保存User信息</p>
<p>有了用户信息，再创建一对角色/角色绑定（集群角色/集群角色绑定）资源对象，就可以完成权限绑定了</p>
<h2 id="Role-and-ClusterRole"><a href="#Role-and-ClusterRole" class="headerlink" title="Role and ClusterRole"></a>Role and ClusterRole</h2><p>在RBAC API中，Role表示一组规则权限，权限只会增加（累加权限），不存在一个资源一开始就拥有很多权限而通过RBAC对其进行减少的操作；Role可以定义在一个namespace中，如果想要跨namespace则可以创建ClusterRole</p>
<p>Role</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1.beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>] <span class="comment"># &quot;&quot; indicates the core API group</span></span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="string">verbs：</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure>



<p>ClusterRole具有与Role相同的权限角色控制能力，不同的是ClusterRole是集群级别的，ClusterRole可以用于：</p>
<ul>
<li><strong>集群级别的资源控制（例如node访问权限）</strong></li>
<li><strong>非资源型endpoints（例如<code>/healthz</code>访问）</strong></li>
<li><strong>所有命名空间资源控制（例如pods）</strong></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="comment"># &quot;namespace&quot; omitted since ClusterRoles are not namespaced</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;secrets&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure>





<h2 id="RoleBinding-and-ClusterRoleBinding"><a href="#RoleBinding-and-ClusterRoleBinding" class="headerlink" title="RoleBinding and ClusterRoleBinding"></a>RoleBinding and ClusterRoleBinding</h2><p>RoleBinding可以将角色中定义的权限授予用户或用户组，RoleBinding包含一组权限列表（subjects），权限列表中包含有不同形式的待授予权限资源类型（users，groups，or service accounts）；RoleBinding同样包含对被Bind的Role引用；RoleBinding适用于某个命名空间内授权，而ClusterRoleBinding适用于集群范围内的授权</p>
<p>将default命名空间的<code>pod-reader</code>Role授予jane用户，此后Jane用户在default命名空间中将具有<code>pod-reader</code>的权限</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersioN:</span> <span class="string">rbac.authorization.kubernetes.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">read-pods</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">jane</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<p>RoleBinding同样可以引用ClusterRole来对当前namespace内用户、用户组或ServiceAccount进行授权，这种操作允许集群管理员在整个集群内定义一些通用的ClusterRole，然后在不同的namespace中使用RoleBinding来引用</p>
<p>例如，一下RoleBinding引用了一个ClusterRole，这个ClusterRole具有整个集群内对secrets的访问权限；但是其授权用户<code>dave</code>只能访问development空间中的secrets（因为RoleBinding定义在development命名空间）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This role binding allows &quot;dave&quot; to read secrets in the &quot;development&quot; namespace</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">read-secrets</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">development</span> <span class="comment"># This only grants permissions within the &quot;development&quot; namesapce</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dave</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<p>使用ClusterRoleBinding可以对整个集群中的所有命名空间资源权限进行授权；以下ClusterRoleBinding示例展示了授权manager组内所有用户在全部命名空间中对secrets进行访问</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This cluster role binding allows anyone in the &quot;manager&quot; group to read secrets in any namespace.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">read-secrets-global</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">manager</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorizatoin.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>



<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><p>Kubernetes集群内一些资源一般以其名称字符串来表示，这些字符串一般会在API的URL地址中出现；同时某些资源也会包含子资源，例如logs资源就属于pods的子资源，API中URL样例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;&#123;namespace&#125;&#x2F;pods&#x2F;&#123;name&#125;&#x2F;log</span><br></pre></td></tr></table></figure>

<p>如果要在RBAC授权模型中控制这些子资源的访问权限，可以通过<code>/</code>分隔符来实现，以下是定义一个pod子资源logs访问权限的Role定义样例</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-and-pod-logs-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>, <span class="string">&quot;pods/log&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>]</span><br></pre></td></tr></table></figure>



<h2 id="to-Subjects"><a href="#to-Subjects" class="headerlink" title="to Subjects"></a>to Subjects</h2><p>RoleBinding和ClusterRoleBinding可以将Role绑定到Subjects；Subjects可以是groups、users或者service account</p>
<p>Subjects中Users使用字符串表示，它可以是一个普通的名字字符串，如“alice”；也可以是email格式的邮箱地址，如“<a href="mailto:&#116;&#101;&#115;&#116;&#x40;&#49;&#x36;&#51;&#46;&#x63;&#111;&#x6d;">&#116;&#101;&#115;&#116;&#x40;&#49;&#x36;&#51;&#46;&#x63;&#111;&#x6d;</a>”；甚至是一组字符串形式的数字ID。但是Users的前缀system：是系统保留的，集群管理员应该确保普通用户不会使用这个前缀格式</p>
<p>Groups书写格式与Users相同，都为一个字符串，并且没有特定的格式要求；同样system：前缀为系统保留</p>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h3 id="创建一个用户只能管理dev空间"><a href="#创建一个用户只能管理dev空间" class="headerlink" title="创建一个用户只能管理dev空间"></a>创建一个用户只能管理dev空间</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 需要先手动创建用户，useradd devuser &amp;&amp; passwd devuser</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;CN&quot;</span>:  <span class="string">&quot;devuser&quot;</span>,</span><br><span class="line">    <span class="string">&quot;hosts&quot;</span>: [],			// 这里不写的话表示对所有节点有效？</span><br><span class="line">    <span class="string">&quot;key&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;algo&quot;</span>: <span class="string">&quot;rsa&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;names&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;C&quot;</span>: <span class="string">&quot;CN&quot;</span>,</span><br><span class="line">            <span class="string">&quot;ST&quot;</span>: <span class="string">&quot;BeiJing&quot;</span>,</span><br><span class="line">            <span class="string">&quot;L&quot;</span>: <span class="string">&quot;BeiJing&quot;</span>,</span><br><span class="line">            <span class="string">&quot;O&quot;</span>: <span class="string">&quot;k8s&quot;</span>,</span><br><span class="line">            <span class="string">&quot;OU&quot;</span>: <span class="string">&quot;System&quot;</span>			//这里不能有逗号，不然报错哦</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mkdir cert</span><br><span class="line"><span class="built_in">cd</span> cert</span><br><span class="line">vim devuser-csr.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载证书生成工具</span></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">mv cfssl_linux-amd64 /usr/<span class="built_in">local</span>/bin/cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">mv cfssljson_linux-amd64 /usr/<span class="built_in">local</span>/bin/cfssljson</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line">mv cfssl-certinfo_linux-amd64 /usr/<span class="built_in">local</span>/bin/cfssl-certinfo</span><br><span class="line">chmod a+x /usr/<span class="built_in">local</span>/bin/cfssl*</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /etc/kubernetes/pki/</span><br><span class="line">cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes /root/cert/devuser-csr.json | cfssljson -bare devuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置集群参数</span></span><br><span class="line"><span class="built_in">export</span> KUBE_APISERVER=<span class="string">&quot;https://192.168.128.140:6443&quot;</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">--certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">--embed-certs=<span class="literal">true</span> \</span><br><span class="line">--server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"><span class="comment"># 视频上这里--certificate-authority参数不一样</span></span><br><span class="line"><span class="comment"># kubectl config set-cluster kubernetes \</span></span><br><span class="line">--certificate-authority=/etc/kubernetes/pki/ca.crt \</span><br><span class="line">--embed-certs=<span class="literal">true</span> \</span><br><span class="line">--server=<span class="variable">$&#123;KUBE_APISERVER&#125;</span> \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials devuser \</span><br><span class="line">--client-certificate=/etc/kubernetes/ssl/devuser.pem \</span><br><span class="line">--client-key=/etc/kubernetes/ssl/devuser-key.pem \</span><br><span class="line">--embed-certs=<span class="literal">true</span> \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"><span class="comment">## 参考视频</span></span><br><span class="line"><span class="comment"># kubectl config set-credentials devuser \</span></span><br><span class="line">--client-certificate=/etc/kubernetes/pki/devuser.pem \</span><br><span class="line">--client-key=/etc/kubernetes/pki/devuser-key.pem \</span><br><span class="line">--embed-certs=<span class="literal">true</span> \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置上下文参数，就是帮我们绑定至某一个名称空间，这里需要先创建名称空间</span></span><br><span class="line"><span class="comment">## kubectl create namespace dev</span></span><br><span class="line">kubectl config set-context kubernetes \</span><br><span class="line">--cluster=kubernetes \</span><br><span class="line">--user=devuser \</span><br><span class="line">--namespace=dev \</span><br><span class="line">--kubeconfig=devuser.kubeconfig </span><br><span class="line"></span><br><span class="line"><span class="comment">## 先设置RoleBinding，admin就是最高权限，这里的意思就是，在dev名称空间下，devuser能为所欲为</span></span><br><span class="line">kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 复制配置文件信息至.kube</span></span><br><span class="line">cp -f ./devuser.kubeconfig /root/.kube/config</span><br><span class="line"><span class="comment"># 视频中复制到了 /home/devuser/.kube/</span></span><br><span class="line">cp -f ./devuser.kubeconfig /home/devuser/.kube/</span><br><span class="line">chown devuser:devuser /home/devuser/.kube/devuser.kubeconfig</span><br><span class="line"><span class="comment"># 用devuser用户修改配置文件为config</span></span><br><span class="line">mv devuser.kubeconfig config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置默认上下文</span></span><br><span class="line">kubectl config use-context kubernetes --kubeconfig=devuser.kubeconfig</span><br><span class="line"><span class="comment"># ，视频中是在devuser用户下切换的</span></span><br><span class="line">kubectl config use-context kubernetes --kubeconfig=config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用devuser用户创建个pod</span></span><br><span class="line">kubectl run nginx --image=hub.test.com/library/myapp:v1</span><br><span class="line">kubectl get pods</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（26）：集群安全-准入控制</title>
    <url>/2020/01/09/26_%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8-%E5%87%86%E5%85%A5%E6%8E%A7%E5%88%B6_/</url>
    <content><![CDATA[<h2 id="准入控制"><a href="#准入控制" class="headerlink" title="准入控制"></a>准入控制</h2><p>准入控制是API Server的插件集合，通过添加不同的插件，实现额外的准入控制规则。甚至于API Server的一些主要的功能都需要通过Admission Controllers（准许进入控制）实现，比如ServiceAccount</p>
<p>官方文档上有一份针对不同banbend准入控制器推荐列表，其中最新的1.14的推荐列表是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NamespaceLifecycle</span><br><span class="line">LimitRanger</span><br><span class="line">ServiceAccount</span><br><span class="line">DefaultStorageClass</span><br><span class="line">DefaultTolerationSeconds</span><br><span class="line">MutatingAdmissionWebhook</span><br><span class="line">ValidatingAdmissionWebhook</span><br><span class="line">ResourceQuota</span><br></pre></td></tr></table></figure>



<p>列举几个插件的功能：</p>
<ul>
<li><strong>NamespaceLifecycle：防止在不存在的namespace上创建对象，防止删除系统预置的namespace。删除namespace时，连带删除它的所有资源对象</strong></li>
<li><strong>LimitRanger：确保请求的资源不会超过资源所在Namespace的LimitRanger的限制</strong></li>
<li><strong>ServiceAccount：实现了自动化添加ServiceAccount</strong></li>
<li><strong>ResourceQuota：确保请求的资源不会超过资源的ResourceQuota限制</strong></li>
</ul>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（27）：部署Helm</title>
    <url>/2020/01/11/27_%E9%83%A8%E7%BD%B2Helm/</url>
    <content><![CDATA[<p><a href="https://github.com/helm/helm/blob/master/docs/charts.md">https://github.com/helm/helm/blob/master/docs/charts.md</a></p>
<h2 id="什么是Helm"><a href="#什么是Helm" class="headerlink" title="什么是Helm"></a>什么是Helm</h2><p>在没使用Helm之前，向kubernetes部署应用，我们要依次部署deployment、svc等，步骤较繁琐，况且随着很多项目微服务化，复杂的应用在容器中部署以及管理显得较为复杂，helm通过打包的方式，<strong>支持发布的版本管理和控制</strong>，很大程度上简化了kubernetes应用的部署和管理</p>
<p>Helm本质就是让k8s的应用管理（deployment，service等）可配置，能动态生成。通过动态生成k8s清单文件（deploy.yaml，svc.yaml）。然后调用kubectl自动执行k8s资源部署</p>
<p>Helm是官方提供的类似于YUM的包管理器，是部署环境的流程封装。Helm有两个重要的概念：chart和release</p>
<ul>
<li><strong>chart是创建一个应用的信息集合，包括各种kubernetes对象的配置模板、参数定义、依赖关系、文档说明等。chart是应用部署的自包含逻辑单元。可以将chart想象成apt、yum中的软件安装包</strong></li>
<li><strong>release是chart的运行实例，代表了一个正在运行的应用。当chart被安装到kubernetes集群，就生成一个release。chart能够多次安装到同一个集群，每次安装都是一个release</strong></li>
</ul>
<p>Helm包含两个组件：Helm客户端和Tiller服务器，如下图所示</p>
<p><img src="/assets/image-20200205181419004.png" alt="image-20200205181419004"></p>
<p>Helm客户端负责chart和release的创建和管理以及和TIller的交互</p>
<p>Tiller服务器运行在kubernetes集群中，它会处理Helm客户端的请求，与kubernetes API Server交互</p>
<h2 id="Helm部署"><a href="#Helm部署" class="headerlink" title="Helm部署"></a>Helm部署</h2><p>越来越多的公司和团队开始使用Helm这个kubernetes的包管理器，我们也将使用Helm安装kubernetes的常用组件。Helm由客户端helm命令行工具和服务端tiller组成，Helm的安装十分简单。下载helm命令行工具到master节点node1的/usr/local/bin下，这里下载的2.13.1版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ntpdate ntp1.aliyun.com</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># k8s1.15版本用的2.13.1没问题，k8s1.17版本用2.13报错，用2.16不报错</span></span></span><br><span class="line">wget https://storage.googleapis.com/kubernetes-helm/helm-v2.13.1-linux-amd64.tar.gz</span><br><span class="line">tar -zxvf helm-v2.13.1-amd64.tar.gz</span><br><span class="line">cd linux-amd64</span><br><span class="line">cp helm /usr/local/bin/</span><br></pre></td></tr></table></figure>

<p>为了安装服务端tiller，还需要在这台机器上配置好kubectl工具和kubeconfig文件，确保kubectl工具可以在这台机器上访问apiserver且正常使用。这里的node1节点以及配置好了kubectl</p>
<p>因为kubernetes APIServer开启了RBAC访问控制，所以需要创建tiller使用的serviceaccount:tiller并分配合适的角色给它。详细内容可以查看helm文档中的<a href="https://docs.helm.sh/using_helm/#role-based-access-control">Role-based Access Control</a>。这里简单起见直接分配cluster-admin这个集群内置的ClusterRole给它。创建rbac-config.yaml文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@k8s-master helm]# kubectl create-f rbac-config.yaml</span><br><span class="line">serviceaccount/tiller created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/tiller created</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 或者直接使用命令行创建rbac</span></span><br><span class="line">kubectl -n kube-system create serviceaccount tiller</span><br><span class="line">kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller</span><br></pre></td></tr></table></figure>



<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">helm</span>]<span class="comment"># helm init --service-account tiller --skip-refresh</span></span><br><span class="line">Creating /root/.helm </span><br><span class="line">Creating /root/.helm/repository </span><br><span class="line">Creating /root/.helm/repository/cache </span><br><span class="line">Creating /root/.helm/repository/local </span><br><span class="line">Creating /root/.helm/plugins </span><br><span class="line">Creating /root/.helm/starters </span><br><span class="line">Creating /root/.helm/cache/archive </span><br><span class="line">Creating /root/.helm/repository/repositories.yaml </span><br><span class="line">Adding stable repo with URL: https://kubernetes<span class="literal">-charts</span>.storage.googleapis.com </span><br><span class="line">Adding local repo with URL: http://<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">8879</span>/charts </span><br><span class="line"><span class="variable">$HELM_HOME</span> has been configured at /root/.helm.</span><br><span class="line"></span><br><span class="line">Tiller (the Helm server<span class="literal">-side</span> component) has been installed into your Kubernetes Cluster.</span><br><span class="line"></span><br><span class="line">Please note: by default, Tiller is deployed with an insecure <span class="string">&#x27;allow unauthenticated users&#x27;</span> policy.</span><br><span class="line">To prevent this, run `helm init` with the -<span class="literal">-tiller</span><span class="literal">-tls</span><span class="literal">-verify</span> flag.</span><br><span class="line"><span class="keyword">For</span> more information on securing your installation see: https://docs.helm.sh/using_helm/<span class="comment">#securing-your-helm-installation</span></span><br><span class="line">Happy Helming!</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">helm</span>]<span class="comment"># kubectl get pods -n kube-system -l app=helm</span></span><br><span class="line">NAME                                 READY   STATUS             RESTARTS   AGE</span><br><span class="line">tiller<span class="literal">-deploy</span><span class="literal">-58565b5464</span><span class="literal">-57xjr</span>       <span class="number">0</span>/<span class="number">1</span>     ImagePullBackOff   <span class="number">0</span>          <span class="number">72</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment">## 镜像下载失败，查看是哪个镜像</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">helm</span>]<span class="comment"># kubectl describe pod tiller-deploy-58565b5464-57xjr -n kube-system</span></span><br><span class="line">...</span><br><span class="line">...省略</span><br><span class="line">...</span><br><span class="line">  Normal   BackOff    <span class="number">72</span>s (x6 over <span class="number">3</span>m37s)  kubelet, k8s<span class="literal">-node02</span>  Back<span class="literal">-off</span> pulling image <span class="string">&quot;gcr.io/kubernetes-helm/tiller:v2.13.1&quot;</span></span><br><span class="line">  Warning  Failed     <span class="number">61</span>s (x7 over <span class="number">3</span>m37s)  kubelet, k8s<span class="literal">-node02</span>  Error: ImagePullBackOff</span><br><span class="line"></span><br><span class="line"><span class="comment">## 下载阿里docker镜像，参考https://www.jianshu.com/p/423a2b19272a</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">node02</span> <span class="type">test</span>]<span class="comment"># docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.13.1</span></span><br><span class="line">v2.<span class="number">13.1</span>: Pulling from google_containers/tiller</span><br><span class="line"><span class="number">5</span>d20c808ce19: Pull complete </span><br><span class="line"><span class="number">43339</span>c468bb6: Pull complete </span><br><span class="line">d6d696e230df: Pull complete </span><br><span class="line"><span class="number">9</span>cf2c942cf64: Pull complete </span><br><span class="line">Digest: sha256:d52b34a9f9aeec1cf74155ca51fcbb5d872a705914565c782be4531790a4ee0e</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/tiller:v2.<span class="number">13.1</span></span><br><span class="line">registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/tiller:v2.<span class="number">13.1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 修改tag</span></span><br><span class="line">docker tag registry.cn<span class="literal">-hangzhou</span>.aliyuncs.com/google_containers/tiller:v2.<span class="number">13.1</span> gcr.io/kubernetes<span class="literal">-helm</span>/tiller:v2.<span class="number">13.1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">helm</span>]<span class="comment"># helm version</span></span><br><span class="line">Client: &amp;version.Version&#123;SemVer:<span class="string">&quot;v2.13.1&quot;</span>, GitCommit:<span class="string">&quot;618447cbf203d147601b4b9bd7f8c37a5d39fbb4&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:<span class="string">&quot;v2.13.1&quot;</span>, GitCommit:<span class="string">&quot;618447cbf203d147601b4b9bd7f8c37a5d39fbb4&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>tiller默认被部署在k8s集群中的kube-system这个namespace下</p>
<h2 id="Helm-自定义模板"><a href="#Helm-自定义模板" class="headerlink" title="Helm 自定义模板"></a>Helm 自定义模板</h2><p>Helm官网已经有为使用者打包好的模板，地址：<a href="https://hub.helm.sh/">https://hub.helm.sh/</a></p>
<p>也可以自己制作模板</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建文件夹</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir ./hello-world</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /hello-world</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建自描述文件 Chart.yaml，这个文件必须有name和version定义</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt; <span class="string">EOF &gt; ./Chart.yaml</span></span></span><br><span class="line">name: hello-world</span><br><span class="line">version: 1.0.0</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建模板文件，用于生成kubernetes资源清单(manifests)</span></span><br><span class="line"><span class="string">$</span> <span class="string">mkdir</span> <span class="string">./templates</span></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">./templates/deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">hello-world</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">./templates/service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">hello-world</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br></pre></td></tr></table></figure>

<p>这里可以有很多个yaml，全部都会执行</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用命令 helm install RELATIVE_PATH_TO_CHART 创建一次Release</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">hello</span>-<span class="type">world</span>]<span class="comment"># helm install .</span></span><br><span class="line">NAME:   ho<span class="built_in">ping-alpaca</span></span><br><span class="line">LAST DEPLOYED: Thu Feb  <span class="number">6</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">06</span> <span class="number">2020</span></span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                         READY  STATUS             RESTARTS  AGE</span><br><span class="line">hello<span class="literal">-world</span><span class="literal">-f75c8749b</span><span class="literal">-kg78f</span>  <span class="number">0</span>/<span class="number">1</span>    ContainerCreating  <span class="number">0</span>         <span class="number">0</span>s</span><br><span class="line">hello<span class="literal">-world</span><span class="literal">-f75c8749b</span><span class="literal">-vhgjc</span>  <span class="number">0</span>/<span class="number">1</span>    ContainerCreating  <span class="number">0</span>         <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME         <span class="built_in">TYPE</span>      CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>  PORT(S)       AGE</span><br><span class="line">hello<span class="literal">-world</span>  NodePort  <span class="number">10.106</span>.<span class="number">106.148</span>  &lt;none&gt;       <span class="number">80</span>:<span class="number">32202</span>/TCP  <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME         READY  UP<span class="literal">-TO</span><span class="literal">-DATE</span>  AVAILABLE  AGE</span><br><span class="line">hello<span class="literal">-world</span>  <span class="number">0</span>/<span class="number">2</span>    <span class="number">0</span>           <span class="number">0</span>          <span class="number">0</span>s</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 列出已经部署的Release</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">hello</span>-<span class="type">world</span>]<span class="comment"># helm ls</span></span><br><span class="line">NAME         	REVISION	UPDATED                 	STATUS  	CHART            	APP VERSION	NAMESPACE</span><br><span class="line">ho<span class="built_in">ping-alpaca</span>	<span class="number">1</span>       	Thu Feb  <span class="number">6</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">06</span> <span class="number">2020</span>	DEPLOYED	hello<span class="literal">-world</span><span class="literal">-1</span>.<span class="number">0.0</span>	           	default  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询一个特定的Release的状态</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">hello</span>-<span class="type">world</span>]<span class="comment"># helm status hoping-alpaca</span></span><br><span class="line">LAST DEPLOYED: Thu Feb  <span class="number">6</span> <span class="number">01</span>:<span class="number">00</span>:<span class="number">06</span> <span class="number">2020</span></span><br><span class="line">NAMESPACE: default</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                         READY  STATUS   RESTARTS  AGE</span><br><span class="line">hello<span class="literal">-world</span><span class="literal">-f75c8749b</span><span class="literal">-kg78f</span>  <span class="number">1</span>/<span class="number">1</span>    Running  <span class="number">0</span>         <span class="number">50</span>s</span><br><span class="line">hello<span class="literal">-world</span><span class="literal">-f75c8749b</span><span class="literal">-vhgjc</span>  <span class="number">1</span>/<span class="number">1</span>    Running  <span class="number">0</span>         <span class="number">50</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME         <span class="built_in">TYPE</span>      CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>  PORT(S)       AGE</span><br><span class="line">hello<span class="literal">-world</span>  NodePort  <span class="number">10.106</span>.<span class="number">106.148</span>  &lt;none&gt;       <span class="number">80</span>:<span class="number">32202</span>/TCP  <span class="number">50</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME         READY  UP<span class="literal">-TO</span><span class="literal">-DATE</span>  AVAILABLE  AGE</span><br><span class="line">hello<span class="literal">-world</span>  <span class="number">2</span>/<span class="number">2</span>    <span class="number">2</span>           <span class="number">2</span>          <span class="number">50</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除所有与这个Release相关的kubernetes资源</span></span><br><span class="line"><span class="variable">$</span> helm delete ho<span class="built_in">ping-alpaca</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># helm rollback RELEASE_NAME  REVISION_NUMBER</span></span><br><span class="line"><span class="variable">$</span> helm rollback ho<span class="built_in">ping-alpaca</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用helm delete --purge RELEASE_NAME 移除所有指定Release相关的kubernetes资源和所有这个Release的记录</span></span><br><span class="line"><span class="variable">$</span> helm  delete -<span class="literal">-purge</span> ho<span class="built_in">ping-alpaca</span></span><br><span class="line"><span class="variable">$</span> helm <span class="built_in">ls</span> -<span class="literal">-deleted</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改了yaml，更新此应用</span></span><br><span class="line">helm upgrade ho<span class="built_in">ping-alpaca</span> .</span><br></pre></td></tr></table></figure>

<p>知识点：</p>
<p>1 可以将关键点做成values</p>
<p>2 删除helm不会真的删除，（可通过<code>helm list --deleted</code>查看），无法再创建同名helm，后期可以rollback</p>
<p>3 真正删除需要加–purge</p>
<h3 id="可修改的helm"><a href="#可修改的helm" class="headerlink" title="可修改的helm"></a>可修改的helm</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 配置体现在配置文件 values.yaml</span></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">./values.yaml</span></span><br><span class="line"><span class="attr">image:</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">gcr.io/google-samples/node-hello</span></span><br><span class="line">  <span class="attr">tag:</span> <span class="string">&#x27;1.0&#x27;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个文件中定义的值，在模板文件中可以通过 .Values对象访问到</span></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">./templates/deployment.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">hello-world</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line">        <span class="attr">image:</span> &#123;&#123; <span class="string">.Values.image.repository</span> &#125;&#125;<span class="string">:&#123;&#123;</span> <span class="string">.Values.image.tag&#125;&#125;</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在values.yaml中的值可以被部署release时用到的参数 --values YAML_FILE_PATH 或 --set key1=value1, key2=value2覆盖掉</span></span><br><span class="line"><span class="string">$</span> <span class="string">helm</span> <span class="string">install</span> <span class="string">--set</span> <span class="string">image.tag=&#x27;latest&#x27;</span> <span class="string">.</span></span><br><span class="line"></span><br><span class="line"><span class="string">$</span> <span class="string">升级版本</span></span><br><span class="line"><span class="string">helm</span> <span class="string">upgrade</span> [<span class="string">-f</span> <span class="string">values.yaml</span>] <span class="string">test</span> <span class="string">.</span></span><br></pre></td></tr></table></figure>



<h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用模板动态生成k8s资源清单，非常需要能提前预览生成的结果</span></span><br><span class="line"><span class="comment"># 使用--dry-run --debug选项来打印出生成的清单文件内容，而不执行部署</span></span><br><span class="line">helm install . -<span class="literal">-dry</span><span class="literal">-run</span> -<span class="literal">-debug</span> -<span class="literal">-set</span> image.tag=latest</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（28）：使用Helm部署Dashboard</title>
    <url>/2020/01/11/28_%E4%BD%BF%E7%94%A8Helm%E9%83%A8%E7%BD%B2Dashboard/</url>
    <content><![CDATA[<p>手动部署kubernetes dashbord</p>
<h3 id="repo"><a href="#repo" class="headerlink" title="repo"></a>repo</h3><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 添加阿里镜像库</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">dashboard</span>]<span class="comment"># helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span></span><br><span class="line"><span class="string">&quot;stable&quot;</span> has been added to your repositories</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">dashboard</span>]<span class="comment"># helm repo list</span></span><br><span class="line">NAME  	URL                                                   </span><br><span class="line">stable	https://kubernetes.oss<span class="literal">-cn</span><span class="literal">-hangzhou</span>.aliyuncs.com/charts</span><br><span class="line">local 	http://<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">8879</span>/charts                          </span><br><span class="line"></span><br><span class="line"><span class="comment">## update</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">dashboard</span>]<span class="comment"># helm repo update</span></span><br><span class="line">Hang tight <span class="keyword">while</span> we grab the latest from your chart repositories...</span><br><span class="line">...Skip local chart repository</span><br><span class="line">...Successfully got an update from the <span class="string">&quot;stable&quot;</span> chart repository</span><br><span class="line">Update Complete. ⎈ Happy Helming!⎈ </span><br><span class="line"></span><br><span class="line"><span class="comment">## 下载dashboard模板</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">dashboard</span>]<span class="comment"># helm fetch stable/kubernetes-dashboard</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">dashboard</span>]<span class="comment"># ls</span></span><br><span class="line">kubernetes<span class="literal">-dashboard</span><span class="literal">-0</span>.<span class="number">6.0</span>.tgz</span><br><span class="line"><span class="comment">## 这里我通过阿里源下载的是0.6.0版本，视频上下载的是1.8.0版本</span></span><br></pre></td></tr></table></figure>





<p>创建values文件：kubernetes-dashboard.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">image:</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">k8s.gcr.io/kubernetes-dashboard-amd64</span>  </span><br><span class="line">  <span class="attr">tag:</span> <span class="string">v1.10.1</span></span><br><span class="line"><span class="attr">ingress:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">k8s.frognew.com</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">&quot;HTTPS&quot;</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">secretName:</span> <span class="string">frognew-com-tls-secret</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s.frognew.com</span></span><br><span class="line"><span class="attr">rbac:</span></span><br><span class="line">  <span class="attr">clusterAdminRole:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>google访问不了可以用阿里的镜像：registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64</p>
<p>开始安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">helm install stable/kubernetes-dashboard \</span><br><span class="line">-n kubernetes-dashboard \</span><br><span class="line">--namespace kube-system \</span><br><span class="line">-f kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl get pods -n kube-system |grep dashboard</span></span><br><span class="line">kubernetes<span class="literal">-dashboard</span><span class="literal">-78dff9db9</span><span class="literal">-8ksvv</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">86</span>s</span><br><span class="line"><span class="comment">## 查看ingress</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl get ingress -n kube-system</span></span><br><span class="line">NAME                   HOSTS             ADDRESS         PORTS     AGE</span><br><span class="line">kubernetes<span class="literal">-dashboard</span>   k8s.frognew.com   <span class="number">10.111</span>.<span class="number">109.71</span>   <span class="number">80</span>, <span class="number">443</span>   <span class="number">105</span>s</span><br><span class="line"><span class="comment">## 查看SVC</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl get ingress -n kube-system</span></span><br><span class="line">NAME                   HOSTS             ADDRESS         PORTS     AGE</span><br><span class="line">kubernetes<span class="literal">-dashboard</span>   k8s.frognew.com   <span class="number">10.111</span>.<span class="number">109.71</span>   <span class="number">80</span>, <span class="number">443</span>   <span class="number">105</span>s</span><br></pre></td></tr></table></figure>



<p>修改ClusterIP，改为NodePort</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl edit svc kubernetes-dashboard -n kube-system</span></span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看svc</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl get svc -n kube-system | grep dashboard</span></span><br><span class="line">kubernetes<span class="literal">-dashboard</span>   NodePort    <span class="number">10.98</span>.<span class="number">213.190</span>   &lt;none&gt;        <span class="number">443</span>:<span class="number">31448</span>/TCP            <span class="number">6</span>m10s</span><br></pre></td></tr></table></figure>



<p>web访问，获取dashboard的NodePort端口 31448  <a href="https://k8s-masterIP:NodePort">https://k8s-masterIP:NodePort</a></p>
<p>我这里就访问的是<a href="https://192.168.128.140:31448/">https://192.168.128.140:31448</a></p>
<p><img src="/assets/image-20200206022014657.png" alt="image-20200206022014657"></p>
<p>这里用Chrome浏览器打开会提示证书问题，解决方法：</p>
<ul>
<li><p><strong>1 导入<code>/etc/kubernetes/pki/ca.crt</code>证书到Chrome</strong>：这里我导入了，还是打不开，所以选择第二种方法</p>
</li>
<li><p><strong>2 下载Firefox浏览器</strong></p>
</li>
</ul>
<p><img src="/assets/image-20200206023134772.png" alt="image-20200206023134772"></p>
<p>获取令牌</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 查看secret名称</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl -n kube-system get secret|grep kubernetes-dashboard-token</span></span><br><span class="line">kubernetes<span class="literal">-dashboard</span><span class="literal">-token</span><span class="literal">-v59pk</span>                 kubernetes.io/service<span class="literal">-account</span><span class="literal">-token</span>   <span class="number">3</span>      <span class="number">23</span>m</span><br><span class="line"></span><br><span class="line"><span class="comment">## 获取token值</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kubernetes</span>-<span class="type">dashboard</span>]<span class="comment"># kubectl describe secret kubernetes-dashboard-token-v59pk  -n kube-system</span></span><br><span class="line">Name:         kubernetes<span class="literal">-dashboard</span><span class="literal">-token</span><span class="literal">-v59pk</span></span><br><span class="line">。。。</span><br><span class="line">。。。省略</span><br><span class="line">。。。</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi12NTlwayIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBkYWRjNTI1LWRjYjAtNGQ2MS04NTU1LTdhZTBkNmI2MjY3NSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.sBtxlso0oEwpoO8NF2HIX1da1Dm7o7yTZEpQBi0GaN7JiytC0eVZq<span class="literal">-KfefNGMgw4ATjLxtkfGsiCAIgFAeKBppOr</span><span class="literal">-mq_r0m6YYasiBY</span><span class="literal">-HSRuk_qAkQK</span><span class="literal">-XCMfUPzfFFcKIjND8sVpUmjrwUhkmMTqd_pw87tJjkclOvGam5cNZENWluu76S3scjcSp46dB2wYiifyjxtHKA7pAI8A8es</span><span class="literal">-_PYpcxTs4IXgGJBE8MZtimeBySSNe3IvXyBkPKbeThRWgVvpq_SdsUL0nUIPbIhxCfsGMdtPdU0BXthVhWcLPnQPEnIgsxmROpUraPwwLPz</span><span class="literal">-y</span><span class="literal">-cfr3SIjtJ7MK3O_7RaoQ</span></span><br></pre></td></tr></table></figure>

<p>将token复制到令牌处，即可登录dashboard</p>
<p><img src="/assets/image-20200206023535082.png" alt="image-20200206023535082"></p>
<p><img src="/assets/image-20200206023554685.png" alt="image-20200206023554685"></p>
<h2 id="通过dashboard创建一个应用"><a href="#通过dashboard创建一个应用" class="headerlink" title="通过dashboard创建一个应用"></a>通过dashboard创建一个应用</h2><p><img src="/assets/image-20200206023747586.png" alt="image-20200206023747586"></p>
<p><img src="/assets/image-20200206023909955.png" alt="image-20200206023909955"></p>
<p><img src="/assets/image-20200206023937022.png" alt="image-20200206023937022"></p>
<p><img src="/assets/image-20200206023951298.png" alt="image-20200206023951298"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（29）：使用Helm部署Prometheus</title>
    <url>/2020/01/11/29_%E4%BD%BF%E7%94%A8Helm%E9%83%A8%E7%BD%B2Prometheus/</url>
    <content><![CDATA[<h2 id="Prometheus架构"><a href="#Prometheus架构" class="headerlink" title="Prometheus架构"></a>Prometheus架构</h2><p>Prometheus是一个非常优秀的监控工具。准确的说，应该是监控方案。Prometheus提供数据收集、存储、处理、可视化和告警一套完整的解决方案</p>
<p><img src="assets/775365-20180607071724091-1886159463.png" alt="img"></p>
<ul>
<li><strong>Prometheus Server：负责数据采集和存储，并提供一套灵活的查询语言（PromQL）供用户使用</strong></li>
<li><strong>Exporter：Exporter负责收集目标对象（host、container）的性能数据，并通过HTTP接口供Prometheus Server获取</strong></li>
<li><strong>Grafana：可视化组件，能够与Prometheus无缝集成，提供完美的数据展示</strong></li>
<li><strong>Alertmanager：用户可以定义基于监控数据的告警规则，规则会触发告警。一旦Alertmanager收到告警，会通过预定义的方式高级功能通知。支持Email、PagerDuty、Webhook</strong></li>
</ul>
<h2 id="Prometheus-Operator架构"><a href="#Prometheus-Operator架构" class="headerlink" title="Prometheus Operator架构"></a>Prometheus Operator架构</h2><p>Prometheus Operator的目标是尽可能简化在k8s中部署和维护Prometheus的工作</p>
<p><img src="assets/775365-20180607071734743-1683096657.png" alt="img"></p>
<ul>
<li>Operator：Operator即Prometheus Operator，在k8s中以Deployment运行。其职责是部署和管理Prometheus Server，根据ServiceMonitor动态更新Prometheus Server的监控对象</li>
<li>Prometheus Server：Prometheus Server会作为K8s应用部署到集群中，为了更好的在k8s中管理Prometheus，CoreOS的开发人员专门定义了一个命名为<code>Prometheus</code>类型的k8s定制化资源，我们可以把<code>Prometheus</code>看做是一种特殊的Deployment，它的用途就是专门部署PrometheusServer</li>
<li>Service：这里的Service就是Cluster中的service资源，也是Prometheus要监控的对象，在Prometheus中叫做Target。每个监控对象都有一个对应的Service。比如要监控<code>kubernetes scheduler</code>，就有一个与Scheduler对应的Service。由Prometheus Operator负责创建</li>
<li>ServiceMonitor：Operator能够动态更新Prometheus的Target列表，ServiceMonitor就是Target的抽象。比如监控K8s Scheduler，用户可以创建一个与Scheduler Service相映射的ServiceMonitor对象。Operator则会发现新的ServiceMonitor，并将Scheduler的Target提阿南爱到Prometheus的监控列表中（ServiceMonitor也是PrometheusOperator专门开发的一种Kubernetes定制化资源类型）</li>
<li>Alertmanager：也是Operator开发的第三种kubernetes定制化资源，用途就是专门部署Alertmanager组件</li>
</ul>
<p>获取资源</p>
<p><img src="/assets/image-20200206114456130.png" alt="image-20200206114456130"></p>
<p>这个heapster在v1.12版本已经被移除，可以通过安装metrice-server来获取这个命令，也可以通过helm安装Prometheus来安装这个服务</p>
<h2 id="相关地址信息"><a href="#相关地址信息" class="headerlink" title="相关地址信息"></a>相关地址信息</h2><p>Prometheus GitHub 地址： <a href="https://github.com/coreos/kube-prometheus">https://github.com/coreos/kube-prometheus</a></p>
<h2 id="组件说明"><a href="#组件说明" class="headerlink" title="组件说明"></a>组件说明</h2><ul>
<li>1 MetricServer：是kubernetes集群资源使用情况的聚合器，收集数据给kubernetes集群内使用，如kubectl、HPA、scheduler等</li>
<li>2 PrometheusOperator：是一个系统检测和警报工具箱，用来存储监控数据</li>
<li>3 NodeExporter：用于各个node的关键度量指标状态数据</li>
<li>4 KubeStateMetrics：手机kubernetes集群内资源对象数据，指定告警规则</li>
<li>5 Prometheus：采用pull方式手机apiserver、scheduler、controller-manager、kubelet组件数据，通过http协议传输</li>
<li>6 Grafana：是可视化数据统计和监控平台</li>
</ul>
<h2 id="构建记录"><a href="#构建记录" class="headerlink" title="构建记录"></a>构建记录</h2><p>从GitHub上下载Prometheus</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">mkdir prometheus</span><br><span class="line"><span class="built_in">cd</span> prometheus</span><br><span class="line">git clone https://github.com/coreos/kube<span class="literal">-prometheus</span>.git</span><br><span class="line"><span class="built_in">cd</span> kube<span class="literal">-prometheus</span>/manifests/</span><br></pre></td></tr></table></figure>

<p>修改grafana-service.yaml文件，使用NodePort方式grafana：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">grafana-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">grafana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span>     <span class="comment">## 添加内容</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">3000</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30100</span>    <span class="comment"># 添加内容</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">grafana</span></span><br></pre></td></tr></table></figure>

<p>修改prometheus-service.yaml，改为NodePort</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">prometheus-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">prometheus:</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">prometheus-k8s</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">9</span><span class="number">-9</span><span class="bullet">-</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30200</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">prometheus</span></span><br><span class="line">    <span class="attr">prometheus:</span> <span class="string">k8s</span></span><br></pre></td></tr></table></figure>

<p>修改alertmanager-service.yaml，改为NodePort</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">alertmanager-service.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">alertmanager:</span> <span class="string">main</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">alertmanager-main</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">9093</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30300</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">alertmanager:</span> <span class="string">main</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">alertmanager</span></span><br></pre></td></tr></table></figure>

<p>安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f ..&#x2F;manifests&#x2F;setup&#x2F;</span><br><span class="line">kubectl apply -f ..&#x2F;manifests&#x2F;</span><br><span class="line">多执行几次，一定要指定目录，不能用&#x2F;*，这里坑了我好久，我还以为我下载的包不对</span><br></pre></td></tr></table></figure>

<p>查看</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">manifests</span>]<span class="comment"># kubectl get pods -n monitoring</span></span><br><span class="line">NAME                                   READY   STATUS              RESTARTS   AGE</span><br><span class="line">alertmanager<span class="literal">-main</span><span class="literal">-0</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">alertmanager<span class="literal">-main</span><span class="literal">-1</span>                    <span class="number">0</span>/<span class="number">2</span>     Terminating         <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">alertmanager<span class="literal">-main</span><span class="literal">-2</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">grafana<span class="literal">-697c9fc764</span><span class="literal">-l5s48</span>               <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">kube<span class="literal">-state</span><span class="literal">-metrics</span><span class="literal">-6df7855645</span><span class="literal">-nqz2v</span>    <span class="number">3</span>/<span class="number">3</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">node<span class="literal">-exporter</span><span class="literal">-c6vzw</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">node<span class="literal">-exporter</span><span class="literal">-dj5bx</span>                    <span class="number">0</span>/<span class="number">2</span>     ContainerCreating   <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">node<span class="literal">-exporter</span><span class="literal">-gr62p</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-adapter</span><span class="literal">-5948989dcf</span><span class="literal">-hjd4l</span>    <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-k8s</span><span class="literal">-0</span>                       <span class="number">3</span>/<span class="number">3</span>     Running             <span class="number">1</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-k8s</span><span class="literal">-1</span>                       <span class="number">0</span>/<span class="number">3</span>     Terminating         <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-operator</span><span class="literal">-85dc59d49b</span><span class="literal">-qp5dq</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">manifests</span>]<span class="comment"># kubectl get pods -n monitoring</span></span><br><span class="line">NAME                                   READY   STATUS              RESTARTS   AGE</span><br><span class="line">alertmanager<span class="literal">-main</span><span class="literal">-0</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">alertmanager<span class="literal">-main</span><span class="literal">-1</span>                    <span class="number">0</span>/<span class="number">2</span>     Terminating         <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">alertmanager<span class="literal">-main</span><span class="literal">-2</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">grafana<span class="literal">-697c9fc764</span><span class="literal">-l5s48</span>               <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">kube<span class="literal">-state</span><span class="literal">-metrics</span><span class="literal">-6df7855645</span><span class="literal">-nqz2v</span>    <span class="number">3</span>/<span class="number">3</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">node<span class="literal">-exporter</span><span class="literal">-c6vzw</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">node<span class="literal">-exporter</span><span class="literal">-dj5bx</span>                    <span class="number">0</span>/<span class="number">2</span>     ContainerCreating   <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">node<span class="literal">-exporter</span><span class="literal">-gr62p</span>                    <span class="number">2</span>/<span class="number">2</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-adapter</span><span class="literal">-5948989dcf</span><span class="literal">-hjd4l</span>    <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-k8s</span><span class="literal">-0</span>                       <span class="number">3</span>/<span class="number">3</span>     Running             <span class="number">1</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-k8s</span><span class="literal">-1</span>                       <span class="number">0</span>/<span class="number">3</span>     Terminating         <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">prometheus<span class="literal">-operator</span><span class="literal">-85dc59d49b</span><span class="literal">-qp5dq</span>   <span class="number">1</span>/<span class="number">1</span>     Running             <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">manifests</span>]<span class="comment"># kubectl top node</span></span><br><span class="line">NAME         CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%     </span><br><span class="line">k8s<span class="literal">-master</span>   <span class="number">212</span>m         <span class="number">5</span>%     <span class="number">1286</span><span class="built_in">Mi</span>          <span class="number">33</span>%         </span><br><span class="line">k8s<span class="literal">-node02</span>   <span class="number">139</span>m         <span class="number">3</span>%     <span class="number">1357</span><span class="built_in">Mi</span>          <span class="number">35</span>%         </span><br><span class="line">k8s<span class="literal">-node01</span>   &lt;unknown&gt;                           &lt;unknown&gt;               &lt;unknown&gt;               &lt;unknown&gt;               </span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">manifests</span>]<span class="comment"># kubectl top pod</span></span><br><span class="line">NAME                           CPU(cores)   MEMORY(bytes)   </span><br><span class="line">hello<span class="literal">-world</span><span class="literal">-658bf986c8</span><span class="literal">-d8v76</span>   <span class="number">0</span>m           <span class="number">1</span><span class="built_in">Mi</span>             </span><br><span class="line">hello<span class="literal">-world</span><span class="literal">-658bf986c8</span><span class="literal">-sx4dv</span>   <span class="number">0</span>m           <span class="number">1</span><span class="built_in">Mi</span>             </span><br><span class="line">myapp<span class="literal">-65b44bddd5</span><span class="literal">-z8vnd</span>         <span class="number">0</span>m           <span class="number">1</span><span class="built_in">Mi</span>             </span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="访问Prometheus"><a href="#访问Prometheus" class="headerlink" title="访问Prometheus"></a>访问Prometheus</h2><h3 id="浏览器访问"><a href="#浏览器访问" class="headerlink" title="浏览器访问"></a>浏览器访问</h3><p>prometheus对应的NodePort端口为30200，访问<a href="http://masterip:30200/">http://masterIP:30200</a>**</p>
<p><img src="/assets/image-20200206181351491.png" alt="image-20200206181351491"></p>
<h3 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h3><p><img src="/assets/image-20200206181443946.png" alt="image-20200206181443946"></p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>prometheus的web提供了基本的查询k8s集群中每个pod的CPU的情况，查询条件如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sum by (pod_name)( rate(container_cpu_usage_seconds_total&#123;image!=<span class="string">&quot;&quot;</span>,pod_name!=<span class="string">&quot;&quot;</span>&#125;[1m]))</span><br></pre></td></tr></table></figure>

<p><img src="/assets/image-20200206181749872.png" alt="image-20200206181749872"></p>
<p><img src="/assets/image-20200206181858371.png" alt="image-20200206181858371"></p>
<p>上述的查询有出现数据，说明node-exporter往Prometheus中写入数据正常，接下来我们就可以部署访问grafana组件，实现更友好的WebUI展示数据</p>
<h2 id="访问Grafana"><a href="#访问Grafana" class="headerlink" title="访问Grafana"></a>访问Grafana</h2><h3 id="浏览器访问-1"><a href="#浏览器访问-1" class="headerlink" title="浏览器访问"></a>浏览器访问</h3><p><a href="http://192.168.128.140:30100/">http://192.168.128.140:30100</a></p>
<p>默认用户名密码：admin/admin</p>
<p><img src="/assets/image-20200206182157204.png" alt="image-20200206182157204"></p>
<p>修改默认密码</p>
<p><img src="/assets/image-20200206182222385.png" alt="image-20200206182222385"></p>
<h3 id="添加数据来源"><a href="#添加数据来源" class="headerlink" title="添加数据来源"></a>添加数据来源</h3><p><img src="/assets/image-20200206182419022.png" alt="image-20200206182419022"></p>
<p>默认已经添加好，点击进入，测试</p>
<p><img src="/assets/image-20200206182543187.png" alt="image-20200206182543187"></p>
<p><img src="/assets/image-20200206182558431.png" alt="image-20200206182558431"></p>
<h3 id="dashboard导入模板"><a href="#dashboard导入模板" class="headerlink" title="dashboard导入模板"></a>dashboard导入模板</h3><p><img src="/assets/image-20200206182637824.png" alt="image-20200206182637824"></p>
<h3 id="查看数据"><a href="#查看数据" class="headerlink" title="查看数据"></a>查看数据</h3><p>进home，点击左上角</p>
<p><img src="/assets/image-20200206182758668.png" alt="image-20200206182758668"></p>
<h3 id="查看node数据"><a href="#查看node数据" class="headerlink" title="查看node数据"></a>查看node数据</h3><p><img src="/assets/image-20200206182840122.png" alt="image-20200206182840122"></p>
<p>可以看到node资源使用情况</p>
<p><img src="/assets/image-20200206182921185.png" alt="image-20200206182921185"></p>
<h2 id="单独安装metrics-server"><a href="#单独安装metrics-server" class="headerlink" title="单独安装metrics-server"></a>单独安装metrics-server</h2><p>metrics-server和Prometheus只能安装一个，metrics-server没有界面</p>
<p><img src="/assets/image-20200206171713920.png" alt="image-20200206171713920"></p>
<p><img src="/assets/image-20200206171729387.png" alt="image-20200206171729387"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（2）：Harbor配置私有镜像仓库</title>
    <url>/2020/01/04/2_Harbor%E9%85%8D%E7%BD%AE%E7%A7%81%E6%9C%89%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/</url>
    <content><![CDATA[<p>Harbor是一个用于存储和分发Docker镜像的企业级registry服务器</p>
<p>镜像在docker distribution（registry v2版本）基础上增加了安全、访问控制、管理的功能，以满足企业对于镜像仓库的需求</p>
<h2 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h2><p>参考k8s集群安装，一直执行到docker安装完毕即可</p>
<h2 id="docker配置"><a href="#docker配置" class="headerlink" title="docker配置"></a>docker配置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 所有节点操作（4个节点）</span><br><span class="line"># 在&#x2F;etc&#x2F;docker&#x2F;daemon.json中添加</span><br><span class="line">&quot;insecure-registries&quot;: [&quot;https:&#x2F;&#x2F;hub.test.com&quot;]</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>



<h2 id="安装docker-compose"><a href="#安装docker-compose" class="headerlink" title="安装docker-compose"></a>安装docker-compose</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -L https://get.daocloud.io/docker/compose/releases/download/1.22.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose</span><br><span class="line">chmod +x /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>



<h2 id="导入harbor包，并解压"><a href="#导入harbor包，并解压" class="headerlink" title="导入harbor包，并解压"></a>导入harbor包，并解压</h2><p> <a href="http://harbor.orientsoft.cn/">http://harbor.orientsoft.cn/</a> </p>
<p>harbor-offline-installer-v1.2.0.tgz</p>
<p>我自己安装的是1.5.0版本</p>
<h2 id="配置harbor-cfg"><a href="#配置harbor-cfg" class="headerlink" title="配置harbor.cfg"></a>配置harbor.cfg</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">必选参数</span><br><span class="line">hostname:主机名 hub.test.com</span><br><span class="line">ui_url_protocol:http或https（配置为https）</span><br><span class="line">db_password：密码</span><br></pre></td></tr></table></figure>



<h2 id="创建ssl目录文件"><a href="#创建ssl目录文件" class="headerlink" title="创建ssl目录文件"></a>创建ssl目录文件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /data/cert</span><br><span class="line">cd /data/cert</span><br><span class="line"><span class="meta">#</span><span class="bash"> 生成私钥</span></span><br><span class="line">openssl genrsa -des3 -out server.key 2048</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建证书请求csr</span></span><br><span class="line">openssl req -new -key server.key -out server.csr</span><br><span class="line"><span class="meta">#</span><span class="bash"> 备份私钥</span></span><br><span class="line">cp server.key server.key.org</span><br><span class="line"><span class="meta">#</span><span class="bash"> 转换成证书（私钥取消密码）</span></span><br><span class="line">openssl rsa -in server.key.org -out server.key</span><br><span class="line"><span class="meta">#</span><span class="bash"> 证书请求签名</span></span><br><span class="line">openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt</span><br><span class="line">chmod -R 777 /data/cert</span><br></pre></td></tr></table></figure>

<p><img src="/assets/image-20200128171040738.png" alt="image-20200128171040738"></p>
<h2 id="运行脚本安装"><a href="#运行脚本安装" class="headerlink" title="运行脚本安装"></a>运行脚本安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd harbor</span><br><span class="line">.&#x2F;install</span><br></pre></td></tr></table></figure>



<h2 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a>配置hosts文件</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;192.168.128.xx hub.test.com&quot; &gt;&gt; &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure>



<h2 id="web访问测试"><a href="#web访问测试" class="headerlink" title="web访问测试"></a>web访问测试</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;hub.test.com</span><br><span class="line">用户名密码 admin&#x2F;Harbor12345</span><br></pre></td></tr></table></figure>



<h2 id="其他节点登录测试"><a href="#其他节点登录测试" class="headerlink" title="其他节点登录测试"></a>其他节点登录测试</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker login https:&#x2F;&#x2F;hub.test.com</span><br><span class="line">docker pull wangyanglinux&#x2F;myapp:v1</span><br><span class="line">docker tag wangyanglinux&#x2F;myapp:v1 hub.test.com&#x2F;library&#x2F;myapp:v1</span><br><span class="line">docker push xxx</span><br></pre></td></tr></table></figure>



<h2 id="创建一个pod"><a href="#创建一个pod" class="headerlink" title="创建一个pod"></a>创建一个pod</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看帮助</span></span><br><span class="line">kubectl run --help</span><br><span class="line">kubectl run nginx-deployment --image=hub.test.com/library/myapp:v1 --port=80 --replicas=1</span><br><span class="line">kubectl get deployment</span><br><span class="line">kubectl get rs</span><br><span class="line">kubectl get pod [-o wide]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在线扩容</span></span><br><span class="line">kubectl scale --replicas=3 deployment/nginx-deployment</span><br><span class="line">kubectl get pod</span><br><span class="line">kubectl delete pod xxx</span><br></pre></td></tr></table></figure>



<h2 id="创建svc"><a href="#创建svc" class="headerlink" title="创建svc"></a>创建svc</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看帮助</span></span><br><span class="line">kubectl expose --help</span><br><span class="line">kubectl expose deployment nginx-deployment --port=8000 --target-port=80</span><br><span class="line">kubectl get svc</span><br><span class="line">curl xxx:8000/hostname.html ## 可以看到正在轮询</span><br><span class="line"></span><br><span class="line">ipvsadm -Ln</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="修改ClusterIP为NodePort"><a href="#修改ClusterIP为NodePort" class="headerlink" title="修改ClusterIP为NodePort"></a>修改ClusterIP为NodePort</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl edit svc nginx-deployment </span><br><span class="line">将ClusterIP改为NodePort</span><br><span class="line">kubectl get svc ## 查看</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（30）：HPA-自动伸缩</title>
    <url>/2020/01/12/30_HPA/</url>
    <content><![CDATA[<h2 id="Horizontal-Pod-Autoscaling-HPA"><a href="#Horizontal-Pod-Autoscaling-HPA" class="headerlink" title="Horizontal Pod Autoscaling(HPA)"></a>Horizontal Pod Autoscaling(HPA)</h2><p>Horizontal Pod Autoscaling可以根据CPU利用率自动伸缩一个Replication Controller、Deployment或Replica Set中的Pod数量</p>
<!--为了掩饰Horizontal Pod Autoscale，我们将使用一个基于php-apache镜像的定制Docker镜像。 在[这里](https://k8smeetup.github.io/docs/user-guide/horizontal-pod-autoscaling/image/Dockerfile)你可以查看完整的Dockefile定义。 镜像中包括一个[index.php](https://k8smeetup.github.io/docs/user-guide/horizontal-pod-autoscaling/image/index.php)页面，其中包含了一些可以运行CPU密集计算任务的代码-->

<h3 id="创建一个deployment"><a href="#创建一个deployment" class="headerlink" title="创建一个deployment"></a><strong>创建一个deployment</strong></h3><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">k8s</span>-<span class="type">install</span>]<span class="comment"># kubectl run php-apache --image=gcr.io/google_containers/hpa-example --image-pull-policy=&#x27;IfNotPresent&#x27;  --requests=cpu=200m --expose --port=80</span></span><br><span class="line">kubectl run -<span class="literal">-generator</span>=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run -<span class="literal">-generator</span>=run<span class="literal">-pod</span>/v1 or kubectl create instead.</span><br><span class="line">service/php<span class="literal">-apache</span> created</span><br><span class="line">deployment.apps/php<span class="literal">-apache</span> created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看pod</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">k8s</span>-<span class="type">install</span>]<span class="comment"># kubectl get pods</span></span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">php<span class="literal">-apache</span><span class="literal">-799f99c985</span><span class="literal">-zqn77</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>s</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看资源使用情况</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">k8s</span>-<span class="type">install</span>]<span class="comment"># kubectl top pod php-apache-799f99c985-zqn77</span></span><br><span class="line">NAME                          CPU(cores)   MEMORY(bytes)   </span><br><span class="line">php<span class="literal">-apache</span><span class="literal">-799f99c985</span><span class="literal">-zqn77</span>   <span class="number">0</span>m           <span class="number">8</span><span class="built_in">Mi</span>             </span><br></pre></td></tr></table></figure>



<h3 id="创建HPA控制器"><a href="#创建HPA控制器" class="headerlink" title="创建HPA控制器"></a>创建HPA控制器</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get hpa</span></span><br><span class="line">NAME         REFERENCE               TARGETS    MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">php<span class="literal">-apache</span>   Deployment/php<span class="literal">-apache</span>   <span class="number">183</span>%/<span class="number">50</span>%   <span class="number">1</span>         <span class="number">10</span>        <span class="number">4</span>          <span class="number">29</span>m</span><br></pre></td></tr></table></figure>



<h3 id="增加负载，查看负载节点数目"><a href="#增加负载，查看负载节点数目" class="headerlink" title="增加负载，查看负载节点数目"></a>增加负载，查看负载节点数目</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl run -i --tty load-generator --image&#x3D;busybox --image-pull-policy&#x3D;&#39;IfNotPresent&#39;   &#x2F;bin&#x2F;sh</span><br><span class="line">$ while true; do wget -q -O- http:&#x2F;&#x2F;php-apache.default.svc.cluster.local;done</span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看pod负载</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl top pod php-apache-799f99c985-zqn77  </span></span><br><span class="line">NAME                          CPU(cores)   MEMORY(bytes)   </span><br><span class="line">php<span class="literal">-apache</span><span class="literal">-799f99c985</span><span class="literal">-zqn77</span>   <span class="number">298</span>m         <span class="number">8</span><span class="built_in">Mi</span>             </span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># kubectl get pod </span></span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">load<span class="literal">-generator</span><span class="literal">-76f9c7b5f8</span><span class="literal">-nx5mz</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">24</span>m</span><br><span class="line">php<span class="literal">-apache</span><span class="literal">-799f99c985</span><span class="literal">-nxhzp</span>       <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">79</span>s</span><br><span class="line">php<span class="literal">-apache</span><span class="literal">-799f99c985</span><span class="literal">-r9zlp</span>       <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">49</span>s</span><br><span class="line">php<span class="literal">-apache</span><span class="literal">-799f99c985</span><span class="literal">-zqn77</span>       <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">30</span>m</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure>





<h2 id="资源限制-Pod"><a href="#资源限制-Pod" class="headerlink" title="资源限制-Pod"></a>资源限制-Pod</h2><p>Kubernetes对资源的限制实际上是通过cgroup来控制的，cgroup是容器的一组来控制内核如何运行进程的相关属性集合。针对内存、CPU和各种设备都有对应的cgroup</p>
<p>默认情况下，pod运行没有CPU和内存的限额。这意味着系统中的任何Pod将能够执行该Pod所在的节点一样，消耗足够多的CPU和内存。一般会针对某些应用的pod资源进行资源限制，这个资源限制是通过resources的requests和limits来实现</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">xxx</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">auth</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;4&quot;</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="string">250m</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">250Mi</span></span><br></pre></td></tr></table></figure>

<p>requests要分配的资源，limits为最高请求的资源值，可以简单理解为初始值和最大值</p>
<h2 id="资源限制-名称空间"><a href="#资源限制-名称空间" class="headerlink" title="资源限制-名称空间"></a>资源限制-名称空间</h2><h3 id="1-计算资源配额"><a href="#1-计算资源配额" class="headerlink" title="1 计算资源配额"></a>1 计算资源配额</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ResourceQuota</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">compute-resources</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">spark-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hard:</span></span><br><span class="line">    <span class="attr">pods:</span> <span class="string">&quot;20&quot;</span></span><br><span class="line">    <span class="attr">requests.cpu:</span> <span class="string">&quot;20&quot;</span></span><br><span class="line">    <span class="attr">requests.memory:</span> <span class="string">100Gi</span></span><br><span class="line">    <span class="attr">limits.cpu:</span> <span class="string">&quot;40&quot;</span></span><br><span class="line">    <span class="attr">limits.memory:</span> <span class="string">200Gi</span></span><br></pre></td></tr></table></figure>



<h3 id="2-配置对象数量配额限制"><a href="#2-配置对象数量配额限制" class="headerlink" title="2 配置对象数量配额限制"></a>2 配置对象数量配额限制</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVesion:</span> <span class="string">v1</span></span><br><span class="line"><span class="string">kindL</span> <span class="string">ResourceQuota</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">object-counts</span></span><br><span class="line">  <span class="string">namespace:spark-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hard:</span></span><br><span class="line">    <span class="attr">configmaps:</span> <span class="string">&quot;10&quot;</span></span><br><span class="line">    <span class="attr">persistentvolumeclaims:</span> <span class="string">&quot;4&quot;</span></span><br><span class="line">    <span class="attr">replicationcontrollers:</span> <span class="string">&quot;20&quot;</span></span><br><span class="line">    <span class="attr">secrets:</span> <span class="string">&quot;10&quot;</span></span><br><span class="line">    <span class="attr">services:</span> <span class="string">&quot;10&quot;</span></span><br><span class="line">    <span class="attr">services.loadbalancers:</span> <span class="string">&quot;2&quot;</span></span><br></pre></td></tr></table></figure>



<h3 id="3-配置CPU和内存limitRange"><a href="#3-配置CPU和内存limitRange" class="headerlink" title="3 配置CPU和内存limitRange"></a>3 配置CPU和内存limitRange</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">LimitRange</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mem-limit-range</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">default:</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">50Gi</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">defaultRequest:</span></span><br><span class="line">      <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">      <span class="attr">cpu:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Container</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong><code>defualt</code>即limit的值</strong></li>
<li><strong><code>defaultRequest</code>即request的值</strong></li>
</ul>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（31）：EFK-日志系统</title>
    <url>/2020/01/12/31_EFK%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<ul>
<li><strong>Elasticsearch：是一个搜索引擎，负责存储日志并提供查询接口；</strong></li>
<li><strong>Fluentd：负责从 Kubernetes 搜集日志，每个node节点上面的fluentd监控并收集该节点上面的系统日志，并将处理过后的日志信息发送给Elasticsearch；</strong></li>
<li><strong>Kibana：提供了一个 Web GUI，用户可以浏览和搜索存储在 Elasticsearch 中的日志。</strong></li>
</ul>
<h1 id="部署EFK"><a href="#部署EFK" class="headerlink" title="部署EFK"></a>部署EFK</h1><h2 id="这里采用的是Helm部署的方式"><a href="#这里采用的是Helm部署的方式" class="headerlink" title="这里采用的是Helm部署的方式"></a>这里采用的是Helm部署的方式</h2><p>首先新建一个目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir efk</span><br><span class="line">cd efk</span><br></pre></td></tr></table></figure>



<h2 id="添加Google-incubator仓库"><a href="#添加Google-incubator仓库" class="headerlink" title="添加Google incubator仓库"></a>添加Google incubator仓库</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># helm repo add incubator http://storage.googleapis.com/kubernetes-charts-incubator</span></span><br><span class="line"><span class="string">&quot;incubator&quot;</span> has been added to your repositories</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># helm repo update</span></span><br><span class="line">Hang tight <span class="keyword">while</span> we grab the latest from your chart repositories...</span><br><span class="line">...Skip local chart repository</span><br><span class="line">...Successfully got an update from the <span class="string">&quot;stable&quot;</span> chart repository</span><br><span class="line">...Successfully got an update from the <span class="string">&quot;incubator&quot;</span> chart repository</span><br><span class="line">Update Complete. ⎈ Happy Helming!⎈ </span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># helm repo list</span></span><br><span class="line">NAME     	URL                                                      </span><br><span class="line">stable   	https://kubernetes.oss<span class="literal">-cn</span><span class="literal">-hangzhou</span>.aliyuncs.com/charts   </span><br><span class="line">local    	http://<span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">8879</span>/charts                             </span><br><span class="line">incubator	http://storage.googleapis.com/kubernetes<span class="literal">-charts</span><span class="literal">-incubator</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="部署Elasticsearch"><a href="#部署Elasticsearch" class="headerlink" title="部署Elasticsearch"></a>部署Elasticsearch</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 创建名称空间</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># kubectl create namespace efk</span></span><br><span class="line">namespace/efk created</span><br><span class="line"></span><br><span class="line"><span class="comment">## fetch</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># helm fetch incubator/elasticsearch</span></span><br><span class="line"><span class="comment">## 解压</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># ls</span></span><br><span class="line">elastic<span class="built_in">search-1</span>.<span class="number">10.2</span>.tgz</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># tar -zxvf elasticsearch-1.10.2.tgz </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># cd elasticsearch</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 修改values.yaml</span></span><br><span class="line">MINIMUM_MASTER_NODES：最大的master节点数</span><br><span class="line">所有的replicas改为<span class="number">1</span></span><br><span class="line">所有的 persistence.enabled=false <span class="comment">## 关闭持久卷</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 安装</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">elasticsearch</span>]<span class="comment"># helm install --name els1 --namespace=efk  -f values.yaml .</span></span><br><span class="line">NAME:   els1</span><br><span class="line">LAST DEPLOYED: Fri Feb  <span class="number">7</span> <span class="number">04</span>:<span class="number">20</span>:<span class="number">28</span> <span class="number">2020</span></span><br><span class="line">NAMESPACE: efk</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                <span class="keyword">DATA</span>  AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span>  <span class="number">4</span>     <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                                        READY  STATUS    RESTARTS  AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span><span class="literal">-59bcdcbfb7</span><span class="literal">-hwbc2</span>  <span class="number">0</span>/<span class="number">1</span>    Init:<span class="number">0</span>/<span class="number">1</span>  <span class="number">0</span>         <span class="number">1</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-data</span><span class="literal">-0</span>                   <span class="number">0</span>/<span class="number">1</span>    Init:<span class="number">0</span>/<span class="number">2</span>  <span class="number">0</span>         <span class="number">1</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-master</span><span class="literal">-0</span>                 <span class="number">0</span>/<span class="number">1</span>    Init:<span class="number">0</span>/<span class="number">2</span>  <span class="number">0</span>         <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME                          <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>  PORT(S)   AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span>     ClusterIP  <span class="number">10.108</span>.<span class="number">189.128</span>  &lt;none&gt;       <span class="number">9200</span>/TCP  <span class="number">1</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-discovery</span>  ClusterIP  None            &lt;none&gt;       <span class="number">9300</span>/TCP  <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME                       READY  UP<span class="literal">-TO</span><span class="literal">-DATE</span>  AVAILABLE  AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span>  <span class="number">0</span>/<span class="number">1</span>    <span class="number">1</span>           <span class="number">0</span>          <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/StatefulSet</span><br><span class="line">NAME                       READY  AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-data</span>    <span class="number">0</span>/<span class="number">1</span>    <span class="number">1</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-master</span>  <span class="number">0</span>/<span class="number">1</span>    <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">The elasticsearch cluster has been installed.</span><br><span class="line"></span><br><span class="line">***</span><br><span class="line">Please note that this chart has been deprecated and moved to stable.</span><br><span class="line">Going forward please use the stable version of this chart.</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line">Elasticsearch can be accessed:</span><br><span class="line"></span><br><span class="line">  * Within your cluster, at the following DNS name at port <span class="number">9200</span>:</span><br><span class="line"></span><br><span class="line">    els1<span class="literal">-elasticsearch</span><span class="literal">-client</span>.efk.svc</span><br><span class="line"></span><br><span class="line">  * From outside the cluster, run these commands <span class="keyword">in</span> the same shell:</span><br><span class="line"></span><br><span class="line">    export POD_NAME=<span class="variable">$</span>(kubectl get pods -<span class="literal">-namespace</span> efk <span class="literal">-l</span> <span class="string">&quot;app=elasticsearch,component=client,release=els1&quot;</span> <span class="literal">-o</span> jsonpath=<span class="string">&quot;&#123;.items[0].metadata.name&#125;&quot;</span>)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Visit http://127.0.0.1:9200 to use Elasticsearch&quot;</span></span><br><span class="line">    kubectl port<span class="literal">-forward</span> -<span class="literal">-namespace</span> efk <span class="variable">$POD_NAME</span> <span class="number">9200</span>:<span class="number">9200</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看pod、svc</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">elasticsearch</span>]<span class="comment"># kubectl get pods -n efk</span></span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span><span class="literal">-59bcdcbfb7</span><span class="literal">-hwbc2</span>   <span class="number">0</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">43</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-data</span><span class="literal">-0</span>                    <span class="number">0</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">43</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-master</span><span class="literal">-0</span>                  <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">42</span>s</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">elasticsearch</span>]<span class="comment"># kubectl get svc  -n efk</span></span><br><span class="line">NAME                           <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>       EXTERNAL<span class="literal">-IP</span>   PORT(S)    AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span>      ClusterIP   <span class="number">10.108</span>.<span class="number">189.128</span>   &lt;none&gt;        <span class="number">9200</span>/TCP   <span class="number">48</span>s</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-discovery</span>   ClusterIP   None             &lt;none&gt;        <span class="number">9300</span>/TCP   <span class="number">48</span>s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 验证</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">k8s</span>-<span class="type">install</span>]<span class="comment"># kubectl run cirros-$RANDOM --rm -it --image=cirros -- /bin/sh</span></span><br><span class="line">kubectl run -<span class="literal">-generator</span>=deployment/apps.v1 is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl run -<span class="literal">-generator</span>=run<span class="literal">-pod</span>/v1 or kubectl create instead.</span><br><span class="line"><span class="keyword">If</span> you don<span class="string">&#x27;t see a command prompt, try pressing enter.</span></span><br><span class="line"><span class="string">/ # curl 10.108.189.128:9200/_cat/nodes</span></span><br><span class="line"><span class="string">10.244.3.22 16 97 14 1.01 0.97 0.67 i  - els1-elasticsearch-client-59bcdcbfb7-hwbc2</span></span><br><span class="line"><span class="string">10.244.3.23  5 97 10 1.01 0.97 0.67 di - els1-elasticsearch-data-0</span></span><br><span class="line"><span class="string">10.244.3.24 16 97  8 1.01 0.97 0.67 mi * els1-elasticsearch-master-0</span></span><br><span class="line"><span class="string">/ # </span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>





<h2 id="部署Fluentd"><a href="#部署Fluentd" class="headerlink" title="部署Fluentd"></a>部署Fluentd</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># helm fetch incubator/fluentd-elasticsearch</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># tar -zxvf fluentd-elasticsearch-2.0.7.tgz </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># cd fluentd-elasticsearch</span></span><br><span class="line"></span><br><span class="line">vim values.yaml</span><br><span class="line"><span class="comment"># 更改其中Elasticsearch访问地址`elasticsearch.host` 更改为 els1-elasticsearch-client的clusterip地址</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">fluentd</span>-<span class="type">elasticsearch</span>]<span class="comment"># helm install --name flu2 --namespace=efk -f values.yaml .</span></span><br><span class="line">NAME:   flu2</span><br><span class="line">LAST DEPLOYED: Fri Feb  <span class="number">7</span> <span class="number">04</span>:<span class="number">24</span>:<span class="number">24</span> <span class="number">2020</span></span><br><span class="line">NAMESPACE: efk</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/ClusterRole</span><br><span class="line">NAME                        AGE</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span>  <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ClusterRoleBinding</span><br><span class="line">NAME                        AGE</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span>  <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ConfigMap</span><br><span class="line">NAME                        <span class="keyword">DATA</span>  AGE</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span>  <span class="number">6</span>     <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/DaemonSet</span><br><span class="line">NAME                        DESIRED  CURRENT  READY  UP<span class="literal">-TO</span><span class="literal">-DATE</span>  AVAILABLE  NODE SELECTOR  AGE</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span>  <span class="number">1</span>        <span class="number">1</span>        <span class="number">0</span>      <span class="number">1</span>           <span class="number">0</span>          &lt;none&gt;         <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                              READY  STATUS             RESTARTS  AGE</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span><span class="literal">-pnsdm</span>  <span class="number">0</span>/<span class="number">1</span>    ContainerCreating  <span class="number">0</span>         <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/ServiceAccount</span><br><span class="line">NAME                        SECRETS  AGE</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span>  <span class="number">1</span>        <span class="number">1</span>s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line"><span class="number">1</span>. To verify that Fluentd has started, run:</span><br><span class="line"></span><br><span class="line">  kubectl -<span class="literal">-namespace</span>=efk get pods <span class="literal">-l</span> <span class="string">&quot;app.kubernetes.io/name=fluentd-elasticsearch,app.kubernetes.io/instance=flu2&quot;</span></span><br><span class="line"></span><br><span class="line">THIS APPLICATION CAPTURES ALL CONSOLE OUTPUT AND FORWARDS IT TO elasticsearch . Anything that might be identifying,</span><br><span class="line">including things like IP addresses, container images, and object names will NOT be anonymized.</span><br></pre></td></tr></table></figure>



<h2 id="部署Kibana"><a href="#部署Kibana" class="headerlink" title="部署Kibana"></a>部署Kibana</h2><p>这里E和K的版本要一致</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">## helm fetch stable/kibana --version 0.14.8  视频上说要指定版本跟E一致，但是我下载不来，先不指定看看能不能跑起来</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># helm fetch stable/kibana </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">efk</span>]<span class="comment"># tar -zxvf kibana-0.2.2.tgz </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改values.yaml，files.kibana.yml.elasticsearch.url</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kibana</span>]<span class="comment"># helm install --name kib1 --namespace=efk -f values.yaml .</span></span><br><span class="line">NAME:   kib1</span><br><span class="line">LAST DEPLOYED: Fri Feb  <span class="number">7</span> <span class="number">04</span>:<span class="number">33</span>:<span class="number">38</span> <span class="number">2020</span></span><br><span class="line">NAMESPACE: efk</span><br><span class="line">STATUS: DEPLOYED</span><br><span class="line"></span><br><span class="line">RESOURCES:</span><br><span class="line">==&gt; v1/Pod(related)</span><br><span class="line">NAME                          READY  STATUS             RESTARTS  AGE</span><br><span class="line">kib1<span class="literal">-kibana</span><span class="literal">-5786c8c9fd</span><span class="literal">-kd94n</span>  <span class="number">0</span>/<span class="number">1</span>    ContainerCreating  <span class="number">0</span>         <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1/Service</span><br><span class="line">NAME         <span class="built_in">TYPE</span>       CLUSTER<span class="literal">-IP</span>      EXTERNAL<span class="literal">-IP</span>  PORT(S)  AGE</span><br><span class="line">kib1<span class="literal">-kibana</span>  ClusterIP  <span class="number">10.107</span>.<span class="number">183.205</span>  &lt;none&gt;       <span class="number">443</span>/TCP  <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line">==&gt; v1beta1/Deployment</span><br><span class="line">NAME         READY  UP<span class="literal">-TO</span><span class="literal">-DATE</span>  AVAILABLE  AGE</span><br><span class="line">kib1<span class="literal">-kibana</span>  <span class="number">0</span>/<span class="number">1</span>    <span class="number">1</span>           <span class="number">0</span>          <span class="number">0</span>s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NOTES:</span><br><span class="line">To verify that kib1<span class="literal">-kibana</span> has started, run:</span><br><span class="line"></span><br><span class="line">  kubectl -<span class="literal">-namespace</span>=efk get pods <span class="literal">-l</span> <span class="string">&quot;app=kib1-kibana&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">root@k8s<span class="literal">-master</span> kibana]<span class="comment"># kubectl get pods -n efk</span></span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span><span class="literal">-59bcdcbfb7</span><span class="literal">-hwbc2</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-data</span><span class="literal">-0</span>                    <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-master</span><span class="literal">-0</span>                  <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">15</span>m</span><br><span class="line">flu2<span class="literal">-fluentd</span><span class="literal">-elasticsearch</span><span class="literal">-r4j2w</span>             <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">4</span>m28s</span><br><span class="line">kib1<span class="literal">-kibana</span><span class="literal">-5786c8c9fd</span><span class="literal">-kd94n</span>                 <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">118</span>s</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kibana</span>]<span class="comment"># kubectl get svc -n efk</span></span><br><span class="line">NAME                           <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>       EXTERNAL<span class="literal">-IP</span>   PORT(S)    AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span>      ClusterIP   <span class="number">10.108</span>.<span class="number">189.128</span>   &lt;none&gt;        <span class="number">9200</span>/TCP   <span class="number">15</span>m</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-discovery</span>   ClusterIP   None             &lt;none&gt;        <span class="number">9300</span>/TCP   <span class="number">15</span>m</span><br><span class="line">kib1<span class="literal">-kibana</span>                    ClusterIP   <span class="number">10.107</span>.<span class="number">183.205</span>   &lt;none&gt;        <span class="number">443</span>/TCP    <span class="number">2</span>m6s</span><br><span class="line"></span><br><span class="line"><span class="comment">## 修改kib1-kibana的svc类型为NodePort</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">kibana</span>]<span class="comment"># kubectl get svc -n efk</span></span><br><span class="line">NAME                           <span class="built_in">TYPE</span>        CLUSTER<span class="literal">-IP</span>       EXTERNAL<span class="literal">-IP</span>   PORT(S)         AGE</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-client</span>      ClusterIP   <span class="number">10.108</span>.<span class="number">189.128</span>   &lt;none&gt;        <span class="number">9200</span>/TCP        <span class="number">15</span>m</span><br><span class="line">els1<span class="literal">-elasticsearch</span><span class="literal">-discovery</span>   ClusterIP   None             &lt;none&gt;        <span class="number">9300</span>/TCP        <span class="number">15</span>m</span><br><span class="line">kib1<span class="literal">-kibana</span>                    NodePort    <span class="number">10.107</span>.<span class="number">183.205</span>   &lt;none&gt;        <span class="number">443</span>:<span class="number">31709</span>/TCP   <span class="number">2</span>m49s</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="浏览器访问-NodeIP-NodePort"><a href="#浏览器访问-NodeIP-NodePort" class="headerlink" title="浏览器访问 NodeIP:NodePort"></a>浏览器访问 NodeIP:NodePort</h2><p>这里#是192.168.128.140:31709</p>
<p>可以看到，由于版本不对，所以导致状态为Red</p>
<p><img src="/assets/image-20200207043800405.png" alt="image-20200207043800405"></p>
<p>解决过程</p>
<p>1 首先修改kibana的镜像版本</p>
<p>2 查看到Elasticsearch镜像版本为6.4.2，于是我改了Kibana的镜像版本为6.4.2，但是状态还是red，看red的点是没连接上Elasticsearch service，怀疑应该是Kibana的values文件没有写对服务的IP</p>
<p><img src="/assets/image-20200207045158441.png" alt="image-20200207045158441"></p>
<p>3 有可能是E或者F有问题 再看</p>
<p>/ # curl 10.108.189.128:9200/_cat/health<br>1581024538 21:28:58 elasticsearch red 3 1 0 0 0 0 0 0 - NaN%</p>
<p>应该是E有问题，删了再创建看看</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（32）：集群证书年限修改</title>
    <url>/2020/01/13/32_%E8%AF%81%E4%B9%A6%E5%8F%AF%E7%94%A8%E5%B9%B4%E9%99%90%E4%BF%AE%E6%94%B9/</url>
    <content><![CDATA[<p>默认的证书是有年限的</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> ~]<span class="comment"># cd /etc/kubernetes/pki/</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># ls</span></span><br><span class="line">apiserver.crt                 apiserver<span class="literal">-kubelet</span><span class="literal">-client</span>.key  devuser.kubeconfig  front<span class="literal">-proxy</span><span class="literal">-client</span>.crt</span><br><span class="line">apiserver<span class="literal">-etcd</span><span class="literal">-client</span>.crt     ca.crt                        devuser.pem         front<span class="literal">-proxy</span><span class="literal">-client</span>.key</span><br><span class="line">apiserver<span class="literal">-etcd</span><span class="literal">-client</span>.key     ca.key                        etcd                sa.key</span><br><span class="line">apiserver.key                 devuser.csr                   front<span class="literal">-proxy</span><span class="literal">-ca</span>.crt  sa.pub</span><br><span class="line">apiserver<span class="literal">-kubelet</span><span class="literal">-client</span>.crt  devuser<span class="literal">-key</span>.pem               front<span class="literal">-proxy</span><span class="literal">-ca</span>.key</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># openssl x509 -in apiserver.crt -text -noout</span></span><br><span class="line">Certificate:</span><br><span class="line">    <span class="keyword">Data</span>:</span><br><span class="line">        Version: <span class="number">3</span> (<span class="number">0</span>x2)</span><br><span class="line">        Serial Number: <span class="number">8026942590652842542</span> (<span class="number">0</span>x6f656dc1f451022e)</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">        Issuer: CN=kubernetes</span><br><span class="line">        Validity</span><br><span class="line">            Not Before: Jan <span class="number">28</span> <span class="number">08</span>:<span class="number">20</span>:<span class="number">48</span> <span class="number">2020</span> GMT</span><br><span class="line">            Not After : Jan <span class="number">27</span> <span class="number">08</span>:<span class="number">20</span>:<span class="number">48</span> <span class="number">2021</span> GMT</span><br><span class="line">...</span><br><span class="line">...省略</span><br><span class="line">...</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">pki</span>]<span class="comment"># openssl x509 -in ca.crt -text -noout</span></span><br><span class="line">Certificate:</span><br><span class="line">    <span class="keyword">Data</span>:</span><br><span class="line">        Version: <span class="number">3</span> (<span class="number">0</span>x2)</span><br><span class="line">        Serial Number: <span class="number">0</span> (<span class="number">0</span>x0)</span><br><span class="line">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class="line">        Issuer: CN=kubernetes</span><br><span class="line">        Validity</span><br><span class="line">            Not Before: Jan <span class="number">28</span> <span class="number">08</span>:<span class="number">20</span>:<span class="number">48</span> <span class="number">2020</span> GMT</span><br><span class="line">            Not After : Jan <span class="number">25</span> <span class="number">08</span>:<span class="number">20</span>:<span class="number">48</span> <span class="number">2030</span> GMT</span><br></pre></td></tr></table></figure>

<p>有些是一年，有些是10年</p>
<p>例如apiserver是1年，ca是10年</p>
<p>为什么是1年，老师说，可能是因为更新集群的时候会自动更新证书，如果1年内有更新集群，则不需要考虑证书到期，但是有些时候，离线业务并不会去手动更新集群</p>
<p><strong>如果需要手动更改证书年限，需要改代码</strong></p>
<h2 id="1-首先需要先安装go语言环境"><a href="#1-首先需要先安装go语言环境" class="headerlink" title="1 首先需要先安装go语言环境"></a>1 首先需要先安装go语言环境</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载go包</span></span><br><span class="line"><span class="comment"># 解压go</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">local</span>]<span class="comment"># pwd</span></span><br><span class="line">/usr/local</span><br><span class="line">[<span class="type">root</span>@<span class="type">k8s</span>-<span class="type">master</span> <span class="type">local</span>]<span class="comment"># tar -zxvf go1.13.7.linux-amd64.tar.gz </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加环境变量 /etc/profile</span></span><br><span class="line">vi /etc/profile</span><br><span class="line">export PATH=<span class="variable">$PATH:</span>/usr/local/go/bin</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>



<h2 id="2-下载源码"><a href="#2-下载源码" class="headerlink" title="2 下载源码"></a>2 下载源码</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /<span class="keyword">data</span> git clone  https://github.com/kubernetes/kubernetes.git</span><br><span class="line"><span class="comment">## 查看kubeadm版本</span></span><br><span class="line">kubeadm version</span><br><span class="line">git checkout <span class="literal">-b</span> remotes/origin/release<span class="literal">-1</span>.<span class="number">15.1</span> v1.<span class="number">15.1</span></span><br></pre></td></tr></table></figure>

<p>这里如果是通过浏览器下载的话，直接下载对应版本的压缩包</p>
<h2 id="3-修改kubeadm源码包更新证书策略"><a href="#3-修改kubeadm源码包更新证书策略" class="headerlink" title="3 修改kubeadm源码包更新证书策略"></a>3 修改kubeadm源码包更新证书策略</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">vim staging/src/k8s.io/client<span class="literal">-go</span>/util//cert/cert.go <span class="comment"># kubeadm1.14版本之前</span></span><br><span class="line">vim cmd/kubeadm/app/util/pkiutil/pki_helpers.go <span class="comment"># kubeadm1.14之后</span></span><br><span class="line"><span class="comment">## 在func NewSignedCert下加</span></span><br><span class="line">	const duration365d = time.Hour * <span class="number">24</span> * <span class="number">365</span>    </span><br><span class="line">	const duration3650d = time.Hour * <span class="number">24</span> * <span class="number">365</span> * <span class="number">10</span>    // 新增</span><br><span class="line">	NotAfter: time.Now().Add(duration365d0).UTC(),    // 修改</span><br><span class="line"></span><br><span class="line"><span class="comment">## 编译kubeadm</span></span><br><span class="line">make WHAT=cmd/kubeadm GOFLAGS=<span class="literal">-v</span></span><br><span class="line"><span class="built_in">cp</span> _output/bin/kubeadm /root/kubeadm<span class="literal">-new</span></span><br></pre></td></tr></table></figure>

<p>1.14和1.15是通过修改这个文件，1.16、1.17就不确定了，可以查看官方文档</p>
<h2 id="4-更新kubeadm"><a href="#4-更新kubeadm" class="headerlink" title="4 更新kubeadm"></a>4 更新kubeadm</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将kubeadm进行替换</span></span><br><span class="line"><span class="built_in">cp</span> /usr/bin/kubeadm /usr/bin/kubeadm.old</span><br><span class="line"><span class="built_in">cp</span> /root/kubeadm<span class="literal">-new</span> /usr/bin/kubeadm</span><br><span class="line">chmod a+x /usr/bin/kubeadm</span><br></pre></td></tr></table></figure>



<h2 id="5-更新各个节点证书至Master节点"><a href="#5-更新各个节点证书至Master节点" class="headerlink" title="5 更新各个节点证书至Master节点"></a>5 更新各个节点证书至Master节点</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 首先备份pki目录</span><br><span class="line">cp &#x2F;etc&#x2F;kubernetes&#x2F;pki&#123;,-bak&#125;</span><br><span class="line">## 更新所有证书日期</span><br><span class="line">kukeadm alpha certs renew all --config&#x3D;kubeadm-config.yaml</span><br><span class="line">## 查看是否更新成功</span><br><span class="line">openssl x509 -in apiserver.crt -text -noout</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（33）：kubeconfig-配置文件上下文</title>
    <url>/2020/01/13/33_%E4%B8%8A%E4%B8%8B%E6%96%87/</url>
    <content><![CDATA[<p>kubeconfig配置文件包含连接k8s集群的相关认证信息，通过这个配置文件可以快速的与k8s集群进行相关创建查询等操作</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>查看默认config</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">root@node01:~#</span> <span class="string">cat</span> <span class="string">~/.kube/config</span> </span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">clusters:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">cluster:</span></span><br><span class="line">    <span class="attr">certificate-authority-data:</span> <span class="string">LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJd01EVXdNekEzTXpNeU1Gb1hEVE13TURVd01UQTNNek15TUZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTDI1CmtGY1AyeEtxc0crQ2NWZ3Zpa2lWOVJVcDBqNlFiYTN0akFoanhxeXFleWpuQmQvNkh3WldjWlpXVXFJU1ZuTEwKTHdMRlJqQXpCSy90b2d1WDgweWUySjdkeEEzTVQvTG4wWEM0NUdmdFFRS3hIT3Z0TVRNRjBkakFDenZNN1hTOQp2OWMyc0tPTU1BY1AxcXEyeE9iRk1EdTJkcVY4SE1SQXladnZ2MXZWNGJZeXRSaDB3YTNrQmJIM29aclU4SWh4Clp3L0ZwbWVVaWtPcW5lMldSZnRoUU0vYkRZWjlDT0hrRnQvTG9wOEhyRjhvcWJneVVXRWNGNlhVbGlMbUFIRTEKK2ZxWnBsa3dOMFZYUWZVbExMcmt1aHAzUWVseHcrQVVwelk3UnkvYS9sZmlrVURZQVVhbnpnMk9mdk95aXM4eQpObW40T1IrVUk3eXlXMDg4TDlzQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFJb3o4Vk1MVlYxQ25uQjF2UXUwNDNKSnk0eWMKTUNuQTRodDJJS1BiMFN6ZGRNY0hqTThEVHdsNEUxWnVHdEI0N2U2akpsNUpEMk81NTFZQS9ScE5CaDJaY0lGMAozTVJMZUlyZnQyWjl5T2V0Y01hZFAwUmxHcFZxUktXRC84TS9DLy9tVVJyYzViUnY2SVA5ZWYxeEFuSGRPZmRMCmF5ZVc1QTk1aU9JQUg1MzJzSTdTcGYzcjVBb1dCRXNCcWdweXdzN1orRW1sOUpBeDlsd2tlOTFPOFVHcEM2KzcKZ2cxKzlpMDhEV0VmRFFGNmJ4ZG1nQjl3L1RaNkJNbXZDVDhXaXZxcEJXeFpBdU9XdE5XTlhPeXdsOXFidkt2eApJVHgyM0ljcitJemszYWFCYmJoL0o4TU03Tm5XcFNGWlRkL1JIcEpwbFpySnRLb1BBNEpWV0RpdVB2VT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</span></span><br><span class="line">    <span class="attr">server:</span> <span class="string">https://172.31.25.174:6443</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes</span></span><br><span class="line"><span class="attr">contexts:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">context:</span></span><br><span class="line">    <span class="attr">cluster:</span> <span class="string">kubernetes</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">kubernetes-admin</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-admin@kubernetes</span></span><br><span class="line"><span class="attr">current-context:</span> <span class="string">kubernetes-admin@kubernetes</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Config</span></span><br><span class="line"><span class="attr">preferences:</span> &#123;&#125;</span><br><span class="line"><span class="attr">users:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">kubernetes-admin</span></span><br><span class="line">  <span class="attr">user:</span></span><br><span class="line">    <span class="attr">client-certificate-data:</span> <span class="string">LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM4akNDQWRxZ0F3SUJBZ0lJRU1rRlV1VjdLR0F3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TURBMU1ETXdOek16TWpCYUZ3MHlNVEExTURNd056TXpNakphTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXhsV29CQVBrT1pQTlk1WnQKZ3YveHdWN0xHdnNJS05pd0E1Z0YvLy93RjVHVEZITnkzT1NQdGg2VlEra1lyRnFuWGxvZlVaTzVjaFIvVnVQcQptbGlIS0RvMXRBaTZYR0VGeWhjdlZBeUZLTnBySSt5eFBoRmdFRDVPUXcySmVMakZOQTdYRUJYQitrQTQxbElPCm5yZGwwTGFuK1lZcTQ5YVI5ZnJDQURjaTdBclJ3M0liWUZNOTZjRmQ4bC8rZzh0QTROYXpDRlFoWmlKWXZiOUsKTDRVeFZ3YXN3a0E0bXMxeG9EL25TZXJPUm1TQkM3TVNpd1QvNi9YWVpwMlBKSHBLaU9FSHIyQnpKWGN1R1NjdQpIaVFIZWFzTFl2MzBiK0hNMWhwK1RiM1NVUGJTT3pJUEtITHNlcGo3VCtPcC9rZjJCeXdQSm5rbEUvbTYxeS9PCnN1V3lCUUlEQVFBQm95Y3dKVEFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFKSDFYQUNxMG8rTnFFeU03MGdPMU96MVk2cHJmUzJ4MHZvWgpoSDNoWkJvVUhsZVoxVFc3ejBtYnpoYnExVGdJSXpISnI4eitvK0tmdmN1OC9VMmMzV2k1b0FNdzdldm5FUnhKClVmMTVqaGhGOEFrSnVRWUxhdE1ENjlkUERDV3V3ZnJYei9QQzk2WEROZXQxWWppV1dQRU1XNGU0azF6U3l5eE0KRTBSb0Z6Qzk3dzVzUXVSNUYvcEw0VDQ3SFR6WEJkQlczcjNQbFhGVVRvM2hOaWtDaXpBOEpNTk0zaG9CZlBaOApYaytQVTRNSWVPUXFhOWMxY2J1dTMxR2FEcFpCOFJzTldMVGhhaW5yZmY4MkVRRG9FMk5IcGdpU0RTWEU5UGpCCklydVJzRFNiK3RGTk1sL0dYU0w3VnFkUGdnY0FtbHBWYnVsNHFjdjFlQXVUVlg2NDVJcz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=</span></span><br><span class="line">    <span class="attr">client-key-data:</span> <span class="string">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</span></span><br></pre></td></tr></table></figure>

<p>解读：</p>
<p>clusters：配置集群信息，例如集群apiserver地址，以及ca证书</p>
<p>users：配置用户</p>
<p>contexts：上下文，一个上下文对应一个cluster和user</p>
<p>demo-config</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line"></span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">  name: development</span><br><span class="line">- cluster:</span><br><span class="line">  name: scratch</span><br><span class="line"></span><br><span class="line">users:</span><br><span class="line">- name: developer</span><br><span class="line">- name: experimenter</span><br><span class="line"></span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">  name: dev-frontend</span><br><span class="line">- context:</span><br><span class="line">  name: dev-storage</span><br><span class="line">- context:</span><br><span class="line">  name: exp-scratch</span><br></pre></td></tr></table></figure>



<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 设置集群参数</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">--server&#x3D;https:&#x2F;&#x2F;192.168.31.61:6443 \</span><br><span class="line">--certificate-authority&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt \</span><br><span class="line">--embed-certs&#x3D;true \</span><br><span class="line">--kubeconfig&#x3D;config</span><br><span class="line"># 设置上下文参数</span><br><span class="line">kubectl config set-context test \</span><br><span class="line">--cluster&#x3D;kubernetes \</span><br><span class="line">--user&#x3D;cluster-admin \</span><br><span class="line">--kubeconfig&#x3D;config</span><br><span class="line"># 设置默认上下文</span><br><span class="line">kubectl config use-context test --kubeconfig&#x3D;config</span><br><span class="line"># 设置客户端认证参数</span><br><span class="line">kubectl config set-credentials cluster-admin \</span><br><span class="line">--certificate-authority&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt \</span><br><span class="line">--embed-certs&#x3D;true \</span><br><span class="line">--client-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;admin-key.pem \</span><br><span class="line">--client-certificate&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;admin.pem \</span><br><span class="line">--kubeconfig&#x3D;config</span><br></pre></td></tr></table></figure>



<p>配置集群详细信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-cluster development --server&#x3D;https:&#x2F;&#x2F;1.2.3.4 --certificate-authority&#x3D;fake-ca-file</span><br><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-cluster scratch --server&#x3D;https:&#x2F;&#x2F;5.6.7.8 --insecure-skip-tls-verify</span><br></pre></td></tr></table></figure>



<p>配置用户详细信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-credentials developer --client-certificate&#x3D;fake-cert-file --client-key&#x3D;fake-key-seefile</span><br><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-credentials experimenter --username&#x3D;exp --password&#x3D;some-password</span><br></pre></td></tr></table></figure>



<p>配置上下文详细信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-context dev-frontend --cluster&#x3D;development --namespace&#x3D;frontend --user&#x3D;developer</span><br><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-context dev-storage --cluster&#x3D;development --namespace&#x3D;storage --user&#x3D;developer</span><br><span class="line">kubectl config --kubeconfig&#x3D;config-demo set-context exp-scratch --cluster&#x3D;scratch --namespace&#x3D;default --user&#x3D;experimenter</span><br></pre></td></tr></table></figure>



<p>查看config</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config --kubeconfig&#x3D;config-demo view</span><br></pre></td></tr></table></figure>



<p>设置当前上下文</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config --kubeconfig&#x3D;config-demo use-context dev-frontend</span><br></pre></td></tr></table></figure>



<p>查看当前上下文的config</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config --kubeconfig&#x3D;config-demo view --minify</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（34）：k8s高可用集群部署</title>
    <url>/2020/01/13/34_k8s-Master%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
    <content><![CDATA[<p>k8s基于kubeadm+keepalived搭建高可用</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1 配置主机，安装docker，kubeadm，kubectl，kubelet</p>
<p>2 ssh免密登录</p>
<p>3 docker配置文件</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>],</span><br><span class="line"> <span class="attr">&quot;log-driver&quot;</span>: <span class="string">&quot;json-file&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;log-opts&quot;</span>: &#123;</span><br><span class="line">   <span class="attr">&quot;max-size&quot;</span>: <span class="string">&quot;100m&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line"> <span class="attr">&quot;storage-driver&quot;</span>: <span class="string">&quot;overlay2&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;storage-opts&quot;</span>: [</span><br><span class="line">   <span class="string">&quot;overlay2.override_kernel_check=true&quot;</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<p>4 开启ipvs</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">#!/bin/bash</span></span><br><span class="line"><span class="string">ipvs_modules=&quot;ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack&quot;</span></span><br><span class="line"><span class="string">for kernel_module in \$&#123;ipvs_modules&#125;; do</span></span><br><span class="line"><span class="string"> /sbin/modinfo -F filename \$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span></span><br><span class="line"><span class="string"> if [ $? -eq 0 ]; then</span></span><br><span class="line"><span class="string"> /sbin/modprobe \$&#123;kernel_module&#125;</span></span><br><span class="line"><span class="string"> fi</span></span><br><span class="line"><span class="string">done</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</span><br></pre></td></tr></table></figure>



<p>安装kubeadm-1.18.2</p>
<p>部署Keepalived+lvs实现对apiserver高可用</p>
<p>master节点安装Keepalived+lvs</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y socat keepalived ipvsadm conntrack</span><br></pre></td></tr></table></figure>

<p>修改master1的/etc/keepalived/keeplived.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">  router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">  state BACKUP</span><br><span class="line">  nopreempt</span><br><span class="line">  interface ens33</span><br><span class="line">  virtual_router_id 80</span><br><span class="line">  priority 100</span><br><span class="line">  advert_int 1</span><br><span class="line">  authentication &#123;</span><br><span class="line">    auth_type PASS</span><br><span class="line">    auth_oass just0kk</span><br><span class="line">  &#125;</span><br><span class="line">  virtual_ipaddress &#123;</span><br><span class="line">    192.168.0.199</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">virtual_server 192.168.0.199 6443 &#123;</span><br><span class="line">    deplay_loop 6</span><br><span class="line">    lb_algo loadbalance</span><br><span class="line">    lb_kind DR</span><br><span class="line">    net_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 0</span><br><span class="line">    protocol TCP</span><br><span class="line">    real_server 192.168.0.6 6443</span><br><span class="line">      weigh 1</span><br><span class="line">      SSL_GET &#123;</span><br><span class="line">        url &#123;</span><br><span class="line">        path &#x2F;healthz</span><br><span class="line">        status_code 200</span><br><span class="line">        &#125;</span><br><span class="line">        connect_timeout 3</span><br><span class="line">        nb_get_retry 3</span><br><span class="line">        delay_before_retry 3</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br><span class="line">real_server 192.168.0.16 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.0.26 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>master2节点的keepalived.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    nopreempt</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 80</span><br><span class="line">    priority 50</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass just0kk</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.0.199</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">virtual_server 192.168.0.199 6443 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo loadbalance</span><br><span class="line">    lb_kind DR    net_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 0</span><br><span class="line">    protocol TCP</span><br><span class="line">    real_server 192.168.0.6 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.0.16 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.0.26 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>master3节点的keepalived.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    nopreempt</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 80</span><br><span class="line">    priority 30</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass just0kk</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.0.199</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">virtual_server 192.168.0.199 6443 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo loadbalance</span><br><span class="line">    lb_kind DR</span><br><span class="line">    net_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 0</span><br><span class="line">    protocol TCP</span><br><span class="line">    real_server 192.168.0.6 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.0.16 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.0.26 6443 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        SSL_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path &#x2F;healthz</span><br><span class="line">              status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注：Keepalived要配置BACKUP，而且是非抢占模式nopreempt，假设master1宕机，启动之后VIP不会飘到master1，可以保证k8s始终处于正常状态。如果master1启动，VIP立刻飘到master1，apiserver还未完全启动，这时候集群就会出问题</p>
<p>按顺序启动 master1&gt;2&gt;3</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl enable keepalived  &amp;&amp; systemctl start keepalived  &amp;&amp; systemctl status keepalived</span><br></pre></td></tr></table></figure>

<p>启动之后ip a查看vip已经绑定到ens33</p>
<p>初始化集群</p>
<p>master1节点</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">kubeadm-config.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.18.2</span></span><br><span class="line"><span class="attr">controlPlaneEndpoint:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.199</span><span class="string">:6443</span></span><br><span class="line"><span class="comment">## 国内源用这个</span></span><br><span class="line"><span class="comment">#imageRepository: registry.aliyuncs.com/google_containers</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line"> <span class="attr">certSANs:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.6</span></span><br><span class="line"> <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.16</span></span><br><span class="line"> <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.26</span></span><br><span class="line"> <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.56</span></span><br><span class="line"> <span class="bullet">-</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.199</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line"> <span class="attr">podSubnet:</span> <span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span><span class="string">/16</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeproxy.config.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span>  <span class="string">KubeProxyConfiguration</span></span><br><span class="line"><span class="attr">mode:</span> <span class="string">ipvs</span></span><br></pre></td></tr></table></figure>

<p>master1节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm init --config kubeadm-config.yaml</span><br></pre></td></tr></table></figure>

<p>master1节点</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">sudo cp -i  &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf  $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">sudo chown $(id -u):$(id -g)  $HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure>

<p>查看集群状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>

<p>master1节点，安装calico网络插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;luckylucky421&#x2F;kubernetes1.17.3&#x2F;master&#x2F;calico.yaml</span><br></pre></td></tr></table></figure>

<p>查看集群状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>

<p>把master1节点的证书拷贝到master2和master3上</p>
<p>1 在master2、3上创建证书存放目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root &amp;&amp; mkdir -p &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd &amp;&amp;mkdir -p ~&#x2F;.kube&#x2F;</span><br></pre></td></tr></table></figure>

<p>2 拷贝</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F; master2:&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;</span><br><span class="line">scp -r &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F; master3:&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;</span><br></pre></td></tr></table></figure>

<p>3 以master身份加入到集群，–control-plane参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.0.199:6443 --token 7dwluq.x6nypje7h55rnrhl \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:fa75619ab0bb6273126350a9dbda9aa6c89828c2c4650299fe1647ab510a7e6c   --control-plane</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p $HOME&#x2F;.kube</span><br><span class="line">sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">sudo chown $(id -u):$(id -g)$HOME&#x2F;.kube&#x2F;config</span><br></pre></td></tr></table></figure>

<p>node节点加入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.0.199:6443 --token 7dwluq.x6nypje7h55rnrhl \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:fa75619ab0bb6273126350a9dbda9aa6c89828c2c4650299fe1647ab510a7e6c</span><br></pre></td></tr></table></figure>

<p>查看node状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>



<p>额外的：使用traefik 作为集群ingress</p>
<p>1 生成traefik证书</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir  ~&#x2F;ikube&#x2F;tls&#x2F; -p</span><br><span class="line">echo &quot;&quot;&quot;</span><br><span class="line">[req]</span><br><span class="line">distinguished_name &#x3D; req_distinguished_name</span><br><span class="line">prompt &#x3D; yes</span><br><span class="line"></span><br><span class="line">[ req_distinguished_name ]</span><br><span class="line">countryName                     &#x3D; Country Name (2 letter code)</span><br><span class="line">countryName_value               &#x3D; CN</span><br><span class="line"></span><br><span class="line">stateOrProvinceName             &#x3D; State or Province Name (full name)</span><br><span class="line">stateOrProvinceName_value       &#x3D; Beijing</span><br><span class="line"></span><br><span class="line">localityName                    &#x3D; Locality Name (eg, city)</span><br><span class="line">localityName_value              &#x3D; Haidian</span><br><span class="line"></span><br><span class="line">organizationName                &#x3D; Organization Name (eg, company)</span><br><span class="line">organizationName_value          &#x3D; Channelsoft</span><br><span class="line"></span><br><span class="line">organizationalUnitName          &#x3D; Organizational Unit Name (eg, section)</span><br><span class="line">organizationalUnitName_value    &#x3D; R &amp; D Department</span><br><span class="line"></span><br><span class="line">commonName                      &#x3D; Common Name (eg, your name or your server\&#39;s hostname)</span><br><span class="line">commonName_value                &#x3D; *.multi.io</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">emailAddress                    &#x3D; Email Address</span><br><span class="line">emailAddress_value              &#x3D; lentil1016@gmail.com</span><br><span class="line">&quot;&quot;&quot; &gt; ~&#x2F;ikube&#x2F;tls&#x2F;openssl.cnf</span><br><span class="line">openssl req -newkey rsa:4096 -nodes -config ~&#x2F;ikube&#x2F;tls&#x2F;openssl.cnf -days 3650 -x509 -out ~&#x2F;ikube&#x2F;tls&#x2F;tls.crt -keyout ~&#x2F;ikube&#x2F;tls&#x2F;tls.key</span><br><span class="line">kubectl create -n kube-system secret tls ssl --cert ~&#x2F;ikube&#x2F;tls&#x2F;tls.crt --key ~&#x2F;ikube&#x2F;tls&#x2F;tls.key</span><br></pre></td></tr></table></figure>

<p>2 执行yaml创建traefik</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;luckylucky421&#x2F;kubernetes1.17.3&#x2F;master&#x2F;traefik.yaml</span><br></pre></td></tr></table></figure>

<p>3 查看是否执行成功</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n kube-system|grep traefik</span><br></pre></td></tr></table></figure>



<p>额外的：安装kubernetes-dashboard 2.0版本</p>
<p>1 执行yaml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;luckylucky421&#x2F;kubernetes1.17.3&#x2F;master&#x2F;kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>

<p>2 修改dashboard的svc类型为NodePort</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xxx</span><br></pre></td></tr></table></figure>

<p>3 使用默认的token登录dashboard，登录成功后，只能看到default名称空间</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl get secret -n kubernetes-dashboard</span><br><span class="line">kubectl  describe  secret  kubernetes-dashboard-token-ngcmg  -n   kubernetes-dashboard</span><br></pre></td></tr></table></figure>

<p>4 创建管理员token，可查看任何名称空间权限</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create clusterrolebinding dashboard-cluster-admin --clusterrole&#x3D;cluster-admin --serviceaccount&#x3D;kubernetes-dashboard:kubernetes-dashboard</span><br></pre></td></tr></table></figure>

<p>5 查看token，并登录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl  describe  secret  kubernetes-dashboard-token-ngcmg  -n   kubernetes-dashboard</span><br></pre></td></tr></table></figure>



<p>额外的：安装metrics监控插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;luckylucky421&#x2F;kubernetes1.17.3&#x2F;master&#x2F;metrics.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（35）：k8s之Network Policy</title>
    <url>/2020/01/14/35_Network_Policy/</url>
    <content><![CDATA[<p>kubernetes采用了Container Networking Interface（CNI）规范，是CoreOS提出的容器网络规范，它使用了插件模型创建容器的网络战</p>
<p>常见的kubernetes网络方案，Flannel、Calico、Canal、Weave Net</p>
<h2 id="network-Policy概念"><a href="#network-Policy概念" class="headerlink" title="network Policy概念"></a>network Policy概念</h2><p>network Policy是kubernetes的一种资源，network policy通过label选择pod，并指定其他pod或外界如何与这些pod通信</p>
<p>默认情况下，所有Pod是非隔离的，即任何来源的网络流量都能够访问Pod，没有任何限制。</p>
<p>并不是所有的kubernetes网络方案都支持network policy，例如：Calico支持，Flannel不支持</p>
<h2 id="Canal"><a href="#Canal" class="headerlink" title="Canal"></a>Canal</h2><p>Canal：使用Flannel实现kubernetes集群网络、同时又使用Calico实现Networ Policy</p>
<!--目前没有太好的方法切换网络方案，即如果你现在用的是Fannel网络，只能重新部署k8s集群来重新部署网络，执行kubeadm reset销毁当前集群，执行kubeadm init初始化k8s集群-->



<h2 id="部署Canal"><a href="#部署Canal" class="headerlink" title="部署Canal"></a>部署Canal</h2><p>相关文档： <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a> </p>
<p>执行如下命令部署 Canal</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">kubectl apply <span class="operator">-f</span> https://raw.githubusercontent.com/projectcalico/canal/master/k8s<span class="literal">-install</span>/<span class="number">1.7</span>/rbac.yaml</span><br><span class="line">kubectl apply <span class="operator">-f</span> https://raw.githubusercontent.com/projectcalico/canal/master/k8s<span class="literal">-install</span>/<span class="number">1.7</span>/canal.yaml</span><br></pre></td></tr></table></figure>

<p>部署成功后，可以查看到 Canal 相关组件</p>
<h2 id="Network-Policy"><a href="#Network-Policy" class="headerlink" title="Network Policy"></a>Network Policy</h2><h3 id="首先部署一个httpd应用"><a href="#首先部署一个httpd应用" class="headerlink" title="首先部署一个httpd应用"></a>首先部署一个httpd应用</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">httpd</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">httpd</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">httpd:latest</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">httpd-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">httpd</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">nodePort:</span> <span class="number">30000</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<h3 id="验证访问"><a href="#验证访问" class="headerlink" title="验证访问"></a>验证访问</h3><p>1 启动一个busybox Pod访问</p>
<p>curl和ping</p>
<p>2 集群节点访问</p>
<p>3集群外部访问</p>
<h3 id="创建Network-Policy"><a href="#创建Network-Policy" class="headerlink" title="创建Network Policy"></a>创建Network Policy</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">access-httpd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">httpd</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">podSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">access:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>解析：</p>
<ul>
<li><strong>定义network policy中的规则应用于label为<code>run: httpd</code>的pod</strong></li>
<li><strong><code>ingress</code>中定义了只有label为<code>access: true</code>的Pod才能访问</strong></li>
<li><strong>只能访问<code>80</code>端口，ping也不行</strong></li>
</ul>
<h3 id="验证Network-Policy的有效性"><a href="#验证Network-Policy的有效性" class="headerlink" title="验证Network Policy的有效性"></a>验证Network Policy的有效性</h3><p>1 busybox Pod访问Service</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl run busybox --rm -it --image=busybox /bin/sh</span><br><span class="line">kubectl run busybox --rm -it --image=busybox --labels=&quot;access=true&quot; /bin/sh</span><br></pre></td></tr></table></figure>

<p>2 集群节点访问</p>
<p>无法访问</p>
<p>3 集群外部访问</p>
<p>无法访问</p>
<h3 id="让某个网络能够访问到应用"><a href="#让某个网络能够访问到应用" class="headerlink" title="让某个网络能够访问到应用"></a>让某个网络能够访问到应用</h3><p>修改yaml文件，添加<code>ipBlock</code>字段</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">from:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">podSelector:</span></span><br><span class="line">        <span class="attr">matchLabels:</span></span><br><span class="line">          <span class="attr">access:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">ipBlock:</span></span><br><span class="line">        <span class="attr">cidr:</span> <span class="number">192.168</span><span class="number">.128</span><span class="number">.0</span><span class="string">/24</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>现在集群节点和集群外已经能够访问应用了</p>
<h3 id="常用"><a href="#常用" class="headerlink" title="常用"></a>常用</h3><ul>
<li><code>ingress</code>限制进入的流量</li>
<li><code>egress</code>限制外出的流量</li>
</ul>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>CNI规范使得kubernetes可以灵活选择多种plugin实现集群网络</p>
<p>Network Policy赋予kubernetes强大的网络访问控制机制</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（3）：资源清单-资源类型</title>
    <url>/2020/01/04/3_%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95-%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="概念：k8s中的资源"><a href="#概念：k8s中的资源" class="headerlink" title="概念：k8s中的资源"></a>概念：k8s中的资源</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">集群资源分类</span><br><span class="line">	名称空间级别：kubeadm k8s kube-system</span><br><span class="line">	集群级别：role</span><br><span class="line">	元数据型：HPA（通过CPU利用率进行平滑扩展）</span><br></pre></td></tr></table></figure>



<p><strong>概念：</strong>K8S中所有的内容都抽象为资源，资源实例化之后，叫做对象</p>
<p><strong>工作负载型资源（workload）</strong>：Pod、ReplicaSet、Deployment、StatefulSet、DaemonSet、Job、CronJob（ReplicationController在v1.11版本中被废弃）</p>
<p><strong>服务发现及负载均衡型资源（ServiceDiscovery LoadBalance）</strong>：Service、Ingress、…</p>
<p><strong>配置域存储型资源：</strong>Volume（存储卷）、CSI（容器存储接口、可以扩展各种各样的第三方存储卷）</p>
<p><strong>特殊类型的存储卷：</strong>ConfigMap（当配置中心来使用的资源类型）、Secret（保存敏感数据）、DownwardAPI（把外部环境中的信息输出给容器）</p>
<p><strong>集群级资源：</strong>Namespace、Node、Role、ClusterRole、RoleBinding、ClusterRoleBinding</p>
<p><strong>元数据型资源：</strong>HPA、PodTemplate、LimitRange</p>
<h2 id="常用字段解释说明"><a href="#常用字段解释说明" class="headerlink" title="常用字段解释说明"></a>常用字段解释说明</h2><h3 id="必须存在的属性"><a href="#必须存在的属性" class="headerlink" title="必须存在的属性"></a>必须存在的属性</h3><p><img src="/assets/image-20200128204708542.png" alt="image-20200128204708542"></p>
<h3 id="主要对象"><a href="#主要对象" class="headerlink" title="主要对象"></a>主要对象</h3><p><img src="/assets/image-20200128205232226.png" alt="image-20200128205232226"></p>
<p><img src="/assets/image-20200128205359305.png" alt="image-20200128205359305"></p>
<p><img src="/assets/image-20200128205445846.png" alt="image-20200128205445846"></p>
<h3 id="额外的参数项"><a href="#额外的参数项" class="headerlink" title="额外的参数项"></a>额外的参数项</h3><p><img src="/assets/image-20200128205520664.png" alt="image-20200128205520664"></p>
<h3 id="系统中使用-kubectl-api-resources和-kubectl-explain-lt-资源对象-gt-可以查询下一级所有字段和类型"><a href="#系统中使用-kubectl-api-resources和-kubectl-explain-lt-资源对象-gt-可以查询下一级所有字段和类型" class="headerlink" title="系统中使用 kubectl api-resources和 kubectl explain &lt;资源对象&gt; 可以查询下一级所有字段和类型"></a>系统中使用 kubectl api-resources和 kubectl explain &lt;资源对象&gt; 可以查询下一级所有字段和类型</h3><h2 id="第一个pod例子"><a href="#第一个pod例子" class="headerlink" title="第一个pod例子"></a>第一个pod例子</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vi pod.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">  labels:</span><br><span class="line">    app: myapp</span><br><span class="line">    version: v1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: app</span><br><span class="line">    image: hub.test.com/library/myapp:v1</span><br><span class="line">  - name: test</span><br><span class="line">    image: hub.test.com/library/myapp:v1</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubectl create -f pod.yaml</span></span><br></pre></td></tr></table></figure>

<p><strong>这个例子会一直重启pod</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl describe pod myapp-pod # 查看pod重启原因</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 查看重启的容器的日志，可以发现80端口被占用了</span></span></span><br><span class="line">kubectl log myapp-pod -c test</span><br></pre></td></tr></table></figure>

<p><strong>找到原因之后，把删除pod，重新编辑pod.yaml文件，删除test容器即可</strong></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（4）：YAML语法</title>
    <url>/2020/01/04/4_YAML%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<h2 id="简单说明"><a href="#简单说明" class="headerlink" title="简单说明"></a>简单说明</h2><p>YAML是一个可读性高，用来表达数据序列的格式。YAML的意思其实是：仍是一种标记语言，但为了强调这种语言以数据作为中心，而不是以标记语言为重点</p>
<h2 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h2><ul>
<li><strong>缩进时不允许使用tab键，只允许使用空格</strong></li>
<li><strong>缩进的空格数目不重要，只要相同层级的元素左侧对齐即可</strong></li>
<li><strong># 标识注释，从这个字符一直到行尾，都会被解释器忽略</strong></li>
</ul>
<h2 id="YAML支持的数据结构"><a href="#YAML支持的数据结构" class="headerlink" title="YAML支持的数据结构"></a>YAML支持的数据结构</h2><ul>
<li><strong>对象：键值对的集合，又称为映射（mapping）/哈希（hashes）</strong></li>
<li><strong>数组：一组按次序排列的值，又称为序列（sequence）/列表（list）</strong></li>
<li><strong>纯量（scalars）：单个的、不可再分的值</strong></li>
</ul>
<h2 id="对象类型：对象的一组键值对，使用冒号结构表示"><a href="#对象类型：对象的一组键值对，使用冒号结构表示" class="headerlink" title="对象类型：对象的一组键值对，使用冒号结构表示"></a>对象类型：对象的一组键值对，使用冒号结构表示</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Steve</span></span><br><span class="line"><span class="attr">age:</span> <span class="number">18</span></span><br></pre></td></tr></table></figure>

<p><strong>YAML也允许另一种写法，将所有键值对写成一个行内对象</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">hash:</span> &#123; <span class="attr">name:</span> <span class="string">Steve</span>, <span class="attr">age:</span> <span class="number">18</span> &#125;</span><br></pre></td></tr></table></figure>



<h2 id="数组类型：一组连词线开头的行，构成一个数组"><a href="#数组类型：一组连词线开头的行，构成一个数组" class="headerlink" title="数组类型：一组连词线开头的行，构成一个数组"></a>数组类型：一组连词线开头的行，构成一个数组</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">animal</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Cat</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Dog</span></span><br></pre></td></tr></table></figure>

<p><strong>数组也可以采用行内表示法</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">animal:</span> [<span class="string">Cat</span>, <span class="string">Dog</span>]</span><br></pre></td></tr></table></figure>



<h2 id="复合结构：对象和数组可以结合使用，形成复合结构"><a href="#复合结构：对象和数组可以结合使用，形成复合结构" class="headerlink" title="复合结构：对象和数组可以结合使用，形成复合结构"></a>复合结构：对象和数组可以结合使用，形成复合结构</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">languages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Ruby</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Perl</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Python</span></span><br><span class="line"><span class="attr">websites:</span></span><br><span class="line"><span class="attr">YAML:</span> <span class="string">yaml.org</span></span><br><span class="line"><span class="attr">Ruby:</span> <span class="string">ruby-lang.org</span></span><br><span class="line"><span class="attr">Python:</span> <span class="string">python.org</span></span><br><span class="line"><span class="attr">Perl:</span> <span class="string">user.perl.org</span></span><br></pre></td></tr></table></figure>



<h2 id="纯量：纯量是最基本的、不可再分的值。以下数据类型都属于纯量"><a href="#纯量：纯量是最基本的、不可再分的值。以下数据类型都属于纯量" class="headerlink" title="纯量：纯量是最基本的、不可再分的值。以下数据类型都属于纯量"></a>纯量：纯量是最基本的、不可再分的值。以下数据类型都属于纯量</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> <span class="string">字符串</span> <span class="string">布尔值</span> <span class="string">证书</span> <span class="string">浮点数</span> <span class="literal">Null</span></span><br><span class="line"><span class="number">2</span> <span class="string">时间</span> <span class="string">日期</span></span><br><span class="line"></span><br><span class="line"><span class="string">数值直接以字面量的形式表示</span></span><br><span class="line"><span class="attr">number:</span> <span class="number">12.30</span></span><br><span class="line"></span><br><span class="line"><span class="string">布尔值用true和false表示</span></span><br><span class="line"><span class="attr">isSet:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="literal">null</span><span class="string">用~表示</span></span><br><span class="line"><span class="attr">parent:</span> <span class="string">~</span></span><br><span class="line"></span><br><span class="line"><span class="string">时间采用ISO8601格式</span></span><br><span class="line"><span class="attr">iso8601:</span> <span class="number">2001-12-14t21:49:43.10-05:00</span></span><br><span class="line"></span><br><span class="line"><span class="string">日期采用复合iso8601格式的年、月、日表示</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">1976-07-31</span></span><br><span class="line"></span><br><span class="line"><span class="string">YAML允许使用两个感叹号，强制转换数据类型</span></span><br><span class="line"><span class="attr">e:</span> <span class="type">!!str</span> <span class="number">123</span></span><br><span class="line"><span class="attr">f:</span> <span class="type">!!str</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><p><strong>字符串默认不使用引号表示</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">str</span> <span class="string">这是一行字符串</span></span><br></pre></td></tr></table></figure>

<p><strong>如果字符串之中包含空格或特殊字符，需要放在引号之中</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">str:</span> <span class="string">&#x27;内容：字符串&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>单引号和双引号都可以使用，双引号不会对特殊字符转义</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">s1:</span> <span class="string">&#x27;内容\n字符串&#x27;</span></span><br><span class="line"><span class="attr">s2:</span> <span class="string">&#x27;内容\n字符串&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>单引号之中如果还有单引号，必须连续使用两个单引号转义</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">str:</span> <span class="string">&#x27;labor&#x27;</span><span class="string">&#x27;s day&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>字符串可以写成多行，从第二行开始，必须有一个单空格缩进，换行符会被转为空格</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">str:</span> <span class="string">这是一段</span></span><br><span class="line">  <span class="string">多行</span></span><br><span class="line">  <span class="string">字符串</span></span><br></pre></td></tr></table></figure>

<p><strong>多行字符串可以使用|保留换行符，也可以使用&gt;折叠换行</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">this:</span> <span class="string">|</span></span><br><span class="line"><span class="string">Foo</span></span><br><span class="line"><span class="string">Bar</span></span><br><span class="line"><span class="attr">that:</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">Foo</span></span><br><span class="line"><span class="string">Bar</span></span><br></pre></td></tr></table></figure>

<p><strong>+表示保留文字块末尾的换行，-表示删除字符串末尾的换行</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">s1:</span> <span class="string">|</span></span><br><span class="line"> <span class="string">Foo</span></span><br><span class="line"><span class="attr">s2:</span> <span class="string">|+</span></span><br><span class="line"> <span class="string">Foo</span></span><br><span class="line"><span class="attr">s3:</span> <span class="string">|-</span></span><br><span class="line"> <span class="string">Foo</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>yaml</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（5）：Pod生命周期</title>
    <url>/2020/01/04/5_%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95-pod%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
    <content><![CDATA[<p><img src="/assets/image-20200128215254638.png" alt="image-20200128215254638"></p>
<p>init C：初始化容器，在pause创建之后开始创建，在初始化完成之后就会死亡，不能并行，必须一个执行完之后才能执行下一个。可以没有</p>
<p>main C：主容器</p>
<p>start：启动命令/脚本</p>
<p>stop：在MainC结束时也可以执行一个stop命令</p>
<p>readiness：就绪检测（可以设置在多少s之后再开始检测），判断pod是否可以对外访问，是，则显示状态为running</p>
<p>liveness：生存检测</p>
<p>kubectl →kubeapi接口→etcd→kubelet→操作CRI→完成环境的初始化（即上图）</p>
<p>在initC启动前会先启动Pause容器，负责网络栈以及存储卷共享</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（6）：init容器</title>
    <url>/2020/01/04/6_init%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><strong>init容器有如下几个特点：</strong></p>
<ul>
<li>init容器总是运行到成功完成为止</li>
<li>每个init容器都必须在下一个init容器启动之前成功完成</li>
<li>如果Pod的init容器失败，kubernetes会不断重启该pod，直到init容器成功为止。如果Pod对应的restartPolicy为Never，他不会重新启动。</li>
</ul>
<p><img src="/assets/image-20200130124724935.png" alt="image-20200130124724935"></p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h3 id="init模板"><a href="#init模板" class="headerlink" title="init模板"></a>init模板</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-pod</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo The app is running! &amp;&amp; sleep 3600&#x27;</span>]</span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup myservice; do echo waiting for myservice; sleep 2; done;&#x27;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;until nslookup mydb; do echo waiting for mydb; sleep2; done&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p><strong>查看pod创建详情</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 这时候查看pod状态</span><br><span class="line">kubectl get pod</span><br><span class="line">NAME        READY   STATUS     RESTARTS   AGE</span><br><span class="line">myapp-pod   0&#x2F;1     Init:0&#x2F;2   0          3m42s</span><br><span class="line"></span><br><span class="line"># 查看pod详情,可以看到创建pod成功，但是并没有继续执行下一步，原因是init容器命令并未执行成功</span><br><span class="line">kubectl describe pod myapp-pod</span><br><span class="line">Name:         myapp-pod</span><br><span class="line">Namespace:    default</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         k8s-node01&#x2F;192.168.128.141</span><br><span class="line">Start Time:   Thu, 30 Jan 2020 15:51:03 +0800</span><br><span class="line">Labels:       app&#x3D;myapp</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Status:       Pending</span><br><span class="line">IP:           10.244.1.6</span><br><span class="line">...</span><br><span class="line">中间省略</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age   From                 Message</span><br><span class="line">  ----    ------     ----  ----                 -------</span><br><span class="line">  Normal  Scheduled  59s   default-scheduler    Successfully assigned default&#x2F;myapp-pod to k8s-node01</span><br><span class="line">  Normal  Pulling    57s   kubelet, k8s-node01  Pulling image &quot;busybox&quot;</span><br><span class="line">  Normal  Pulled     45s   kubelet, k8s-node01  Successfully pulled image &quot;busybox&quot;</span><br><span class="line">  Normal  Created    45s   kubelet, k8s-node01  Created container init-myservice</span><br><span class="line">  Normal  Started    44s   kubelet, k8s-node01  Started container init-myservice</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看pod日志，可以看到nslookup执行不通过</span><br><span class="line">kubectl log myapp-pod -c  init-myservice</span><br><span class="line">log is DEPRECATED and will be removed in a future version. Use logs instead.</span><br><span class="line">Server:		10.96.0.10</span><br><span class="line">Address:	10.96.0.10:53</span><br><span class="line"></span><br><span class="line">** server can&#39;t find myservice.default.svc.cluster.local: NXDOMAIN</span><br><span class="line"></span><br><span class="line">*** Can&#39;t find myservice.svc.cluster.local: No answer</span><br><span class="line">*** Can&#39;t find myservice.cluster.local: No answer</span><br><span class="line">*** Can&#39;t find myservice.default.svc.cluster.local: No answer</span><br><span class="line">*** Can&#39;t find myservice.svc.cluster.local: No answer</span><br><span class="line">*** Can&#39;t find myservice.cluster.local: No answer</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>这时候需要创建一个svc，使得init容器可以nslookup执行成功</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myservice</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mydb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9377</span></span><br></pre></td></tr></table></figure>





<h2 id="特殊说明"><a href="#特殊说明" class="headerlink" title="特殊说明"></a>特殊说明</h2><p><img src="/assets/image-20200130161407116.png" alt="image-20200130161407116"></p>
<p><img src="/assets/image-20200130161726618.png" alt="image-20200130161726618"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（7）：pod检测探针</title>
    <url>/2020/01/04/7_%E6%8E%A2%E9%92%88/</url>
    <content><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p><img src="/assets/image-20200130162213788.png" alt="image-20200130162213788"></p>
<h2 id="探针方式"><a href="#探针方式" class="headerlink" title="探针方式"></a>探针方式</h2><p><img src="/assets/image-20200130162511586.png" alt="image-20200130162511586"></p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h3 id="检测探针-就绪检测"><a href="#检测探针-就绪检测" class="headerlink" title="检测探针-就绪检测"></a>检测探针-就绪检测</h3><h4 id="readinessProbe-httpGet"><a href="#readinessProbe-httpGet" class="headerlink" title="readinessProbe-httpGet"></a><strong>readinessProbe-httpGet</strong></h4><p>一开始pod容器中并没有index1.html，监测失败，当在容器中添加index1.html，监测成功</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">readiness-httpget-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-httpget-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">readinessProbe:</span></span><br><span class="line">      <span class="attr">httpGet:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/index1.html</span></span><br><span class="line">      <span class="attr">initialDelaySenconds:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">periodSenconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p><strong>initialDeplaySenconds：</strong>初始化监测延时时间，上述例子为1秒之后开始监测</p>
<p><strong>periodSenconds：</strong>重试监测时间，上述例子为3秒监测一次</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行pod创建</span></span><br><span class="line">kubectl create -f readiness-http-pod-yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod状态</span></span><br><span class="line">kubectl get pod</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看pod详细状态</span></span><br><span class="line">kubectl describe pod</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入pod的容器中修改</span></span><br><span class="line">kubectl exec readiness-httpget-pod -it -- /bin/sh</span><br></pre></td></tr></table></figure>





<h3 id="监测探针-存活监测"><a href="#监测探针-存活监测" class="headerlink" title="监测探针-存活监测"></a>监测探针-存活监测</h3><h4 id="livenessProbe-exec"><a href="#livenessProbe-exec" class="headerlink" title="livenessProbe-exec"></a>livenessProbe-exec</h4><p>一开始在容器中创建tmp文件，60s后删除，监测失败</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-exec-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">livness-exec-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&#x27;/bin/sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;touch /tmp/live; sleep 10;rm -rf /tmp/live; sleep 3600&#x27;</span>]</span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;-e&#x27;</span>, <span class="string">&#x27;/tmp/live&#x27;</span>]</span><br><span class="line">      <span class="attr">initialDeplaySeconds:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>



<h4 id="livenessProbe-httpGet"><a href="#livenessProbe-httpGet" class="headerlink" title="livenessProbe-httpGet"></a>livenessProbe-httpGet</h4><p>监测index.html文件是否能够get到</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-httpget-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-httpget-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">      <span class="attr">port:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/index.html</span></span><br><span class="line">    <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">timeoutSeconds:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>



<h4 id="livenessProbe-tcpSocket"><a href="#livenessProbe-tcpSocket" class="headerlink" title="livenessProbe-tcpSocket"></a>livenessProbe-tcpSocket</h4><p>检测pod8080端口是否能通信</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-tcp-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-tcp-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">initalDelayPSeconds:</span> <span class="number">5</span></span><br><span class="line">      <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>



<h4 id="也可以将就绪检测和存活检测写到一起"><a href="#也可以将就绪检测和存活检测写到一起" class="headerlink" title="也可以将就绪检测和存活检测写到一起"></a>也可以将就绪检测和存活检测写到一起</h4>]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（8）：pod-start、stop</title>
    <url>/2020/01/04/8_pod-start%E3%80%81stop%E3%80%81%E7%9B%B8%E4%BD%8D/</url>
    <content><![CDATA[<h2 id="start"><a href="#start" class="headerlink" title="start"></a>start</h2><p>Pod.spec.containers.lifecycle.<strong>postStart</strong></p>
<h2 id="stop"><a href="#stop" class="headerlink" title="stop"></a>stop</h2><p>Pod.spec.containers.lifecycle.<strong>preStop</strong></p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">lifecycle-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">hub.test.com/library/myapp:v1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">lifecycle:</span></span><br><span class="line">      <span class="attr">postStart:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo postStart &gt; /usr/share/message&#x27;</span>]</span><br><span class="line">      <span class="attr">preStop:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo preStop &gt; /usr/share/message&#x27;</span>]</span><br></pre></td></tr></table></figure>



<h2 id="pod-phase-可能存在的值"><a href="#pod-phase-可能存在的值" class="headerlink" title="pod phase 可能存在的值"></a>pod phase 可能存在的值</h2><p><img src="/assets/image-20200130235102503.png" alt="image-20200130235102503"></p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s学习（9）：资源控制器</title>
    <url>/2020/01/05/9_%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/</url>
    <content><![CDATA[<p>控制器管理的pod，在控制器的生命周期里，始终要位置pod的副本数目</p>
<h2 id="什么是控制器"><a href="#什么是控制器" class="headerlink" title="什么是控制器"></a>什么是控制器</h2><p><strong>kubernetes中内建了很多controller（控制器），这里相当于一个状态机，用来控制pod的具体状态和行为</strong></p>
<h2 id="控制器类型"><a href="#控制器类型" class="headerlink" title="控制器类型"></a>控制器类型</h2><ul>
<li><strong>ReplicationController(不再使用)和ReplicaSet</strong></li>
<li><strong>Deployment</strong></li>
<li><strong>DaemonSet</strong></li>
<li><strong>StateFulSet</strong></li>
<li><strong>Job/cronJob</strong></li>
<li><strong>Horizontal Pod Autoscaling(HPA)</strong></li>
</ul>
<h2 id="ReplicationController和ReplicaSet"><a href="#ReplicationController和ReplicaSet" class="headerlink" title="ReplicationController和ReplicaSet"></a>ReplicationController和ReplicaSet</h2><p>RC用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod来替代；而如果异常多出来的容器也会自动回收；</p>
<p>RS在新版本已经取代了RC，RS支持集合式的selector</p>
<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><p>Deployment为Pod和ReplicaSet提供了一个声明式定义（declarative）方法，用来替代以前的RC来方便的管理应用。典型的应用场景包括：</p>
<ul>
<li><strong>定义deployment来创建pod和ReplicaSet</strong></li>
<li><strong>滚动升级和回滚应用</strong></li>
<li><strong>扩容和缩容</strong></li>
<li><strong>暂停和继续deployment</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">声明 deployment apply</span><br><span class="line">命令 rs create</span><br></pre></td></tr></table></figure>



<h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2><p>DaemonSet确保全部（或者一些）Node上<strong>运行一个Pod的副本</strong>。当有Node加入集群时，也会为他们新增一个Pod。当有Node从集群移除时，这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod</p>
<p>典型用法：</p>
<ul>
<li><strong>运行集群存储daemon，例如在每个Node上运行glusterd、ceph-mon</strong></li>
<li><strong>在每个Node上运行日志收集daemon，例如fluentd、logstash</strong></li>
<li><strong>在每个Node上运行监控daemon，例如Prometheus Node Exporter、collectd、Datadog代理、New Relic代理、Ganglia gmond</strong></li>
</ul>
<h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2><p>Job负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束</p>
<h2 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob * * * * *"></a>CronJob * * * * *</h2><ul>
<li><strong>CronJob管理基于时间的Job，即：</strong></li>
<li><strong>在给定时间点只运行一次</strong></li>
<li><strong>周期性在给定时间点运行</strong></li>
</ul>
<p>使用前提条件： 当前使用的k8s集群版本&gt;=1.8，小于1.8的集群，在启动API Server时，通过传递选项–runtime-config=batch/v2alpha1=true</p>
<p>典型用法：</p>
<ul>
<li><strong>在给定时间点调度Job运行</strong></li>
<li><strong>创建周期性运行的Job，例如：数据库备份、发送邮件</strong></li>
</ul>
<h2 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h2><p>StatefulSet作为controller为Pod提供唯一的标识。它可以保证部署和scale的顺序</p>
<p>StatefulSet是为了解决有状态服务的问题（对应Deployments和RS是为了无状态服务而设计），其应用场景包括：</p>
<ul>
<li><strong>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC实现</strong></li>
<li><strong>稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于headless Service（即没有ClusterIP的Service）来实现</strong></li>
<li><strong>有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init Containers来实现</strong></li>
<li><strong>有序收缩，有序删除（即从N-1到0）</strong></li>
</ul>
<h2 id="Horizontal-Pod-Autoscaling（HPA）"><a href="#Horizontal-Pod-Autoscaling（HPA）" class="headerlink" title="Horizontal Pod Autoscaling（HPA）"></a>Horizontal Pod Autoscaling（HPA）</h2><p>应用的资源使用率通常都有高峰和低谷，如何削峰填谷，提高集群的整体资源利用率让service和Pod个数自动调整，就需要用到HPA，即Pod水平自动缩放</p>
]]></content>
      <categories>
        <category>kubernetes教程</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes安全认证专家(CKS) 考纲</title>
    <url>/2021/03/08/CKS%E8%80%83%E8%AF%95%E5%A4%A7%E7%BA%B2/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>年后花了点时间准备了下CKS的考试，，通过了CKS的认证，记录一下考试的内容</p>
<p><img src="/images/about/CKS.png" alt="CKS"></p>
<h2 id="1-要求"><a href="#1-要求" class="headerlink" title="1. 要求"></a>1. 要求</h2><p>考试模式：线上考试</p>
<p>考试时间：2小时</p>
<p>认证有效期：2年</p>
<p>软件版本：Kubernetes v1.20</p>
<p>系统：Ubuntu 18.4</p>
<p>有效期：考试资格自购买之日起12个月内有效</p>
<p>重考政策：可接受1次重考</p>
<p>经验水平：中级</p>
<p><strong>考试报名</strong>：<a href="https://training.linuxfoundation.cn/certificates/16">https://training.linuxfoundation.cn/certificates/16</a></p>
<h2 id="2-考点内容-CKS-课程（翻译）"><a href="#2-考点内容-CKS-课程（翻译）" class="headerlink" title="2. 考点内容-CKS 课程（翻译）"></a>2. 考点内容-CKS 课程（翻译）</h2><h3 id="10-Cluster-Setup集群设置"><a href="#10-Cluster-Setup集群设置" class="headerlink" title="10% - Cluster Setup集群设置"></a>10% - Cluster Setup集群设置</h3><ul>
<li>Use Network security policies to restrict cluster level access（使用网络安全策略限制群集级别的访问）</li>
<li>Use CIS benchmark to review the security configuration of Kubernetes components (etcd, kubelet, kubedns, kubeapi)（使用CIS基准来检查Kubernetes组件（etcd，kubelet，kubedns，kubeapi）的安全配置）</li>
<li>Properly set up Ingress objects with security control（通过安全控制正确设置Ingress对象）</li>
<li>Protect node metadata and endpoints（保护节点元数据和端点）</li>
<li>Minimize use of, and access to, GUI elements（最大限度地减少对GUI元素的使用和访问）</li>
<li>Verify platform binaries before deploying（部署前验证平台二进制文件）</li>
</ul>
<h3 id="15-Cluster-Hardening集群强化"><a href="#15-Cluster-Hardening集群强化" class="headerlink" title="15% - Cluster Hardening集群强化"></a>15% - Cluster Hardening集群强化</h3><ul>
<li><p>Restrict access to Kubernetes API（限制对Kubernetes API的访问）</p>
</li>
<li><p>Use Role Based Access Controls to minimize exposure（使用基于角色的访问控制来最大程度地减少暴露）</p>
</li>
<li><p>Exercise caution in using service accounts e.g. disable defaults, minimize permissions on newly created ones（使用服务帐户时请格外小心，例如 禁用默认值，最小化对新创建的权限）</p>
</li>
<li><p>Update Kubernetes frequently（经常更新Kubernetes）</p>
</li>
</ul>
<h3 id="15-System-Hardening系统强化"><a href="#15-System-Hardening系统强化" class="headerlink" title="15% - System Hardening系统强化"></a>15% - System Hardening系统强化</h3><ul>
<li><p>Minimize host OS footprint (reduce attack surface)（最小化主机操作系统的占用空间（减少攻击面））</p>
</li>
<li><p>Minimize IAM roles（最小化IAM角色）</p>
</li>
<li><p>Minimize external access to the network（最小化对网络的外部访问）</p>
</li>
<li><p>Appropriately use kernel hardening tools such as AppArmor, seccomp（适当使用内核强化工具，例如AppArmor，seccomp）</p>
</li>
</ul>
<h3 id="20-Minimize-Microservice-Vulnerabilities最小化微服务漏洞"><a href="#20-Minimize-Microservice-Vulnerabilities最小化微服务漏洞" class="headerlink" title="20% - Minimize Microservice Vulnerabilities最小化微服务漏洞"></a>20% - Minimize Microservice Vulnerabilities最小化微服务漏洞</h3><ul>
<li>Setup appropriate OS level security domains e.g. using PSP, OPA, security contexts（设置适当的操作系统级别的安全域，例如 使用PSP，OPA，安全上下文）</li>
<li>Manage kubernetes secrets（管理kubernetes的secret）</li>
<li>Use container runtime sandboxes in multi-tenant environments (e.g. gvisor, kata containers) （在多租户环境中使用容器运行时沙箱（例如gvisor，kata容器））</li>
<li>Implement pod to pod encryption by use of mTLS（通过使用mTLS实现Pod到Pod的加密）</li>
</ul>
<h3 id="20-Supply-Chain-Security供应链安全"><a href="#20-Supply-Chain-Security供应链安全" class="headerlink" title="20% - Supply Chain Security供应链安全"></a>20% - Supply Chain Security供应链安全</h3><ul>
<li>Minimize base image footprint（最大限度地减少基础镜像占用空间）</li>
<li>Secure your supply chain: whitelist allowed image registries, sign and validate images（保护您的供应链：将允许的图像注册表列入白名单，对图像进行签名和验证）</li>
<li>Use static analysis of user workloads (e.g. kubernetes resources, docker files)（使用静态分析用户工作负载（例如kubernetes资源，docker文件））</li>
<li>Scan images for known vulnerabilities（扫描镜像中的已知漏洞）</li>
</ul>
<h3 id="20-Monitoring-Logging-and-Runtime-Security监视，记录和运行时安全"><a href="#20-Monitoring-Logging-and-Runtime-Security监视，记录和运行时安全" class="headerlink" title="20% - Monitoring, Logging and Runtime Security监视，记录和运行时安全"></a>20% - Monitoring, Logging and Runtime Security监视，记录和运行时安全</h3><ul>
<li>Perform behavioral analytics of syscall process and file activities at the host and container level to detect malicious activities（在主机和容器级别执行系统调用过程和文件活动的行为分析，以检测恶意活动）</li>
<li>Detect threats within physical infrastructure, apps, networks, data, users and workloads（检测物理基础架构，应用程序，网络，数据，用户和工作负载中的威胁）</li>
<li>Detect all phases of attack regardless where it occurs and how it spreads（检测攻击的所有阶段，无论攻击发生在何处以及如何扩散）</li>
<li>Perform deep analytical investigation and identification of bad actors within environment • Ensure immutability of containers at runtime（对环境中的不良行为进行深入的分析调查和识别•确保运行时容器不变）</li>
<li>Use Audit Logs to monitor access（使用审核日志来监视访问）</li>
</ul>
<h2 id="3-需要掌握内容"><a href="#3-需要掌握内容" class="headerlink" title="3. 需要掌握内容"></a>3. 需要掌握内容</h2><h3 id="3-1-群集设置-10"><a href="#3-1-群集设置-10" class="headerlink" title="3.1 群集设置 10%"></a>3.1 群集设置 10%</h3><p>1.使用网络安全策略限制群集级别的访问</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">使用网络策略控制流量</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/">保护Kubernetes集群安全</a></li>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/">声明网络策略以控制Pod的通信方式</a></li>
<li><a href="https://kubernetes.io/blog/2017/10/enforcing-network-policies-in-kubernetes/">强化集群网络策略</a></li>
</ul>
<p>2.使用CIS基准来检查Kubernetes组件（etcd，kubelet，kubedns，kubeapi）的安全配置</p>
<ul>
<li>[了解什么是Center for Internet Security（CIS）基准](<a href="https://docs.microsoft.com/en-us/compliance/regulatory/offering-CIS-Benchmark#:~:text=CIS">https://docs.microsoft.com/en-us/compliance/regulatory/offering-CIS-Benchmark#:~:text=CIS</a> benchmarks are configuration baselines,organizations improve their cyberdefense capabilities.)</li>
<li><a href="https://github.com/aquasecurity/kube-bench#running-kube-bench">Kubernetes CIS Benchmark测试的工具：kube-bench的安装</a></li>
<li><a href="https://cloud.google.com/kubernetes-engine/docs/concepts/cis-benchmarks#default-valueshttps://cloud.google.com/kubernetes-engine/docs/concepts/cis-benchmarks#default-values">etcd和kubelet的CIS基准</a></li>
<li>用kube-bench检测master及worker上隐患配置</li>
</ul>
<p>3.配置ingress的安全设置</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">了解什么是Ingress</a></li>
<li><a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">什么是输入控制器（Ingress Controllers?）?</a></li>
<li><a href="https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/">在Minikube入口控制器上设置入口</a></li>
<li>创建自签名证书替换ingress自带的证书</li>
</ul>
<p>4.保护节点元数据</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/#restricting-cloud-metadata-api-access">限制通过API访问元数据</a></li>
<li><a href="https://blog.cloud66.com/setting-up-secure-endpoints-in-kubernetes/">在Kubernetes中设置安全端点</a></li>
<li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/protecting-cluster-metadata">保护集群元数据(GKE)</a></li>
<li>通过配置文件设置 Kubelet 参数</li>
</ul>
<p>5.最大限度地减少对dashboard的使用和访问</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">基于web的Kubernetes用户界面</a></li>
<li><a href="https://blog.heptio.com/on-securing-the-kubernetes-dashboard-16b09b1b7aca?gi=ed673f28dbc8">设置Kubernetes dashboard的安全</a></li>
</ul>
<p>6.部署前验证kubernetes二进制文件</p>
<ul>
<li><a href="https://github.com/kubernetes/kubernetes/releases">通过sha512sum验证kubernetes二进制文件</a></li>
</ul>
<h3 id="3-2-群集强化-15"><a href="#3-2-群集强化-15" class="headerlink" title="3.2 群集强化 15%"></a>3.2 群集强化 15%</h3><p>1.限制对Kubernetes API的访问</p>
<ul>
<li><a href="https://cloud.google.com/anthos/gke/docs/on-prem/how-to/hardening-your-cluster">加强集群的安全性</a></li>
<li>了解访问kubernetes api的流程</li>
<li><a href="https://kubernetes.io/docs/concepts/security/controlling-access/">控制对Kubernetes API的访问</a></li>
</ul>
<p>2.使用RBAC最大程度的减少资源暴露</p>
<ul>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/authorization/#authorization-modules">了解kubernetes api server的授权模块</a></li>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">使用RBAC授权</a></li>
<li><a href="https://www.youtube.com/watch?v=G3R24JSlGjY">理解RBAC授权</a></li>
</ul>
<p>3.SA的安全设置，例如禁用默认值，最小化对新创建sa的权限</p>
<ul>
<li><a href="https://thenewstack.io/kubernetes-access-control-exploring-service-accounts/">Kubernetes访问控制:探索服务帐户SA</a></li>
<li><a href="https://docs.armory.io/docs/spinnaker-install-admin-guides/manual-service-account/">Kubernetes:创建服务帐户和Kubeconfigs</a></li>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/">置Pods的服务帐号SA</a></li>
<li><a href="https://stackoverflow.com/questions/52583497/how-to-disable-the-use-of-a-default-service-account-by-a-statefulset-deployments">在Kubernetes中部署时禁用默认服务帐户</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/57601">Kubernetes不应该挂载默认的服务帐户</a></li>
<li><a href="https://www.cyberark.com/resources/threat-research-blog/securing-kubernetes-clusters-by-eliminating-risky-permissions">通过消除危险的权限来保护Kubernetes集群</a></li>
<li>了解默认情况下SA带来的安全隐患及演示</li>
<li>如何有效解决sa的权限问题</li>
</ul>
<p>4.更新Kubernetes</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/">用kubeadm升级集群</a></li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-upgrade/">kubeadm升级</a></li>
</ul>
<h3 id="3-3-系统强化-15"><a href="#3-3-系统强化-15" class="headerlink" title="3.3 系统强化 15%"></a>3.3 系统强化 15%</h3><p>1.服务器的安全设置</p>
<ul>
<li>[最小化主机操作系统占用空间(减少攻击面)](<a href="https://blog.sonatype.com/kubesecops-kubernetes-security-practices-you-should-follow#:~:text=Reduce">https://blog.sonatype.com/kubesecops-kubernetes-security-practices-you-should-follow#:~:text=Reduce</a> Kubernetes Attack Surfaces)</li>
<li>去除系统不需要的内核模块</li>
</ul>
<p>2.最小化IAM角色</p>
<ul>
<li><a href="https://digitalguardian.com/blog/what-principle-least-privilege-polp-best-practice-information-security-and-compliance">了解什么是最低特权原则（POLP）</a></li>
</ul>
<p>3.最小化外部网络访问</p>
<ul>
<li><a href="https://help.replicated.com/community/t/managing-firewalls-with-ufw-on-kubernetes/230">使用操作系统级防火墙保护主机</a></li>
<li><a href="https://docs.microsoft.com/en-us/azure/aks/concepts-security#azure-network-security-groups">使用安全组来保护网络(Azure)</a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/sec-group-reqs.html">亚马逊重视安全组的考虑</a></li>
<li>使resourcequota及limitrange限制对资源的访问</li>
</ul>
<p>4.适当使用内核强化工具，例如AppArmor，seccomp</p>
<ul>
<li><a href="https://www.sumologic.com/blog/kubernetes-security/#security-best-practices">Kubernetes强化了最佳实践</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/clusters/apparmor/">使用AppArmor限制容器对资源的访问</a></li>
<li><a href="https://kubernetes.io/docs/tutorials/clusters/seccomp/">使用Seccomp限制容器的syscall</a></li>
</ul>
<h3 id="3-4-最小化微服务漏洞-20"><a href="#3-4-最小化微服务漏洞-20" class="headerlink" title="3.4 最小化微服务漏洞 20%"></a>3.4 最小化微服务漏洞 20%</h3><p>1.使用PSP，OPA，安全上下文提高安全性</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/">了解并配置Pod安全策略(PSP)</a></li>
<li><a href="https://www.youtube.com/watch?v=Yup1FUc2Qn0&feature=youtu.be">了解什么是 Open Policy Agent(OPA)</a></li>
<li><a href="https://kubernetes.io/blog/2019/08/06/opa-gatekeeper-policy-and-governance-for-kubernetes/">OPA Gatekeeper的配置</a></li>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">为Pod或容器配置安全上下文(securityContext)</a></li>
</ul>
<p>2.管理Kubernetes secret</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/configuration/secret/">使用secret存储敏感信息</a></li>
<li><a href="https://www.weave.works/blog/managing-secrets-in-kubernetes">静态加密 Secret 数据</a></li>
</ul>
<p>3.在多租户环境中使用沙箱运行容器（例如gvisor，kata容器）</p>
<ul>
<li>了解为什么要部署沙箱</li>
<li><a href="https://gvisor.dev/docs/">什么是gVisor？安装gvisor</a></li>
<li><a href="https://thenewstack.io/how-to-implement-secure-containers-using-googles-gvisor/">使用谷歌的gVisor实现安全容器</a></li>
<li><a href="https://gvisor.dev/docs/user_guide/quick_start/kubernetes/">使用gVisor运行Pod</a></li>
<li><a href="https://platform9.com/blog/kata-containers-docker-and-kubernetes-how-they-all-fit-together/">Kata容器和Kubernetes:它们如何组合在一起?</a></li>
<li><a href="https://github.com/kata-containers/documentation/blob/master/how-to/how-to-use-k8s-with-cri-containerd-and-kata.md">如何使用Kata容器与Kubernetes?</a></li>
</ul>
<p>4.使用mTLS实施Pod到Pod的加密</p>
<ul>
<li><a href="https://codeburst.io/mutual-tls-authentication-mtls-de-mystified-11fa2a52e9cf?gi=9e3ace049450">了解什么是mTLS(mutual TLS)</a></li>
<li><a href="https://www.istioworkshop.io/11-security/01-mtls/">使用mTLS进行流量加密</a></li>
<li><a href="https://istio.io/latest/blog/2017/0.1-auth/">使用Istio提高端到端安全性</a></li>
</ul>
<h3 id="3-5-供应链安全-20"><a href="#3-5-供应链安全-20" class="headerlink" title="3.5 供应链安全 20%"></a>3.5 供应链安全 20%</h3><p>1.减小image的大小</p>
<ul>
<li><a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-how-and-why-to-build-small-container-images">为什么要在Kubernetes中构建小容器映像</a></li>
<li><a href="https://cloud.google.com/solutions/best-practices-for-building-containers#build-the-smallest-image-possible">如何创建比较小的镜像</a></li>
</ul>
<p>2.保护供应链：将允许的镜像仓库列入白名单，对镜像进行签名和验证</p>
<ul>
<li><a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">了解准入控制器Admission Controllers</a></li>
<li><a href="https://stackoverflow.com/questions/54463125/how-to-reject-docker-registries-in-kubernetes">如何拒绝docker镜像仓库（黑名单）在Kubernetes?</a></li>
<li><a href="https://github.com/kubernetes/kubernetes/issues/22888">了解并配置ImagePolicyWebhook，确保只运行来自批准来源的映像</a></li>
<li><a href="https://www.openpolicyagent.org/docs/latest/kubernetes-primer/">配置kubernetes所使用镜像仓库的白名单及黑名单</a></li>
<li><a href="https://medium.com/sse-blog/container-image-signatures-in-kubernetes-19264ac5d8ce">对镜像进行签名和验证</a></li>
</ul>
<p>3.分析文件及镜像安全隐患（例如Kubernetes的yaml文件，Dockerfile）</p>
<ul>
<li><a href="https://kube-score.com/">使用Kube-score进行静态分析</a></li>
<li><a href="https://bridgecrew.io/blog/kubernetes-static-code-analysis-with-checkov/">Kubernetes静态代码分析与Checkov</a></li>
<li><a href="https://github.com/quay/clair">使用Clair进行静态分析</a></li>
</ul>
<p>4.扫描图像，找出已知的漏洞</p>
<ul>
<li><a href="https://medium.com/better-programming/scan-your-docker-images-for-vulnerabilities-81d37ae32cb3">扫描你的Docker镜像的漏洞</a></li>
<li><a href="https://github.com/leahnp/clair-klar-kubernetes-demo">用Clair扫描Docker容器的漏洞</a></li>
</ul>
<h3 id="3-6-监控、审计和runtime-20"><a href="#3-6-监控、审计和runtime-20" class="headerlink" title="3.6 监控、审计和runtime 20%"></a>3.6 监控、审计和runtime 20%</h3><p>1.分析容器系统调用，以检测恶意进程</p>
<ul>
<li><a href="https://sysdig.com/blog/how-to-detect-kubernetes-vulnerability-cve-2019-11246-using-falco/">如何使用Falco检测Kubernetes漏洞</a></li>
<li><a href="https://medium.com/@SkyscannerEng/kubernetes-security-monitoring-at-scale-with-sysdig-falco-a60cfdb0f67a">用sysdig 对kubernetes进行安全监控</a></li>
</ul>
<p>2.检测物理基础设施、应用程序、网络、数据、用户和工作负载中的威胁</p>
<ul>
<li><a href="https://www.cncf.io/blog/2020/08/07/common-kubernetes-config-security-threats/">Common Kubernetes配置安全威胁</a></li>
<li><a href="https://www.trendmicro.com/vinfo/us/security/news/virtualization-and-cloud/guidance-on-kubernetes-threat-modeling">Kubernetes威胁建模指南</a></li>
</ul>
<p>3.检测攻击的所有阶段，无论它发生在哪里，如何传播</p>
<ul>
<li><a href="https://www.threatstack.com/blog/kubernetes-attack-scenarios-part-1">在威胁堆栈中调查Kubernetes的攻击场景</a></li>
<li><a href="https://www.optiv.com/explore-optiv-insights/source-zero/anatomy-kubernetes-attack-how-untrusted-docker-images-fail-us">Kubernetes攻击剖析——不可信的Docker镜像是如何让我们失望的</a><br>4.对环境中的不良行为进行深入的分析调查和识别<br><a href="https://www.stackrox.com/post/2020/05/kubernetes-security-101/">Kubernetes安全101:风险和最佳实践</a><br>5.确保容器在运行时的不变性</li>
<li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/keeping_containers_fresh_and_updateable#leveraging_kubernetes_and_openshift_to_ensure_that_containers_are_immutable">利用Kubernetes确保容器是不可变的</a></li>
<li><a href="https://medium.com/sroze/why-i-think-we-should-all-use-immutable-docker-images-9f4fdcb5212f">为什么我们要使用不可变的Docker图像?</a></li>
<li><a href="https://techbeacon.com/enterprise-it/immutable-infrastructure-your-systems-can-rise-dead">有了不可变的基础设施，您的系统可以起死回生</a></li>
</ul>
<p>6.Kubernetes审计</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/">kubernetes审计</a></li>
<li><a href="https://www.datadoghq.com/blog/monitor-kubernetes-audit-logs/">如何监控Kubernetes审计日志</a></li>
<li><a href="https://docs.sysdig.com/en/kubernetes-audit-logging.html">分析Kubernetes审计日志</a></li>
</ul>
<h2 id="4-考试资料"><a href="#4-考试资料" class="headerlink" title="4. 考试资料"></a>4. 考试资料</h2><ul>
<li><a href="https://github.com/Evalle/CKS">https://github.com/Evalle/CKS</a></li>
<li><a href="https://www.stackrox.com/post/2020/04/enhancing-kubernetes-security-with-open-policy-agent-opa-part-1/">kubernetes-security书籍</a></li>
</ul>
<p>相关阅读：</p>
<ul>
<li><a href="https://ghostwritten.blog.csdn.net/article/details/104956536">CKA、CKAD考试经验</a></li>
<li><a href="https://ghostwritten.blog.csdn.net/article/details/108313252">CKAD考试预备动员</a></li>
<li><a href="https://ghostwritten.blog.csdn.net/article/details/107133651">ubuntu16.0安装kubernetes集群为练习CKA准备</a></li>
<li><a href="https://ghostwritten.blog.csdn.net/article/details/107884669">CKA原英文考试2019年12月答案</a></li>
</ul>
<h2 id="5-考试期间允许的资源"><a href="#5-考试期间允许的资源" class="headerlink" title="5. 考试期间允许的资源"></a>5. <strong>考试期间允许的资源</strong></h2><p>考试期间，考生可以：</p>
<ul>
<li><p>查看命令行终端中显示的考试内容说明。</p>
</li>
<li><p>查看发行版安装的文档（即/ usr / share及其子目录）</p>
</li>
<li><p>使用他们的Chrome或Chromium浏览器打开另一个标签以访问 </p>
<ul>
<li><p><strong>Kubernetes文档：</strong> </p>
<ul>
<li><a href="https://kubernetes.io/docs/%E5%8F%8A%E5%85%B6%E5%AD%90%E5%9F%9F%E5%90%8D">https://kubernetes.io/docs/及其子域名</a></li>
<li><a href="https://github.com/kubernetes/%E5%8F%8A%E5%85%B6%E5%AD%90%E5%9F%9F%E5%90%8D">https://github.com/kubernetes/及其子域名</a></li>
<li><a href="https://kubernetes.io/blog/%E5%8F%8A%E5%85%B6%E5%AD%90%E5%9F%9F%E5%90%8D">https://kubernetes.io/blog/及其子域名</a></li>
</ul>
<p>这包括这些页面的所有可用语言翻译（例如<a href="https://kubernetes.io/zh/docs/home/">https://kubernetes.io/zh/docs/</a>）</p>
</li>
<li><p><strong>工具：</strong></p>
<ul>
<li>Trivy文档<a href="https://github.com/aquasecurity/trivy">https://github.com/aquasecurity/trivy</a></li>
<li>Sysdig文档<a href="https://docs.sysdig.com/">https://docs.sysdig.com/</a></li>
<li>法尔科文档<a href="https://falco.org/docs/">https://falco.org/docs/</a></li>
</ul>
<p>这包括这些页面的所有可用语言翻译（例如<a href="https://falco.org/zh/docs/%EF%BC%89">https://falco.org/zh/docs/）</a></p>
</li>
<li><p><strong>App Armor：</strong></p>
<ul>
<li>文档<a href="https://gitlab.com/apparmor/apparmor/-/wikis/Documentation">https://gitlab.com/apparmor/apparmor/-/wikis/Documentation</a></li>
</ul>
<p><em>上面允许的站点可能包含指向外部站点的链接。考生有责任不单击任何链接导航到不允许的域</em></p>
</li>
</ul>
</li>
</ul>
<p>可能有用的优惠码</p>
<p><code>SCOFFER15</code></p>
<!-- 可能有用的连接：-->

<!-- https://github.com/Evalle/CKS -->



]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>cks</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7.7升级内核至5.x</title>
    <url>/2020/08/10/CentOS7-7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E8%87%B35-x/</url>
    <content><![CDATA[<p> CentOS7.7升级内核至5.x</p>
<p>由于需要验证一个问题，需要将CentOS7内核升级至5.x版本</p>
<ol>
<li>查看系统版本和内核版本</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># cat /etc/redhat-release </span></span><br><span class="line">CentOS Linux release 7.7.1908 (Core)</span><br><span class="line"></span><br><span class="line">[root@k8s ~]<span class="comment"># uname -a</span></span><br><span class="line">Linux k8s 3.10.0-1062.18.1.el7.x86_64 <span class="comment">#1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>导入elrepo的key，并安装内核（elrepo）仓库</li>
</ol>
<p>elrepo仓库支持Red Hat Enterprise Linux（RHEL）及其衍生版本（Scientific Linux，CentOS等）。</p>
<p>参考：<a href="http://elrepo.org/tiki/tiki-index.php">http://elrepo.org/tiki/tiki-index.php</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span></span><br><span class="line">[root@k8s ~]<span class="comment"># yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm</span></span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">elrepo-release-7.el7.elrepo.noarch.rpm                                                                                                               | 8.6 kB  00:00:00     </span><br><span class="line">Examining /var/tmp/yum-root-GHYeAv/elrepo-release-7.el7.elrepo.noarch.rpm: elrepo-release-7.0-5.el7.elrepo.noarch</span><br><span class="line">Marking /var/tmp/yum-root-GHYeAv/elrepo-release-7.el7.elrepo.noarch.rpm to be installed</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package elrepo-release.noarch 0:7.0-5.el7.elrepo will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">============================================================================================================================================================================</span><br><span class="line"> Package                              Arch                         Version                                  Repository                                                 Size</span><br><span class="line">============================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> elrepo-release                       noarch                       7.0-5.el7.elrepo                         /elrepo-release-7.el7.elrepo.noarch                       5.0 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">============================================================================================================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total size: 5.0 k</span><br><span class="line">Installed size: 5.0 k</span><br><span class="line">Is this ok [y/d/N]: y</span><br><span class="line">Downloading packages:</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction <span class="built_in">test</span></span><br><span class="line">Transaction <span class="built_in">test</span> succeeded</span><br><span class="line">Running transaction</span><br><span class="line">Warning: RPMDB altered outside of yum.</span><br><span class="line">  Installing : elrepo-release-7.0-5.el7.elrepo.noarch                                                                                                                   1/1 </span><br><span class="line">  Verifying  : elrepo-release-7.0-5.el7.elrepo.noarch                                                                                                                   1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  elrepo-release.noarch 0:7.0-5.el7.elrepo                                                                                                                                  </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>查看可用内核版本</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available</span></span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Determining fastest mirrors</span><br><span class="line"> * elrepo-kernel: mirror-hk.koddos.net</span><br><span class="line">elrepo-kernel                                                                                                                                        | 2.9 kB  00:00:00     </span><br><span class="line">elrepo-kernel/primary_db                                                                                                                             | 1.9 MB  00:00:00     </span><br><span class="line">Available Packages</span><br><span class="line">kernel-lt.x86_64                                                                      4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-lt-devel.x86_64                                                                4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-lt-doc.noarch                                                                  4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-lt-headers.x86_64                                                              4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-lt-tools.x86_64                                                                4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs.x86_64                                                           4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs-devel.x86_64                                                     4.4.232-1.el7.elrepo                                                     elrepo-kernel</span><br><span class="line">kernel-ml.x86_64                                                                      5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">kernel-ml-devel.x86_64                                                                5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">kernel-ml-doc.noarch                                                                  5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">kernel-ml-headers.x86_64                                                              5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">kernel-ml-tools.x86_64                                                                5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs.x86_64                                                           5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs-devel.x86_64                                                     5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">perf.x86_64                                                                           5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br><span class="line">python-perf.x86_64                                                                    5.8.0-1.el7.elrepo                                                       elrepo-kernel</span><br></pre></td></tr></table></figure>





<ol start="4">
<li>yum安装kernel-ml 最新版内核</li>
</ol>
<p>其中lt为4.4版本，ml是5.8版本，所以这里我们需要安装ml版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># yum install kernel-ml --enablerepo=elrepo-kernel -y</span></span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * elrepo: mirror-hk.koddos.net</span><br><span class="line"> * elrepo-kernel: mirror-hk.koddos.net</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package kernel-ml.x86_64 0:5.8.0-1.el7.elrepo will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">============================================================================================================================================================================</span><br><span class="line"> Package                               Arch                               Version                                           Repository                                 Size</span><br><span class="line">============================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> kernel-ml                             x86_64                             5.8.0-1.el7.elrepo                                elrepo-kernel                              51 M</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">============================================================================================================================================================================</span><br><span class="line">Install  1 Package</span><br><span class="line"></span><br><span class="line">Total download size: 51 M</span><br><span class="line">Installed size: 232 M</span><br><span class="line">Downloading packages:</span><br><span class="line">kernel-ml-5.8.0-1.el7.elrepo.x86_64.rpm                                                                                                              |  51 MB  00:00:03     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction <span class="built_in">test</span></span><br><span class="line">Transaction <span class="built_in">test</span> succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : kernel-ml-5.8.0-1.el7.elrepo.x86_64                                                                                                                      1/1 </span><br><span class="line">  Verifying  : kernel-ml-5.8.0-1.el7.elrepo.x86_64                                                                                                                      1/1 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  kernel-ml.x86_64 0:5.8.0-1.el7.elrepo                                                                                                                                     </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure>

<p>这里如果下载很慢，可以提前<a href="https://elrepo.org/linux/kernel/el7/x86_64/RPMS/">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/</a>  (手动下载包)在这里下载好</p>
<ol start="5">
<li>修改grub中默认的内核版本</li>
</ol>
<p>查看默认的启动顺序</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># awk -F\&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print $2&#125;&#x27; /boot/grub2/grub.cfg</span></span><br><span class="line">CentOS Linux (5.8.0-1.el7.elrepo.x86_64) 7 (Core)</span><br><span class="line">CentOS Linux (3.10.0-1062.18.1.el7.x86_64) 7 (Core)</span><br><span class="line">CentOS Linux (3.10.0-1062.el7.x86_64) 7 (Core)</span><br><span class="line">CentOS Linux (0-rescue-20200426154603174201708213343640) 7 (Core)</span><br></pre></td></tr></table></figure>

<p>修改cat /etc/default/grub，将GRUB_DEFAULT的值设置为0，重启后就会使用新内核</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># sed -i &#x27;s/GRUB_DEFAULT=saved/GRUB_DEFAULT=0/g&#x27; /etc/default/grub </span></span><br></pre></td></tr></table></figure>

<!--在我另一篇升级内核到4.4版本中，有个命令grub2-set-default 也可以设置开机从新内核启动-->

<p>最后运行grub2-mkconfig刷新一下配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># grub2-mkconfig -o /boot/grub2/grub.cfg </span></span><br><span class="line">Generating grub configuration file ...</span><br><span class="line">Found linux image: /boot/vmlinuz-5.8.0-1.el7.elrepo.x86_64</span><br><span class="line">Found initrd image: /boot/initramfs-5.8.0-1.el7.elrepo.x86_64.img</span><br><span class="line">Found linux image: /boot/vmlinuz-3.10.0-1062.18.1.el7.x86_64</span><br><span class="line">Found initrd image: /boot/initramfs-3.10.0-1062.18.1.el7.x86_64.img</span><br><span class="line">Found linux image: /boot/vmlinuz-3.10.0-1062.el7.x86_64</span><br><span class="line">Found initrd image: /boot/initramfs-3.10.0-1062.el7.x86_64.img</span><br><span class="line">Found linux image: /boot/vmlinuz-0-rescue-20200426154603174201708213343640</span><br><span class="line">Found initrd image: /boot/initramfs-0-rescue-20200426154603174201708213343640.img</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>



<ol start="6">
<li>重启主机，查看内核版本</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@k8s ~]<span class="comment"># uname -a</span></span><br><span class="line">Linux k8s 5.8.0-1.el7.elrepo.x86_64 <span class="comment">#1 SMP Sun Aug 2 18:18:16 EDT 2020 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure>

<p>升级成功</p>
]]></content>
      <categories>
        <category>CentOS</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7.5安装OpenStack Rocky版本</title>
    <url>/2018/09/04/CentOS7.5%E5%AE%89%E8%A3%85OpenStack_Rocky%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<p>刚刚更新了版本，就忍不住想安装一下，因时间有限，只安装到了dashboari<br>搭建过程中，跟着官网走了遍流程，基本上没啥问题<br>建议还是跟着官网搭一遍会舒服很多 <a href="https://docs.openstack.org/install-guide">https://docs.openstack.org/install-guide</a><br>因为是自己搭着玩，为了方便，所有关于密码的设置，都设置成000000</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><table>
<thead>
<tr>
<th>主机</th>
<th>系统</th>
<th>网卡1:eth0</th>
<th>网卡2:eth1</th>
</tr>
</thead>
<tbody><tr>
<td>controller</td>
<td>CentOS7.5</td>
<td>192.168.100.10</td>
<td>192.168.200.10</td>
</tr>
<tr>
<td>compute</td>
<td>CentOS7.5</td>
<td>192.168.100.20</td>
<td>192.168.200.20</td>
</tr>
</tbody></table>
<h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl restart network</span></span><br><span class="line"><span class="comment"># systemctl stop firewalld</span></span><br><span class="line"><span class="comment"># systemctl disable firewalld</span></span><br><span class="line"><span class="comment"># setenforce 0</span></span><br><span class="line"><span class="comment"># sed -i &#x27;s/=enforcing/=disabled/&#x27; /etc/selinux/config</span></span><br></pre></td></tr></table></figure>
<h2 id="更新软件包"><a href="#更新软件包" class="headerlink" title="更新软件包"></a>更新软件包</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum upgrade -y</span></span><br></pre></td></tr></table></figure>
<h2 id="更新完成后重启系统"><a href="#更新完成后重启系统" class="headerlink" title="更新完成后重启系统"></a>更新完成后重启系统</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reboot</span></span><br></pre></td></tr></table></figure>
<h2 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hostnamectl set-hostname controller</span></span><br><span class="line"><span class="comment"># hostnamectl set-hostname compute</span></span><br></pre></td></tr></table></figure>
<h2 id="添加主机映射"><a href="#添加主机映射" class="headerlink" title="添加主机映射"></a>添加主机映射</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat &lt;&lt; EOF &gt;&gt; /etc/hosts</span></span><br><span class="line">192.168.100.10 controller</span><br><span class="line">192.168.100.20 compute</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="配置时间同步"><a href="#配置时间同步" class="headerlink" title="配置时间同步"></a>配置时间同步</h2><h3 id="controller节点"><a href="#controller节点" class="headerlink" title="controller节点"></a>controller节点</h3><h3 id="安装软件包"><a href="#安装软件包" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install -y chrony</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-chrony-conf文件"><a href="#编辑-etc-chrony-conf文件" class="headerlink" title="编辑/etc/chrony.conf文件"></a>编辑/etc/chrony.conf文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server controller iburst</span><br><span class="line">allow 192.168.0.0/16</span><br></pre></td></tr></table></figure>
<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start chronyd</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable chronyd</span></span><br></pre></td></tr></table></figure>
<h4 id="compute节点"><a href="#compute节点" class="headerlink" title="compute节点"></a>compute节点</h4><h3 id="安装软件包-1"><a href="#安装软件包-1" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># yum install -y chrony</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-chrony-conf文件-1"><a href="#编辑-etc-chrony-conf文件-1" class="headerlink" title="编辑/etc/chrony.conf文件"></a>编辑/etc/chrony.conf文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server controller iburst</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-1"><a href="#启动服务-1" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># systemctl start chronyd</span></span><br><span class="line">[root@compute ~]<span class="comment"># systemctl enable chronyd</span></span><br></pre></td></tr></table></figure>
<h2 id="配置OpenStack-rocky的yum源文件"><a href="#配置OpenStack-rocky的yum源文件" class="headerlink" title="配置OpenStack-rocky的yum源文件"></a>配置OpenStack-rocky的yum源文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat &lt;&lt; EOF &gt;&gt; /etc/yum.repos.d/openstack.repo</span></span><br><span class="line">[openstack-rocky]</span><br><span class="line">name=openstack-rocky</span><br><span class="line">baseurl=https://mirrors.aliyun.com/centos/7/cloud/x86_64/openstack-rocky/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">[qume-kvm]</span><br><span class="line">name=qemu-kvm</span><br><span class="line">baseurl= https://mirrors.aliyun.com/centos/7/virt/x86_64/kvm-common/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h2 id="安装OpenStack客户端和selinux服务"><a href="#安装OpenStack客户端和selinux服务" class="headerlink" title="安装OpenStack客户端和selinux服务"></a>安装OpenStack客户端和selinux服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install -y python-openstackclient openstack-selinux</span></span><br></pre></td></tr></table></figure>
<h2 id="安装数据库服务"><a href="#安装数据库服务" class="headerlink" title="安装数据库服务"></a>安装数据库服务</h2><h3 id="在controller节点安装数据库"><a href="#在controller节点安装数据库" class="headerlink" title="在controller节点安装数据库"></a>在controller节点安装数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install -y mariadb mariadb-server python2-PyMySQL</span></span><br></pre></td></tr></table></figure>
<h3 id="修改数据库配置文件"><a href="#修改数据库配置文件" class="headerlink" title="修改数据库配置文件"></a>修改数据库配置文件</h3><p>新建数据库配置文件/etc/my.cnf.d/openstack.cnf，添加以下内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">bind-address = 192.168.100.10</span><br><span class="line">default-storage-engine = innodb</span><br><span class="line">innodb_file_per_table = on</span><br><span class="line">max_connections = 4096</span><br><span class="line">collation-server = utf8_general_ci</span><br><span class="line">character-set-server = utf8</span><br></pre></td></tr></table></figure>
<h3 id="启动数据库服务"><a href="#启动数据库服务" class="headerlink" title="启动数据库服务"></a>启动数据库服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl enable mariadb.service</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl start mariadb.service</span></span><br></pre></td></tr></table></figure>
<h3 id="设置数据库密码"><a href="#设置数据库密码" class="headerlink" title="设置数据库密码"></a>设置数据库密码</h3><p>运行mysql_secure_installation命令，创建数据库root密码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># mysql_secure_installation</span></span><br><span class="line">NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB</span><br><span class="line">SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!</span><br><span class="line">In order to <span class="built_in">log</span> into MariaDB to secure it, we<span class="string">&#x27;ll need the current</span></span><br><span class="line"><span class="string">password for the root user. If you&#x27;</span>ve just installed MariaDB, and</span><br><span class="line">you haven<span class="string">&#x27;t set the root password yet, the password will be blank,</span></span><br><span class="line"><span class="string">so you should just press enter here.</span></span><br><span class="line"><span class="string">Enter current password for root (enter for none):</span></span><br><span class="line"><span class="string">OK, successfully used password, moving on...</span></span><br><span class="line"><span class="string">Setting the root password ensures that nobody can log into the MariaDB</span></span><br><span class="line"><span class="string">root user without the proper authorisation.</span></span><br><span class="line"><span class="string">Set root password? [Y/n] y</span></span><br><span class="line"><span class="string">New password: ## 此处为root用户密码，这里设为000000</span></span><br><span class="line"><span class="string">Re-enter new password:</span></span><br><span class="line"><span class="string">Password updated successfully!</span></span><br><span class="line"><span class="string">Reloading privilege tables..</span></span><br><span class="line"><span class="string">... Success!</span></span><br><span class="line"><span class="string">By default, a MariaDB installation has an anonymous user, allowing anyone</span></span><br><span class="line"><span class="string">to log into MariaDB without having to have a user account created for</span></span><br><span class="line"><span class="string">them. This is intended only for testing, and to make the installation</span></span><br><span class="line"><span class="string">go a bit smoother. You should remove them before moving into a</span></span><br><span class="line"><span class="string">production environment.</span></span><br><span class="line"><span class="string">Remove anonymous users? [Y/n] y</span></span><br><span class="line"><span class="string">... Success!</span></span><br><span class="line"><span class="string">Normally, root should only be allowed to connect from &#x27;</span>localhost<span class="string">&#x27;. This</span></span><br><span class="line"><span class="string">ensures that someone cannot guess at the root password from the network.</span></span><br><span class="line"><span class="string">Disallow root login remotely? [Y/n] n</span></span><br><span class="line"><span class="string">... skipping.</span></span><br><span class="line"><span class="string">By default, MariaDB comes with a database named &#x27;</span><span class="built_in">test</span><span class="string">&#x27; that anyone can</span></span><br><span class="line"><span class="string">access. This is also intended only for testing, and should be removed</span></span><br><span class="line"><span class="string">before moving into a production environment.</span></span><br><span class="line"><span class="string">Remove test database and access to it? [Y/n] y</span></span><br><span class="line"><span class="string">- Dropping test database...</span></span><br><span class="line"><span class="string">... Success!</span></span><br><span class="line"><span class="string">- Removing privileges on test database...</span></span><br><span class="line"><span class="string">... Success!</span></span><br><span class="line"><span class="string">Reloading the privilege tables will ensure that all changes made so far</span></span><br><span class="line"><span class="string">will take effect immediately.</span></span><br><span class="line"><span class="string">Reload privilege tables now? [Y/n] y</span></span><br><span class="line"><span class="string">... Success!</span></span><br><span class="line"><span class="string">Cleaning up...</span></span><br><span class="line"><span class="string">All done! If you&#x27;</span>ve completed all of the above steps, your MariaDB</span><br><span class="line">installation should now be secure.</span><br><span class="line">Thanks <span class="keyword">for</span> using MariaDB!</span><br></pre></td></tr></table></figure>
<h2 id="安装消息队列服务"><a href="#安装消息队列服务" class="headerlink" title="安装消息队列服务"></a>安装消息队列服务</h2><h3 id="在controller节点安装rabbitmq-server"><a href="#在controller节点安装rabbitmq-server" class="headerlink" title="在controller节点安装rabbitmq-server"></a>在controller节点安装rabbitmq-server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install -y rabbitmq-server -y</span></span><br></pre></td></tr></table></figure>
<h3 id="启动消息队列服务"><a href="#启动消息队列服务" class="headerlink" title="启动消息队列服务"></a>启动消息队列服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start rabbitmq-server.service</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable rabbitmq-server.service</span></span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/rabbitmq-server.service to</span><br><span class="line">/usr/lib/systemd/system/rabbitmq-server.service.</span><br></pre></td></tr></table></figure>
<h3 id="添加openstack用户"><a href="#添加openstack用户" class="headerlink" title="添加openstack用户"></a>添加openstack用户</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># rabbitmqctl add_user openstack 000000</span></span><br><span class="line">Creating user <span class="string">&quot;openstack&quot;</span> ...</span><br></pre></td></tr></table></figure>
<h3 id="设置openstack用户最高权限"><a href="#设置openstack用户最高权限" class="headerlink" title="设置openstack用户最高权限"></a>设置openstack用户最高权限</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># rabbitmqctl set_permissions openstack &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;</span></span><br><span class="line">Setting permissions <span class="keyword">for</span> user <span class="string">&quot;openstack&quot;</span> <span class="keyword">in</span> vhost <span class="string">&quot;/&quot;</span> ...</span><br></pre></td></tr></table></figure>
<h2 id="安装memcached-服务"><a href="#安装memcached-服务" class="headerlink" title="安装memcached 服务"></a>安装memcached 服务</h2><h3 id="在controller节点上安装memcached"><a href="#在controller节点上安装memcached" class="headerlink" title="在controller节点上安装memcached"></a>在controller节点上安装memcached</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install -y memcached</span></span><br></pre></td></tr></table></figure>
<h3 id="修改memcached配置文件"><a href="#修改memcached配置文件" class="headerlink" title="修改memcached配置文件"></a>修改memcached配置文件</h3><p>编辑/etc/sysconfig/memcached，修改以下内容<br>修改OPTIONS=”-l 127.0.0.1,::1”为</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OPTIONS=<span class="string">&quot;-l 127.0.0.1,::1,controller&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="启动memcached服务"><a href="#启动memcached服务" class="headerlink" title="启动memcached服务"></a>启动memcached服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start memcached.service</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable memcached.service</span></span><br></pre></td></tr></table></figure>
<h2 id="安装etcd服务"><a href="#安装etcd服务" class="headerlink" title="安装etcd服务"></a>安装etcd服务</h2><h3 id="在controller节点上安装etcd服务"><a href="#在controller节点上安装etcd服务" class="headerlink" title="在controller节点上安装etcd服务"></a>在controller节点上安装etcd服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install etcd -y</span></span><br></pre></td></tr></table></figure>
<h3 id="修改etcd配置文件，使其他节点能够访问"><a href="#修改etcd配置文件，使其他节点能够访问" class="headerlink" title="修改etcd配置文件，使其他节点能够访问"></a>修改etcd配置文件，使其他节点能够访问</h3><p>编辑/etc/etcd/etcd.conf，在各自的位置修改以下内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#[Member]</span></span><br><span class="line">ETCD_DATA_DIR=<span class="string">&quot;/var/lib/etcd/default.etcd&quot;</span></span><br><span class="line">ETCD_LISTEN_PEER_URLS=<span class="string">&quot;http://192.168.100.10:2380&quot;</span></span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=<span class="string">&quot;http://192.168.100.10:2379&quot;</span></span><br><span class="line">ETCD_NAME=<span class="string">&quot;controller&quot;</span></span><br><span class="line"><span class="comment">#[Clustering]</span></span><br><span class="line">ETCD_INITIAL_ADVERTISE_PEER_URLS=<span class="string">&quot;http://192.168.100.10:2380&quot;</span></span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=<span class="string">&quot;http://192.168.100.10:2379&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER=<span class="string">&quot;controller=http://192.168.100.10:2380&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_TOKEN=<span class="string">&quot;etcd-cluster-01&quot;</span></span><br><span class="line">ETCD_INITIAL_CLUSTER_STATE=<span class="string">&quot;new&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="启动etcd服务"><a href="#启动etcd服务" class="headerlink" title="启动etcd服务"></a>启动etcd服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start etcd</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable etcd</span></span><br></pre></td></tr></table></figure>
<p>（在我想查看集群的时候，报错了，虽然好像无关）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># etcdctl cluster-health</span></span><br><span class="line">cluster may be unhealthy: failed to list members</span><br><span class="line">Error: client: etcd cluster is unavailable or misconfigured; error <span class="comment">#0: dial tcp</span></span><br><span class="line">127.0.0.1:4001: getsockopt: connection refused</span><br><span class="line">; error <span class="comment">#1: dial tcp 127.0.0.1:2379: getsockopt: connection refused</span></span><br><span class="line">error <span class="comment">#0: dial tcp 127.0.0.1:4001: getsockopt: connection refused</span></span><br><span class="line">error <span class="comment">#1: dial tcp 127.0.0.1:2379: getsockopt: connection refused</span></span><br></pre></td></tr></table></figure>
<h2 id="安装keystone服务"><a href="#安装keystone服务" class="headerlink" title="安装keystone服务"></a>安装keystone服务</h2><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># mysql -uroot -p000000</span></span><br><span class="line">Welcome to the MariaDB monitor. Commands end with ; or \g.</span><br><span class="line">Your MariaDB connection id is 9</span><br><span class="line">Server version: 10.1.20-MariaDB MariaDB Server</span><br><span class="line">Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line">Type <span class="string">&#x27;help;&#x27;</span> or <span class="string">&#x27;\h&#x27;</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">&#x27;\c&#x27;</span> to clear the current input statement.</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE keystone;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO</span><br><span class="line"><span class="string">&#x27;keystone&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>\</span><br><span class="line">-&gt; IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO <span class="string">&#x27;keystone&#x27;</span>@<span class="string">&#x27;%&#x27;</span></span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>
<h3 id="安装软件包-2"><a href="#安装软件包-2" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install openstack-keystone httpd mod_wsgi -y</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-keystone-keystone-conf"><a href="#编辑配置文件-etc-keystone-keystone-conf" class="headerlink" title="编辑配置文件/etc/keystone/keystone.conf"></a>编辑配置文件/etc/keystone/keystone.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[database]</span><br><span class="line">connection = mysql+pymysql://keystone:000000@controller/keystone</span><br><span class="line">[token]</span><br><span class="line">provider = fernet</span><br></pre></td></tr></table></figure>
<h3 id="同步数据库"><a href="#同步数据库" class="headerlink" title="同步数据库"></a>同步数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;keystone-manage db_sync&quot; keystone</span></span><br></pre></td></tr></table></figure>
<h3 id="初始化fernet-key库"><a href="#初始化fernet-key库" class="headerlink" title="初始化fernet key库"></a>初始化fernet key库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># keystone-manage fernet_setup --keystone-user keystone</span></span><br><span class="line">--keystone-group keystone</span><br><span class="line">[root@controller ~]<span class="comment"># keystone-manage credential_setup --keystone-user</span></span><br><span class="line">keystone --keystone-group keystone</span><br></pre></td></tr></table></figure>
<h3 id="引导身份认证"><a href="#引导身份认证" class="headerlink" title="引导身份认证"></a>引导身份认证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># keystone-manage bootstrap --bootstrap-password 000000 \</span></span><br><span class="line">--bootstrap-admin-url http://controller:5000/v3/ \</span><br><span class="line">--bootstrap-internal-url http://controller:5000/v3/ \</span><br><span class="line">--bootstrap-public-url http://controller:5000/v3/ \</span><br><span class="line">--bootstrap-region-id RegionOne</span><br></pre></td></tr></table></figure>
<h3 id="编辑httpd配置文件-etc-httpd-conf-httpd-conf"><a href="#编辑httpd配置文件-etc-httpd-conf-httpd-conf" class="headerlink" title="编辑httpd配置文件/etc/httpd/conf/httpd.conf"></a>编辑httpd配置文件/etc/httpd/conf/httpd.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ServerName controller</span><br></pre></td></tr></table></figure>
<h3 id="创建文件链接"><a href="#创建文件链接" class="headerlink" title="创建文件链接"></a>创建文件链接</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># ln -s /usr/share/keystone/wsgi-keystone.conf</span></span><br><span class="line">/etc/httpd/conf.d/</span><br></pre></td></tr></table></figure>
<h3 id="启动httpd服务"><a href="#启动httpd服务" class="headerlink" title="启动httpd服务"></a>启动httpd服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start httpd</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable httpd</span></span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service</span><br><span class="line">to /usr/lib/systemd/system/httpd.service.</span><br></pre></td></tr></table></figure>
<h3 id="编写环境变量脚本admin-openrc"><a href="#编写环境变量脚本admin-openrc" class="headerlink" title="编写环境变量脚本admin-openrc"></a>编写环境变量脚本admin-openrc</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> OS_USERNAME=admin</span><br><span class="line"><span class="built_in">export</span> OS_PASSWORD=000000</span><br><span class="line"><span class="built_in">export</span> OS_PROJECT_NAME=admin</span><br><span class="line"><span class="built_in">export</span> OS_USER_DOMAIN_NAME=Default</span><br><span class="line"><span class="built_in">export</span> OS_PROJECT_DOMAIN_NAME=Default</span><br><span class="line"><span class="built_in">export</span> OS_AUTH_URL=http://controller:5000/v3</span><br><span class="line"><span class="built_in">export</span> OS_IDENTITY_API_VERSION=3</span><br><span class="line"><span class="built_in">export</span> OS_IMAGE_API_VERSION=2</span><br></pre></td></tr></table></figure>
<h3 id="创建service项目"><a href="#创建service项目" class="headerlink" title="创建service项目"></a>创建service项目</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack project create --domain default \</span></span><br><span class="line">&gt; --description <span class="string">&quot;Service Project&quot;</span> service</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description | Service Project |</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 617e64ff415b45ef975b8faf3d5207dd |</span><br><span class="line">| is_domain | False |</span><br><span class="line">| name | service |</span><br><span class="line">| parent_id | default |</span><br><span class="line">| tags | [] |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line"><span class="comment">### 验证</span></span><br><span class="line">[root@controller ~]<span class="comment"># openstack user list</span></span><br><span class="line">+----------------------------------+-------+</span><br><span class="line">| ID | Name |</span><br><span class="line">+----------------------------------+-------+</span><br><span class="line">| 5238d646322346be9e3f9750422bcf4d | admin |</span><br><span class="line">+----------------------------------+-------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack token issue</span></span><br><span class="line">+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| expires | 2018-09-03T14:30:02+0000 |</span><br><span class="line">| id |</span><br><span class="line">gAAAAABbjTdauHEUmA_PQ1deLrPsMXiITgOyGu325OkqBYxhwYK5pS5A217gFJcnt_T50T6vfVXDTPR1HJ-HM7_Dlmm5GbPBAe_4KuWygSebGPAU7_NQoZT5gH0gjtyW5aF0mw-dyqvVykcXQWeeZ_q15HOjUZ2ujn_O2GYfjFhUmhaagrUvYys</span><br><span class="line">|</span><br><span class="line">| project_id | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| user_id | 5238d646322346be9e3f9750422bcf4d |</span><br><span class="line">+------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<h2 id="glance安装"><a href="#glance安装" class="headerlink" title="glance安装"></a>glance安装</h2><h3 id="创建数据库-1"><a href="#创建数据库-1" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># mysql -uroot -p000000</span></span><br><span class="line">Welcome to the MariaDB monitor. Commands end with ; or \g.</span><br><span class="line">Your MariaDB connection id is 17</span><br><span class="line">Server version: 10.1.20-MariaDB MariaDB Server</span><br><span class="line">Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line">Type <span class="string">&#x27;help;&#x27;</span> or <span class="string">&#x27;\h&#x27;</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">&#x27;\c&#x27;</span> to clear the current input statement.</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE glance;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO <span class="string">&#x27;glance&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO <span class="string">&#x27;glance&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED</span><br><span class="line">BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>
<h3 id="创建用户、服务等"><a href="#创建用户、服务等" class="headerlink" title="创建用户、服务等"></a>创建用户、服务等</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># source admin-openrc</span></span><br><span class="line">[root@controller ~]<span class="comment"># openstack user create --domain default --password-prompt</span></span><br><span class="line">glance</span><br><span class="line">User Password:000000</span><br><span class="line">Repeat User Password:</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 73e040b3ca46485dad6ce8c49bfbd8e2 |</span><br><span class="line">| name | glance |</span><br><span class="line">| options | &#123;&#125; |</span><br><span class="line">| password_expires_at | None |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack role add --project service --user glance admin</span></span><br><span class="line">[root@controller ~]<span class="comment"># openstack service create --name glance \</span></span><br><span class="line">&gt; --description <span class="string">&quot;OpenStack Image&quot;</span> image</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description | OpenStack Image |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | e61eb0929ae842e48c2b1f029e67578b |</span><br><span class="line">| name | glance |</span><br><span class="line">| <span class="built_in">type</span> | image |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; image public http://controller:9292</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | ee8719ec7a5547fbaa1ca685fca1d8e0 |</span><br><span class="line">| interface | public |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | e61eb0929ae842e48c2b1f029e67578b |</span><br><span class="line">| service_name | glance |</span><br><span class="line">| service_type | image |</span><br><span class="line">| url | http://controller:9292 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; image internal http://controller:9292</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 27379aa551644711b2f3568a5387e003 |</span><br><span class="line">| interface | internal |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | e61eb0929ae842e48c2b1f029e67578b |</span><br><span class="line">| service_name | glance |</span><br><span class="line">| service_type | image |</span><br><span class="line">| url | http://controller:9292 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; image admin http://controller:9292</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | b9f6c2bfee5f46bf8d654336094c4360 |</span><br><span class="line">| interface | admin |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | e61eb0929ae842e48c2b1f029e67578b |</span><br><span class="line">| service_name | glance |</span><br><span class="line">| service_type | image |</span><br><span class="line">| url | http://controller:9292 |</span><br><span class="line">+--------------+----------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="安装软件包-3"><a href="#安装软件包-3" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install -y openstack-glance</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-glance-glance-api-conf"><a href="#编辑配置文件-etc-glance-glance-api-conf" class="headerlink" title="编辑配置文件/etc/glance/glance-api.conf"></a>编辑配置文件/etc/glance/glance-api.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[database]</span><br><span class="line">connection = mysql+pymysql://glance:000000@controller/glance</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">www_authenticate_uri = http://controller:5000</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = Default</span><br><span class="line">user_domain_name = Default</span><br><span class="line">project_name = service</span><br><span class="line">username = glance</span><br><span class="line">password = 000000</span><br><span class="line">[paste_deploy]</span><br><span class="line">flavor = keystone</span><br><span class="line">[glance_store]</span><br><span class="line">stores = file,http</span><br><span class="line">default_store = file</span><br><span class="line">filesystem_store_datadir = /var/lib/glance/images/</span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-glance-glance-registry-conf"><a href="#编辑配置文件-etc-glance-glance-registry-conf" class="headerlink" title="编辑配置文件/etc/glance/glance-registry.conf"></a>编辑配置文件/etc/glance/glance-registry.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[database]</span><br><span class="line">connection = mysql+pymysql://glance:000000@controller/glance</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">www_authenticate_uri = http://controller:5000</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = Default</span><br><span class="line">user_domain_name = Default</span><br><span class="line">project_name = service</span><br><span class="line">username = glance</span><br><span class="line">password = 000000</span><br><span class="line">[paste_deploy]</span><br><span class="line">flavor = keystone</span><br></pre></td></tr></table></figure>
<h3 id="同步数据库-1"><a href="#同步数据库-1" class="headerlink" title="同步数据库"></a>同步数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance</span></span><br><span class="line">/usr/lib/python2.7/site-packages/oslo_db/sqlalchemy/enginefacade.py:1352:</span><br><span class="line">OsloDBDeprecationWarning: EngineFacade is deprecated; please use</span><br><span class="line">oslo_db.sqlalchemy.enginefacade</span><br><span class="line">expire_on_commit=expire_on_commit, \_conf=conf)</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade -&gt; liberty, liberty initial</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade liberty -&gt; mitaka01, add index</span><br><span class="line">on created_at and updated_at columns of <span class="string">&#x27;images&#x27;</span> table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade mitaka01 -&gt; mitaka02, update</span><br><span class="line">metadef os_nova_server</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade mitaka02 -&gt; ocata_expand01,</span><br><span class="line">add visibility to images</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade ocata_expand01 -&gt;</span><br><span class="line">pike_expand01, empty expand <span class="keyword">for</span> symmetry with pike_contract01</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade pike_expand01 -&gt;</span><br><span class="line">queens_expand01</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade queens_expand01 -&gt;</span><br><span class="line">rocky_expand01, add os_hidden column to images table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade rocky_expand01 -&gt;</span><br><span class="line">rocky_expand02, add os_hash_algo and os_hash_value columns to images table</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">Upgraded database to: rocky_expand02, current revision(s): rocky_expand02</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">Database migration is up to date. No migration needed.</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade mitaka02 -&gt; ocata_contract01,</span><br><span class="line">remove is_public from images</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade ocata_contract01 -&gt;</span><br><span class="line">pike_contract01, drop glare artifacts tables</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade pike_contract01 -&gt;</span><br><span class="line">queens_contract01</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade queens_contract01 -&gt;</span><br><span class="line">rocky_contract01</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade rocky_contract01 -&gt;</span><br><span class="line">rocky_contract02</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">Upgraded database to: rocky_contract02, current revision(s): rocky_contract02</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">Database is synced successfully.</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-2"><a href="#启动服务-2" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start openstack-glance-api.service</span></span><br><span class="line">openstack-glance-registry.service</span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable openstack-glance-api.service</span></span><br><span class="line">openstack-glance-registry.service</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-glance-api.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-glance-api.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-glance-registry.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-glance-registry.service.</span><br></pre></td></tr></table></figure>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment">#. admin-openrc</span></span><br><span class="line">[root@controller ~]<span class="comment"># wget</span></span><br><span class="line">http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img</span><br><span class="line">[root@controller ~]<span class="comment"># openstack image create &quot;cirros&quot; --file</span></span><br><span class="line">cirros-0.3.4-x86_64-disk.img --disk-format qcow2 --container-format bare</span><br><span class="line">--public</span><br><span class="line">+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| checksum | ee1eca47dc88f4879d8a229cc70a07c6 |</span><br><span class="line">| container_format | bare |</span><br><span class="line">| created_at | 2018-09-03T13:49:12Z |</span><br><span class="line">| disk_format | qcow2 |</span><br><span class="line">| file | /v2/images/8faa9dc9-7f29-4570-ae87-9bab0d01aa63/file |</span><br><span class="line">| id | 8faa9dc9-7f29-4570-ae87-9bab0d01aa63 |</span><br><span class="line">| min_disk | 0 |</span><br><span class="line">| min_ram | 0 |</span><br><span class="line">| name | cirros |</span><br><span class="line">| owner | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| properties | os_hash_algo=<span class="string">&#x27;sha512&#x27;</span>,</span><br><span class="line">os_hash_value=<span class="string">&#x27;1b03ca1bc3fafe448b90583c12f367949f8b0e665685979d95b004e48574b953316799e23240f4f739d1b5eb4c4ca24d38fdc6f4f9d8247a2bc64db25d6bbdb2&#x27;</span>,</span><br><span class="line">os_hidden=<span class="string">&#x27;False&#x27;</span> |</span><br><span class="line">| protected | False |</span><br><span class="line">| schema | /v2/schemas/image |</span><br><span class="line">| size | 13287936 |</span><br><span class="line">| status | active |</span><br><span class="line">| tags | |</span><br><span class="line">| updated_at | 2018-09-03T13:49:13Z |</span><br><span class="line">| virtual_size | None |</span><br><span class="line">| visibility | public |</span><br><span class="line">+------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack image list</span></span><br><span class="line">+--------------------------------------+--------+--------+</span><br><span class="line">| ID | Name | Status |</span><br><span class="line">+--------------------------------------+--------+--------+</span><br><span class="line">| 8faa9dc9-7f29-4570-ae87-9bab0d01aa63 | cirros | active |</span><br><span class="line">+--------------------------------------+--------+--------+</span><br></pre></td></tr></table></figure>
<h2 id="安装nova服务"><a href="#安装nova服务" class="headerlink" title="安装nova服务"></a>安装nova服务</h2><h3 id="controller节点-1"><a href="#controller节点-1" class="headerlink" title="controller节点"></a>controller节点</h3><h3 id="创建数据库-2"><a href="#创建数据库-2" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mysql -u root -p000000</span></span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE nova_api;</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE nova;</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE nova_cell0;</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE placement;</span><br><span class="line">Grant proper access to the databases:</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO <span class="string">&#x27;nova&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.* TO <span class="string">&#x27;nova&#x27;</span>@<span class="string">&#x27;%&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO <span class="string">&#x27;nova&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO <span class="string">&#x27;nova&#x27;</span>@<span class="string">&#x27;%&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO <span class="string">&#x27;nova&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">\</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.* TO <span class="string">&#x27;nova&#x27;</span>@<span class="string">&#x27;%&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON placement.* TO</span><br><span class="line"><span class="string">&#x27;placement&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON placement.* TO <span class="string">&#x27;placement&#x27;</span>@<span class="string">&#x27;%&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br></pre></td></tr></table></figure>
<h3 id="创建相关用户、服务"><a href="#创建相关用户、服务" class="headerlink" title="创建相关用户、服务"></a>创建相关用户、服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack user create --domain default --password-prompt</span></span><br><span class="line">nova</span><br><span class="line">User Password:</span><br><span class="line">Repeat User Password:</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | ea181b4b1de3430e8646795f133ad8fe |</span><br><span class="line">| name | nova |</span><br><span class="line">| options | &#123;&#125; |</span><br><span class="line">| password_expires_at | None |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack role add --project service --user nova admin</span></span><br><span class="line">[root@controller ~]<span class="comment"># openstack service create --name nova \</span></span><br><span class="line">&gt; --description <span class="string">&quot;OpenStack Compute&quot;</span> compute</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description | OpenStack Compute |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 52a1c2cd42fb45df9ab5ac0782faae4e |</span><br><span class="line">| name | nova |</span><br><span class="line">| <span class="built_in">type</span> | compute |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; compute public http://controller:8774/v2.1</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 4f009d7ff354428ab5dafadf0ed0095d |</span><br><span class="line">| interface | public |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | 52a1c2cd42fb45df9ab5ac0782faae4e |</span><br><span class="line">| service_name | nova |</span><br><span class="line">| service_type | compute |</span><br><span class="line">| url | http://controller:8774/v2.1 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; compute internal http://controller:8774/v2.1</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 5191feea83ba4a17b79a4a7d83f85651 |</span><br><span class="line">| interface | internal |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | 52a1c2cd42fb45df9ab5ac0782faae4e |</span><br><span class="line">| service_name | nova |</span><br><span class="line">| service_type | compute |</span><br><span class="line">| url | http://controller:8774/v2.1 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; compute admin http://controller:8774/v2.1</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 2fa5622c3f134f0ba8215baab1bad899 |</span><br><span class="line">| interface | admin |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | 52a1c2cd42fb45df9ab5ac0782faae4e |</span><br><span class="line">| service_name | nova |</span><br><span class="line">| service_type | compute |</span><br><span class="line">| url | http://controller:8774/v2.1 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack user create --domain default --password-prompt</span></span><br><span class="line">placement</span><br><span class="line">User Password:</span><br><span class="line">Repeat User Password:</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | ab7f16a5e08c4140b396f27f8fc75f69 |</span><br><span class="line">| name | placement |</span><br><span class="line">| options | &#123;&#125; |</span><br><span class="line">| password_expires_at | None |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack role add --project service --user placement</span></span><br><span class="line">admin</span><br><span class="line">[root@controller ~]<span class="comment"># openstack service create --name placement \</span></span><br><span class="line">&gt; --description <span class="string">&quot;Placement API&quot;</span> placement</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description | Placement API |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | be7f6d35fbd448c79b04d816df68e2d1 |</span><br><span class="line">| name | placement |</span><br><span class="line">| <span class="built_in">type</span> | placement |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; placement public http://controller:8778</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 443ad9ccf38c4930be407e6c755c37fd |</span><br><span class="line">| interface | public |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | be7f6d35fbd448c79b04d816df68e2d1 |</span><br><span class="line">| service_name | placement |</span><br><span class="line">| service_type | placement |</span><br><span class="line">| url | http://controller:8778 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; placement internal http://controller:8778</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 8827a5950f1a49fbb77267812daae462 |</span><br><span class="line">| interface | internal |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | be7f6d35fbd448c79b04d816df68e2d1 |</span><br><span class="line">| service_name | placement |</span><br><span class="line">| service_type | placement |</span><br><span class="line">| url | http://controller:8778 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; placement admin http://controller:8778</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 2e5bb38b860643f1b2bf7c2cd6ff6447 |</span><br><span class="line">| interface | admin |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | be7f6d35fbd448c79b04d816df68e2d1 |</span><br><span class="line">| service_name | placement |</span><br><span class="line">| service_type | placement |</span><br><span class="line">| url | http://controller:8778 |</span><br><span class="line">+--------------+----------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="安装软件包-4"><a href="#安装软件包-4" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install openstack-nova-api openstack-nova-conductor</span></span><br><span class="line">\</span><br><span class="line">openstack-nova-console openstack-nova-novncproxy \</span><br><span class="line">openstack-nova-scheduler openstack-nova-placement-api -y</span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-nova-nova-conf"><a href="#编辑配置文件-etc-nova-nova-conf" class="headerlink" title="编辑配置文件/etc/nova/nova.conf"></a>编辑配置文件/etc/nova/nova.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">enabled_apis = osapi_compute,metadata</span><br><span class="line">[api_database]</span><br><span class="line">connection = mysql+pymysql://nova:000000@controller/nova_api</span><br><span class="line">[database]</span><br><span class="line">connection = mysql+pymysql://nova:000000@controller/nova</span><br><span class="line">[placement_database]</span><br><span class="line">connection = mysql+pymysql://placement:000000@controller/placement</span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url = rabbit://openstack:000000@controller</span><br><span class="line">[api]</span><br><span class="line">auth_strategy = keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">auth_url = http://controller:5000/v3</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">project_name = service</span><br><span class="line">username = nova</span><br><span class="line">password = 000000</span><br><span class="line">[DEFAULT]</span><br><span class="line">my_ip = 192.168.100.10</span><br><span class="line">[DEFAULT]</span><br><span class="line">use_neutron = <span class="literal">true</span></span><br><span class="line">firewall_driver = nova.virt.firewall.NoopFirewallDriver</span><br><span class="line">[vnc]</span><br><span class="line">enabled = <span class="literal">true</span></span><br><span class="line">server_listen = <span class="variable">$my_ip</span></span><br><span class="line">server_proxyclient_address = <span class="variable">$my_ip</span></span><br><span class="line">[glance]</span><br><span class="line">api_servers = http://controller:9292</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path = /var/lib/nova/tmp</span><br><span class="line">[placement]</span><br><span class="line">region_name = RegionOne</span><br><span class="line">project_domain_name = Default</span><br><span class="line">project_name = service</span><br><span class="line">auth_type = password</span><br><span class="line">user_domain_name = Default</span><br><span class="line">auth_url = http://controller:5000/v3</span><br><span class="line">username = placement</span><br><span class="line">password = 000000</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-httpd-conf-d-00-nova-placement-api-conf，添加以下内容"><a href="#编辑-etc-httpd-conf-d-00-nova-placement-api-conf，添加以下内容" class="headerlink" title="编辑/etc/httpd/conf.d/00-nova-placement-api.conf，添加以下内容"></a>编辑/etc/httpd/conf.d/00-nova-placement-api.conf，添加以下内容</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;Directory /usr/bin&gt;</span><br><span class="line">&lt;IfVersion &gt;= 2.4&gt;</span><br><span class="line">Require all granted</span><br><span class="line">&lt;/IfVersion&gt;</span><br><span class="line">&lt;IfVersion &lt; 2.4&gt;</span><br><span class="line">Order allow,deny</span><br><span class="line">Allow from all</span><br><span class="line">&lt;/IfVersion&gt;</span><br><span class="line">&lt;/Directory&gt;</span><br></pre></td></tr></table></figure>
<h3 id="重启httpd服务"><a href="#重启httpd服务" class="headerlink" title="重启httpd服务"></a>重启httpd服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl restart httpd</span></span><br></pre></td></tr></table></figure>
<h3 id="同步nova-api数据库"><a href="#同步nova-api数据库" class="headerlink" title="同步nova_api数据库"></a>同步nova_api数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;nova-manage api_db sync&quot; nova</span></span><br></pre></td></tr></table></figure>
<h3 id="注册cell0数据库"><a href="#注册cell0数据库" class="headerlink" title="注册cell0数据库"></a>注册cell0数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;nova-manage cell_v2 map_cell0&quot; nova</span></span><br></pre></td></tr></table></figure>
<h3 id="创建cell1单元"><a href="#创建cell1单元" class="headerlink" title="创建cell1单元"></a>创建cell1单元</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;nova-manage cell_v2 create_cell</span></span><br><span class="line">--name=cell1 --verbose<span class="string">&quot; nova</span></span><br><span class="line"><span class="string">54e6c270-7390-4390-8702-02b72874c5a7</span></span><br></pre></td></tr></table></figure>
<h3 id="同步nova数据库"><a href="#同步nova数据库" class="headerlink" title="同步nova数据库"></a>同步nova数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;nova-manage db sync&quot; nova</span></span><br><span class="line">/usr/lib/python2.7/site-packages/pymysql/cursors.py:166: Warning: (1831,</span><br><span class="line">u<span class="string">&#x27;Duplicate index</span></span><br><span class="line"><span class="string">\`block_device_mapping_instance_uuid_virtual_name_device_name_idx\`. This is</span></span><br><span class="line"><span class="string">deprecated and will be disallowed in a future release.&#x27;</span>)</span><br><span class="line">result = self._query(query)</span><br><span class="line">/usr/lib/python2.7/site-packages/pymysql/cursors.py:166: Warning: (1831,</span><br><span class="line">u<span class="string">&#x27;Duplicate index \`uniq_instances0uuid\`. This is deprecated and will be</span></span><br><span class="line"><span class="string">disallowed in a future release.&#x27;</span>)</span><br><span class="line">result = self._query(query)</span><br></pre></td></tr></table></figure>
<h3 id="验证cell0和cell1注册成功"><a href="#验证cell0和cell1注册成功" class="headerlink" title="验证cell0和cell1注册成功"></a>验证cell0和cell1注册成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;nova-manage cell_v2 list_cells&quot; nova</span></span><br><span class="line">+-------+--------------------------------------+------------------------------------+-------------------------------------------------+----------+</span><br><span class="line">| Name | UUID | Transport URL | Database Connection | Disabled |</span><br><span class="line">+-------+--------------------------------------+------------------------------------+-------------------------------------------------+----------+</span><br><span class="line">| cell0 | 00000000-0000-0000-0000-000000000000 | none:/ |</span><br><span class="line">mysql+pymysql://nova:****@controller/nova_cell0 | False |</span><br><span class="line">| cell1 | 54e6c270-7390-4390-8702-02b72874c5a7 |</span><br><span class="line">rabbit://openstack:****@controller |</span><br><span class="line">mysql+pymysql://nova:****@controller/nova | False |</span><br><span class="line">+-------+--------------------------------------+------------------------------------+-------------------------------------------------+----------+</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-3"><a href="#启动服务-3" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start openstack-nova-api.service \</span></span><br><span class="line">openstack-nova-scheduler.service openstack-nova-conductor.service \</span><br><span class="line">openstack-nova-novncproxy.service openstack-nova-conductor</span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable openstack-nova-api.service \</span></span><br><span class="line">openstack-nova-scheduler.service openstack-nova-conductor.service \</span><br><span class="line">openstack-nova-novncproxy.service openstack-nova-conductor</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-nova-api.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-nova-api.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-nova-scheduler.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-nova-scheduler.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-nova-conductor.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-nova-conductor.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-nova-novncproxy.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-nova-novncproxy.service.</span><br></pre></td></tr></table></figure>
<p>官网没有启动nova-conductor服务</p>
<h3 id="compute节点-1"><a href="#compute节点-1" class="headerlink" title="compute节点"></a>compute节点</h3><h3 id="安装软件包-5"><a href="#安装软件包-5" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># yum install openstack-nova-compute -y</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-nova-nova-conf-1"><a href="#编辑配置文件-etc-nova-nova-conf-1" class="headerlink" title="编辑配置文件/etc/nova/nova.conf"></a>编辑配置文件/etc/nova/nova.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">enabled_apis = osapi_compute,metadata</span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url = rabbit://openstack:000000@controller</span><br><span class="line">[api]</span><br><span class="line">auth_strategy = keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">auth_url = http://controller:5000/v3</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">project_name = service</span><br><span class="line">username = nova</span><br><span class="line">password = 000000</span><br><span class="line">[DEFAULT]</span><br><span class="line">my_ip = 192.168.100.20</span><br><span class="line">[DEFAULT]</span><br><span class="line">use_neutron = <span class="literal">true</span></span><br><span class="line">firewall_driver = nova.virt.firewall.NoopFirewallDriver</span><br><span class="line">[vnc]</span><br><span class="line">enabled = <span class="literal">true</span></span><br><span class="line">server_listen = 0.0.0.0</span><br><span class="line">server_proxyclient_address = <span class="variable">$my_ip</span></span><br><span class="line">novncproxy_base_url = http:// 192.168.100.10:6080/vnc_auto.html</span><br><span class="line">[glance]</span><br><span class="line">api_servers = http://controller:9292</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path = /var/lib/nova/tmp</span><br><span class="line">[placement]</span><br><span class="line">region_name = RegionOne</span><br><span class="line">project_domain_name = Default</span><br><span class="line">project_name = service</span><br><span class="line">auth_type = password</span><br><span class="line">user_domain_name = Default</span><br><span class="line">auth_url = http://controller:5000/v3</span><br><span class="line">username = placement</span><br><span class="line">password = 000000</span><br></pre></td></tr></table></figure>
<h3 id="检查是否支持虚拟化"><a href="#检查是否支持虚拟化" class="headerlink" title="检查是否支持虚拟化"></a>检查是否支持虚拟化</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># egrep -c &#x27;(vmx|svm)&#x27; /proc/cpuinfo</span></span><br></pre></td></tr></table></figure>
<p>如果等于0，则要在/etc/nova/nova.conf的[libvirt]下添加以下参数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[libvirt]</span><br><span class="line">virt_type = qemu</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-4"><a href="#启动服务-4" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~] <span class="comment"># systemctl start libvirtd.service</span></span><br><span class="line">openstack-nova-compute.service</span><br><span class="line">[root@compute ~] <span class="comment"># systemctl enable libvirtd.service</span></span><br><span class="line">openstack-nova-compute.service</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/openstack-nova-compute.service to</span><br><span class="line">/usr/lib/systemd/system/openstack-nova-compute.service.</span><br></pre></td></tr></table></figure>
<h3 id="controller节点-2"><a href="#controller节点-2" class="headerlink" title="controller节点"></a>controller节点</h3><h3 id="确认数据库中有计算节点"><a href="#确认数据库中有计算节点" class="headerlink" title="确认数据库中有计算节点"></a>确认数据库中有计算节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># . admin-openrc</span></span><br><span class="line">[root@controller ~]<span class="comment"># openstack compute service list --service nova-compute</span></span><br><span class="line">+----+--------------+---------+------+---------+-------+----------------------------+</span><br><span class="line">| ID | Binary | Host | Zone | Status | State | Updated At |</span><br><span class="line">+----+--------------+---------+------+---------+-------+----------------------------+</span><br><span class="line">| 6 | nova-compute | compute | nova | enabled | up |</span><br><span class="line">2018-09-03T14:16:10.000000 |</span><br><span class="line">+----+--------------+---------+------+---------+-------+----------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="发现计算节点"><a href="#发现计算节点" class="headerlink" title="发现计算节点"></a>发现计算节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;nova-manage cell_v2 discover_hosts</span></span><br><span class="line">--verbose<span class="string">&quot; nova</span></span><br><span class="line"><span class="string">Found 2 cell mappings.</span></span><br><span class="line"><span class="string">Skipping cell0 since it does not contain hosts.</span></span><br><span class="line"><span class="string">Getting computes from cell &#x27;cell1&#x27;: 54e6c270-7390-4390-8702-02b72874c5a7</span></span><br><span class="line"><span class="string">Checking host mapping for compute host &#x27;compute&#x27;:</span></span><br><span class="line"><span class="string">39d80423-6001-4036-a546-5287c1e93ec5</span></span><br><span class="line"><span class="string">Creating host mapping for compute host &#x27;compute&#x27;:</span></span><br><span class="line"><span class="string">39d80423-6001-4036-a546-5287c1e93ec5</span></span><br><span class="line"><span class="string">Found 1 unmapped computes in cell: 54e6c270-7390-4390-8702-02b72874c5a7</span></span><br></pre></td></tr></table></figure>
<p>如果想要自动发现新compute节点，可以在/etc/nova/nova.conf的[scheduler]下添加以下参数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[scheduler]</span><br><span class="line">discover_hosts_in_cells_interval = 300</span><br></pre></td></tr></table></figure>
<h2 id="安装neutron服务"><a href="#安装neutron服务" class="headerlink" title="安装neutron服务"></a>安装neutron服务</h2><h3 id="controller节点-3"><a href="#controller节点-3" class="headerlink" title="controller节点"></a>controller节点</h3><h3 id="创建数据库-3"><a href="#创建数据库-3" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># mysql -uroot -p000000</span></span><br><span class="line">MariaDB [(none)] CREATE DATABASE neutron;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO <span class="string">&#x27;neutron&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">\</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.* TO <span class="string">&#x27;neutron&#x27;</span>@<span class="string">&#x27;%&#x27;</span> \</span><br><span class="line">IDENTIFIED BY <span class="string">&#x27;000000&#x27;</span>;</span><br></pre></td></tr></table></figure>
<h3 id="创建用户、服务"><a href="#创建用户、服务" class="headerlink" title="创建用户、服务"></a>创建用户、服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack user create --domain default --password-prompt</span></span><br><span class="line">neutron</span><br><span class="line">User Password:</span><br><span class="line">Repeat User Password:</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | d5b2036ead024ac0b09d3cf4c1b00e7c |</span><br><span class="line">| name | neutron |</span><br><span class="line">| options | &#123;&#125; |</span><br><span class="line">| password_expires_at | None |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack role add --project service --user neutron</span></span><br><span class="line">admin</span><br><span class="line">[root@controller ~]<span class="comment"># openstack service create --name neutron \</span></span><br><span class="line">&gt; --description <span class="string">&quot;OpenStack Networking&quot;</span> network</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description | OpenStack Networking |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | bfad907188c74a6f99120124b36b5113 |</span><br><span class="line">| name | neutron |</span><br><span class="line">| <span class="built_in">type</span> | network |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; network public http://controller:9696</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | bcd2134aab2d4202aa8ca0ca0de32d5a |</span><br><span class="line">| interface | public |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | bfad907188c74a6f99120124b36b5113 |</span><br><span class="line">| service_name | neutron |</span><br><span class="line">| service_type | network |</span><br><span class="line">| url | http://controller:9696 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; network internal http://controller:9696</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 3ca0c46da89749cfba9b0f117e3ac201 |</span><br><span class="line">| interface | internal |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | bfad907188c74a6f99120124b36b5113 |</span><br><span class="line">| service_name | neutron |</span><br><span class="line">| service_type | network |</span><br><span class="line">| url | http://controller:9696 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack endpoint create --region RegionOne \</span></span><br><span class="line">&gt; network admin http://controller:9696</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | cf69a76a963b41e0a0dd327072c3b5e4 |</span><br><span class="line">| interface | admin |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | bfad907188c74a6f99120124b36b5113 |</span><br><span class="line">| service_name | neutron |</span><br><span class="line">| service_type | network |</span><br><span class="line">| url | http://controller:9696 |</span><br><span class="line">+--------------+----------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="配置provider-network网络"><a href="#配置provider-network网络" class="headerlink" title="配置provider network网络"></a>配置provider network网络</h3><h3 id="安装软件包-6"><a href="#安装软件包-6" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install openstack-neutron openstack-neutron-ml2 \</span></span><br><span class="line">openstack-neutron-linuxbridge ebtables -y</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-neutron-conf配置文件"><a href="#编辑-etc-neutron-neutron-conf配置文件" class="headerlink" title="编辑/etc/neutron/neutron.conf配置文件"></a>编辑/etc/neutron/neutron.conf配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[database]</span><br><span class="line">connection = mysql+pymysql://neutron:000000@controller/neutron</span><br><span class="line">[DEFAULT]</span><br><span class="line">core_plugin = ml2</span><br><span class="line">service_plugins =</span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url = rabbit://openstack:000000@controller</span><br><span class="line">[DEFAULT]</span><br><span class="line">auth_strategy = keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">www_authenticate_uri = http://controller:5000</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">project_name = service</span><br><span class="line">username = neutron</span><br><span class="line">password = 000000</span><br><span class="line">[DEFAULT]</span><br><span class="line">notify_nova_on_port_status_changes = <span class="literal">true</span></span><br><span class="line">notify_nova_on_port_data_changes = <span class="literal">true</span></span><br><span class="line">[nova]</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">region_name = RegionOne</span><br><span class="line">project_name = service</span><br><span class="line">username = nova</span><br><span class="line">password = 000000</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path = /var/lib/neutron/tmp</span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-neutron-plugins-ml2-ml2-conf-ini"><a href="#编辑配置文件-etc-neutron-plugins-ml2-ml2-conf-ini" class="headerlink" title="编辑配置文件/etc/neutron/plugins/ml2/ml2_conf.ini"></a>编辑配置文件/etc/neutron/plugins/ml2/ml2_conf.ini</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[ml2]</span><br><span class="line">type_drivers = flat,vlan</span><br><span class="line">[ml2]</span><br><span class="line">tenant_network_types =</span><br><span class="line">[ml2]</span><br><span class="line">mechanism_drivers = linuxbridge</span><br><span class="line">[ml2]</span><br><span class="line">extension_drivers = port_security</span><br><span class="line">[ml2_type_flat]</span><br><span class="line">flat_networks = provider</span><br><span class="line">[securitygroup]</span><br><span class="line">enable_ipset = <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-plugins-ml2-linuxbridge-agent-ini配置文件"><a href="#编辑-etc-neutron-plugins-ml2-linuxbridge-agent-ini配置文件" class="headerlink" title="编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini配置文件"></a>编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[linux_bridge]</span><br><span class="line">physical_interface_mappings = provider:eth1</span><br><span class="line">[vxlan]</span><br><span class="line">enable_vxlan = <span class="literal">false</span></span><br><span class="line">[securitygroup]</span><br><span class="line">enable_security_group = <span class="literal">true</span></span><br><span class="line">firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver</span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-neutron-dhcp-agent-ini"><a href="#编辑配置文件-etc-neutron-dhcp-agent-ini" class="headerlink" title="编辑配置文件/etc/neutron/dhcp_agent.ini"></a>编辑配置文件/etc/neutron/dhcp_agent.ini</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">interface_driver = linuxbridge</span><br><span class="line">dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq</span><br><span class="line">enable_isolated_metadata = <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="配置Self-service网络"><a href="#配置Self-service网络" class="headerlink" title="配置Self-service网络"></a>配置Self-service网络</h3><h3 id="安装软件包-7"><a href="#安装软件包-7" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install openstack-neutron openstack-neutron-ml2 \</span></span><br><span class="line">openstack-neutron-linuxbridge ebtables -y</span><br></pre></td></tr></table></figure>
<h3 id="配置-etc-neutron-neutron-conf文件"><a href="#配置-etc-neutron-neutron-conf文件" class="headerlink" title="配置/etc/neutron/neutron.conf文件"></a>配置/etc/neutron/neutron.conf文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[database]</span><br><span class="line">connection = mysql+pymysql://neutron:000000@controller/neutron</span><br><span class="line">[DEFAULT]</span><br><span class="line">core_plugin = ml2</span><br><span class="line">service_plugins = router</span><br><span class="line">allow_overlapping_ips = <span class="literal">true</span></span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url = rabbit://openstack:000000@controller</span><br><span class="line">[DEFAULT]</span><br><span class="line">auth_strategy = keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">www_authenticate_uri = http://controller:5000</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">project_name = service</span><br><span class="line">username = neutron</span><br><span class="line">password = 000000</span><br><span class="line">[DEFAULT]</span><br><span class="line">notify_nova_on_port_status_changes = <span class="literal">true</span></span><br><span class="line">notify_nova_on_port_data_changes = <span class="literal">true</span></span><br><span class="line">[nova]</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">region_name = RegionOne</span><br><span class="line">project_name = service</span><br><span class="line">username = nova</span><br><span class="line">password = 000000</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path = /var/lib/neutron/tmp</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-plugins-ml2-ml2-conf-ini文件"><a href="#编辑-etc-neutron-plugins-ml2-ml2-conf-ini文件" class="headerlink" title="编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件"></a>编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[ml2]</span><br><span class="line">type_drivers = flat,vlan,vxlan</span><br><span class="line">[ml2]</span><br><span class="line">tenant_network_types = vxlan</span><br><span class="line">[ml2]</span><br><span class="line">mechanism_drivers = linuxbridge,l2population</span><br><span class="line">[ml2]</span><br><span class="line">extension_drivers = port_security</span><br><span class="line">[ml2_type_flat]</span><br><span class="line">flat_networks = provider</span><br><span class="line">[ml2_type_vxlan]</span><br><span class="line">vni_ranges = 1:1000</span><br><span class="line">[securitygroup]</span><br><span class="line">enable_ipset = <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-plugins-ml2-linuxbridge-agent-ini文件"><a href="#编辑-etc-neutron-plugins-ml2-linuxbridge-agent-ini文件" class="headerlink" title="编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件"></a>编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[linux_bridge]</span><br><span class="line">physical_interface_mappings = provider:eth1</span><br><span class="line">[vxlan]</span><br><span class="line">enable_vxlan = <span class="literal">true</span></span><br><span class="line">local_ip = 192.168.200.10</span><br><span class="line">l2_population = <span class="literal">true</span></span><br><span class="line">[securitygroup]</span><br><span class="line">enable_security_group = <span class="literal">true</span></span><br><span class="line">firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-l3-agent-ini文件"><a href="#编辑-etc-neutron-l3-agent-ini文件" class="headerlink" title="编辑/etc/neutron/l3_agent.ini文件"></a>编辑/etc/neutron/l3_agent.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">interface_driver = linuxbridge</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-dhcp-agent-ini文件"><a href="#编辑-etc-neutron-dhcp-agent-ini文件" class="headerlink" title="编辑/etc/neutron/dhcp_agent.ini文件"></a>编辑/etc/neutron/dhcp_agent.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">interface_driver = linuxbridge</span><br><span class="line">dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq</span><br><span class="line">enable_isolated_metadata = <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-neutron-metadata-agent-ini文件"><a href="#编辑-etc-neutron-metadata-agent-ini文件" class="headerlink" title="编辑/etc/neutron/metadata_agent.ini文件"></a>编辑/etc/neutron/metadata_agent.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">nova_metadata_host = controller</span><br><span class="line">metadata_proxy_shared_secret = METADATA_SECRET</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-nova-nova-conf文件"><a href="#编辑-etc-nova-nova-conf文件" class="headerlink" title="编辑/etc/nova/nova.conf文件"></a>编辑/etc/nova/nova.conf文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[neutron]</span><br><span class="line">url = http://controller:9696</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">region_name = RegionOne</span><br><span class="line">project_name = service</span><br><span class="line">username = neutron</span><br><span class="line">password = 000000</span><br><span class="line">service_metadata_proxy = <span class="literal">true</span></span><br><span class="line">metadata_proxy_shared_secret = METADATA_SECRET</span><br></pre></td></tr></table></figure>
<h3 id="创建链接"><a href="#创建链接" class="headerlink" title="创建链接"></a>创建链接</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># ln -s /etc/neutron/plugins/ml2/ml2_conf.ini</span></span><br><span class="line">/etc/neutron/plugin.ini</span><br></pre></td></tr></table></figure>
<h3 id="同步数据库-2"><a href="#同步数据库-2" class="headerlink" title="同步数据库"></a>同步数据库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># su -s /bin/sh -c &quot;neutron-db-manage --config-file</span></span><br><span class="line">/etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini</span><br><span class="line">upgrade head<span class="string">&quot; neutron</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span></span><br><span class="line"><span class="string">Running upgrade for neutron ...</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade -&gt; kilo</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade kilo -&gt; 354db87e3225</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 354db87e3225 -&gt; 599c6a226151</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 599c6a226151 -&gt; 52c5312f6baf</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 52c5312f6baf -&gt; 313373c0ffee</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 313373c0ffee -&gt; 8675309a5c4f</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 8675309a5c4f -&gt; 45f955889773</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 45f955889773 -&gt; 26c371498592</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 26c371498592 -&gt; 1c844d1677f7</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 1c844d1677f7 -&gt; 1b4c6e320f79</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 1b4c6e320f79 -&gt; 48153cb5f051</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 48153cb5f051 -&gt; 9859ac9c136</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 9859ac9c136 -&gt; 34af2b5c5a59</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 34af2b5c5a59 -&gt; 59cb5b6cf4d</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 59cb5b6cf4d -&gt; 13cfb89f881a</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 13cfb89f881a -&gt; 32e5974ada25</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 32e5974ada25 -&gt; ec7fcfbf72ee</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade ec7fcfbf72ee -&gt; dce3ec7a25c9</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade dce3ec7a25c9 -&gt; c3a73f615e4</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade c3a73f615e4 -&gt; 659bf3d90664</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 659bf3d90664 -&gt; 1df244e556f5</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 1df244e556f5 -&gt; 19f26505c74f</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 19f26505c74f -&gt; 15be73214821</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 15be73214821 -&gt; b4caf27aae4</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade b4caf27aae4 -&gt; 15e43b934f81</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 15e43b934f81 -&gt; 31ed664953e6</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 31ed664953e6 -&gt; 2f9e956e7532</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 2f9e956e7532 -&gt; 3894bccad37f</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 3894bccad37f -&gt; 0e66c5227a8a</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 0e66c5227a8a -&gt; 45f8dd33480b</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 45f8dd33480b -&gt; 5abc0278ca73</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 5abc0278ca73 -&gt; d3435b514502</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade d3435b514502 -&gt; 30107ab6a3ee</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 30107ab6a3ee -&gt; c415aab1c048</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade c415aab1c048 -&gt; a963b38d82f4</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade kilo -&gt; 30018084ec99</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 30018084ec99 -&gt; 4ffceebfada</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 4ffceebfada -&gt; 5498d17be016</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 5498d17be016 -&gt; 2a16083502f3</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 2a16083502f3 -&gt; 2e5352a0ad4d</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 2e5352a0ad4d -&gt; 11926bcfe72d</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 11926bcfe72d -&gt; 4af11ca47297</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 4af11ca47297 -&gt; 1b294093239c</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 1b294093239c -&gt; 8a6d8bdae39</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 8a6d8bdae39 -&gt; 2b4c2465d44b</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 2b4c2465d44b -&gt; e3278ee65050</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade e3278ee65050 -&gt; c6c112992c9</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade c6c112992c9 -&gt; 5ffceebfada</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 5ffceebfada -&gt; 4ffceebfcdc</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 4ffceebfcdc -&gt; 7bbb25278f53</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 7bbb25278f53 -&gt; 89ab9a816d70</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade a963b38d82f4 -&gt; 3d0e74aa7d37</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 3d0e74aa7d37 -&gt; 030a959ceafa</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 030a959ceafa -&gt; a5648cfeeadf</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade a5648cfeeadf -&gt; 0f5bef0f87d4</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 0f5bef0f87d4 -&gt; 67daae611b6e</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 89ab9a816d70 -&gt; c879c5e1ee90</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade c879c5e1ee90 -&gt; 8fd3918ef6f4</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 8fd3918ef6f4 -&gt; 4bcd4df1f426</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 4bcd4df1f426 -&gt; b67e765a3524</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 67daae611b6e -&gt; 6b461a21bcfc</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 6b461a21bcfc -&gt; 5cd92597d11d</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 5cd92597d11d -&gt; 929c968efe70</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 929c968efe70 -&gt; a9c43481023c</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade a9c43481023c -&gt; 804a3c76314c</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 804a3c76314c -&gt; 2b42d90729da</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 2b42d90729da -&gt; 62c781cb6192</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 62c781cb6192 -&gt; c8c222d42aa9</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade c8c222d42aa9 -&gt; 349b6fd605a6</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 349b6fd605a6 -&gt; 7d32f979895f</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 7d32f979895f -&gt; 594422d373ee</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 594422d373ee -&gt; 61663558142c</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 61663558142c -&gt; 867d39095bf4,</span></span><br><span class="line"><span class="string">port forwarding</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade b67e765a3524 -&gt; a84ccf28f06a</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade a84ccf28f06a -&gt; 7d9d8eeec6ad</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 7d9d8eeec6ad -&gt; a8b517cff8ab</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade a8b517cff8ab -&gt; 3b935b28e7a0</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 3b935b28e7a0 -&gt; b12a3ef66e62</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade b12a3ef66e62 -&gt; 97c25b0d2353</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 97c25b0d2353 -&gt; 2e0d7a8a1586</span></span><br><span class="line"><span class="string">INFO [alembic.runtime.migration] Running upgrade 2e0d7a8a1586 -&gt; 5c85685d616d</span></span><br><span class="line"><span class="string">OK</span></span><br></pre></td></tr></table></figure>
<h3 id="启动服务-5"><a href="#启动服务-5" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl restart openstack-nova-api</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl start neutron-server.service</span></span><br><span class="line">neutron-linuxbridge-agent.service neutron-dhcp-agent.service</span><br><span class="line">neutron-metadata-agent.service</span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable neutron-server.service</span></span><br><span class="line">neutron-linuxbridge-agent.service neutron-dhcp-agent.service</span><br><span class="line">neutron-metadata-agent.service</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/neutron-server.service to</span><br><span class="line">/usr/lib/systemd/system/neutron-server.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/neutron-linuxbridge-agent.service to</span><br><span class="line">/usr/lib/systemd/system/neutron-linuxbridge-agent.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/neutron-dhcp-agent.service to</span><br><span class="line">/usr/lib/systemd/system/neutron-dhcp-agent.service.</span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/neutron-metadata-agent.service to</span><br><span class="line">/usr/lib/systemd/system/neutron-metadata-agent.service.</span><br></pre></td></tr></table></figure>
<p>如果选择了Self-service网络，还需要启动这个服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl start neutron-l3-agent.service</span></span><br><span class="line">[root@controller ~]<span class="comment"># systemctl enable neutron-l3-agent.service</span></span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/neutron-l3-agent.service to</span><br><span class="line">/usr/lib/systemd/system/neutron-l3-agent.service.</span><br></pre></td></tr></table></figure>
<h3 id="compute节点-2"><a href="#compute节点-2" class="headerlink" title="compute节点"></a>compute节点</h3><h3 id="安装软件包-8"><a href="#安装软件包-8" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># yum install openstack-neutron-linuxbridge ebtables ipset -y</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑配置-etc-neutron-neutron-conf文件"><a href="#编辑配置-etc-neutron-neutron-conf文件" class="headerlink" title="编辑配置/etc/neutron/neutron.conf文件"></a>编辑配置/etc/neutron/neutron.conf文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">transport_url = rabbit://openstack:000000@controller</span><br><span class="line">[DEFAULT]</span><br><span class="line">auth_strategy = keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">www_authenticate_uri = http://controller:5000</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">memcached_servers = controller:11211</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">project_name = service</span><br><span class="line">username = neutron</span><br><span class="line">password = 000000</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path = /var/lib/neutron/tmp</span><br></pre></td></tr></table></figure>
<h3 id="配置provider网络"><a href="#配置provider网络" class="headerlink" title="配置provider网络"></a>配置provider网络</h3><h3 id="编辑配置-etc-neutron-plugins-ml2-linuxbridge-agent-ini文件"><a href="#编辑配置-etc-neutron-plugins-ml2-linuxbridge-agent-ini文件" class="headerlink" title="编辑配置/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件"></a>编辑配置/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[linux_bridge]</span><br><span class="line">physical_interface_mappings = provider:eth1</span><br><span class="line">[vxlan]</span><br><span class="line">enable_vxlan = <span class="literal">false</span></span><br><span class="line">[securitygroup]</span><br><span class="line">enable_security_group = <span class="literal">true</span></span><br><span class="line">firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver</span><br></pre></td></tr></table></figure>
<h3 id="配置Self-service网络-1"><a href="#配置Self-service网络-1" class="headerlink" title="配置Self-service网络"></a>配置Self-service网络</h3><h3 id="编辑配置-etc-neutron-plugins-ml2-linuxbridge-agent-ini文件-1"><a href="#编辑配置-etc-neutron-plugins-ml2-linuxbridge-agent-ini文件-1" class="headerlink" title="编辑配置/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件"></a>编辑配置/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[linux_bridge]</span><br><span class="line">physical_interface_mappings = provider:eth1</span><br><span class="line">[vxlan]</span><br><span class="line">enable_vxlan = <span class="literal">true</span></span><br><span class="line">local_ip = 192.168.200.20</span><br><span class="line">l2_population = <span class="literal">true</span></span><br><span class="line">[securitygroup]</span><br><span class="line">enable_security_group = <span class="literal">true</span></span><br><span class="line">firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver</span><br></pre></td></tr></table></figure>
<h3 id="配置nova配置-etc-nova-nova-conf文件"><a href="#配置nova配置-etc-nova-nova-conf文件" class="headerlink" title="配置nova配置/etc/nova/nova.conf文件"></a>配置nova配置/etc/nova/nova.conf文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[neutron]</span><br><span class="line">url = http://controller:9696</span><br><span class="line">auth_url = http://controller:5000</span><br><span class="line">auth_type = password</span><br><span class="line">project_domain_name = default</span><br><span class="line">user_domain_name = default</span><br><span class="line">region_name = RegionOne</span><br><span class="line">project_name = service</span><br><span class="line">username = neutron</span><br><span class="line">password = 000000</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-6"><a href="#启动服务-6" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># systemctl restart openstack-nova-compute</span></span><br><span class="line">[root@compute ~]<span class="comment"># systemctl start neutron-linuxbridge-agent.service</span></span><br><span class="line">[root@compute ~]<span class="comment"># systemctl enable neutron-linuxbridge-agent.service</span></span><br><span class="line">Created symlink from</span><br><span class="line">/etc/systemd/system/multi-user.target.wants/neutron-linuxbridge-agent.service to</span><br><span class="line">/usr/lib/systemd/system/neutron-linuxbridge-agent.service.</span><br></pre></td></tr></table></figure>
<h3 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack network agent list</span></span><br><span class="line">+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+</span><br><span class="line">| ID | Agent Type | Host | Availability Zone | Alive | State | Binary |</span><br><span class="line">+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+</span><br><span class="line">| 06323fbc-0b13-4c14-a05d-d414678177bf | Linux bridge agent | controller |</span><br><span class="line">None | :-) | UP | neutron-linuxbridge-agent |</span><br><span class="line">| 4bd1d3eb-d178-4ff5-8d3f-7307a4415209 | Linux bridge agent | compute | None</span><br><span class="line">| :-) | UP | neutron-linuxbridge-agent |</span><br><span class="line">| 74ba6229-1449-40c7-a0de-53688fbb560a | Metadata agent | controller | None</span><br><span class="line">| :-) | UP | neutron-metadata-agent |</span><br><span class="line">| d43e223f-c23d-4e60-88b6-ffe12243853f | DHCP agent | controller | nova |</span><br><span class="line">:-) | UP | neutron-dhcp-agent |</span><br><span class="line">| da0e8763-8082-4a5e-8188-7161d7ad8a05 | L3 agent | controller | nova | :-)</span><br><span class="line">| UP | neutron-l3-agent |</span><br><span class="line">+--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+</span><br></pre></td></tr></table></figure>
<h2 id="安装dashboard"><a href="#安装dashboard" class="headerlink" title="安装dashboard"></a>安装dashboard</h2><h3 id="controller节点-4"><a href="#controller节点-4" class="headerlink" title="controller节点"></a>controller节点</h3><h3 id="安装软件包-9"><a href="#安装软件包-9" class="headerlink" title="安装软件包"></a>安装软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># yum install -y openstack-dashboard</span></span><br></pre></td></tr></table></figure>
<h3 id="编辑配置文件-etc-openstack-dashboard-local-settings"><a href="#编辑配置文件-etc-openstack-dashboard-local-settings" class="headerlink" title="编辑配置文件/etc/openstack-dashboard/local_settings"></a>编辑配置文件/etc/openstack-dashboard/local_settings</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OPENSTACK_HOST = <span class="string">&quot;controller&quot;</span></span><br><span class="line">ALLOWED_HOSTS = [<span class="string">&#x27;*&#x27;</span>, <span class="string">&#x27;localhost&#x27;</span>]</span><br><span class="line">SESSION_ENGINE = <span class="string">&#x27;django.contrib.sessions.backends.cache&#x27;</span></span><br><span class="line">CACHES = &#123;</span><br><span class="line"><span class="string">&#x27;default&#x27;</span>: &#123;</span><br><span class="line"><span class="string">&#x27;BACKEND&#x27;</span>: <span class="string">&#x27;django.core.cache.backends.memcached.MemcachedCache&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;LOCATION&#x27;</span>: <span class="string">&#x27;controller:11211&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">OPENSTACK_KEYSTONE_URL = <span class="string">&quot;http://%s:5000/v3&quot;</span> % OPENSTACK_HOST</span><br><span class="line">OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True</span><br><span class="line">OPENSTACK_API_VERSIONS = &#123;</span><br><span class="line"><span class="string">&quot;identity&quot;</span>: 3,</span><br><span class="line"><span class="string">&quot;image&quot;</span>: 2,</span><br><span class="line"><span class="string">&quot;volume&quot;</span>: 2,</span><br><span class="line">&#125;</span><br><span class="line">OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = <span class="string">&quot;Default&quot;</span></span><br><span class="line">OPENSTACK_KEYSTONE_DEFAULT_ROLE = <span class="string">&quot;user&quot;</span></span><br><span class="line">OPENSTACK_NEUTRON_NETWORK = &#123;</span><br><span class="line">...</span><br><span class="line"><span class="string">&#x27;enable_router&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_quotas&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_distributed_router&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_ha_router&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_lb&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_firewall&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_vpn&#x27;</span>: False,</span><br><span class="line"><span class="string">&#x27;enable_fip_topology_check&#x27;</span>: False,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="编辑-etc-httpd-conf-d-openstack-dashboard-conf"><a href="#编辑-etc-httpd-conf-d-openstack-dashboard-conf" class="headerlink" title="编辑/etc/httpd/conf.d/openstack-dashboard.conf"></a>编辑/etc/httpd/conf.d/openstack-dashboard.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">WSGIApplicationGroup %&#123;GLOBAL&#125;</span><br></pre></td></tr></table></figure>
<h3 id="启动服务-7"><a href="#启动服务-7" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># systemctl restart httpd.service memcached.service</span></span><br></pre></td></tr></table></figure>
<h3 id="验证-2"><a href="#验证-2" class="headerlink" title="验证"></a>验证</h3><p>浏览器打开192.168.100.10/dashboard<br><img src="/images/mk/openstack-install-guide/dashboard.png" alt="dashboard"></p>
<h2 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h2><h3 id="创建provider网络"><a href="#创建provider网络" class="headerlink" title="创建provider网络"></a>创建provider网络</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># . admin-openrc</span></span><br><span class="line">[root@controller ~]<span class="comment"># openstack network create --share --external</span></span><br><span class="line">--provider-physical-network provider --provider-network-type flat provider</span><br><span class="line">+---------------------------+--------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------------+--------------------------------------+</span><br><span class="line">| admin_state_up | UP |</span><br><span class="line">| availability_zone_hints | |</span><br><span class="line">| availability_zones | |</span><br><span class="line">| created_at | 2018-09-03T15:02:08Z |</span><br><span class="line">| description | |</span><br><span class="line">| dns_domain | None |</span><br><span class="line">| id | 2aa01a54-8f0b-4d13-a831-24c752fd0487 |</span><br><span class="line">| ipv4_address_scope | None |</span><br><span class="line">| ipv6_address_scope | None |</span><br><span class="line">| is_default | False |</span><br><span class="line">| is_vlan_transparent | None |</span><br><span class="line">| mtu | 1500 |</span><br><span class="line">| name | provider |</span><br><span class="line">| port_security_enabled | True |</span><br><span class="line">| project_id | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| provider:network_type | flat |</span><br><span class="line">| provider:physical_network | provider |</span><br><span class="line">| provider:segmentation_id | None |</span><br><span class="line">| qos_policy_id | None |</span><br><span class="line">| revision_number | 0 |</span><br><span class="line">| router:external | External |</span><br><span class="line">| segments | None |</span><br><span class="line">| shared | True |</span><br><span class="line">| status | ACTIVE |</span><br><span class="line">| subnets | |</span><br><span class="line">| tags | |</span><br><span class="line">| updated_at | 2018-09-03T15:02:08Z |</span><br><span class="line">+---------------------------+--------------------------------------+<span class="comment">#</span></span><br></pre></td></tr></table></figure>
<h3 id="创建子网"><a href="#创建子网" class="headerlink" title="创建子网"></a>创建子网</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack subnet create --network provider</span></span><br><span class="line">--allocation-pool start=192.168.200.100,end=192.168.200.200 --dns-nameserver</span><br><span class="line">114.114.114.114 --gateway 192.168.200.1 --subnet-range 192.168.200.0/24 provider</span><br><span class="line">+-------------------+--------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------------+--------------------------------------+</span><br><span class="line">| allocation_pools | 192.168.200.100-192.168.200.200 |</span><br><span class="line">| cidr | 192.168.200.0/24 |</span><br><span class="line">| created_at | 2018-09-03T15:03:51Z |</span><br><span class="line">| description | |</span><br><span class="line">| dns_nameservers | 114.114.114.114 |</span><br><span class="line">| enable_dhcp | True |</span><br><span class="line">| gateway_ip | 192.168.200.1 |</span><br><span class="line">| host_routes | |</span><br><span class="line">| id | 4d67937d-43ef-4a7f-941c-5dbef19732be |</span><br><span class="line">| ip_version | 4 |</span><br><span class="line">| ipv6_address_mode | None |</span><br><span class="line">| ipv6_ra_mode | None |</span><br><span class="line">| name | provider |</span><br><span class="line">| network_id | 2aa01a54-8f0b-4d13-a831-24c752fd0487 |</span><br><span class="line">| project_id | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| revision_number | 0 |</span><br><span class="line">| segment_id | None |</span><br><span class="line">| service_types | |</span><br><span class="line">| subnetpool_id | None |</span><br><span class="line">| tags | |</span><br><span class="line">| updated_at | 2018-09-03T15:03:51Z |</span><br><span class="line">+-------------------+--------------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="创建Self-service网络"><a href="#创建Self-service网络" class="headerlink" title="创建Self-service网络"></a>创建Self-service网络</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack network create selfservice</span></span><br><span class="line">+---------------------------+--------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------------+--------------------------------------+</span><br><span class="line">| admin_state_up | UP |</span><br><span class="line">| availability_zone_hints | |</span><br><span class="line">| availability_zones | |</span><br><span class="line">| created_at | 2018-09-03T15:04:12Z |</span><br><span class="line">| description | |</span><br><span class="line">| dns_domain | None |</span><br><span class="line">| id | 1c5078e9-8dbb-47d7-976d-5ac1d8b35181 |</span><br><span class="line">| ipv4_address_scope | None |</span><br><span class="line">| ipv6_address_scope | None |</span><br><span class="line">| is_default | False |</span><br><span class="line">| is_vlan_transparent | None |</span><br><span class="line">| mtu | 1450 |</span><br><span class="line">| name | selfservice |</span><br><span class="line">| port_security_enabled | True |</span><br><span class="line">| project_id | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| provider:network_type | vxlan |</span><br><span class="line">| provider:physical_network | None |</span><br><span class="line">| provider:segmentation_id | 89 |</span><br><span class="line">| qos_policy_id | None |</span><br><span class="line">| revision_number | 1 |</span><br><span class="line">| router:external | Internal |</span><br><span class="line">| segments | None |</span><br><span class="line">| shared | False |</span><br><span class="line">| status | ACTIVE |</span><br><span class="line">| subnets | |</span><br><span class="line">| tags | |</span><br><span class="line">| updated_at | 2018-09-03T15:04:12Z |</span><br><span class="line">+---------------------------+--------------------------------------+</span><br><span class="line">[root@controller ~]<span class="comment"># openstack subnet create --network selfservice</span></span><br><span class="line">--dns-nameserver 8.8.4.4 --gateway 172.16.1.1 --subnet-range 172.16.1.0/24</span><br><span class="line">selfservice</span><br><span class="line">+-------------------+--------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------------+--------------------------------------+</span><br><span class="line">| allocation_pools | 172.16.1.2-172.16.1.254 |</span><br><span class="line">| cidr | 172.16.1.0/24 |</span><br><span class="line">| created_at | 2018-09-03T15:04:19Z |</span><br><span class="line">| description | |</span><br><span class="line">| dns_nameservers | 8.8.4.4 |</span><br><span class="line">| enable_dhcp | True |</span><br><span class="line">| gateway_ip | 172.16.1.1 |</span><br><span class="line">| host_routes | |</span><br><span class="line">| id | fd6791d8-7a53-43fe-bc35-45168dbd13f0 |</span><br><span class="line">| ip_version | 4 |</span><br><span class="line">| ipv6_address_mode | None |</span><br><span class="line">| ipv6_ra_mode | None |</span><br><span class="line">| name | selfservice |</span><br><span class="line">| network_id | 1c5078e9-8dbb-47d7-976d-5ac1d8b35181 |</span><br><span class="line">| project_id | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| revision_number | 0 |</span><br><span class="line">| segment_id | None |</span><br><span class="line">| service_types | |</span><br><span class="line">| subnetpool_id | None |</span><br><span class="line">| tags | |</span><br><span class="line">| updated_at | 2018-09-03T15:04:19Z |</span><br><span class="line">+-------------------+--------------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="创建路由"><a href="#创建路由" class="headerlink" title="创建路由"></a>创建路由</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack router create router</span><br></pre></td></tr></table></figure>
<h3 id="创建子网接口"><a href="#创建子网接口" class="headerlink" title="创建子网接口"></a>创建子网接口</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack router add subnet router selfservice</span><br></pre></td></tr></table></figure>
<h3 id="创建网关"><a href="#创建网关" class="headerlink" title="创建网关"></a>创建网关</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack router <span class="built_in">set</span> router --external-gateway provider</span><br></pre></td></tr></table></figure>
<h3 id="创建类型"><a href="#创建类型" class="headerlink" title="创建类型"></a>创建类型</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openstack flavor create --id 0 --vcpus 1 --ram 64 --disk 1 m1.nano</span><br></pre></td></tr></table></figure>
<h3 id="创建一个Self-service网络的虚拟机"><a href="#创建一个Self-service网络的虚拟机" class="headerlink" title="创建一个Self-service网络的虚拟机"></a>创建一个Self-service网络的虚拟机</h3><p>这里的net-id是openstack network list查看到的id</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack server create --flavor m1.nano --image cirros</span></span><br><span class="line">--nic net-id=1c5078e9-8dbb-47d7-976d-5ac1d8b35181 cirros</span><br><span class="line">+-------------------------------------+-----------------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------------------------------+-----------------------------------------------+</span><br><span class="line">| OS-DCF:diskConfig | MANUAL |</span><br><span class="line">| OS-EXT-AZ:availability_zone | |</span><br><span class="line">| OS-EXT-SRV-ATTR:host | None |</span><br><span class="line">| OS-EXT-SRV-ATTR:hypervisor_hostname | None |</span><br><span class="line">| OS-EXT-SRV-ATTR:instance_name | |</span><br><span class="line">| OS-EXT-STS:power_state | NOSTATE |</span><br><span class="line">| OS-EXT-STS:task_state | scheduling |</span><br><span class="line">| OS-EXT-STS:vm_state | building |</span><br><span class="line">| OS-SRV-USG:launched_at | None |</span><br><span class="line">| OS-SRV-USG:terminated_at | None |</span><br><span class="line">| accessIPv4 | |</span><br><span class="line">| accessIPv6 | |</span><br><span class="line">| addresses | |</span><br><span class="line">| adminPass | Y3Vh6RnFq4C7 |</span><br><span class="line">| config_drive | |</span><br><span class="line">| created | 2018-09-03T15:08:50Z |</span><br><span class="line">| flavor | m1.nano (0) |</span><br><span class="line">| hostId | |</span><br><span class="line">| id | 38339165-fb68-4657-8ca6-457370a2202e |</span><br><span class="line">| image | cirros (8faa9dc9-7f29-4570-ae87-9bab0d01aa63) |</span><br><span class="line">| key_name | None |</span><br><span class="line">| name | cirros |</span><br><span class="line">| progress | 0 |</span><br><span class="line">| project_id | 1a74d2a87e734feea8577477955e0b06 |</span><br><span class="line">| properties | |</span><br><span class="line">| security_groups | name=<span class="string">&#x27;default&#x27;</span> |</span><br><span class="line">| status | BUILD |</span><br><span class="line">| updated | 2018-09-03T15:08:50Z |</span><br><span class="line">| user_id | 5238d646322346be9e3f9750422bcf4d |</span><br><span class="line">| volumes_attached | |</span><br><span class="line">+-------------------------------------+-----------------------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="查看是否创建成功"><a href="#查看是否创建成功" class="headerlink" title="查看是否创建成功"></a>查看是否创建成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># openstack server list</span></span><br><span class="line">+--------------------------------------+--------+--------+-------------------------+--------+---------+</span><br><span class="line">| ID | Name | Status | Networks | Image | Flavor |</span><br><span class="line">+--------------------------------------+--------+--------+-------------------------+--------+---------+</span><br><span class="line">| 38339165-fb68-4657-8ca6-457370a2202e | cirros | ACTIVE |</span><br><span class="line">selfservice=172.16.1.25 | cirros | m1.nano |</span><br><span class="line">+--------------------------------------+--------+--------+-------------------------+--------+---------+</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7安装KVM</title>
    <url>/2018/08/13/CentOS7%E5%AE%89%E8%A3%85KVM/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>KVM是是个开源的系统虚拟化模块，自内核2.6.20之后集成在各个Linux的主要发行版中。</p>
<p>也就是创建虚拟机的一个工具。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="1-关闭防火墙，关selinux"><a href="#1-关闭防火墙，关selinux" class="headerlink" title="1 关闭防火墙，关selinux"></a>1 关闭防火墙，关selinux</h3><p>为了方便，防火墙先关闭</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl stop firewalld</span></span><br><span class="line"><span class="comment"># systemctl disable firewalld</span></span><br><span class="line"><span class="comment"># vi /etc/selinux/config</span></span><br><span class="line"><span class="comment"># setenforce 0</span></span><br></pre></td></tr></table></figure>

<h3 id="2-安装工具包"><a href="#2-安装工具包" class="headerlink" title="2 安装工具包"></a>2 安装工具包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install -y net-tools -y epel-release</span></span><br></pre></td></tr></table></figure>

<h3 id="3-安装kvm相关软件包"><a href="#3-安装kvm相关软件包" class="headerlink" title="3 安装kvm相关软件包"></a>3 安装kvm相关软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install qemu-kvm libvirt virt-install bridge-utils libvirt-python libguestfs-tools virt-manager virt-viewer virt-top kvm  xauth -y</span></span><br></pre></td></tr></table></figure>

<h3 id="4-编辑网卡，创建网桥"><a href="#4-编辑网卡，创建网桥" class="headerlink" title="4  编辑网卡，创建网桥"></a>4  编辑网卡，创建网桥</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># cat /etc/sysconfig/network-scripts/ifcfg-ens34</span></span><br><span class="line">BOOTPROTO=none</span><br><span class="line">NM_CONTROLLED=no</span><br><span class="line">DEVICE=ens34</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BRIDGE=br0</span><br><span class="line">[root@localhost ~]<span class="comment"># cat /etc/sysconfig/network-scripts/ifcfg-br0</span></span><br><span class="line">BOOTPROTO=static</span><br><span class="line">DEVICE=br0</span><br><span class="line">TYPE=Bridge</span><br><span class="line">NM_CONTROLLED=no</span><br><span class="line">IPADDR=192.168.100.101</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line"><span class="comment"># systemctl restart network</span></span><br></pre></td></tr></table></figure>

<h3 id="5-添加镜像到系统中"><a href="#5-添加镜像到系统中" class="headerlink" title="5  添加镜像到系统中"></a>5  添加镜像到系统中</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /data/IaaS/ISO/CentOS/</span></span><br><span class="line"><span class="comment"># mv /opt/CentOS-7-x86_64-DVD-1511.iso /data/IaaS/ISO/CentOS/</span></span><br></pre></td></tr></table></figure>

<h3 id="6-查看kvm模块是否加载（如果没有则执行modprobe-kvm）"><a href="#6-查看kvm模块是否加载（如果没有则执行modprobe-kvm）" class="headerlink" title="6  查看kvm模块是否加载（如果没有则执行modprobe kvm）"></a>6  查看kvm模块是否加载（如果没有则执行modprobe kvm）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># lsmod |grep kvm</span></span><br><span class="line"><span class="comment"># virsh -c qemu:///system list  (查看虚拟机，等同于virsh list --all)</span></span><br><span class="line"><span class="comment"># virsh list</span></span><br></pre></td></tr></table></figure>

<h3 id="7-开启端口转发"><a href="#7-开启端口转发" class="headerlink" title="7 开启端口转发"></a>7 开启端口转发</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span></span><br></pre></td></tr></table></figure>

<h3 id="8-查看virsh版本号"><a href="#8-查看virsh版本号" class="headerlink" title="8 查看virsh版本号"></a>8 查看virsh版本号</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># virsh version</span></span><br></pre></td></tr></table></figure>

<h3 id="9-修改vnc监听端口，并重启libvirtd-并开机自启"><a href="#9-修改vnc监听端口，并重启libvirtd-并开机自启" class="headerlink" title="9 修改vnc监听端口，并重启libvirtd,并开机自启"></a>9 修改vnc监听端口，并重启libvirtd,并开机自启</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/libvirt/qemu.conf</span></span><br><span class="line">vnc_listen = <span class="string">&quot;0.0.0.0&quot;</span></span><br><span class="line"><span class="comment"># systemctl restart libvirtd</span></span><br></pre></td></tr></table></figure>

<h3 id="10-创建镜像存放地址"><a href="#10-创建镜像存放地址" class="headerlink" title="10 创建镜像存放地址"></a>10 创建镜像存放地址</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /data/IaaS/Storage/Primary</span></span><br><span class="line"><span class="comment"># qemu-img create -o compat=0.10 -f qcow2 /data/IaaS/Storage/Primary/centos7.qcow2 10G</span></span><br><span class="line"><span class="comment"># qemu-img info /data/IaaS/Storage/Primary/centos7.qcow2</span></span><br><span class="line"><span class="comment"># virt-install --connect=qemu:///system --name centos7 --ram 1024 --vcpus=1 --disk path=/data/IaaS/Storage/Primary/centos7.qcow2,device=disk,format=qcow2,bus=virtio,cache=none,size=100 --cdrom /data/IaaS/ISO/CentOS/CentOS-7-x86_64-DVD-1511.iso --graphics vnc,password=000000,port=5901 --network bridge=br0,model=virtio,model=e1000 --os-type=linux --virt-type=kvm --accelerate --network bridge=br0 –noautoconsole</span></span><br></pre></td></tr></table></figure>

<h3 id="11到这步虚拟机就起来了，可以通过vnc软件连接物理机ip-5901端口连接虚拟机了"><a href="#11到这步虚拟机就起来了，可以通过vnc软件连接物理机ip-5901端口连接虚拟机了" class="headerlink" title="11到这步虚拟机就起来了，可以通过vnc软件连接物理机ip+5901端口连接虚拟机了"></a>11到这步虚拟机就起来了，可以通过vnc软件连接物理机ip+5901端口连接虚拟机了</h3><p><img src="/images/mk/CentOS7_install_KVM/vnc.png" alt="img"></p>
<h3 id="12-如果之前忘记修改vnc-listen的地址，则无法连接到vnc，需要修改vnc监听端口并重启libvirtd。这时候重启虚拟机就行"><a href="#12-如果之前忘记修改vnc-listen的地址，则无法连接到vnc，需要修改vnc监听端口并重启libvirtd。这时候重启虚拟机就行" class="headerlink" title="12 如果之前忘记修改vnc_listen的地址，则无法连接到vnc，需要修改vnc监听端口并重启libvirtd。这时候重启虚拟机就行"></a>12 如果之前忘记修改vnc_listen的地址，则无法连接到vnc，需要修改vnc监听端口并重启libvirtd。这时候重启虚拟机就行</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh reboot centos7</span><br></pre></td></tr></table></figure>

<h3 id="13-virsh-相关命令"><a href="#13-virsh-相关命令" class="headerlink" title="13 virsh 相关命令"></a>13 virsh 相关命令</h3><h4 id="删除虚拟机"><a href="#删除虚拟机" class="headerlink" title="删除虚拟机"></a>删除虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh undefine centos7</span><br></pre></td></tr></table></figure>

<h4 id="查看虚拟机列表"><a href="#查看虚拟机列表" class="headerlink" title="查看虚拟机列表"></a>查看虚拟机列表</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh list –all</span><br></pre></td></tr></table></figure>

<h4 id="开机自动启动"><a href="#开机自动启动" class="headerlink" title="开机自动启动"></a>开机自动启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh autostart centos7</span><br></pre></td></tr></table></figure>

<h4 id="关闭开机自启"><a href="#关闭开机自启" class="headerlink" title="关闭开机自启"></a>关闭开机自启</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh autostart –<span class="built_in">disable</span> centos7</span><br></pre></td></tr></table></figure>

<h4 id="关闭虚拟机"><a href="#关闭虚拟机" class="headerlink" title="关闭虚拟机"></a>关闭虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh shutdown centos7</span><br></pre></td></tr></table></figure>

<h4 id="开启虚拟机"><a href="#开启虚拟机" class="headerlink" title="开启虚拟机"></a>开启虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh start centos7</span><br></pre></td></tr></table></figure>

<h4 id="重启虚拟机-关机状态无法重启，需要用start命令"><a href="#重启虚拟机-关机状态无法重启，需要用start命令" class="headerlink" title="重启虚拟机(关机状态无法重启，需要用start命令)"></a>重启虚拟机(关机状态无法重启，需要用start命令)</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh reboot centos7</span><br></pre></td></tr></table></figure>

<h4 id="彻底删除虚拟机"><a href="#彻底删除虚拟机" class="headerlink" title="彻底删除虚拟机"></a>彻底删除虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh destroy centos7</span><br><span class="line">virsh undefined centos7 (最后删除虚拟机文件)</span><br></pre></td></tr></table></figure>

<h4 id="挂起虚拟机"><a href="#挂起虚拟机" class="headerlink" title="挂起虚拟机"></a>挂起虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh <span class="built_in">suspend</span> centos7</span><br></pre></td></tr></table></figure>

<h4 id="恢复挂起的虚拟机"><a href="#恢复挂起的虚拟机" class="headerlink" title="恢复挂起的虚拟机"></a>恢复挂起的虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh resume centos7</span><br></pre></td></tr></table></figure>

<h4 id="启动虚拟机并进入该虚拟机"><a href="#启动虚拟机并进入该虚拟机" class="headerlink" title="启动虚拟机并进入该虚拟机"></a>启动虚拟机并进入该虚拟机</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">virsh start centos7 --console</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>kvm</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>kvm</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7更改网卡名为eth0</title>
    <url>/2018/08/07/CentOS7%E6%9B%B4%E6%94%B9%E7%BD%91%E5%8D%A1%E5%90%8D%E4%B8%BAeth0/</url>
    <content><![CDATA[<p>centos7以前的网卡名是eth0、eth1这样的命名方式</p>
<p>但是centos7的网卡名称命名方式却并不是这样，这让使用惯了eth0命名方式的童鞋用着不习惯</p>
<p>那么我们何不修改成我们自己惯用的形式呢？</p>
<h3 id="查看一下网络"><a href="#查看一下网络" class="headerlink" title="查看一下网络"></a>查看一下网络</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">  link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">  inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">  inet6 ::1&#x2F;128 scope host </span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">  link&#x2F;ether 00:0c:29:9a:c4:3c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">  inet 192.168.152.101&#x2F;24 brd 192.168.152.255 scope global noprefixroute ens33</span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">  inet6 fe80::a114:2782:6e84:1af&#x2F;64 scope link noprefixroute </span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">3: ens34: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">  link&#x2F;ether 00:0c:29:9a:c4:46 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">  inet 192.168.100.101&#x2F;24 brd 192.168.100.255 scope global noprefixroute ens34</span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">  inet6 fe80::7900:1c46:c414:246f&#x2F;64 scope link noprefixroute </span><br><span class="line">    valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>
<p>这里发现网卡名称为ens33和ens34（有的是eno16777736，修改的方式也一样）</p>
<h3 id="编辑网卡配置文件，将其中的ens33改为eth0，ens34改为eth1"><a href="#编辑网卡配置文件，将其中的ens33改为eth0，ens34改为eth1" class="headerlink" title="编辑网卡配置文件，将其中的ens33改为eth0，ens34改为eth1"></a>编辑网卡配置文件，将其中的ens33改为eth0，ens34改为eth1</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens33 </span><br><span class="line">TYPE&#x3D;Ethernet</span><br><span class="line">PROXY_METHOD&#x3D;none</span><br><span class="line">BROWSER_ONLY&#x3D;no</span><br><span class="line">BOOTPROTO&#x3D;dhcp</span><br><span class="line">DEFROUTE&#x3D;yes</span><br><span class="line">IPV4_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6INIT&#x3D;yes</span><br><span class="line">IPV6_AUTOCONF&#x3D;yes</span><br><span class="line">IPV6_DEFROUTE&#x3D;yes</span><br><span class="line">IPV6_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6_ADDR_GEN_MODE&#x3D;stable-privacy</span><br><span class="line">NAME&#x3D;eth0</span><br><span class="line">UUID&#x3D;0c45b774-fc29-4a3e-81cf-07735671244f</span><br><span class="line">DEVICE&#x3D;eth0</span><br><span class="line">ONBOOT&#x3D;yes</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-ens34</span><br><span class="line">TYPE&#x3D;Ethernet</span><br><span class="line">PROXY_METHOD&#x3D;none</span><br><span class="line">BROWSER_ONLY&#x3D;no</span><br><span class="line">BOOTPROTO&#x3D;dhcp</span><br><span class="line">DEFROUTE&#x3D;yes</span><br><span class="line">IPV4_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6INIT&#x3D;yes</span><br><span class="line">IPV6_AUTOCONF&#x3D;yes</span><br><span class="line">IPV6_DEFROUTE&#x3D;yes</span><br><span class="line">IPV6_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6_ADDR_GEN_MODE&#x3D;stable-privacy</span><br><span class="line">NAME&#x3D;eth1</span><br><span class="line">UUID&#x3D;a62ec7be-a3e2-4322-844a-500eae2de10d</span><br><span class="line">DEVICE&#x3D;eth1</span><br><span class="line">ONBOOT&#x3D;yes</span><br></pre></td></tr></table></figure>
<h3 id="重命名网卡配置文件"><a href="#重命名网卡配置文件" class="headerlink" title="重命名网卡配置文件"></a>重命名网卡配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# mv &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;&#123;ifcfg-ens33,ifcfg-eth0&#125;</span><br><span class="line">&gt;</span><br><span class="line">[root@localhost ~]# mv &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;&#123;ifcfg-ens34,ifcfg-eth1&#125;</span><br></pre></td></tr></table></figure>
<h3 id="禁用可预测命名规则，在GRUB-CMDLINE-LINUX中添加-“net-ifnames-0-biosdevname-0”"><a href="#禁用可预测命名规则，在GRUB-CMDLINE-LINUX中添加-“net-ifnames-0-biosdevname-0”" class="headerlink" title="禁用可预测命名规则，在GRUB_CMDLINE_LINUX中添加 “net.ifnames=0 biosdevname=0”"></a>禁用可预测命名规则，在GRUB_CMDLINE_LINUX中添加 “net.ifnames=0 biosdevname=0”</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# vi &#x2F;etc&#x2F;default&#x2F;grub </span><br><span class="line">GRUB_TIMEOUT&#x3D;5</span><br><span class="line">GRUB_DISTRIBUTOR&#x3D;&quot;$(sed &#39;s, release .*$,,g&#39; &#x2F;etc&#x2F;system-release)&quot;</span><br><span class="line">GRUB_DEFAULT&#x3D;saved</span><br><span class="line">GRUB_DISABLE_SUBMENU&#x3D;true</span><br><span class="line">GRUB_TERMINAL_OUTPUT&#x3D;&quot;console&quot;</span><br><span class="line">GRUB_CMDLINE_LINUX&#x3D;&quot;crashkernel&#x3D;auto rd.lvm.lv&#x3D;centos&#x2F;root net.&quot;ifnames&#x3D;0 biosdevname&#x3D;0&quot; rd.lvm.lv&#x3D;centos&#x2F;</span><br><span class="line">swap rhgb quiet&quot;</span><br><span class="line">GRUB_DISABLE_RECOVERY&#x3D;&quot;true&quot;</span><br></pre></td></tr></table></figure>
<h3 id="重新生成GRUB配置并更新内核参数"><a href="#重新生成GRUB配置并更新内核参数" class="headerlink" title="重新生成GRUB配置并更新内核参数"></a>重新生成GRUB配置并更新内核参数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# grub2-mkconfig -o &#x2F;boot&#x2F;grub2&#x2F;grub.cfg </span><br><span class="line">Generating grub configuration file ...</span><br><span class="line">Found linux image: &#x2F;boot&#x2F;vmlinuz-3.10.0-862.el7.x86_64</span><br><span class="line">Found initrd image: &#x2F;boot&#x2F;initramfs-3.10.0-862.el7.x86_64.img</span><br><span class="line">Found linux image: &#x2F;boot&#x2F;vmlinuz-0-rescue-5ed95dee0a7544bcbc28372bf0d34e68</span><br><span class="line">Found initrd image: &#x2F;boot&#x2F;initramfs-0-rescue-5ed95dee0a7544bcbc28372bf0d34e68.img</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="执行reboot命令重启机子"><a href="#执行reboot命令重启机子" class="headerlink" title="执行reboot命令重启机子"></a>执行reboot命令重启机子</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# reboot </span><br></pre></td></tr></table></figure>
<h3 id="重启完成后，验证网卡是否更改成功"><a href="#重启完成后，验证网卡是否更改成功" class="headerlink" title="重启完成后，验证网卡是否更改成功"></a>重启完成后，验证网卡是否更改成功</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">  link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">  inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">  inet6 ::1&#x2F;128 scope host </span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">  link&#x2F;ether 00:0c:29:9a:c4:3c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">  inet 192.168.152.101&#x2F;24 brd 192.168.152.255 scope global noprefixroute eth0</span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">  inet6 fe80::db97:8ab6:f566:2a29&#x2F;64 scope link noprefixroute </span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">  link&#x2F;ether 00:0c:29:9a:c4:46 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">  inet 192.168.100.101&#x2F;24 brd 192.168.100.255 scope global noprefixroute eth1</span><br><span class="line">    valid_lft forever preferred_lft forever</span><br><span class="line">  inet6 fe80::de72:3532:eacd:df4c&#x2F;64 scope link noprefixroute </span><br><span class="line">    valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 部署Cobbler(PXE)实现自动化安装Centos、Windows</title>
    <url>/2019/01/16/Cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>CentOS7 部署Cobbler(PXE)实现自动化安装Centos、Windows</strong></p>
<h2 id="1-环境"><a href="#1-环境" class="headerlink" title="1 环境"></a>1 环境</h2><table>
<thead>
<tr>
<th>系统</th>
<th>CentOS7.5</th>
</tr>
</thead>
<tbody><tr>
<td>IP</td>
<td>192.168.100.2</td>
</tr>
</tbody></table>
<p>Cobbler是基于PXE的升级版，简化了配置步骤，能同时管理DHCP、TFTP等，还提供了web界面，但是没有记录下来，我大概看了下，web界面还是挺方便的，感兴趣的童鞋可以安装看看<br>这里用的是CentOS7.5，我用CentOS7.2也是成功了，所以理论上，CentOS7各版本都是可以的</p>
<h2 id="2-cobbler部署"><a href="#2-cobbler部署" class="headerlink" title="2 cobbler部署"></a>2 cobbler部署</h2><h3 id="2-1-关闭防火墙"><a href="#2-1-关闭防火墙" class="headerlink" title="2.1 关闭防火墙"></a>2.1 关闭防火墙</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl stop firewalld</span></span><br><span class="line"><span class="comment"># systemctl disable firewalld</span></span><br></pre></td></tr></table></figure>

<h3 id="2-2-关闭selinux"><a href="#2-2-关闭selinux" class="headerlink" title="2.2 关闭selinux"></a>2.2 关闭selinux</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># setenforce 0</span></span><br><span class="line"><span class="comment"># sed -i &quot;s/^SELINUX=.*/SELINUX=permissive/g&quot; /etc/sysconfig/selinux</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-安装epel源"><a href="#2-3-安装epel源" class="headerlink" title="2.3 安装epel源"></a>2.3 安装epel源</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install -y epel-release</span></span><br></pre></td></tr></table></figure>

<h3 id="2-4-安装cobbler及其相关软件"><a href="#2-4-安装cobbler及其相关软件" class="headerlink" title="2.4 安装cobbler及其相关软件"></a>2.4 安装cobbler及其相关软件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum -y install cobbler dhcp tftp-server pykickstart httpd</span></span><br></pre></td></tr></table></figure>

<h3 id="2-5-修改cobbler配置文件"><a href="#2-5-修改cobbler配置文件" class="headerlink" title="2.5 修改cobbler配置文件"></a>2.5 修改cobbler配置文件</h3><h4 id="2-5-1-修改server和next-server参数"><a href="#2-5-1-修改server和next-server参数" class="headerlink" title="2.5.1 修改server和next_server参数"></a>2.5.1 修改server和next_server参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/cobbler/settings</span></span><br><span class="line">将server: 127.0.0.1修改为server: 192.168.100.2</span><br><span class="line">将next_server: 127.0.0.1修改为next_server: 192.168.100.2</span><br></pre></td></tr></table></figure>

<p>这里的192.168.100.2为当前节点IP</p>
<h4 id="2-5-2-修改default-password-crypted参数"><a href="#2-5-2-修改default-password-crypted参数" class="headerlink" title="2.5.2 修改default_password_crypted参数"></a>2.5.2 修改default_password_crypted参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># openssl passwd -1 -salt &#x27;passwd&#x27; &#x27;123456&#x27;</span></span><br><span class="line">$1$passwd<span class="variable">$h</span>/du.ylwCiLuPa1Br.Ho2.</span><br></pre></td></tr></table></figure>

<p>这里的123456设置的是默认密码<br>将得到的结果替换default_password_crypted的参数<br>例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/cobbler/settings</span></span><br><span class="line">default_password_crypred: <span class="string">&quot;$1$passwd<span class="variable">$h</span>/du.ylwCiLuPa1Br.Ho2.&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="2-5-3-开启管理DHCP"><a href="#2-5-3-开启管理DHCP" class="headerlink" title="2.5.3 开启管理DHCP"></a>2.5.3 开启管理DHCP</h4><p># vi /etc/cobbler/settings<br>将manage_dhcp参数改为1<br>将pxe_just_once参数改为1<br>修改DHCP模板</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/cobbler/dhcp.template</span></span><br><span class="line">subnet 192.168.100.0 netmask 255.255.255.0 &#123;</span><br><span class="line">     option routers             192.168.100.1;</span><br><span class="line">     option domain-name-servers 114.114.114.114;</span><br><span class="line">     option subnet-mask         255.255.255.0;</span><br><span class="line">     range dynamic-bootp        192.168.100.10 192.168.100.200;</span><br><span class="line">     default-lease-time         21600;</span><br><span class="line">     max-lease-time             43200;</span><br><span class="line">     next-server                <span class="variable">$next_server</span>;</span><br></pre></td></tr></table></figure>

<h3 id="2-6-启用tftp"><a href="#2-6-启用tftp" class="headerlink" title="2.6 启用tftp"></a>2.6 启用tftp</h3><p>将/etc/xinetd.d/tftp的disable选项改为no</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/xinetd.d/tftp</span></span><br><span class="line"><span class="built_in">disable</span> = no</span><br></pre></td></tr></table></figure>

<h3 id="2-7-启动相关服务"><a href="#2-7-启动相关服务" class="headerlink" title="2.7 启动相关服务"></a>2.7 启动相关服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl start httpd rsyncd tftp cobblerd</span></span><br><span class="line"><span class="comment"># systemctl enable httpd rsyncd tftp cobblerd</span></span><br></pre></td></tr></table></figure>

<h3 id="2-8-检查cobbler"><a href="#2-8-检查cobbler" class="headerlink" title="2.8 检查cobbler"></a>2.8 检查cobbler</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cobbler check</span></span><br><span class="line">The following are potential configuration items that you may want to fix:</span><br><span class="line">1 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run <span class="string">&#x27;cobbler get-loaders&#x27;</span> to download them, or, <span class="keyword">if</span> you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely.  Files <span class="keyword">in</span> this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The <span class="string">&#x27;cobbler get-loaders&#x27;</span> <span class="built_in">command</span> is the easiest way to resolve these requirements.</span><br><span class="line">2 : debmirror package is not installed, it will be required to manage debian deployments and repositories</span><br><span class="line">3 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them</span><br><span class="line">Restart cobblerd and <span class="keyword">then</span> run <span class="string">&#x27;cobbler sync&#x27;</span> to apply changes.</span><br></pre></td></tr></table></figure>

<h3 id="2-9-修复上述检查出的问题1，其中问题2、3可以忽略"><a href="#2-9-修复上述检查出的问题1，其中问题2、3可以忽略" class="headerlink" title="2.9 修复上述检查出的问题1，其中问题2、3可以忽略"></a>2.9 修复上述检查出的问题1，其中问题2、3可以忽略</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cobbler get-loaders</span></span><br><span class="line">task started: 2018-12-12_110817_get_loaders</span><br><span class="line">task started (id=Download Bootloader Content, time=Wed Dec 12 11:08:17 2018)</span><br><span class="line">downloading https://cobbler.github.io/loaders/README to /var/lib/cobbler/loaders/README</span><br><span class="line">downloading https://cobbler.github.io/loaders/COPYING.elilo to /var/lib/cobbler/loaders/COPYING.elilo</span><br><span class="line">downloading https://cobbler.github.io/loaders/COPYING.yaboot to /var/lib/cobbler/loaders/COPYING.yaboot</span><br><span class="line">downloading https://cobbler.github.io/loaders/COPYING.syslinux to /var/lib/cobbler/loaders/COPYING.syslinux</span><br><span class="line">downloading https://cobbler.github.io/loaders/elilo-3.8-ia64.efi to /var/lib/cobbler/loaders/elilo-ia64.efi</span><br><span class="line">downloading https://cobbler.github.io/loaders/yaboot-1.3.17 to /var/lib/cobbler/loaders/yaboot</span><br><span class="line">downloading https://cobbler.github.io/loaders/pxelinux.0-3.86 to /var/lib/cobbler/loaders/pxelinux.0</span><br><span class="line">downloading https://cobbler.github.io/loaders/menu.c32-3.86 to /var/lib/cobbler/loaders/menu.c32</span><br><span class="line">downloading https://cobbler.github.io/loaders/grub-0.97-x86.efi to /var/lib/cobbler/loaders/grub-x86.efi</span><br><span class="line">downloading https://cobbler.github.io/loaders/grub-0.97-x86_64.efi to /var/lib/cobbler/loaders/grub-x86_64.efi</span><br><span class="line">*** TASK COMPLETE ***</span><br></pre></td></tr></table></figure>

<h3 id="2-10-重启cobblerd服务，并进行同步"><a href="#2-10-重启cobblerd服务，并进行同步" class="headerlink" title="2.10 重启cobblerd服务，并进行同步"></a>2.10 重启cobblerd服务，并进行同步</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl restart cobblerd</span></span><br><span class="line"><span class="comment"># cobbler sync</span></span><br><span class="line">task started: 2018-12-12_110924_sync</span><br><span class="line">task started (id=Sync, time=Wed Dec 12 11:09:24 2018)</span><br><span class="line">running pre-sync triggers</span><br><span class="line">cleaning trees</span><br><span class="line">removing: /var/lib/tftpboot/grub/images</span><br><span class="line">copying bootloaders</span><br><span class="line">trying hardlink /var/lib/cobbler/loaders/pxelinux.0 -&gt; /var/lib/tftpboot/pxelinux.0</span><br><span class="line">trying hardlink /var/lib/cobbler/loaders/menu.c32 -&gt; /var/lib/tftpboot/menu.c32</span><br><span class="line">trying hardlink /var/lib/cobbler/loaders/yaboot -&gt; /var/lib/tftpboot/yaboot</span><br><span class="line">trying hardlink /usr/share/syslinux/memdisk -&gt; /var/lib/tftpboot/memdisk</span><br><span class="line">trying hardlink /var/lib/cobbler/loaders/grub-x86.efi -&gt; /var/lib/tftpboot/grub/grub-x86.efi</span><br><span class="line">trying hardlink /var/lib/cobbler/loaders/grub-x86_64.efi -&gt; /var/lib/tftpboot/grub/grub-x86_64.efi</span><br><span class="line">copying distros to tftpboot</span><br><span class="line">copying images</span><br><span class="line">generating PXE configuration files</span><br><span class="line">generating PXE menu structure</span><br><span class="line">rendering DHCP files</span><br><span class="line">generating /etc/dhcp/dhcpd.conf</span><br><span class="line">rendering TFTPD files</span><br><span class="line">generating /etc/xinetd.d/tftp</span><br><span class="line">cleaning link caches</span><br><span class="line">running post-sync triggers</span><br><span class="line">running python triggers from /var/lib/cobbler/triggers/sync/post/*</span><br><span class="line">running python trigger cobbler.modules.sync_post_restart_services</span><br><span class="line">running: dhcpd -t -q</span><br><span class="line">received on stdout:</span><br><span class="line">received on stderr:</span><br><span class="line">running: service dhcpd restart</span><br><span class="line">received on stdout:</span><br><span class="line">received on stderr: Redirecting to /bin/systemctl restart dhcpd.service</span><br><span class="line">running shell triggers from /var/lib/cobbler/triggers/sync/post/*</span><br><span class="line">running python triggers from /var/lib/cobbler/triggers/change/*</span><br><span class="line">running python trigger cobbler.modules.scm_track</span><br><span class="line">running shell triggers from /var/lib/cobbler/triggers/change/*</span><br><span class="line">*** TASK COMPLETE ***</span><br></pre></td></tr></table></figure>

<h3 id="2-11-再次检查cobbler"><a href="#2-11-再次检查cobbler" class="headerlink" title="2.11 再次检查cobbler"></a>2.11 再次检查cobbler</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cobbler check</span></span><br><span class="line">The following are potential configuration items that you may want to fix:</span><br><span class="line">1 : debmirror package is not installed, it will be required to manage debian deployments and repositories</span><br><span class="line">2 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them</span><br><span class="line">Restart cobblerd and <span class="keyword">then</span> run <span class="string">&#x27;cobbler sync&#x27;</span> to apply changes.</span><br></pre></td></tr></table></figure>

<p>刚刚的问题1已经解决了</p>
<h2 id="3-安装CentOS7-5系统"><a href="#3-安装CentOS7-5系统" class="headerlink" title="3 安装CentOS7.5系统"></a>3 安装CentOS7.5系统</h2><h3 id="3-1-挂载CentOS7-5镜像文件"><a href="#3-1-挂载CentOS7-5镜像文件" class="headerlink" title="3.1 挂载CentOS7.5镜像文件"></a>3.1 挂载CentOS7.5镜像文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir /mnt/CentOS7.5</span></span><br><span class="line"><span class="comment"># mount CentOS-7-x86_64-DVD-1804.iso /mnt/CentOS7.5/</span></span><br></pre></td></tr></table></figure>

<h3 id="3-2-导入镜像"><a href="#3-2-导入镜像" class="headerlink" title="3.2 导入镜像"></a>3.2 导入镜像</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  cobbler import --path=/mnt/CentOS7.5 --name=CentOS7.5 --arch=x86_64</span></span><br><span class="line">task started: 2018-12-12_111742_import</span><br><span class="line">task started (id=Media import, time=Wed Dec 12 11:17:42 2018)</span><br><span class="line">Found a candidate signature: breed=redhat, version=rhel6</span><br><span class="line">Found a candidate signature: breed=redhat, version=rhel7</span><br><span class="line">Found a matching signature: breed=redhat, version=rhel7</span><br><span class="line">Adding distros from path /var/www/cobbler/ks_mirror/CentOS7.5-x86_64:</span><br><span class="line">creating new distro: CentOS7.5-x86_64</span><br><span class="line">trying symlink: /var/www/cobbler/ks_mirror/CentOS7.5-x86_64 -&gt; /var/www/cobbler/links/CentOS7.5-x86_64</span><br><span class="line">creating new profile: CentOS7.5-x86_64</span><br><span class="line">associating repos</span><br><span class="line">checking <span class="keyword">for</span> rsync repo(s)</span><br><span class="line">checking <span class="keyword">for</span> rhn repo(s)</span><br><span class="line">checking <span class="keyword">for</span> yum repo(s)</span><br><span class="line">starting descent into /var/www/cobbler/ks_mirror/CentOS7.5-x86_64 <span class="keyword">for</span> CentOS7.5-x86_64</span><br><span class="line">processing repo at : /var/www/cobbler/ks_mirror/CentOS7.5-x86_64</span><br><span class="line">need to process repo/comps: /var/www/cobbler/ks_mirror/CentOS7.5-x86_64</span><br><span class="line">looking <span class="keyword">for</span> /var/www/cobbler/ks_mirror/CentOS7.5-x86_64/repodata/*comps*.xml</span><br><span class="line">Keeping repodata as-is :/var/www/cobbler/ks_mirror/CentOS7.5-x86_64/repodata</span><br><span class="line">*** TASK COMPLETE ***</span><br></pre></td></tr></table></figure>

<h3 id="3-3-查看镜像列表"><a href="#3-3-查看镜像列表" class="headerlink" title="3.3 查看镜像列表"></a>3.3 查看镜像列表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cobbler distro list</span><br><span class="line">   CentOS7.5-x86_64</span><br><span class="line"># cobbler profile list</span><br><span class="line">   CentOS7.5-x86_64</span><br></pre></td></tr></table></figure>

<h3 id="3-4-创建一台空的虚拟机，不挂载CD-DVD光盘镜像，并启动"><a href="#3-4-创建一台空的虚拟机，不挂载CD-DVD光盘镜像，并启动" class="headerlink" title="3.4 创建一台空的虚拟机，不挂载CD/DVD光盘镜像，并启动"></a>3.4 创建一台空的虚拟机，不挂载CD/DVD光盘镜像，并启动</h3><p>虚拟机内存必须大于等于2G，启动后，会自动获取IP地址。</p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/vm-boot.png" alt="vm-boot"></p>
<h3 id="3-5-选择CentOS7-5-x86-64，开始自动化安装CentOS7-5系统"><a href="#3-5-选择CentOS7-5-x86-64，开始自动化安装CentOS7-5系统" class="headerlink" title="3.5 选择CentOS7.5-x86_64，开始自动化安装CentOS7.5系统"></a>3.5 选择CentOS7.5-x86_64，开始自动化安装CentOS7.5系统</h3><p>选择CentOS7.5-x86_64后，虚拟机会自动安装CentOS7.5系统，自动分区磁盘，并设置好root密码，密码为前面设置的123456</p>
<h3 id="3-6-登录CentOS7-5系统"><a href="#3-6-登录CentOS7-5系统" class="headerlink" title="3.6 登录CentOS7.5系统"></a>3.6 登录CentOS7.5系统</h3><p>安装完后的用户名密码为 root：123456</p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/vm-console.png" alt="vm-console"></p>
<h3 id="3-7-自己手写ks文件"><a href="#3-7-自己手写ks文件" class="headerlink" title="3.7 自己手写ks文件"></a>3.7 自己手写ks文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi ks-centos7.5.cfs</span></span><br><span class="line">install</span><br><span class="line">keyboard <span class="string">&#x27;us&#x27;</span></span><br><span class="line">rootpw --iscrypted <span class="variable">$default_password_crypted</span></span><br><span class="line">timezone Asia/Shanghai</span><br><span class="line">url --url=<span class="variable">$tree</span></span><br><span class="line">lang en_US</span><br><span class="line">firewall --disabled</span><br><span class="line">auth  --useshadow  --passalgo=sha512</span><br><span class="line">text</span><br><span class="line">selinux --disabled</span><br><span class="line">skipx</span><br><span class="line">network  --bootproto=dhcp --device=eth0</span><br><span class="line">network  --hostname=xzq</span><br><span class="line">reboot</span><br><span class="line">bootloader --location=mbr</span><br><span class="line">zerombr</span><br><span class="line">clearpart --all --initlabel</span><br><span class="line">part /boot --asprimary --fstype=<span class="string">&quot;xfs&quot;</span> --size=1024</span><br><span class="line">part swap --fstype=<span class="string">&quot;swap&quot;</span> --recommended</span><br><span class="line">part / --fstype=<span class="string">&quot;xfs&quot;</span> --grow --size=1</span><br><span class="line">%packages</span><br><span class="line">@^minimal</span><br><span class="line">@core</span><br><span class="line">@compat-libraries</span><br><span class="line">@debugging</span><br><span class="line">@development</span><br><span class="line">tree</span><br><span class="line">nmap</span><br><span class="line">sysstat</span><br><span class="line">lrzsz</span><br><span class="line">dos2unix</span><br><span class="line">telnet</span><br><span class="line">wget</span><br><span class="line">vim</span><br><span class="line">net-tools</span><br><span class="line">bash-completion</span><br><span class="line">%end</span><br><span class="line">%post</span><br><span class="line">systemctl <span class="built_in">disable</span> postfix.service  </span><br><span class="line">%end</span><br></pre></td></tr></table></figure>

<h3 id="3-8-复制ks文件到cobbler目录下"><a href="#3-8-复制ks文件到cobbler目录下" class="headerlink" title="3.8 复制ks文件到cobbler目录下"></a>3.8 复制ks文件到cobbler目录下</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cp ks-centos7.5.cfg /var/lib/cobbler/kickstarts/.</span></span><br></pre></td></tr></table></figure>

<h3 id="3-9-指定CentOS7-5的ks文件"><a href="#3-9-指定CentOS7-5的ks文件" class="headerlink" title="3.9 指定CentOS7.5的ks文件"></a>3.9 指定CentOS7.5的ks文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cobbler profile edit --name=Centos-7.5-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks-centos7.5.cfg</span></span><br><span class="line"><span class="comment"># cobbler profile report</span></span><br></pre></td></tr></table></figure>

<h3 id="3-10-创建CentOS7-5虚拟机"><a href="#3-10-创建CentOS7-5虚拟机" class="headerlink" title="3.10 创建CentOS7.5虚拟机"></a>3.10 创建CentOS7.5虚拟机</h3><p>重复3.4-3.6的操作即可</p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/vm-boot2.png" alt="vm-boot2"></p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/vm-console2.png" alt="vm-console2"></p>
<h2 id="4-安装Windows7系统"><a href="#4-安装Windows7系统" class="headerlink" title="4 安装Windows7系统"></a>4 安装Windows7系统</h2><h3 id="4-1-定制Win-PE"><a href="#4-1-定制Win-PE" class="headerlink" title="4.1 定制Win PE"></a>4.1 定制Win PE</h3><p>使用Windows AIK（适用于win7的）工具来定制Win PE<br>去Microsoft官网下载ISO包</p>
<h4 id="4-1-1-需要在个人电脑上下载安装AIK，具体如下"><a href="#4-1-1-需要在个人电脑上下载安装AIK，具体如下" class="headerlink" title="4.1.1 需要在个人电脑上下载安装AIK，具体如下"></a>4.1.1 需要在个人电脑上下载安装AIK，具体如下</h4><p>解压AIK包</p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-1.png" alt="win-1"></p>
<h4 id="4-1-2-进入解压后的目录，双击StartCD-exe，点击Windows-AIK安装程序-开始安装"><a href="#4-1-2-进入解压后的目录，双击StartCD-exe，点击Windows-AIK安装程序-开始安装" class="headerlink" title="4.1.2 进入解压后的目录，双击StartCD.exe，点击Windows AIK安装程序 开始安装"></a>4.1.2 进入解压后的目录，双击StartCD.exe，点击Windows AIK安装程序 开始安装</h4><p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-2.png" alt="win-2"></p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-3.png" alt="win-3"></p>
<h4 id="4-1-3-安装完毕后，启动这个工具来定制Win-PE镜像"><a href="#4-1-3-安装完毕后，启动这个工具来定制Win-PE镜像" class="headerlink" title="4.1.3 安装完毕后，启动这个工具来定制Win PE镜像"></a>4.1.3 安装完毕后，启动这个工具来定制Win PE镜像</h4><p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-4.png" alt="win-4"></p>
<h4 id="4-1-4-通过命令行制作Win-PE镜像"><a href="#4-1-4-通过命令行制作Win-PE镜像" class="headerlink" title="4.1.4 通过命令行制作Win PE镜像"></a>4.1.4 通过命令行制作Win PE镜像</h4><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 进入一个盘，例如这里进入E盘</span></span><br><span class="line">C:\Program Files\Windows AIK\Tools\PETools&gt; E:</span><br><span class="line"><span class="comment">## 生成Win PE预安装文件</span></span><br><span class="line">E:\&gt; copype amd64 E:\winpe</span><br><span class="line"><span class="comment">## 挂载成可读写形式</span></span><br><span class="line">E:\&gt; imagex /mountrw E:\winpe\winpe.wim <span class="number">1</span> E:\winpe\mount</span><br><span class="line"><span class="comment">## 制作start脚本</span></span><br><span class="line">E:\&gt; <span class="built_in">echo</span> ping <span class="literal">-n</span> <span class="number">7</span> <span class="literal">-l</span> <span class="number">69</span> <span class="number">192.168</span>.<span class="number">100.2</span> &gt;&gt; E:\winpe\mount\Windows\System32\startnet.cmd</span><br><span class="line">E:\&gt; <span class="built_in">echo</span> net use Z: \\<span class="number">192.168</span>.<span class="number">100.2</span>\share &gt;&gt; E:\winpe\mount\Windows\System32\startnet.cmd</span><br><span class="line">E:\&gt; <span class="built_in">echo</span> Z: &gt;&gt; E:\winpe\mount\Windows\System32\startnet.cmd</span><br><span class="line">E:\&gt; <span class="built_in">echo</span> <span class="built_in">cd</span> win &gt;&gt; E:\winpe\mount\Windows\System32\startnet.cmd</span><br><span class="line">E:\&gt; <span class="built_in">echo</span> setup.exe /unattend:Autounattend.xml &gt;&gt; E:\winpe\mount\Windows\System32\startnet.cmd</span><br><span class="line"><span class="comment">## 卸载</span></span><br><span class="line">E:\&gt; imagex /unmount c:\winpe\mount /commit</span><br><span class="line"><span class="comment">## 复制启动文件</span></span><br><span class="line">E:\&gt; <span class="built_in">copy</span> E:\winpe\winpe.wim E:\winpe\ISO\sources\boot.wim</span><br><span class="line"><span class="comment">## 生成Win PE ISO镜像</span></span><br><span class="line">E:\&gt; oscdimg <span class="literal">-n</span> <span class="literal">-bE</span>:\\winpe\etfsboot.com E:\winpe\ISO E:\\winpe\winpe_cobbler_amd64.iso</span><br></pre></td></tr></table></figure>

<h3 id="4-2-导入ISO镜像"><a href="#4-2-导入ISO镜像" class="headerlink" title="4.2 导入ISO镜像"></a>4.2 导入ISO镜像</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cobbler distro add --name=windows7 --kernel=/var/lib/tftpboot/memdisk --initrd=/root/winpe_cobbler_amd64.iso --kopts=&quot;raw iso&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-3-配置ISO镜像的无人值守安装文件"><a href="#4-3-配置ISO镜像的无人值守安装文件" class="headerlink" title="4.3 配置ISO镜像的无人值守安装文件"></a>4.3 配置ISO镜像的无人值守安装文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># touch /var/lib/cobbler/kickstarts/win7pe.xml</span></span><br><span class="line"><span class="comment">#cobbler profile add --name=windows7 --distro=windows7 --kickstart=/var/lib/cobbler/kickstarts/win7pe.xml</span></span><br></pre></td></tr></table></figure>

<h3 id="4-4-安装Samba服务"><a href="#4-4-安装Samba服务" class="headerlink" title="4.4 安装Samba服务"></a>4.4 安装Samba服务</h3><h4 id="4-4-1-安装Samba软件包"><a href="#4-4-1-安装Samba软件包" class="headerlink" title="4.4.1 安装Samba软件包"></a>4.4.1 安装Samba软件包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum install samba -y</span></span><br></pre></td></tr></table></figure>

<h4 id="4-4-2-配置Samba文件"><a href="#4-4-2-配置Samba文件" class="headerlink" title="4.4.2 配置Samba文件"></a>4.4.2 配置Samba文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/samba/smb.conf</span></span><br><span class="line">[global]</span><br><span class="line">        map to guest = Bad User</span><br><span class="line">[share]</span><br><span class="line">        comment = share directory</span><br><span class="line">        path = /smb/</span><br><span class="line">        directory mask = 0755</span><br><span class="line">        create mask = 0755</span><br><span class="line">        guest ok = yes</span><br><span class="line">        writable = yes</span><br></pre></td></tr></table></figure>

<h4 id="4-4-3-配置win7共享文件夹"><a href="#4-4-3-配置win7共享文件夹" class="headerlink" title="4.4.3 配置win7共享文件夹"></a>4.4.3 配置win7共享文件夹</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mkdir -p /smb/win</span></span><br><span class="line"><span class="comment"># mkdir /mnt/win7</span></span><br><span class="line"><span class="comment"># mount /root/cn_windows_7_ultimate_with_sp1_x64_dvd_u_677408.iso /mnt/win7</span></span><br><span class="line"><span class="comment"># cp -rf /mnt/win7/* /smb/win/.</span></span><br></pre></td></tr></table></figure>

<h4 id="4-4-4-启动Samba服务"><a href="#4-4-4-启动Samba服务" class="headerlink" title="4.4.4 启动Samba服务"></a>4.4.4 启动Samba服务</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl start smb</span></span><br><span class="line"><span class="comment"># systemctl enable smb</span></span><br></pre></td></tr></table></figure>

<h4 id="4-4-5-验证smb能否访问"><a href="#4-4-5-验证smb能否访问" class="headerlink" title="4.4.5 验证smb能否访问"></a>4.4.5 验证smb能否访问</h4><p>打开\192.168.100.2，看看能否访问</p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-smb.png" alt="win-smb"></p>
<h3 id="4-5-添加Autounattend-xml文件到-smb-win-下"><a href="#4-5-添加Autounattend-xml文件到-smb-win-下" class="headerlink" title="4.5 添加Autounattend.xml文件到/smb/win/下"></a>4.5 添加Autounattend.xml文件到/smb/win/下</h3><p>将Autounattend.xml自动值守安装文件添加到Samba共享目录下<br>这个文件可以自己制作，我这边已经写好了一个，需要的可以参考<a href="https://pan.baidu.com/s/1WaDHshXauSJx9NiSqvbfLw">https://pan.baidu.com/s/1WaDHshXauSJx9NiSqvbfLw</a></p>
<h3 id="4-6-创建一台空的虚拟机，不挂载CD-DVD光盘镜像，并启动"><a href="#4-6-创建一台空的虚拟机，不挂载CD-DVD光盘镜像，并启动" class="headerlink" title="4.6 创建一台空的虚拟机，不挂载CD/DVD光盘镜像，并启动"></a>4.6 创建一台空的虚拟机，不挂载CD/DVD光盘镜像，并启动</h3><p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/vm-win-boot.png" alt="vm-win-boot"></p>
<h3 id="4-7-选择Windows7进行安装"><a href="#4-7-选择Windows7进行安装" class="headerlink" title="4.7 选择Windows7进行安装"></a>4.7 选择Windows7进行安装</h3><p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-install-1.png" alt="win-install-1"></p>
<p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-install-2.png" alt="win-install-2"></p>
<h3 id="4-8-等待安装完毕即可进入系统"><a href="#4-8-等待安装完毕即可进入系统" class="headerlink" title="4.8 等待安装完毕即可进入系统"></a>4.8 等待安装完毕即可进入系统</h3><p><img src="/images/mk/cobbler%E8%87%AA%E5%8A%A8%E5%8C%96/win-install-3.png" alt="win-install-3"></p>
<h2 id="5-遇到的问题"><a href="#5-遇到的问题" class="headerlink" title="5 遇到的问题"></a>5 遇到的问题</h2><h3 id="环境中已有DHCP服务"><a href="#环境中已有DHCP服务" class="headerlink" title="环境中已有DHCP服务"></a>环境中已有DHCP服务</h3><p>在大部分网络环境中都会已经有一个dhcp服务了，如果要在这样的网络环境中构筑pxe就需要dhcp proxy（就近选择原理）<br>在CentOS上可以安装dnsmasq服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">首先关闭cobbler的dhcp设置</span><br><span class="line"><span class="comment"># vi /etc/cobbler/settings</span></span><br><span class="line">将manage_dhcp参数改为0</span><br><span class="line">接着配置dnsmasq</span><br><span class="line">[root@localhost ~]<span class="comment"># yum install dnsmasq -y</span></span><br><span class="line">[root@localhost ~]<span class="comment"># vi /etc/dnsmasq.d/dhcp</span></span><br><span class="line">port=0   <span class="comment">#禁用DNS端口</span></span><br><span class="line">dhcp-range=192.168.100.0,proxy  <span class="comment">#当前所在网段</span></span><br><span class="line">dhcp-boot=pxelinux.0</span><br><span class="line">pxe-service=x86PC,<span class="string">&#x27;Cobbler-Install&#x27;</span>,pxelinux</span><br><span class="line">[root@localhost ~]<span class="comment"># systemctl start dnsmasq</span></span><br><span class="line">[root@localhost ~]<span class="comment"># systemctl enable dnsmasq</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>Ubuntu系统试了能成，自动化模板cobbler也有提供，其他的没试，理论上也是可以的<br>Windows部署参考链接：<a href="https://www.cnblogs.com/pluse/p/8508538.html">https://www.cnblogs.com/pluse/p/8508538.html</a></p>
</blockquote>
]]></content>
      <categories>
        <category>cobbler</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>cobbler</tag>
      </tags>
  </entry>
  <entry>
    <title>CoreDNS不断重启问题排查</title>
    <url>/2021/08/12/CoreDNS%E4%B8%8D%E6%96%AD%E9%87%8D%E5%90%AF%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<h2 id="问题概述"><a href="#问题概述" class="headerlink" title="问题概述"></a>问题概述</h2><p>客户反馈CoreDNS不断报错重启，pod报错日志如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.:53</span><br><span class="line">[INFO] plugin/reload: Running configuration MD5 = 801a899438c9341e1de6cf893d986920</span><br><span class="line">CoreDNS-1.6.9</span><br><span class="line">linux/amd64, go1.14.1, 1766568</span><br><span class="line">[FATAL] plugin/loop: Loop (127.0.0.1:40650 -&gt; :53) detected <span class="keyword">for</span> zone <span class="string">&quot;.&quot;</span>, see https://coredns.io/plugins/loop<span class="comment">#troubleshooting. Query: &quot;HINFO 5862268011232388643.388723831076506841.&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/CoreDNS%E4%B8%8D%E6%96%AD%E9%87%8D%E5%90%AF%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5.assets/log-1.png" alt="log-1"></p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>根据报错我们可以看到，coredns抛出了一个致命的日志，coredns的loop插件检测到上游DNS服务器的无限转发循环，无限转发循环会不断的消耗内存和 CPU，直到主机最终因内存不足而死亡。</p>
<p>转发循环一般是CoreDNS将请求转发给自身导致的，例如<code>127.0.0.1</code>，<code>::1</code>或<code>127.0.0.53</code></p>
<p>这种报错一般发生在Ubuntu操作系统上，由于Ubuntu操作系统会启动<code>systemd-resolved</code>服务管理DNS系统进行DNS缓存，此时会将主机的/etc/resolv.conf文件配置成127.0.0.53的地址。coredns会拿这个配置进行转发，最终导致无限转发的情况。</p>
<h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>有几种解决方法：</p>
<h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><ol>
<li>禁用<code>systemd-resolved</code>服务，并手动配置<code>/etc/resolv.conf</code></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> systemd-resolved.service </span><br><span class="line">systemctl stop systemd-resolved.service </span><br><span class="line">mv /etc/resolv.conf /opt</span><br><span class="line"><span class="built_in">echo</span> nameserver 114.114.114.114 &gt;&gt; /etc/resolv.conf</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>由于coredns会去拿kubelet的resolv.conf，而rancher的k8s组件是容器运行的，也就是说kubelet是容器运行，所以需要重启一下kubelet容器去让kubelet拿主机的resolv.conf文件配置（其他k8s集群可以不用这个操作）</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker restart kubelet</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>重启coredns即可</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system delete pods -l k8s-app=kube-dns </span><br></pre></td></tr></table></figure>



<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>如果因为某些原因暂时无法禁用<code>systemd-resolved</code>服务，可以先修改Corefile配置，该配置在kube-system命名空间的<code>coredns</code> configmap下，将<code>forward . /etc/resolv.conf</code>替换成DNS服务器的地址，例如替换成<code>forward . 114.114.114.114</code>，完成配置参考如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.:53 &#123;</span><br><span class="line">    log</span><br><span class="line">    errors</span><br><span class="line">    health &#123;</span><br><span class="line">      lameduck 5s</span><br><span class="line">    &#125;</span><br><span class="line">    ready</span><br><span class="line">    kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">      pods insecure</span><br><span class="line">      fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">    &#125;</span><br><span class="line">    prometheus :9153</span><br><span class="line">    forward . 114.114.114.114</span><br><span class="line">    cache 30</span><br><span class="line">    loop</span><br><span class="line">    reload</span><br><span class="line">    loadbalance</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p>参考：<a href="https://coredns.io/plugins/loop/#troubleshooting">https://coredns.io/plugins/loop/#troubleshooting</a></p>
</blockquote>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>coredns</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker使用Devicemapper存储驱动异常处理</title>
    <url>/2020/04/30/Docker%E4%BD%BF%E7%94%A8Devicemapper%E5%AD%98%E5%82%A8%E9%A9%B1%E5%8A%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>集群的一个节点NotReady，kubelet报错PLEG，查看docker日志，可以看到如下的报错，停止docker服务，响应的容器进程还在进行，无法umount相关的设备。<br><img src="/images/mk/docker_use_devicemapper_error/error.png" alt="error"></p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>这个问题发生在使用 devicemapper 存储驱动时Docker试图重用之前使用 LVM thin pool。例如，尝试更改节点上的 Docker 的数据目录时会发生此问题。由于安全措施旨在防止 Docker 因配置问题而意外使用和覆盖 LVM thin pool 中的数据，因此会发生此错误。</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><ol>
<li>停止docker服务<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure></li>
<li>备份Docker目录<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv /var/lib/docker&#123;,.bak&#125;</span><br></pre></td></tr></table></figure></li>
<li>删除已经创建的thinpool逻辑卷<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lvremove docker/thinpool</span><br></pre></td></tr></table></figure></li>
<li>创建新的逻辑卷<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lvcreater -L 100g --thin docker/thinpool</span><br></pre></td></tr></table></figure>
根据实际磁盘大小设置</li>
<li>编辑/etc/docker/daemon.json配置文件，添加<code>dm.directlvm_device_force=true</code>参数<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;storage-driver&quot;</span>: <span class="string">&quot;devicemapper&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;storage-opts&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;dm.directlvm_device_force=true&quot;</span>     ## 添加此参数</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>最后启动docker服务即可<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Harbor-1.7.5版本安装，升级至1.8.6，回滚到1.7.5</title>
    <url>/2020/07/30/Harbor-1-7-5%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85%EF%BC%8C%E5%8D%87%E7%BA%A7%E8%87%B31-8-6%EF%BC%8C%E5%9B%9E%E6%BB%9A%E5%88%B01-7-5/</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>帮客户验证，所以使用跟客户相同的版本：v1.7.5</p>
<p>安装包地址：<a href="https://github.com/goharbor/harbor/releases/tag/v1.7.5">https://github.com/goharbor/harbor/releases/tag/v1.7.5</a></p>
<ol>
<li>下载安装包，并解压。如果是离线环境，可以下载 offline 安装包</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/harbor/1.7.5</span><br><span class="line"><span class="built_in">cd</span> /root/harbor/1.7.5</span><br><span class="line">wget https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.5.tgz</span><br><span class="line">tar -zxvf harbor-offline-installer-v1.7.5.tgz</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>编辑harbor.cfg配置文件，修改以下配置</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/harbor/<span class="number">1.7</span>.<span class="number">5</span>/harbor</span><br><span class="line"></span><br><span class="line">vi harbor.cfg</span><br><span class="line"><span class="comment">## 1.修改访问域名</span></span><br><span class="line">hostname = harbor.chin.com</span><br><span class="line"></span><br><span class="line"><span class="comment">## 2. 使用https协议</span></span><br><span class="line">ui_url_protocol = https</span><br><span class="line"></span><br><span class="line"><span class="comment">## 其他常用的配置，我这里没有修改</span></span><br><span class="line">ssl_cert = /<span class="keyword">data</span>/cert/server.crt</span><br><span class="line">ssl_cert_key = /<span class="keyword">data</span>/cert/server.key</span><br><span class="line"></span><br><span class="line">secretkey_path = /<span class="keyword">data</span></span><br><span class="line"></span><br><span class="line">harbor_admin_password = Harbor12345</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>生成自签名证书，并复制到/data/cert目录下</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /root/harbor/1.7.5/harbor/ssl</span><br><span class="line"><span class="built_in">cd</span> /root/harbor/1.7.5/harbor/ssl</span><br><span class="line"><span class="comment">## 生成CA秘钥和CA证书</span></span><br><span class="line">openssl genrsa -out ca.key 4096</span><br><span class="line">openssl req -x509 -new -nodes -sha512 -days 3650  -subj <span class="string">&quot;/C=CN/ST=GD/L=SZ/O=chin/OU=chin/CN=chin.ca&quot;</span>  -key ca.key -out ca.crt</span><br><span class="line"></span><br><span class="line"><span class="comment">## 这里如果报Can&#x27;t load /root/.rnd into RNG这个错，执行这个生成rnd文件</span></span><br><span class="line"><span class="comment"># openssl rand -writerand /root/.rnd</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 生成服务器证书</span></span><br><span class="line">openssl genrsa -out harbor.chin.com.key 4096</span><br><span class="line"></span><br><span class="line">openssl req -sha512 -new     -subj <span class="string">&quot;/C=CN/ST=GD/L=SZ/O=chin/OU=chin/CN=harbor.chin.com&quot;</span> -key harbor.chin.com.key -out harbor.chin.com.csr</span><br><span class="line"></span><br><span class="line">cat &gt; v3.ext &lt;&lt;-<span class="string">EOF</span></span><br><span class="line"><span class="string">authorityKeyIdentifier=keyid,issuer</span></span><br><span class="line"><span class="string">basicConstraints=CA:FALSE</span></span><br><span class="line"><span class="string">keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment</span></span><br><span class="line"><span class="string">extendedKeyUsage = serverAuth</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[alt_names]</span></span><br><span class="line"><span class="string">DNS.1=yourdomain.com</span></span><br><span class="line"><span class="string">DNS.2=yourdomain</span></span><br><span class="line"><span class="string">DNS.3=hostname</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line">openssl x509 -req -sha512 -days 3650 -extfile v3.ext -CA ca.crt -CAkey ca.key -CAcreateserial -<span class="keyword">in</span> harbor.chin.com.csr -out harbor.chin.com.crt</span><br><span class="line"></span><br><span class="line"><span class="comment">##复制证书到/data/cert目录下</span></span><br><span class="line">cp harbor.chin.com.key /data/cert/server.key</span><br><span class="line">cp harbor.chin.com.crt /data/cert/server.crt</span><br></pre></td></tr></table></figure>


<ol start="4">
<li>执行./install.sh脚本自动安装harbor</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/harbor/1.7.5/harbor</span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure>

<p>这里需要用到docker-compose，如果没安装会报错，安装步骤如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/1.26.2/docker-compose-<span class="subst">$(uname -s)</span>-<span class="subst">$(uname -m)</span>&quot;</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">docker-compose --version</span><br></pre></td></tr></table></figure>

<p>安装完成后，重新执行一下./install.sh</p>
<ol start="5">
<li>安装完成后，浏览器访问 <a href="https://harbor.chin.com/">https://harbor.chin.com</a></li>
</ol>
<p>用户名密码：admin/Harbor12345</p>
<ol start="6">
<li>docker使用harbor镜像库</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /etc/docker/daemon.json </span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;insecure-registries&quot;</span>:[<span class="string">&quot;harbor.chin.com&quot;</span>]</span><br><span class="line">&#125;</span><br><span class="line">systemctl restart docker</span><br><span class="line"></span><br><span class="line">docker pull nginx:1.17 </span><br><span class="line">docker tag nginx:1.17 harbor.chin.com/library/nginx:1.17</span><br><span class="line">docker push harbor.chin.com/library/nginx:1.17</span><br></pre></td></tr></table></figure>



<h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><p>根据客户环境，升级至1.8.6版本</p>
<p>地址：<a href="https://github.com/goharbor/harbor/releases/tag/v1.8.6">https://github.com/goharbor/harbor/releases/tag/v1.8.6</a></p>
<ol>
<li>下载安装包，并解压</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p &#x2F;root&#x2F;harbor&#x2F;1.8.6</span><br><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.8.6</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;goharbor&#x2F;harbor&#x2F;releases&#x2F;download&#x2F;v1.8.6&#x2F;harbor-offline-installer-v1.8.6.tgz</span><br><span class="line">tar -zxvf harbor-offline-installer-v1.8.6.tgz</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>停止harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.7.5&#x2F;harbor</span><br><span class="line">docker-compose down</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>备份database</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data</span><br><span class="line">cp -rf database&#x2F;  database-1.7.5</span><br></pre></td></tr></table></figure>



<ol start="4">
<li>迁移harbor配置文件</li>
</ol>
<p>原先的harbor配置文件是harbor.cfg，新版本使用harbor.yml</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -it --rm -v &#x2F;root&#x2F;harbor&#x2F;1.7.5&#x2F;harbor&#x2F;harbor.cfg:&#x2F;harbor-migration&#x2F;harbor-cfg&#x2F;harbor.cfg -v &#x2F;root&#x2F;harbor&#x2F;1.8.6&#x2F;harbor&#x2F;harbor.yml:&#x2F;harbor-migration&#x2F;harbor-cfg-out&#x2F;harbor.yml goharbor&#x2F;harbor-migrator:v1.8.6 --cfg up</span><br></pre></td></tr></table></figure>

<p>迁移完成后，查看harbor.yml配置文件，可以看到相关配置已经自动修改</p>
<ol start="5">
<li>升级harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.8.6&#x2F;harbor</span><br><span class="line">.&#x2F;install.sh</span><br></pre></td></tr></table></figure>

<p>至此升级成功</p>
<h2 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h2><p>版本回滚操作需要升级时备份的数据库文件，如果之前升级没有备份，则回滚失败</p>
<ol>
<li>停止harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.8.6&#x2F;harbor</span><br><span class="line">docker-compose down</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>使用升级时备份的数据库文件</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data</span><br><span class="line">mv database database-bak</span><br><span class="line">mv database-1.7.5 database</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>回滚harbor版本</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.7.5&#x2F;harbor</span><br><span class="line">.&#x2F;install.sh</span><br></pre></td></tr></table></figure>

<p>至此回滚成功</p>
]]></content>
      <categories>
        <category>harbor</category>
      </categories>
      <tags>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title>Harbor1.10.4升级到2.0.1</title>
    <url>/2020/07/30/Harbor1-10-4%E5%8D%87%E7%BA%A7%E5%88%B02-0-1/</url>
    <content><![CDATA[<h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><ol>
<li>下载安装包，并解压</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/harbor/2.0.1</span><br><span class="line"><span class="built_in">cd</span> /root/harbor/2.0.1</span><br><span class="line">wget https://github.com/goharbor/harbor/releases/download/v2.0.1/harbor-offline-installer-v2.0.1.tgz</span><br><span class="line">tar -zxvf harbor-offline-installer-v2.0.1.tgz </span><br></pre></td></tr></table></figure>



<ol start="2">
<li>停止harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.10.4&#x2F;harbor</span><br><span class="line">docker-compose down</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>备份harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data&#x2F;</span><br><span class="line">cp -rf database database-1.10.4-bak</span><br></pre></td></tr></table></figure>



<ol start="4">
<li>迁移harbor配置文件</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;root&#x2F;harbor&#x2F;1.10.4&#x2F;harbor&#x2F;harbor.yml &#x2F;root&#x2F;harbor&#x2F;2.0.1&#x2F;harbor&#x2F;harbor.yml </span><br><span class="line">docker run -it --rm -v &#x2F;:&#x2F;hostfs goharbor&#x2F;prepare:v2.0.1 migrate -i &#x2F;root&#x2F;harbor&#x2F;2.0.1&#x2F;harbor&#x2F;harbor.yml</span><br></pre></td></tr></table></figure>



<ol start="5">
<li>升级harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;2.0.1&#x2F;harbor</span><br><span class="line">.&#x2F;install.sh</span><br></pre></td></tr></table></figure>



<h2 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h2><ol>
<li>停止harbor</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;2.0.1&#x2F;harbor</span><br><span class="line">docker-compose down</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>使用升级时备份的数据库文件</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;data</span><br><span class="line">mv database database-2.0.1-bak</span><br><span class="line">mv database-1.10.4-bak database</span><br></pre></td></tr></table></figure>



<ol start="3">
<li>回滚harbor版本</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;root&#x2F;harbor&#x2F;1.10.4&#x2F;harbor</span><br><span class="line">.&#x2F;install.sh</span><br></pre></td></tr></table></figure>




]]></content>
      <categories>
        <category>harbor</category>
      </categories>
      <tags>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s 1.18.6版本基于 ingress-nginx 实现金丝雀发布（灰度发布）</title>
    <url>/2020/08/10/K8s-1-18-6%E7%89%88%E6%9C%AC%E5%9F%BA%E4%BA%8E-ingress-nginx-%E5%AE%9E%E7%8E%B0%E9%87%91%E4%B8%9D%E9%9B%80%E5%8F%91%E5%B8%83%EF%BC%88%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%EF%BC%89/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>金丝雀发布：又叫灰度发布，控制产品从A版本平滑的过度到B版本</p>
<p>ingress-nginx：k8s ingress工具，支持金丝雀发布，可以实现基于权重、请求头、请求头的值、cookie转发流量。</p>
<p>rancher：k8s集群管理工具，使用UI简化k8s相关操作</p>
<p>ingress-nginx canary官方说明：<a href="https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md#canary">https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md#canary</a></p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>kubernetes</td>
<td>v1.18.6</td>
</tr>
<tr>
<td>nginx-ingress-controller</td>
<td>0.32.0</td>
</tr>
<tr>
<td>Rancher</td>
<td>v2.4.5</td>
</tr>
</tbody></table>
<p>本次实验基于 Rancher-v2.4.5 部署了1.18.6版本的k8s集群，nginx-ingress 版本为0.32.0，理论上 ingress-nginx &gt;= 0.21.0都是可以的。</p>
<p>以下所有的实验，都可以直接在rancher UI上直接配置。</p>
<h2 id="首先创建两个nginx应用"><a href="#首先创建两个nginx应用" class="headerlink" title="首先创建两个nginx应用"></a>首先创建两个nginx应用</h2><ol>
<li>部署两个deployment的http应用</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">appv1</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">zerchin/canary:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">appv2</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">v2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">zerchin/canary:v2</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>kubectl查看pod</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod -o wide |grep app</span></span><br><span class="line">appv1<span class="literal">-77655949f8</span><span class="literal">-hx6nm</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">44</span>m   <span class="number">10.60</span>.<span class="number">0.91</span>   xie<span class="literal">-node001</span>   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">appv2<span class="literal">-7b8659cd88</span><span class="literal">-dgd5c</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">44</span>m   <span class="number">10.60</span>.<span class="number">0.92</span>   xie<span class="literal">-node001</span>   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>

<p>这两个应用输出以下内容</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl 10.60.0.91</span></span><br><span class="line">v1</span><br><span class="line"><span class="comment"># curl 10.60.0.92</span></span><br><span class="line">canary<span class="literal">-v2</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>分别为应用创建对应的service</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">appv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">appv2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">v2</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>kubectl查看service</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># kubectl get svc |grep app</span><br><span class="line">appv1         ClusterIP   10.50.42.17    &lt;none&gt;        80&#x2F;TCP    26m</span><br><span class="line">appv2         ClusterIP   10.50.42.131   &lt;none&gt;        80&#x2F;TCP    26m</span><br></pre></td></tr></table></figure>



<h2 id="部署一个正常的ingress"><a href="#部署一个正常的ingress" class="headerlink" title="部署一个正常的ingress"></a>部署一个正常的ingress</h2><p>现在这个ingress能正常的将访问路由到appv1上</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.zerchin.xyz</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">appv1</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/</span></span><br></pre></td></tr></table></figure>

<p>kubectl查看ingress</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get ingress</span></span><br><span class="line">NAME         <span class="class"><span class="keyword">CLASS</span>    <span class="title">HOSTS</span>               <span class="title">ADDRESS</span>                     <span class="title">PORTS</span>   <span class="title">AGE</span></span></span><br><span class="line"><span class="class"><span class="title">app</span>          &lt;<span class="title">none</span>&gt;   <span class="title">nginx</span>.<span class="title">zerchin</span>.<span class="title">xyz</span>   172.16.0.195,172.16.0.196   80      11<span class="title">m</span></span></span><br></pre></td></tr></table></figure>

<p>访问nginx.zerchin.xyz</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl nginx.zerchin.xyz</span></span><br><span class="line">v1</span><br></pre></td></tr></table></figure>



<h2 id="基于权重转发流量"><a href="#基于权重转发流量" class="headerlink" title="基于权重转发流量"></a>基于权重转发流量</h2><p><code>nginx.ingress.kubernetes.io/canary-weight</code>：随机整数请求的整数百分比（0-100），应将其路由到canary Ingress中指定的服务。权重0表示此Canary规则不会在Canary入口中将任何请求发送到服务。权重为100表示所有请求都将发送到Ingress中指定的替代服务。</p>
<p>新建一个ingress，配置如下</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/canary-weight:</span> <span class="string">&quot;30&quot;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">app-canary</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">nginx.zerchin.xyz</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">appv2</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/</span></span><br></pre></td></tr></table></figure>

<p>kubectl查看ingress</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get ingress</span></span><br><span class="line">NAME         <span class="class"><span class="keyword">CLASS</span>    <span class="title">HOSTS</span>               <span class="title">ADDRESS</span>                     <span class="title">PORTS</span>   <span class="title">AGE</span></span></span><br><span class="line"><span class="class"><span class="title">app</span>          &lt;<span class="title">none</span>&gt;   <span class="title">nginx</span>.<span class="title">zerchin</span>.<span class="title">xyz</span>   172.16.0.195,172.16.0.196   80      11<span class="title">m</span></span></span><br><span class="line"><span class="class"><span class="title">app</span>-<span class="title">canary</span>   &lt;<span class="title">none</span>&gt;   <span class="title">nginx</span>.<span class="title">zerchin</span>.<span class="title">xyz</span>   172.16.0.195,172.16.0.196   80      7<span class="title">m13s</span></span></span><br></pre></td></tr></table></figure>

<p>这时候再访问nginx.zerchin.xyz，会发现其中30%的流量会路由到v2版本上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># for i in `seq 1 10`;do curl nginx.zerchin.xyz;done</span></span><br><span class="line">canary-v2</span><br><span class="line">canary-v2</span><br><span class="line">v1</span><br><span class="line">v1</span><br><span class="line">canary-v2</span><br><span class="line">v1</span><br><span class="line">v1</span><br><span class="line">v1</span><br><span class="line">v1</span><br><span class="line">v1</span><br></pre></td></tr></table></figure>



<h2 id="基于请求头转发流量"><a href="#基于请求头转发流量" class="headerlink" title="基于请求头转发流量"></a>基于请求头转发流量</h2><p><code>nginx.ingress.kubernetes.io/canary-by-header</code>：用于通知Ingress将请求路由到Canary Ingress中指定的服务的标头。当请求标头设置<code>always</code>为时，它将被路由到Canary。当标头设置<code>never</code>为时，它将永远不会路由到金丝雀。对于任何其他值，标头将被忽略，并且按优先级将请求与其他金丝雀规则进行比较。</p>
<p>修改app-canary的ingress配置，修改annotation，如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">annotations:</span></span><br><span class="line">  <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary-by-header:</span> <span class="string">&quot;canary&quot;</span></span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl nginx.zerchin.xyz </span></span><br><span class="line">v1</span><br><span class="line"><span class="comment"># curl -H &quot;canary:always&quot; nginx.zerchin.xyz </span></span><br><span class="line">canary<span class="literal">-v2</span></span><br></pre></td></tr></table></figure>



<h2 id="基于请求头和请求头的值转发流量"><a href="#基于请求头和请求头的值转发流量" class="headerlink" title="基于请求头和请求头的值转发流量"></a>基于请求头和请求头的值转发流量</h2><p><code>nginx.ingress.kubernetes.io/canary-by-header-value</code>：匹配的报头值，用于通知Ingress将请求路由到Canary Ingress中指定的服务。当请求标头设置为此值时，它将被路由到Canary。对于任何其他标头值，标头将被忽略，并按优先级将请求与其他金丝雀规则进行比较。此注释必须与<code>nginx.ingress.kubernetes.io/canary-by-header</code>一起使用。</p>
<p>修改app-canary的ingress配置，修改annotation，如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">annotations:</span></span><br><span class="line">  <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary-by-header:</span> <span class="string">&quot;canary&quot;</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary-by-header-value:</span> <span class="string">&quot;haha&quot;</span></span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl nginx.zerchin.xyz</span></span><br><span class="line">v1</span><br><span class="line"><span class="comment"># curl -H &quot;canary:haha&quot; nginx.zerchin.xyz</span></span><br><span class="line">canary<span class="literal">-v2</span></span><br><span class="line"><span class="comment"># curl -H &quot;canary:always&quot; nginx.zerchin.xyz</span></span><br><span class="line">v1</span><br></pre></td></tr></table></figure>



<h2 id="基于cookie转发流量"><a href="#基于cookie转发流量" class="headerlink" title="基于cookie转发流量"></a>基于cookie转发流量</h2><p><code>nginx.ingress.kubernetes.io/canary-by-cookie</code>：用于通知Ingress将请求路由到Canary Ingress中指定的服务的cookie。当cookie值设置<code>always</code>为时，它将被路由到canary。当cookie设置<code>never</code>为时，它将永远不会路由到Canary。对于任何其他值，将忽略cookie，并按优先级将请求与其他canary规则进行比较。</p>
<p>修改app-canary的ingress配置，修改annotation，如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">annotations:</span></span><br><span class="line">  <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">  <span class="attr">nginx.ingress.kubernetes.io/canary-by-cookie:</span> <span class="string">&quot;test&quot;</span></span><br></pre></td></tr></table></figure>

<p>测试结果</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl nginx.zerchin.xyz</span></span><br><span class="line">v1</span><br><span class="line"><span class="comment"># curl -b &quot;test=never&quot; nginx.zerchin.xyz</span></span><br><span class="line">v1</span><br><span class="line"><span class="comment"># curl -b &quot;test=always&quot; nginx.zerchin.xyz</span></span><br><span class="line">canary<span class="literal">-v2</span></span><br><span class="line"><span class="comment"># curl -b &quot;test=1&quot; nginx.zerchin.xyz</span></span><br><span class="line">v1</span><br></pre></td></tr></table></figure>



<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li><p>金丝雀发布规则优先级：<code>canary-by-header</code> -&gt; <code>canary-by-cookie </code>-&gt; <code>canary-weight</code></p>
</li>
<li><p>目前，每个ingress规则最多可以应用一个canary ingress</p>
</li>
</ol>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL数据库主从复制</title>
    <url>/2018/08/15/MySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>随着访问量的不断增加，单台MySQL数据库服务器压力不断增加，需要对MySQL进行优化和架构改造，如果MySQL优化不能明显改善压力，可使用高可用、主从复制、读写分离来拆分库和表等方法进行优化<br>MySQL主从复制集群在中小企业、大型企业中被广泛应用，MySQL主从复制的目的是实现数据库冗余备份，将master数据库数据定时同步至slave库中，一旦master数据库宕机，可以将Web应用数据库配置快速切换至slave数据库，确保Web应用有较高的可用率，主从复制架构如图所示：</p>
<p><img src="/images/mk/MySQL_master-slave_replication/mysql-1.png" alt="mysql-1"></p>
<p>MySQL主从复制集群至少需要2台数据库服务器，其中一台为master，另一台为slave，MySQL主从数据同步是一个异步复制的过程，要实现复制首先需要在master上开启bin-log日志功能，bin-log日志用于记录在master库中执行的增删改操作的SQL语句，整个过程需要开启3个线程，分别是master开启I/O线程，slave开启I/O线程和SQL线程，具体主从同步原理详解如下：</p>
<ol>
<li>slave上执行slave start，slave I/O线程会通过在master创建的授权用户连接上至master，并请求master从指定的文件和位置之后发送bin-log日志内容</li>
<li>master接收到来自slave I/O线程的请求后，master I/O线程根据slave发送的指定bin-log日志position点之后的内容，然后返回给slave的I/O线程</li>
<li>返回的信息中处理bin-log日志内容外，还有master最新的bin-log文件名以及在bin-log中的下一个指定更新position点</li>
<li>slave I/O线程接收到信息后，将接收到的日志内容依次添加到slave端的relay-log文件的最末端，并将读取到的master端的bin-log的文件名和position点记录到master.info文件中，以便在下一次读取的时候能告知master从响应的bin-log文件名及最后一个position点开始发起请求</li>
<li>slave SQL线程检测到relay-log中内容有更新，会立刻解析relay-log日志中的内容，将解析后的SQL预计在slave里执行，执行成功后slave库与master库则会保持数据一致。<br>下面我们来实验一下MySQL主从复制<br><strong>实验环境：</strong></li>
</ol>
<table>
<thead>
<tr>
<th>master</th>
<th>192.168.5.2</th>
</tr>
</thead>
<tbody><tr>
<td>slave</td>
<td>192.168.5.3</td>
</tr>
</tbody></table>
<p><strong>主从服务器都已经安装好了mariadb，此方法适用于所有系统，这里我用的是centos7</strong><br>这是我服务器安装的数据库版本</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; show variables like &#x27;version&#x27;;</span><br><span class="line">+<span class="comment">---------------+--------------------------------------+</span></span><br><span class="line">| Variable_name | Value                                |</span><br><span class="line">+<span class="comment">---------------+--------------------------------------+</span></span><br><span class="line">| version       | 10.3.8-MariaDB-1:10.3.8+maria~bionic |</span><br><span class="line">+<span class="comment">---------------+--------------------------------------+</span></span><br></pre></td></tr></table></figure>

<h2 id="首先在master上的my-cnf的-mysqld-内添加"><a href="#首先在master上的my-cnf的-mysqld-内添加" class="headerlink" title="首先在master上的my.cnf的[mysqld]内添加"></a>首先在master上的my.cnf的[mysqld]内添加</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/mysql/my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">server-id = 1</span><br><span class="line">log-bin = mysql-bin</span><br></pre></td></tr></table></figure>

<h2 id="并重启mysql服务"><a href="#并重启mysql服务" class="headerlink" title="并重启mysql服务"></a>并重启mysql服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl restart mariadb</span></span><br></pre></td></tr></table></figure>

<h2 id="查看master状态-获取bin-log信息和position点，并授予tongbu用户权限"><a href="#查看master状态-获取bin-log信息和position点，并授予tongbu用户权限" class="headerlink" title="查看master状态,获取bin-log信息和position点，并授予tongbu用户权限"></a>查看master状态,获取bin-log信息和position点，并授予tongbu用户权限</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; show master status;</span><br><span class="line">+<span class="comment">------------------+----------+--------------+------------------+</span></span><br><span class="line">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class="line">+<span class="comment">------------------+----------+--------------+------------------+</span></span><br><span class="line">| mysql-bin.000001 |      328 |              |                  |</span><br><span class="line">+<span class="comment">------------------+----------+--------------+------------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.000</span> sec)</span><br><span class="line">MariaDB [(<span class="keyword">none</span>)]&gt; <span class="keyword">grant</span> <span class="keyword">replication</span> <span class="keyword">slave</span> <span class="keyword">on</span> *.* <span class="keyword">to</span> <span class="string">&#x27;tongbu&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="keyword">identified</span> <span class="keyword">by</span> <span class="string">&#x27;000000&#x27;</span>;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br></pre></td></tr></table></figure>

<h2 id="在slave上的my-cnf的-mysqld-内添加"><a href="#在slave上的my-cnf的-mysqld-内添加" class="headerlink" title="在slave上的my.cnf的[mysqld]内添加"></a>在slave上的my.cnf的[mysqld]内添加</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi /etc/mysql/my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">server-id = 2</span><br></pre></td></tr></table></figure>

<h2 id="并重启mysql服务-1"><a href="#并重启mysql服务-1" class="headerlink" title="并重启mysql服务"></a>并重启mysql服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl restart mariadb</span></span><br></pre></td></tr></table></figure>

<h2 id="slave指定master的ip，用户名，密码，bing-log，position"><a href="#slave指定master的ip，用户名，密码，bing-log，position" class="headerlink" title="slave指定master的ip，用户名，密码，bing-log，position"></a>slave指定master的ip，用户名，密码，bing-log，position</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; change master to master_host=&#x27;192.168.5.2&#x27;,master_user=&#x27;tongbu&#x27;,master_password=&#x27;000000&#x27;,master_log_file=&#x27;mysql-bin.000001&#x27;,master_log_pos=328;</span><br><span class="line">Query OK, 0 rows affected (2.485 sec)</span><br><span class="line">MariaDB [(none)]&gt; start slave;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br></pre></td></tr></table></figure>

<h2 id="当出现以下状态则为成功"><a href="#当出现以下状态则为成功" class="headerlink" title="当出现以下状态则为成功"></a>当出现以下状态则为成功</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; show slave status\G;</span><br><span class="line">…</span><br><span class="line">Slave_IO_Running: Yes</span><br><span class="line">Slave_SQL_Running: Yes</span><br><span class="line">…</span><br></pre></td></tr></table></figure>

<h2 id="验证-在master上创建数据库"><a href="#验证-在master上创建数据库" class="headerlink" title="验证,在master上创建数据库"></a>验证,在master上创建数据库</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; create database db_test;</span><br><span class="line">Query OK, 1 row affected (0.001 sec)</span><br><span class="line">MariaDB [(none)]&gt; show databases;</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| Database           |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| db_test            |</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">4 rows in <span class="keyword">set</span> (<span class="number">0.001</span> sec)</span><br></pre></td></tr></table></figure>

<h2 id="通过查询发现slave也能查到db-test数据库，说明已经成功实现MySQL主从复制"><a href="#通过查询发现slave也能查到db-test数据库，说明已经成功实现MySQL主从复制" class="headerlink" title="通过查询发现slave也能查到db_test数据库，说明已经成功实现MySQL主从复制"></a>通过查询发现slave也能查到db_test数据库，说明已经成功实现MySQL主从复制</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; show databases;</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| Database           |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">| db_test            |</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">+<span class="comment">--------------------+</span></span><br><span class="line">4 rows in <span class="keyword">set</span> (<span class="number">0.001</span> sec)</span><br></pre></td></tr></table></figure>

<h2 id="MySQL主从同步排错思路"><a href="#MySQL主从同步排错思路" class="headerlink" title="MySQL主从同步排错思路"></a>MySQL主从同步排错思路</h2><p>MySQL主从同步集群在生产环境使用时，如果主从服务器之间网络通信条件差或者数据库数据量非常大，容易导致MySQL主从同步延迟<br>MySQL主从产生延迟之后，一旦主库宕机，会导致部分数据没有及时同步至从库，重新启动主库，会导致从库与主库同步错误，快速回复主从同步关系有如下两种方法：</p>
<ol>
<li>忽略错误后，继续同步<br>此种方法适用于主从库数据内容相差不大的情况。<br>master端执行如下命令，将数据库设置为全局读锁，不允许写入新数据</li>
</ol>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; flush tables with read lock;</span><br></pre></td></tr></table></figure>

<p>slave端停止slave I/O及 SQL线程，同时将同步错误的SQL跳过一次，跳过错误会导致数据补一次，启动start slave，同步状态恢复，命令如下：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; stop slave;</span><br><span class="line">MariaDB [(none)]&gt; set global sql_slave_skip_counter = 1;</span><br><span class="line">MariaDB [(none)]&gt; start slave;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>重新做主从同步，使数据完全同步。<br>此种方法适用于主从库数据内容相差很大的情况<br>master端执行如下命令。将数据库设置全局读锁，不允许写入新数据。</li>
</ol>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; flush tables with read lock;</span><br></pre></td></tr></table></figure>

<p>master端基于mysqldump\xtrabackup工具对数据库进行完整备份，也可以用shell脚本或python脚本实现定时备份，备份成功后，将完整的数据导入至从库，重新配置主从关系，当slave端的I/O线程、SQL线程均为Yes之后，最后将master端读锁解开即可，解锁命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; unlock tables;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack（Rocky）安装部署Cinder</title>
    <url>/2018/09/05/OpenStack-Rocky-Cinder-guide/</url>
    <content><![CDATA[<p>基于OpenStack Rocky版本安装部署Cinder块存储服务</p>
<h1 id="Cinder服务"><a href="#Cinder服务" class="headerlink" title="Cinder服务"></a>Cinder服务</h1><h2 id="controller节点"><a href="#controller节点" class="headerlink" title="controller节点"></a>controller节点</h2><h3 id="1-创建数据库"><a href="#1-创建数据库" class="headerlink" title="1 创建数据库"></a>1 创建数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ mysql -u root -p</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE cinder;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON cinder.* TO &#39;cinder&#39;@&#39;localhost&#39; \</span><br><span class="line">IDENTIFIED BY &#39;000000&#39;;</span><br><span class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON cinder.* TO &#39;cinder&#39;@&#39;%&#39; \</span><br><span class="line">IDENTIFIED BY &#39;000000&#39;;</span><br></pre></td></tr></table></figure>
<h3 id="2-创建用户"><a href="#2-创建用户" class="headerlink" title="2 创建用户"></a>2 创建用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openstack user create --domain default --password-prompt cinder</span><br><span class="line">openstack role add --project service --user cinder admin</span><br><span class="line">openstack service create --name cinderv2 \</span><br><span class="line">--description &quot;OpenStack Block Storage&quot; volumev2</span><br><span class="line">openstack service create --name cinderv3 \</span><br><span class="line">--description &quot;OpenStack Block Storage&quot; volumev3</span><br><span class="line">openstack endpoint create --region RegionOne \</span><br><span class="line">volumev2 public http:&#x2F;&#x2F;controller:8776&#x2F;v2&#x2F;%\(project_id\)s</span><br><span class="line">openstack endpoint create --region RegionOne \</span><br><span class="line">volumev2 internal http:&#x2F;&#x2F;controller:8776&#x2F;v2&#x2F;%\(project_id\)s</span><br><span class="line">openstack endpoint create --region RegionOne \</span><br><span class="line">volumev2 admin http:&#x2F;&#x2F;controller:8776&#x2F;v2&#x2F;%\(project_id\)s</span><br><span class="line">openstack endpoint create --region RegionOne \</span><br><span class="line">volumev3 public http:&#x2F;&#x2F;controller:8776&#x2F;v3&#x2F;%\(project_id\)s</span><br><span class="line">openstack endpoint create --region RegionOne \</span><br><span class="line">volumev3 internal http:&#x2F;&#x2F;controller:8776&#x2F;v3&#x2F;%\(project_id\)s</span><br><span class="line">openstack endpoint create --region RegionOne \</span><br><span class="line">volumev3 admin http:&#x2F;&#x2F;controller:8776&#x2F;v3&#x2F;%\(project_id\)s</span><br></pre></td></tr></table></figure>
<h3 id="3-安装包"><a href="#3-安装包" class="headerlink" title="3 安装包"></a>3 安装包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install openstack-cinder -y</span><br></pre></td></tr></table></figure>
<h3 id="4-配置"><a href="#4-配置" class="headerlink" title="4 配置"></a>4 配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**&#x2F;etc&#x2F;cinder&#x2F;cinder.conf**</span><br><span class="line">[database]</span><br><span class="line">connection &#x3D; mysql+pymysql:&#x2F;&#x2F;cinder:000000@controller&#x2F;cinder</span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:000000@controller</span><br><span class="line">[DEFAULT]</span><br><span class="line">auth_strategy &#x3D; keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">auth_uri &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">memcached_servers &#x3D; controller:11211</span><br><span class="line">auth_type &#x3D; password</span><br><span class="line">project_domain_id &#x3D; default</span><br><span class="line">user_domain_id &#x3D; default</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">username &#x3D; cinder</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">[DEFAULT]</span><br><span class="line">my_ip &#x3D; 192.168.100.10</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;cinder&#x2F;tmp</span><br></pre></td></tr></table></figure>
<h3 id="5-填充数据库"><a href="#5-填充数据库" class="headerlink" title="5 填充数据库"></a>5 填充数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">su -s &#x2F;bin&#x2F;sh -c &quot;cinder-manage db sync&quot; cinder</span><br></pre></td></tr></table></figure>
<h3 id="6-配置nova使用块存储"><a href="#6-配置nova使用块存储" class="headerlink" title="6 配置nova使用块存储"></a>6 配置nova使用块存储</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;nova&#x2F;nova.conf</span><br><span class="line">[cinder]</span><br><span class="line">os_region_name &#x3D; RegionOne</span><br></pre></td></tr></table></figure>
<h3 id="7-启动服务"><a href="#7-启动服务" class="headerlink" title="7 启动服务"></a>7 启动服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart openstack-nova-api.service</span><br><span class="line">systemctl enable openstack-cinder-api.service openstack-cinder-scheduler.service</span><br><span class="line">systemctl start openstack-cinder-api.service openstack-cinder-scheduler.service</span><br></pre></td></tr></table></figure>
<h2 id="compute节点"><a href="#compute节点" class="headerlink" title="compute节点"></a>compute节点</h2><h3 id="1-安装lvm服务"><a href="#1-安装lvm服务" class="headerlink" title="1 安装lvm服务"></a>1 安装lvm服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install lvm2 device-mapper-persistent-data -y</span><br><span class="line"># systemctl enable lvm2-lvmetad.service</span><br><span class="line"># systemctl start lvm2-lvmetad.service</span><br><span class="line">pvcreate &#x2F;dev&#x2F;sdb</span><br><span class="line">vgcreate cinder-volumes &#x2F;dev&#x2F;sdb</span><br></pre></td></tr></table></figure>
<h3 id="2-安装cinder-volume"><a href="#2-安装cinder-volume" class="headerlink" title="2 安装cinder-volume"></a>2 安装cinder-volume</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install openstack-cinder targetcli python-keystone -y</span><br></pre></td></tr></table></figure>
<h3 id="3-编辑配置文件"><a href="#3-编辑配置文件" class="headerlink" title="3 编辑配置文件"></a>3 编辑配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**&#x2F;etc&#x2F;cinder&#x2F;cinder.conf**</span><br><span class="line">[database]</span><br><span class="line">connection &#x3D; mysql+pymysql:&#x2F;&#x2F;cinder:000000@controller&#x2F;cinder</span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:000000@controller</span><br><span class="line">[DEFAULT]</span><br><span class="line">auth_strategy &#x3D; keystone</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">www_authenticate_uri &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">memcached_servers &#x3D; controller:11211</span><br><span class="line">auth_type &#x3D; password</span><br><span class="line">project_domain_id &#x3D; default</span><br><span class="line">user_domain_id &#x3D; default</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">username &#x3D; cinder</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">[DEFAULT]</span><br><span class="line">my_ip &#x3D; 192.168.100.20</span><br><span class="line">[lvm]</span><br><span class="line">volume_driver &#x3D; cinder.volume.drivers.lvm.LVMVolumeDriver</span><br><span class="line">volume_group &#x3D; cinder-volumes</span><br><span class="line">iscsi_protocol &#x3D; iscsi</span><br><span class="line">iscsi_helper &#x3D; lioadm</span><br><span class="line">[DEFAULT]</span><br><span class="line">enabled_backends &#x3D; lvm</span><br><span class="line">[DEFAULT]</span><br><span class="line">glance_api_servers &#x3D; http:&#x2F;&#x2F;controller:9292</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;cinder&#x2F;tmp</span><br></pre></td></tr></table></figure>
<h3 id="4-启动服务"><a href="#4-启动服务" class="headerlink" title="4 启动服务"></a>4 启动服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl enable openstack-cinder-volume.service target.service</span><br><span class="line">systemctl start openstack-cinder-volume.service target.service</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack-kilo版本cinder对接多Ceph存储</title>
    <url>/2018/09/06/OpenStack-kilo%E7%89%88%E6%9C%ACcinder%E5%AF%B9%E6%8E%A5%E5%A4%9ACeph%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本文为您介绍如何配置OpenStack kilo版本 cinder对接多个ceph存储</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th>主机</th>
<th>地址</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>controller</td>
<td>192.168.11.71</td>
<td>OpenStack-kilo</td>
</tr>
<tr>
<td>compute</td>
<td>192.168.11.72</td>
<td>OpenStack-kilo</td>
</tr>
<tr>
<td>ceph01</td>
<td>192.168.11.235</td>
<td>Ceph-Giant</td>
</tr>
<tr>
<td>ceph02</td>
<td>192.168.11.232</td>
<td>Ceph-Giant</td>
</tr>
</tbody></table>
<h2 id="Cinder配置"><a href="#Cinder配置" class="headerlink" title="Cinder配置"></a>Cinder配置</h2><p>在compute节点上操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># vi /etc/cinder/cinder.conf</span></span><br><span class="line">[DEFAULT]</span><br><span class="line">glance_host = controller</span><br><span class="line">enabled_backends = ceph01,ceph02    <span class="comment"># 这里设置两种存储</span></span><br><span class="line">[ceph01]</span><br><span class="line">volume_driver = cinder.volume.drivers.rbd.RBDDriver</span><br><span class="line">rbd_pool = volumes</span><br><span class="line">rbd_ceph_conf = /etc/ceph/ceph01.conf</span><br><span class="line">rbd_flatten_volume_from_snapshot = <span class="literal">false</span></span><br><span class="line">rbd_max_clone_depth = 5</span><br><span class="line">rbd_store_chunk_size = 4</span><br><span class="line">rados_connect_timeout = -1</span><br><span class="line">glance_api_version = 2</span><br><span class="line">rbd_user = cinder</span><br><span class="line">rbd_secret_uuid = df76a280-68fb-4bfb-bfab-976f0c71efa2   <span class="comment"># 这里要自行导入到vrish中，下同</span></span><br><span class="line">volume_backend_name = ceph01                  <span class="comment"># 设置命名，以便引用，下同</span></span><br><span class="line">[ceph02]</span><br><span class="line">volume_driver = cinder.volume.drivers.rbd.RBDDriver</span><br><span class="line">rbd_pool = ceph-cinder</span><br><span class="line">rbd_ceph_conf = /etc/ceph/ceph02.conf</span><br><span class="line">rbd_flatten_volume_from_snapshot = <span class="literal">false</span></span><br><span class="line">rbd_max_clone_depth = 5</span><br><span class="line">rbd_store_chunk_size = 4</span><br><span class="line">rados_connect_timeout = -1</span><br><span class="line">glance_api_version = 2</span><br><span class="line">rbd_user = ceph-cinder</span><br><span class="line">rbd_secret_uuid = 207a92a6-acaf-47c2-9556-e560a79ba472</span><br><span class="line">volume_backend_name = ceph02</span><br></pre></td></tr></table></figure>

<p>具体如何配置key到virsh中，请看我的另一篇<a href="https://blog.zerchin.xyz/2018/09/04/OpenStack-kilo%E7%89%88%E6%9C%AC%E5%AF%B9%E6%8E%A5ceph/">设置cinder存储</a></p>
<h2 id="重启cinder服务"><a href="#重启cinder服务" class="headerlink" title="重启cinder服务"></a>重启cinder服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># systemctl restart openstack-cinder-volumes</span></span><br></pre></td></tr></table></figure>

<h2 id="查看存储是否都启动成功"><a href="#查看存储是否都启动成功" class="headerlink" title="查看存储是否都启动成功"></a>查看存储是否都启动成功</h2><p>在controller节点上查看</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># source admin-openrc</span></span><br><span class="line">[root@controller ~]<span class="comment"># cinder service-list</span></span><br><span class="line">+------------------+-----------------+------+---------+-------+----------------------------+-----------------+</span><br><span class="line">|      Binary      |       Host      | Zone |  Status | State |         Updated_at         | Disabled Reason |</span><br><span class="line">+------------------+-----------------+------+---------+-------+----------------------------+-----------------+</span><br><span class="line">| cinder-scheduler |    controller   | nova | enabled |   up  | 2018-09-05T04:28:07.000000 |        -        |</span><br><span class="line">|  cinder-volume   |   compute@ceph01| nova | enabled |   up  | 2018-09-05T04:28:05.000000 |        -        |</span><br><span class="line">|  cinder-volume   |   compute@ceph02| nova | enabled |   up  | 2018-09-05T04:28:05.000000 |        -        |</span><br><span class="line">+------------------+-----------------+------+---------+-------+----------------------------+-----------------+</span><br></pre></td></tr></table></figure>

<p>能看到compute@ceph01和compute@ceph02，并且状态都为up状态，说明多ceph存储启用成功</p>
<h2 id="设置存储类型"><a href="#设置存储类型" class="headerlink" title="设置存储类型"></a>设置存储类型</h2><p>现在如果创建卷，scheduler会选择合适的位置创建卷，如果想要创建的时候选择某个存储池，可以设置存储类型</p>
<h3 id="创建卷类型"><a href="#创建卷类型" class="headerlink" title="创建卷类型"></a>创建卷类型</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder type-create ceph01</span></span><br><span class="line">[root@controller ~]<span class="comment"># cinder type-create ceph02</span></span><br></pre></td></tr></table></figure>

<h3 id="查看卷类型"><a href="#查看卷类型" class="headerlink" title="查看卷类型"></a>查看卷类型</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder type-list</span></span><br><span class="line">+--------------------------------------+------+</span><br><span class="line">|                  ID                  | Name |</span><br><span class="line">+--------------------------------------+------+</span><br><span class="line">| 8c50de7d-d6ba-4866-ba42-93d14859860b | ceph01|</span><br><span class="line">| abdaa7a5-f95b-4f24-ab21-6d5bc74344a7 | ceph02|</span><br><span class="line">+--------------------------------------+------+</span><br></pre></td></tr></table></figure>

<h3 id="这时候还不能选择存储池，还需要设置volume-backend-name"><a href="#这时候还不能选择存储池，还需要设置volume-backend-name" class="headerlink" title="这时候还不能选择存储池，还需要设置volume_backend_name"></a>这时候还不能选择存储池，还需要设置volume_backend_name</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder type-key ceph01 set volume_backend_name=ceph01</span></span><br><span class="line">[root@controller ~]<span class="comment"># cinder type-key ceph02 set volume_backend_name=ceph02</span></span><br></pre></td></tr></table></figure>

<p>这里的volume_backend_name是我们一开始设置的</p>
<h3 id="查看是否设置成功"><a href="#查看是否设置成功" class="headerlink" title="查看是否设置成功"></a>查看是否设置成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder extra-specs-list</span></span><br><span class="line">+--------------------------------------+-------+-------------------------------------+</span><br><span class="line">|                  ID                  |  Name |             extra_specs             |</span><br><span class="line">+--------------------------------------+-------+-------------------------------------+</span><br><span class="line">| 8c50de7d-d6ba-4866-ba42-93d14859860b | ceph01| &#123;u<span class="string">&#x27;volume_backend_name&#x27;</span>: u<span class="string">&#x27;ceph01&#x27;</span>&#125; |</span><br><span class="line">| abdaa7a5-f95b-4f24-ab21-6d5bc74344a7 | ceph02| &#123;u<span class="string">&#x27;volume_backend_name&#x27;</span>: u<span class="string">&#x27;ceph02&#x27;</span>&#125; |</span><br><span class="line">+--------------------------------------+------+-----------------------------------+</span><br></pre></td></tr></table></figure>

<p>现在可以根据类型选择存储池位置创建卷了</p>
<h2 id="创建一个ceph01类型的存储"><a href="#创建一个ceph01类型的存储" class="headerlink" title="创建一个ceph01类型的存储"></a>创建一个ceph01类型的存储</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder create --display-name ceph01 --volume-type ceph01 1</span></span><br><span class="line">+---------------------+--------------------------------------+</span><br><span class="line">|       Property      |                Value                 |</span><br><span class="line">+---------------------+--------------------------------------+</span><br><span class="line">|     attachments     |                  []                  |</span><br><span class="line">|  availability_zone  |                 nova                 |</span><br><span class="line">|       bootable      |                <span class="literal">false</span>                 |</span><br><span class="line">|      created_at     |      2018-09-05T04:40:44.892618      |</span><br><span class="line">| display_description |                 None                 |</span><br><span class="line">|     display_name    |                 ceph01               |</span><br><span class="line">|      encrypted      |                False                 |</span><br><span class="line">|          id         | 29b71020-8f0f-46d5-a2e3-5e89953a15ee |</span><br><span class="line">|       metadata      |                  &#123;&#125;                  |</span><br><span class="line">|     multiattach     |                <span class="literal">false</span>                 |</span><br><span class="line">|         size        |                  1                   |</span><br><span class="line">|     snapshot_id     |                 None                 |</span><br><span class="line">|     source_volid    |                 None                 |</span><br><span class="line">|        status       |               creating               |</span><br><span class="line">|     volume_type     |                 ceph01               |</span><br><span class="line">+---------------------+--------------------------------------+</span><br></pre></td></tr></table></figure>

<h3 id="查看是否创建成功"><a href="#查看是否创建成功" class="headerlink" title="查看是否创建成功"></a>查看是否创建成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder list</span></span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br><span class="line">|                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |</span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br><span class="line">| 29b71020-8f0f-46d5-a2e3-5e89953a15ee | available |     ceph01   |  1   |    ceph01   |  <span class="literal">false</span>   |             |</span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br></pre></td></tr></table></figure>

<p>看到状态为available，说明创建成功</p>
<h3 id="再看看ceph01的存储池是否有数据"><a href="#再看看ceph01的存储池是否有数据" class="headerlink" title="再看看ceph01的存储池是否有数据"></a>再看看ceph01的存储池是否有数据</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 my-cluster]<span class="comment"># rbd ls ceph-cinder</span></span><br><span class="line">volume-29b71020-8f0f-46d5-a2e3-5e89953a15ee</span><br></pre></td></tr></table></figure>

<p>看到id对应刚刚创建的卷id，说明类型设置成功</p>
<h2 id="接下来创建ceph02卷"><a href="#接下来创建ceph02卷" class="headerlink" title="接下来创建ceph02卷"></a>接下来创建ceph02卷</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder create --display-name ceph02 --volume-type ceph02 1</span></span><br><span class="line">+---------------------+--------------------------------------+</span><br><span class="line">|       Property      |                Value                 |</span><br><span class="line">+---------------------+--------------------------------------+</span><br><span class="line">|     attachments     |                  []                  |</span><br><span class="line">|  availability_zone  |                 nova                 |</span><br><span class="line">|       bootable      |                <span class="literal">false</span>                 |</span><br><span class="line">|      created_at     |      2018-09-05T04:44:26.657639      |</span><br><span class="line">| display_description |                 None                 |</span><br><span class="line">|     display_name    |                ceph02                |</span><br><span class="line">|      encrypted      |                False                 |</span><br><span class="line">|          id         | e170af88-5cb3-4b47-b550-f254bf544b50 |</span><br><span class="line">|       metadata      |                  &#123;&#125;                  |</span><br><span class="line">|     multiattach     |                <span class="literal">false</span>                 |</span><br><span class="line">|         size        |                  1                   |</span><br><span class="line">|     snapshot_id     |                 None                 |</span><br><span class="line">|     source_volid    |                 None                 |</span><br><span class="line">|        status       |               creating               |</span><br><span class="line">|     volume_type     |                ceph02                |</span><br><span class="line">+---------------------+--------------------------------------+</span><br></pre></td></tr></table></figure>

<h3 id="查看卷是否创建成功"><a href="#查看卷是否创建成功" class="headerlink" title="查看卷是否创建成功"></a>查看卷是否创建成功</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder list</span></span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br><span class="line">|                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |</span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br><span class="line">| 29b71020-8f0f-46d5-a2e3-5e89953a15ee | available |    ceph01    |  1   |    ceph01   |  <span class="literal">false</span>   |             |</span><br><span class="line">| e170af88-5cb3-4b47-b550-f254bf544b50 | available |    ceph02    |  1   |    ceph02   |  <span class="literal">false</span>   |             |</span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br></pre></td></tr></table></figure>

<p>可以看到ceph02的状态为available，说明创建成功</p>
<h3 id="再看看ceph02存储池中是否有数据"><a href="#再看看ceph02存储池中是否有数据" class="headerlink" title="再看看ceph02存储池中是否有数据"></a>再看看ceph02存储池中是否有数据</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph02 ~]<span class="comment"># rbd ls volumes</span></span><br><span class="line">volume-e170af88-5cb3-4b47-b550-f254bf544b50</span><br></pre></td></tr></table></figure>

<p>看到存储池中id对应卷id，说明类型设置成功</p>
]]></content>
      <categories>
        <category>ingress</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenStack-kilo版本对接ceph</title>
    <url>/2018/09/04/OpenStack-kilo%E7%89%88%E6%9C%AC%E5%AF%B9%E6%8E%A5ceph/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本文为您介绍如何配置OpenStack kilo版本cinder对接ceph存储</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th>集群</th>
<th>主机</th>
<th>ip</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>OpenStack</td>
<td>controller</td>
<td>66.66.66.71</td>
<td>openstack-kilo</td>
</tr>
<tr>
<td>OpenStack</td>
<td>compute</td>
<td>66.66.66.72</td>
<td>openstack-kilo</td>
</tr>
<tr>
<td>Ceph</td>
<td>ceph01</td>
<td>66.66.66.235</td>
<td>ceph-0.87</td>
</tr>
</tbody></table>
<h2 id="首先检测一下ceph集群的状态"><a href="#首先检测一下ceph集群的状态" class="headerlink" title="首先检测一下ceph集群的状态"></a>首先检测一下ceph集群的状态</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 ceph]<span class="comment"># ceph- s</span></span><br><span class="line">-bash: ceph-: <span class="built_in">command</span> not found</span><br><span class="line">[root@ceph01 ceph]<span class="comment"># ceph -s</span></span><br><span class="line">    cluster 3ec3f0f5-74d7-41ce-a497-1425705cd717</span><br><span class="line">     health HEALTH_OK</span><br><span class="line">     monmap e1: 1 mons at &#123;ceph01=66.66.66.235:6789/0&#125;, election epoch 1, quorum 0 ceph01</span><br><span class="line">     osdmap e42: 3 osds: 3 up, 3 <span class="keyword">in</span></span><br><span class="line">      pgmap v273: 320 pgs, 3 pools, 16 bytes data, 3 objects</span><br><span class="line">            27094 MB used, 243 GB / 269 GB avail</span><br><span class="line">                 320 active+clean</span><br></pre></td></tr></table></figure>

<p>Ceph01节点操作</p>
<h2 id="创建存储池"><a href="#创建存储池" class="headerlink" title="创建存储池"></a>创建存储池</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 ~]<span class="comment"># ceph osd pool create ceph-cinder 128</span></span><br><span class="line">pool <span class="string">&#x27;ceph-cinder&#x27;</span> created</span><br></pre></td></tr></table></figure>

<h2 id="创建认证用户"><a href="#创建认证用户" class="headerlink" title="创建认证用户"></a>创建认证用户</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 ~]<span class="comment"># ceph auth get-or-create client.ceph-cinder mon &#x27;allow r&#x27; osd &#x27;allow class-read ohildren, allow rwx pool=ceph-cinder&#x27;</span></span><br><span class="line">[client.ceph-cinder]</span><br><span class="line">         key = AQCIVY5beGJDNxAAphG+hdDC1vG4yVC5Ew7Y+w==</span><br></pre></td></tr></table></figure>

<p>生成keyring，并发送到compute节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 ~]<span class="comment"># ceph auth get-or-create client.ceph-cinder |ssh compute /etc/ceph/ceph.client.ceph-cinder.keyring</span></span><br></pre></td></tr></table></figure>

<h2 id="发送ceph配置文件到compute节点"><a href="#发送ceph配置文件到compute节点" class="headerlink" title="发送ceph配置文件到compute节点"></a>发送ceph配置文件到compute节点</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 ~]<span class="comment"># scp /etc/ceph/ceph.conf compute:/etc/ceph/ceph.conf</span></span><br></pre></td></tr></table></figure>

<p>compute节点操作</p>
<h2 id="生成uuid，并写入到秘钥文件中"><a href="#生成uuid，并写入到秘钥文件中" class="headerlink" title="生成uuid，并写入到秘钥文件中"></a>生成uuid，并写入到秘钥文件中</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># uuidgen</span></span><br><span class="line">207a92a6-acaf-47c2-9556-e560a79ba472</span><br><span class="line">[root@compute ~]<span class="comment"># cat &gt; secret.xml &lt;&lt;EOF</span></span><br><span class="line">&lt;secret ephemeral=<span class="string">&#x27;no&#x27;</span> private=<span class="string">&#x27;no&#x27;</span>&gt;</span><br><span class="line">&lt;uuid&gt;207a92a6-acaf-47c2-9556-e560a79ba472&lt;/uuid&gt;</span><br><span class="line">&lt;usage <span class="built_in">type</span>=<span class="string">&#x27;ceph&#x27;</span>&gt;</span><br><span class="line">&lt;name&gt;client.ceph-cinder secret &lt;/name&gt;</span><br><span class="line">&lt;/usage&gt;</span><br><span class="line">&lt;/secret&gt;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h2 id="定义秘钥"><a href="#定义秘钥" class="headerlink" title="定义秘钥"></a>定义秘钥</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># virsh secret-define --file secret.xml</span></span><br><span class="line">Secret 207a92a6-acaf-47c2-9556-e560a79ba472 created</span><br></pre></td></tr></table></figure>

<h2 id="设置秘钥加密值"><a href="#设置秘钥加密值" class="headerlink" title="设置秘钥加密值"></a>设置秘钥加密值</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># virsh secret-set-value --secret 207a92a6-acaf-47c2-9556-e560a79ba472 --base64 AQCIVY5beGJDNxAAphG+hdDC1vG4yVC5Ew7Y+w==</span></span><br></pre></td></tr></table></figure>

<h2 id="编辑cinder配置文件"><a href="#编辑cinder配置文件" class="headerlink" title="编辑cinder配置文件"></a>编辑cinder配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># vi /etc/cinder/cinder.conf</span></span><br><span class="line">[DEFAULT]</span><br><span class="line">enabled_backends = ceph</span><br><span class="line">[ceph]</span><br><span class="line">volume_driver = cinder.volume.drivers.rbd.RBDDriver</span><br><span class="line">rbd_pool = ceph-cinder</span><br><span class="line">rbd_ceph_conf = /etc/ceph/ceph.conf</span><br><span class="line">rbd_flatten_volume_from_snapshot = <span class="literal">false</span></span><br><span class="line">rbd_max_clone_depth = 5</span><br><span class="line">rbd_store_chunk_size = 4</span><br><span class="line">rados_connect_timeout = -1</span><br><span class="line">glance_api_version = 2</span><br><span class="line">rbd_user = ceph-cinder</span><br><span class="line">rbd_secret_uuid = 207a92a6-acaf-47c2-9556-e560a79ba472</span><br><span class="line"><span class="comment"># 这里的uuid是我们刚刚生成的uuid</span></span><br><span class="line">并注释掉[lvm]块下的所有配置</span><br></pre></td></tr></table></figure>

<h2 id="重启cinder服务"><a href="#重启cinder服务" class="headerlink" title="重启cinder服务"></a>重启cinder服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@compute ~]<span class="comment"># systemctl restart openstack-cinder-volume</span></span><br></pre></td></tr></table></figure>

<p>Controller节点操作</p>
<h2 id="查看服务是否启动"><a href="#查看服务是否启动" class="headerlink" title="查看服务是否启动"></a>查看服务是否启动</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> [root@compute ~]<span class="comment"># ssh controller</span></span><br><span class="line">[root@controller ~]<span class="comment"># source admin-openrc</span></span><br><span class="line">[root@controller ~]<span class="comment"># cinder service-list</span></span><br><span class="line">+------------------+-----------------+------+---------+-------+----------------------------+-----------------+</span><br><span class="line">|      Binary      |       Host      | Zone |  Status | State |         Updated_at         | Disabled Reason |</span><br><span class="line">+------------------+-----------------+------+---------+-------+----------------------------+-----------------+</span><br><span class="line">| cinder-scheduler |    controller   | nova | enabled |   up  | 2018-09-04T10:37:36.000000 |        -        |</span><br><span class="line">|  cinder-volume   |   compute@ceph  | nova | enabled |   up  | 2018-09-04T10:37:37.000000 |        -        |</span><br><span class="line">|  cinder-volume   |  controller@lvm | nova | enabled |  down | 2018-09-03T09:04:57.000000 |        -        |</span><br><span class="line">+------------------+-----------------+------+---------+-------+----------------------------+-----------------+</span><br></pre></td></tr></table></figure>

<p>查看到lvm存储是down状态，ceph存储是up状态</p>
<h2 id="创建cinder卷"><a href="#创建cinder卷" class="headerlink" title="创建cinder卷"></a>创建cinder卷</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder create --display-name vol-1 1</span></span><br><span class="line">+---------------------+--------------------------------------+</span><br><span class="line">|       Property      |                Value                 |</span><br><span class="line">+---------------------+--------------------------------------+</span><br><span class="line">|     attachments     |                  []                  |</span><br><span class="line">|  availability_zone  |                 nova                 |</span><br><span class="line">|       bootable      |                <span class="literal">false</span>                 |</span><br><span class="line">|      created_at     |      2018-09-04T10:43:50.386006      |</span><br><span class="line">| display_description |                 None                 |</span><br><span class="line">|     display_name    |                vol-1                 |</span><br><span class="line">|      encrypted      |                False                 |</span><br><span class="line">|          id         | 418344cf-3955-479b-8d5e-94633abae1f8 |</span><br><span class="line">|       metadata      |                  &#123;&#125;                  |</span><br><span class="line">|     multiattach     |                <span class="literal">false</span>                 |</span><br><span class="line">|         size        |                  1                   |</span><br><span class="line">|     snapshot_id     |                 None                 |</span><br><span class="line">|     source_volid    |                 None                 |</span><br><span class="line">|        status       |               creating               |</span><br><span class="line">|     volume_type     |                 None                 |</span><br><span class="line">+---------------------+--------------------------------------+</span><br></pre></td></tr></table></figure>

<h2 id="查看卷是否创建成功"><a href="#查看卷是否创建成功" class="headerlink" title="查看卷是否创建成功"></a>查看卷是否创建成功</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@controller ~]<span class="comment"># cinder list</span></span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br><span class="line">|                  ID                  |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |</span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br><span class="line">| 418344cf-3955-479b-8d5e-94633abae1f8 | available |    vol-1     |  1   |      -      |  <span class="literal">false</span>   |             |</span><br><span class="line">+--------------------------------------+-----------+--------------+------+-------------+----------+-------------+</span><br></pre></td></tr></table></figure>

<p>这时候看到vol-1卷的状态是available</p>
<h2 id="查看卷是否存储到ceph的存储池中"><a href="#查看卷是否存储到ceph的存储池中" class="headerlink" title="查看卷是否存储到ceph的存储池中"></a>查看卷是否存储到ceph的存储池中</h2><p>在ceph01上操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@ceph01 ceph]<span class="comment"># rbd ls ceph-cinder</span></span><br><span class="line">volume-418344cf-3955-479b-8d5e-94633abae1f8</span><br></pre></td></tr></table></figure>

<p>能看到已经存储到ceph的存储池中，并且id也是相对应的</p>
<h2 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h2><p>创建卷失败了<br>查看/var/log/cinder/volume.log日志</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oslo_messaging.rpc.dispatcher PermissionError: error creating image</span><br><span class="line">cinder.volume.manager PermissionError: error creating image</span><br></pre></td></tr></table></figure>

<p>发现是权限问题<br>后来查到是没有生成uuid，所以我就执行了导入操作到virsh中，成功创建卷</p>
]]></content>
      <categories>
        <category>openstack</category>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>openstack</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Pod定时重启</title>
    <url>/2020/05/13/Pod%E5%AE%9A%E6%97%B6%E9%87%8D%E5%90%AF/</url>
    <content><![CDATA[<p>Pod定时重启，可以通过Cronjob定时执行kubectl命令来实现。</p>
<h2 id="Dockerfile构建镜像"><a href="#Dockerfile构建镜像" class="headerlink" title="Dockerfile构建镜像"></a>Dockerfile构建镜像</h2><p>首先，需要构建一个带有kubectl+jq命令的镜像，kubectl命令执行pod重启，jq命令解析json文本</p>
<ol>
<li>新建一个目录，并存放如下所示的文件</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ls</span></span><br><span class="line">Dockerfile  kubernetes.repo  redeploy.sh</span><br></pre></td></tr></table></figure>

<p><code>Dockerfile</code>，主要是安装kubectl和jq命令，并设置CMD为 <code>redeploy.sh</code></p>
<figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> kubernetes.repo /etc/yum.repos.d/kubernetes.repo</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install kubectl jq -y</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> redeploy.sh /opt/redeploy.sh</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> chmod 755 /opt/redeploy.sh</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/opt/redeploy.sh&quot;</span>]</span></span><br></pre></td></tr></table></figure>

<p><code>kubernetes.repo</code>，这里使用阿里云的k8s yum源</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br></pre></td></tr></table></figure>

<p><code>redeploy.sh</code>，该脚本通过给应用添加一个注释，触发应用自动更新，类似于UI 上的重新部署，有三个参数</p>
<p>WORKLOAD_TYPY：工作负载类型，默认为deployment</p>
<p>APP_NAME：具体的工作负载名称</p>
<p>NAMESPACE：命名空间，默认为default</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line">WORKLOAD_TYPY&#x3D;$&#123;WORKLOAD_TYPY:-deployment&#125;</span><br><span class="line">APP_NAME&#x3D;$&#123;APP_NAME&#125;</span><br><span class="line">NAMESPACE&#x3D;$&#123;NAMESPACE:-default&#125;</span><br><span class="line"></span><br><span class="line">kubectl -n $NAMESPACE get $&#123;WORKLOAD_TYPY&#125;&#x2F;$&#123;APP_NAME&#125; -o json | \</span><br><span class="line">jq --arg time $( date -Iseconds ) &#39;.spec.template.metadata.annotations +&#x3D; &#123;&quot;cronjob&#x2F;restartTimestamp&quot;: $time&#125;&#39; | \</span><br><span class="line">kubectl  apply -f -</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>构建镜像</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">docker build <span class="literal">-t</span> TAGNAME:VERSION .</span><br><span class="line"><span class="comment">##例如</span></span><br><span class="line">docker build <span class="literal">-t</span> hub/k8s<span class="literal">-redeploy</span><span class="literal">-pod</span>:v1 .</span><br></pre></td></tr></table></figure>



<h2 id="在k8s集群创建Cronjob定时重启pod"><a href="#在k8s集群创建Cronjob定时重启pod" class="headerlink" title="在k8s集群创建Cronjob定时重启pod"></a>在k8s集群创建Cronjob定时重启pod</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redeploy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cattle-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">concurrencyPolicy:</span> <span class="string">Allow</span></span><br><span class="line">  <span class="attr">failedJobsHistoryLimit:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/opt/redeploy.sh</span></span><br><span class="line">            <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">APP_NAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">nginx</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">hub/k8s-redeploy-pod:v1</span> <span class="string">.</span></span><br><span class="line">            <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">redeploy</span></span><br><span class="line">            <span class="attr">resources:</span> &#123;&#125;</span><br><span class="line">            <span class="attr">securityContext:</span></span><br><span class="line">              <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line">              <span class="attr">capabilities:</span> &#123;&#125;</span><br><span class="line">              <span class="attr">privileged:</span> <span class="literal">false</span></span><br><span class="line">              <span class="attr">readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line">              <span class="attr">runAsNonRoot:</span> <span class="literal">false</span></span><br><span class="line">            <span class="attr">stdin:</span> <span class="literal">true</span></span><br><span class="line">            <span class="attr">tty:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">          <span class="attr">schedulerName:</span> <span class="string">default-scheduler</span></span><br><span class="line">          <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">          <span class="attr">serviceAccount:</span> <span class="string">cattle</span></span><br><span class="line">          <span class="attr">serviceAccountName:</span> <span class="string">cattle</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&#x27;* * * * *&#x27;</span></span><br><span class="line">  <span class="attr">successfulJobsHistoryLimit:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">suspend:</span> <span class="literal">false</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这里有四个地方要设置：</p>
<ol>
<li><code>.spec.jobTemplate.spec.template.spec.containers.image</code>：需要使用的镜像</li>
<li><code>.spec.jobTemplate.spec.template.spec.containers.env</code>：环境变量，需要设置<code>APP_NAME</code>为具体的工作负载，如果负载类型和命名空间不一致，还需要设置<code>NAMESPACE</code>、<code>WORKLOAD_TYPY</code></li>
<li><code>.spec.jobTemplate.spec.template.spec.serviceAccount</code>、<code>.spec.jobTemplate.spec.template.specserviceAccountName</code>：使用sa进行鉴权，让pod可以使用kubectl命令。这里使用了cattle-system命名空间下的cattle的sa，如果权限不适用，可以手动创建一个sa。</li>
<li><code>.spec.schedule</code>：设置需要定时执行的时间</li>
</ol>
<h2 id="执行Cronjob"><a href="#执行Cronjob" class="headerlink" title="执行Cronjob"></a>执行Cronjob</h2><p>执行该Cronjob，就可以定时重启对应的工作负载(Pod)。</p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Rancher-2.4.8-ent企业版监控unauthorized解决方法</title>
    <url>/2020/10/21/Rancher-2-4-8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h2><p>Rancher-v2.4.8-ent企业版启用监控(0.1.2000版本)后，只能通过Rancher-URL去访问，通过service暴露nodeport去访问，会报<code>unauthorized</code>错误。</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/error.png" alt="error"></p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>默认情况下，社区版本的监控将认证步骤做在了Prometheus-proxy容器中，所以我们可以直接通过pod IP/service IP就能访问Prometheus UI页面。</p>
<p>企业版0.1.2000监控版本，取消了项目监控的开关，只保留了集群监控，并取消了社区版在prometheus-proxy中进行认证的方式，将认证统一设置在Rancher-api-proxy中，这样设计是为了控制不同用户，根据其角色权限访问不同的资源。所以企业版默认只能通过rancher-api-proxy去访问prometheus UI界面。</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>Rancher</td>
<td>2.4.8-ent</td>
</tr>
<tr>
<td>monitoring</td>
<td>0.1.2000</td>
</tr>
</tbody></table>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>有两种解决方法，一种是通过ingress在header中传递token认证信息，另一种方法就是修改chart，将认证方式改成在Prometheus-proxy容器中认证。但是不管是在ingress中传递token，还是修改chart，都存在一定的权限泄露问题。</p>
<h3 id="方法一：通过ingress进行认证"><a href="#方法一：通过ingress进行认证" class="headerlink" title="方法一：通过ingress进行认证"></a>方法一：通过ingress进行认证</h3><h4 id="1、首先获取cluster-monitoring的token"><a href="#1、首先获取cluster-monitoring的token" class="headerlink" title="1、首先获取cluster-monitoring的token"></a>1、首先获取cluster-monitoring的token</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl -n cattle-prometheus -o template get sa cluster-monitoring --template&#x3D;&#39;&#123;&#123;range .secrets&#125;&#125; &#123;&#123;.name&#125;&#125; &#123;&#123;end&#125;&#125;&#39; | xargs kubectl -n cattle-prometheus get secrets -o template --template&#x3D;&#39;&#123;&#123;.data.token&#125;&#125;&#39; |base64 -d</span><br></pre></td></tr></table></figure>

<h4 id="2、创建ingress，并添加token至header中"><a href="#2、创建ingress，并添加token至header中" class="headerlink" title="2、创建ingress，并添加token至header中"></a>2、创建ingress，并添加token至header中</h4><p>通过Rancher UI创建Ingress，在cattle-prometheus命名空间下，选择目前后端为 access-prometheus</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/ingress-1.png" alt="ingress-1"></p>
<p>添加annotations注释：将其中<TOKEN>换成上一步获取的token值</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">nginx.ingress.kubernetes.io/configuration-snippet:</span> <span class="string">proxy_set_header</span> <span class="string">Authorization</span> <span class="string">&quot;Bearer &lt;TOKEN&gt;&quot;</span><span class="string">;</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/ingress-2.png" alt="ingress-2"></p>
<p>创建完成yaml配置文件如下：</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/ingress-yaml.png" alt="ingress-yaml"></p>
<h4 id="3、通过ingress访问Prometheus-UI界面"><a href="#3、通过ingress访问Prometheus-UI界面" class="headerlink" title="3、通过ingress访问Prometheus UI界面"></a>3、通过ingress访问Prometheus UI界面</h4><p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/prom-ui.png" alt="prom-ui"></p>
<h3 id="4、小结"><a href="#4、小结" class="headerlink" title="4、小结"></a>4、小结</h3><p>通过ingress可以实现访问Prometheus UI页面，但是由于token明文展示在了ingress的注释中，用户仅需有查看system项目的就可以获取到token，存在一定权限泄露问题。</p>
<h3 id="方法二：修改chart"><a href="#方法二：修改chart" class="headerlink" title="方法二：修改chart"></a>方法二：修改chart</h3><p>此方法适用于有本地git仓库</p>
<h4 id="1、同步-system-charts"><a href="#1、同步-system-charts" class="headerlink" title="1、同步 system-charts"></a>1、同步 system-charts</h4><p>同步<a href="https://github.com/cnrancher/system-charts">https://github.com/cnrancher/system-charts</a> 到本地git仓库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/cnrancher/system-charts</span><br></pre></td></tr></table></figure>



<h4 id="2、切换release-v2-4-ent分支"><a href="#2、切换release-v2-4-ent分支" class="headerlink" title="2、切换release-v2.4-ent分支"></a>2、切换release-v2.4-ent分支</h4><p>查看当前分支</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> system-charts/</span><br><span class="line">git branch -a</span><br></pre></td></tr></table></figure>

<p>默认是release-v2.4-ent分支，如果不是，则用这个命令切换</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout release-v2.4-ent</span><br></pre></td></tr></table></figure>



<h4 id="3、修改proxy配置"><a href="#3、修改proxy配置" class="headerlink" title="3、修改proxy配置"></a>3、修改proxy配置</h4><p>进入到Prometheus目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd charts&#x2F;rancher-monitoring&#x2F;v0.1.2000&#x2F;charts&#x2F;prometheus&#x2F;templates&#x2F;</span><br></pre></td></tr></table></figure>

<p>编辑<code>nginx-configmap.yaml</code>文件</p>
<p>3.1、找到这一行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed &quot;s&#x2F;REPLACE_PARAM_IP&#x2F;$&#123;POD_IP&#125;&#x2F;g&quot; $srcpath &gt; $dstpath</span><br></pre></td></tr></table></figure>

<p>将这一行删除，然后替换成</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">token&#x3D;$(cat &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount&#x2F;token)</span><br><span class="line">sed &quot;s&#x2F;REPLACE_PARAM_AUTHORIZATION&#x2F;Bearer $&#123;token&#125;&#x2F;g&quot; $srcpath | sed &quot;s&#x2F;REPLACE_PARAM_IP&#x2F;$&#123;POD_IP&#125;&#x2F;g&quot; &gt; $dstpath</span><br></pre></td></tr></table></figure>

<p>3.2、在server下，添加<code>proxy_set_header</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">proxy_set_header    Authorization &quot;REPLACE_PARAM_AUTHORIZATION&quot;;</span><br></pre></td></tr></table></figure>

<p>如图所示</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/monitoring-chart.png" alt="monitoring-chart"></p>
<h4 id="4、上传到本地git仓库"><a href="#4、上传到本地git仓库" class="headerlink" title="4、上传到本地git仓库"></a>4、上传到本地git仓库</h4><h4 id="5、设置system-charts地址"><a href="#5、设置system-charts地址" class="headerlink" title="5、设置system-charts地址"></a>5、设置system-charts地址</h4><p>在 全局-&gt; 工具 -&gt; 商店设置 中，找到 system-library，编辑这个应用商店，修改URL地址为本地git仓库地址，并刷新一下</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/system-chart.png" alt="system-chart"></p>
<h4 id="6、重启监控"><a href="#6、重启监控" class="headerlink" title="6、重启监控"></a>6、重启监控</h4><p>禁用监控，等所有组件删除完毕后，再开启监控</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/start-monitoring.png" alt="start-monitoring"></p>
<h4 id="7、通过nodeport-service访问Prometheus-UI页面"><a href="#7、通过nodeport-service访问Prometheus-UI页面" class="headerlink" title="7、通过nodeport service访问Prometheus UI页面"></a>7、通过nodeport service访问Prometheus UI页面</h4><p>克隆access-prometheus service，并设置service类型为nodeport类型</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/prom-nodeport.png" alt="prom-nodeport"></p>
<h4 id="8、小结"><a href="#8、小结" class="headerlink" title="8、小结"></a>8、小结</h4><p>使用修改chart方式也可以实现通过service IP访问Prometheus UI页面，可能会放大prometheus权限。grafana经测试可以对用户进行隔离。</p>
<h2 id="Grafana-访问"><a href="#Grafana-访问" class="headerlink" title="Grafana 访问"></a>Grafana 访问</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>由于企业版监控架构调整，基于用户权限控制，使不同用户登录Grafana查看到对应的图表监控信息，导致默认的admin用户没有权限查看到监控图表。</p>
<h3 id="解决方法-1"><a href="#解决方法-1" class="headerlink" title="解决方法"></a>解决方法</h3><p>可以通过ingress携带对应token去访问Grafana UI界面</p>
<h4 id="1、获取Rancher-admin用户ID"><a href="#1、获取Rancher-admin用户ID" class="headerlink" title="1、获取Rancher admin用户ID"></a>1、获取Rancher admin用户ID</h4><p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/get-user-id.png" alt="get-user-id"></p>
<p>例如这里获取到的ID为：user-87tkg</p>
<h4 id="2、创建ingress，并添加user-ID至header中"><a href="#2、创建ingress，并添加user-ID至header中" class="headerlink" title="2、创建ingress，并添加user ID至header中"></a>2、创建ingress，并添加user ID至header中</h4><p>通过Rancher UI创建Ingress，在cattle-prometheus命名空间下，选择目前后端为 access-grafana</p>
<p>添加annotations注释：将其中<USER_ID>改为上一步获取的user ID</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">nginx.ingress.kubernetes.io/configuration-snippet:</span> <span class="string">proxy_set_header</span>    <span class="string">X-RANCHER-USER</span> <span class="string">&quot;&lt;USER_ID&gt;&quot;</span><span class="string">;</span></span><br></pre></td></tr></table></figure>



<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/ingress-grafana-1.png" alt="ingress-grafana-1"></p>
<h4 id="3、通过ingress访问Grafana-UI界面"><a href="#3、通过ingress访问Grafana-UI界面" class="headerlink" title="3、通过ingress访问Grafana UI界面"></a>3、通过ingress访问Grafana UI界面</h4><p>查看左下角用户是否处于登录状态</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/grafana-1.png" alt="grafana-1"></p>
<p>尝试访问监控图表</p>
<p><img src="/images/mk/Rancher-2.4.8-ent%E4%BC%81%E4%B8%9A%E7%89%88%E7%9B%91%E6%8E%A7unauthorized%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95.assets/grafana-2.png" alt="grafana-2"></p>
]]></content>
      <categories>
        <category>rancher</category>
      </categories>
      <tags>
        <tag>rancher</tag>
      </tags>
  </entry>
  <entry>
    <title>Rancher2.4替换权威证书</title>
    <url>/2021/02/01/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6/</url>
    <content><![CDATA[<h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>一开始安装rancher时使用的是自签名证书，现需要替换成权威证书，方便内部的一些使用和流程</p>
<p>替换如下：</p>
<p><code>rancher.zerchin.com</code>（自签名） →  <code>rancher.zerchin.xyz</code>（权威证书）</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ul>
<li><p>k8s-v1.17.14</p>
</li>
<li><p>rancher-v2.4.12</p>
</li>
</ul>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Rancher是以7层负载均衡的方式部署在集群中，用户访问rancher地址后，首先解析到nginx负载均衡上，然后在nginx负载均衡上作为ssl终止，最后nginx负载均衡反向代理到后端的rancher server的80端口上。</p>
<p>所以，替换证书的操作，只需要在nginx负载均衡上进行替换即可</p>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/Architecture_diagram.png" alt="Architecture_diagram"></p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="查看当前rancher使用的证书"><a href="#查看当前rancher使用的证书" class="headerlink" title="查看当前rancher使用的证书"></a>查看当前rancher使用的证书</h3><p>在浏览器地址栏中可以看到，由于当前的证书是自签名证书，所以显示是不安全的</p>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/ui-1.png" alt="ui-1"></p>
<h3 id="申请权威证书"><a href="#申请权威证书" class="headerlink" title="申请权威证书"></a>申请权威证书</h3><p>这里我是用腾讯云申请的证书（免费为腾讯打了波广告）</p>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/appli_cert.png" alt="appli_cert"></p>
<p>证书颁发之后，将证书下载下来，并上传到nginx负载均衡上，并重新命名</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># mv 1_rancher.zerchin.xyz_bundle.crt tls_new.crt</span></span><br><span class="line"><span class="comment"># mv 2_rancher.zerchin.xyz.key tls_new.key</span></span><br></pre></td></tr></table></figure>





<h3 id="修改nginx配置"><a href="#修改nginx配置" class="headerlink" title="修改nginx配置"></a>修改nginx配置</h3><p>默认的配置如下：</p>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/nginx_conf.png" alt="nginx_conf"></p>
<p>其中主要关注这几个信息：</p>
<ol>
<li><code>server_name</code>：证书的签发地址</li>
<li><code>ssl_certificate</code>：证书存放的地址</li>
<li><code>ssl_certificate_key</code>：证书的key存放的地址</li>
<li><code>proxy_set_header</code>：访问后端rancher的地址</li>
</ol>
<p>修改成：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        server_name rancher.zerchin.xyz;                  <span class="comment">## 替换成新的域名</span></span><br><span class="line">        ssl_certificate /etc/nginx/ssl/tls_new.crt;       <span class="comment">## 替换新的证书地址</span></span><br><span class="line">        ssl_certificate_key /etc/nginx/ssl/tls_new.key;   <span class="comment">## 替换新的key的地址</span></span><br><span class="line">        </span><br><span class="line">        location / &#123;</span><br><span class="line">            proxy_set_header Host rancher.zerchin.xyz;    <span class="comment">## 替换新的访问地址</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">    server &#123;</span><br><span class="line">        server_name rancher.zerchin.xyz;                  <span class="comment">## 替换新的域名</span></span><br><span class="line"> ...</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>

<p>修改完后重启nginx</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nginx -t</span><br><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>



<h3 id="helm更新rancher配置"><a href="#helm更新rancher配置" class="headerlink" title="helm更新rancher配置"></a>helm更新rancher配置</h3><p>rancher部署在后端的k8s上，并通过ingress-nginx暴露出来，由于我们在nginx负载均衡上更改了访问地址，所以需要更新rancher的ingress</p>
<p>获取rancher的chart value</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm get values -n cattle-system rancher</span><br></pre></td></tr></table></figure>
<p>会输出如下结果：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">USER-SUPPLIED VALUES:</span><br><span class="line">hostname: rancher.zerchin.com</span><br><span class="line">privateCA: <span class="literal">true</span></span><br><span class="line">tls: external</span><br></pre></td></tr></table></figure>

<p>使用helm更新rancher，并填充上一步获取的value，其中将hostname配置成新的访问地址</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm upgrade rancher rancher-stable/rancher -n cattle-system --<span class="built_in">set</span> hostname=rancher.zerchin.xyz --<span class="built_in">set</span> privateCA=<span class="literal">true</span> --<span class="built_in">set</span> tls=external --version v2.4.12</span><br></pre></td></tr></table></figure>

<p>由于使用了权威证书，所以privateCA这个参数不用加上去，另外version为具体的rancher版本，需要带v</p>
<h3 id="浏览器查看证书"><a href="#浏览器查看证书" class="headerlink" title="浏览器查看证书"></a>浏览器查看证书</h3><p>rancher更新完之后，浏览器查看证书是否替换成功</p>
<p>使用新地址去访问</p>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/ui-2.png" alt="ui-2"></p>
<p>可以看到，已经能够使用新的域名去访问，并且显示的是可以信任的安全连接</p>
<h3 id="修改server-url"><a href="#修改server-url" class="headerlink" title="修改server_url"></a>修改server_url</h3><p>登录进去后，我们需要修改server_url地址</p>
<p>在 全局 -&gt; 系统设置 -&gt; 高级设置 中，找到<code>server-url</code>，并替换成现在新的地址</p>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/server_conf.png" alt="server_conf"></p>
<h3 id="更新下游k8s集群"><a href="#更新下游k8s集群" class="headerlink" title="更新下游k8s集群"></a>更新下游k8s集群</h3><p>之前rancher创建和纳管的k8s集群，还是监听旧的rancher地址，所以我们需要更新下游k8s集群访问rancher的地址</p>
<ol>
<li>打开集群API</li>
</ol>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/api-1.png" alt="api-1"></p>
<ol start="2">
<li>找到clusterRegistrationTokens，点进去</li>
</ol>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/api-2.png" alt="api-2"></p>
<ol start="3">
<li>找到id为system，复制insecureCommand后面的命令到k8s集群中执行</li>
</ol>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/api-3.png" alt="api-3"></p>
<ol start="4">
<li>执行第三步复制的命令</li>
</ol>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/api-4.png" alt="api-4"></p>
<ol start="5">
<li>所有的集群都需要执行该操作，等待cattle-cluster-agent和cattle-node-agent启动完毕可以了</li>
</ol>
<p><img src="/images/mk/Rancher2.4%E6%9B%BF%E6%8D%A2%E6%9D%83%E5%A8%81%E8%AF%81%E4%B9%A6.assets/finished.png" alt="finished"></p>
<p>替换成功</p>
]]></content>
      <categories>
        <category>rancher</category>
      </categories>
      <tags>
        <tag>rancher</tag>
      </tags>
  </entry>
  <entry>
    <title>Rancher2.6 Monitoring Grafana对接LDAP</title>
    <url>/2022/06/19/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP/</url>
    <content><![CDATA[<h2 id="Rancher-Monitoring-介绍"><a href="#Rancher-Monitoring-介绍" class="headerlink" title="Rancher Monitoring 介绍"></a>Rancher Monitoring 介绍</h2><p>在 Rancher 管理平台上，我们可以很顺利的在任何我们支持管理的 Kubernetes 集群上去启用 Rancher Monitoring 来为我们提供监控告警的功能。Rancher Monitoring 默认使用 Prometheus 来为我们提供相关系统和应用服务的监控，并通过 Grafana 的仪表盘可视化工具进行数据统计监控展示。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>默认情况下，Rancher没有对访问的 Grafana 的用户进行太多的限制，我们可以使用 Anonymous 用户来查看 Rancher 部署的任何默认仪表盘展示界面。但更多情况下，我们需要通过 Grafana 来制定自定义的仪表盘，此时 Anonymous 用户的 ReadOnly 权限就无法满足我们的需求，但是登录 admin 用户又会对我们 Grafana 造成一定安全隐患。此时我们就需要这么一套用户管理系统来管理 Grafana 的用户，对访问的用户进行一定权限的限制与管控。</p>
<p>虽然我们可以使用 Grafana 自带的用户管理列表来对访问的用户进行一定的权限管理，但是这需要我们额外维护一套用户列表。那么可不可以直接对接企业内部的LDAP系统从而减少我们维护用户的成本呢？</p>
<p>答案是肯定的。Rancher2.5 版本开始，监控架构进行了调整，允许用户自定义更多相关组件的配置。本文将介绍如何在 Rancher2.6 上，如何在通过配置 Rancher Monitoring 来进行 Grafana 对接 LDAP 认证。</p>
<h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><ul>
<li><p>Rancher：2.6.4</p>
</li>
<li><p>k8s：1.20.11</p>
</li>
<li><p>monitoring：100.1.2+up19.0.3</p>
</li>
<li><p>OpenLDAP：1.5.0</p>
</li>
</ul>
<h2 id="详细操作"><a href="#详细操作" class="headerlink" title="详细操作"></a>详细操作</h2><h3 id="Grafana对接LDAP"><a href="#Grafana对接LDAP" class="headerlink" title="Grafana对接LDAP"></a>Grafana对接LDAP</h3><h4 id="编辑Monitoring-Yaml配置LDAP"><a href="#编辑Monitoring-Yaml配置LDAP" class="headerlink" title="编辑Monitoring Yaml配置LDAP"></a>编辑Monitoring Yaml配置LDAP</h4><ol>
<li>访问Rancher explorer UI，进入Apps &amp; Marketplace，选择Monitoring，在配置选项中选择Edit YAML：</li>
</ol>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/rancher-1.png" alt="rancher-1"></p>
<ol start="2">
<li>开启LDAP认证配置</li>
</ol>
<p>在<code>grafana.grafana.ini</code>层级下新增如下<code>auth.ldap</code>配置信息开启LDAP：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">grafana:</span></span><br><span class="line">  <span class="attr">grafana.ini:</span></span><br><span class="line">    <span class="attr">auth.ldap:</span></span><br><span class="line">      <span class="attr">allow_sign_up:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">config_file:</span> <span class="string">/etc/grafana/ldap.toml</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/rancher-2.png" alt="rancher-2"></p>
<ol start="3">
<li>在<code>grafana</code>层级下，添加LDAP认证参数</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">grafana:</span></span><br><span class="line">  <span class="attr">ldap:</span></span><br><span class="line">    <span class="attr">config:</span> <span class="string">|</span></span><br><span class="line">      [[<span class="string">servers</span>]]</span><br><span class="line">      <span class="string">host</span> <span class="string">=</span> <span class="string">&quot;test.zerchin.xyz&quot;</span> </span><br><span class="line">      <span class="string">port</span> <span class="string">=</span> <span class="number">389</span></span><br><span class="line">      <span class="string">use_ssl</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">      <span class="string">start_tls</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">      <span class="string">ssl_skip_verify</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">bind_dn</span> <span class="string">=</span> <span class="string">&quot;cn=admin,dc=rancherldap,dc=com&quot;</span></span><br><span class="line">      <span class="string">bind_password</span> <span class="string">=</span> <span class="string">&#x27;Rancher123&#x27;</span></span><br><span class="line">      <span class="string">search_filter</span> <span class="string">=</span> <span class="string">&quot;(cn=%s)&quot;</span></span><br><span class="line">      <span class="string">search_base_dns</span> <span class="string">=</span> [<span class="string">&quot;cn=group,ou=rancher,dc=rancherldap,dc=com&quot;</span>]</span><br><span class="line">      [<span class="string">servers.attributes</span>]</span><br><span class="line">      <span class="string">name</span> <span class="string">=</span> <span class="string">&quot;givenName&quot;</span></span><br><span class="line">      <span class="string">surname</span> <span class="string">=</span> <span class="string">&quot;sn&quot;</span></span><br><span class="line">      <span class="string">username</span> <span class="string">=</span> <span class="string">&quot;cn&quot;</span></span><br><span class="line">      <span class="string">member_of</span> <span class="string">=</span> <span class="string">&quot;memberOf&quot;</span></span><br><span class="line">      <span class="string">email</span> <span class="string">=</span> <span class="string">&quot;email&quot;</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p><strong>参数说明</strong>：</p>
<p><code>host</code>：LDAP服务器地址（IP/Domain，指定多个地址空格分隔）。</p>
<p><code>port</code>：LDAP端口，默认是389，如果use_ssl=true则是636。</p>
<p><code>use_ssl</code>：是否使用加密TLS连接。</p>
<p><code>start_tls</code>：STARTTLS是一种明文通信协议的扩展，能够让明文的通信连线直接成为加密连线（使用SSL/TLS加密），而不需要使用另一个特别的端口来进行加密通信。</p>
<p><code>ssl_skip_verify</code>：是否跳过SSL证书验证。</p>
<p><code>bind_dn</code>：LDAP服务账户用户名。</p>
<p><code>bind_password</code>：密码（如果密码包含#，则需要用三个括号引起来，例如：”””#password;”””）。</p>
<p><code>search_filter</code>：用户查询过滤字段，例如<code>&quot;(cn=%s)&quot;</code> 、<code>&quot;(sAMAccountName=%s)&quot;</code> 、 <code>&quot;(uid=%s)&quot;</code>。</p>
<p><code>search_base_dns</code>：用户搜索起点。</p>
<ol start="4">
<li>配置好之后启动监控。</li>
</ol>
<p>等待监控启动成功后，打开Grafana UI界面，默认账号密码为：admin/prom-operator</p>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/grafana-1.png" alt="grafana-1"></p>
<h4 id="LDAP验证"><a href="#LDAP验证" class="headerlink" title="LDAP验证"></a>LDAP验证</h4><p>登录之后，左侧进入Server Admin - LDAP，在LDAP Connection下可以看到连接的主机。</p>
<p>在Test user mapping下，搜索存在的LDAP用户，可以查到用户信息。</p>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/grafana-2.png" alt="grafana-2"></p>
<p>并且可以使用LDAP用户登录访问Grafana UI界面。</p>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/grafana-3.png" alt="grafana-3"></p>
<h3 id="Grafana基于SSL对接LDAP"><a href="#Grafana基于SSL对接LDAP" class="headerlink" title="Grafana基于SSL对接LDAP"></a>Grafana基于SSL对接LDAP</h3><p>上述方法对接了LDAP的389端口，我们可以使用此端口进行LDAP连接。 </p>
<p>但是该端口是非安全和未加密的连接，容易造成安全问题，暴露用户相关信息，一般建议389端口仅用在内网或者测试环境。</p>
<p>对于安全要求比较高的环境下，我们可以使用LDAP另一个SSL加密端口来对接LDAP服务：636端口。</p>
<h4 id="创建证书secret"><a href="#创建证书secret" class="headerlink" title="创建证书secret"></a>创建证书secret</h4><p>在<code>cattle-monitoring-system</code>命名空间下，新建一个名叫<code>certs</code>的secret，其中<code>ca.pem</code>写入CA证书，<code>tls.crt</code>写入LDAP服务器证书，<code>tls.key</code>写入LDAP服务器证书秘钥。</p>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/secret-1.png" alt="secret-1"></p>
<p>也可以通过命令行导入相关证书：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create secret generic certs -n cattle-monitoring-system --from-file=ca.pem --from-file=tls.crt --from-file=tls.key</span><br></pre></td></tr></table></figure>



<h4 id="LDAP-SSL认证配置"><a href="#LDAP-SSL认证配置" class="headerlink" title="LDAP SSL认证配置"></a>LDAP SSL认证配置</h4><p>编辑Monitoring yaml配置</p>
<ol>
<li>在<code>grafana</code>层级下，添加<code>extraSecretMounts</code>挂载secret证书：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">grafana:</span></span><br><span class="line">  <span class="attr">extraSecretMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">defaultMode:</span> <span class="number">440</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/opt/certs</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">certs</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">certs</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>LDAP开启SSL认证：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">grafana:</span></span><br><span class="line">  <span class="attr">ldap:</span></span><br><span class="line">    <span class="attr">config:</span> <span class="string">|</span></span><br><span class="line">      [[<span class="string">servers</span>]] </span><br><span class="line">      <span class="string">host</span> <span class="string">=</span> <span class="string">&quot;test.zerchin.xyz&quot;</span> </span><br><span class="line">      <span class="string">port</span> <span class="string">=</span> <span class="number">636</span> </span><br><span class="line">      <span class="string">use_ssl</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line">      <span class="string">start_tls</span> <span class="string">=</span> <span class="literal">false</span> </span><br><span class="line">      <span class="string">ssl_skip_verify</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">      <span class="string">root_ca_cert</span> <span class="string">=</span> <span class="string">&quot;/opt/certs/ca.pem&quot;</span></span><br><span class="line">      <span class="string">client_cert</span> <span class="string">=</span> <span class="string">&quot;/opt/certs/tls.crt&quot;</span></span><br><span class="line">      <span class="string">client_key</span> <span class="string">=</span> <span class="string">&quot;/opt/certs/tls.key&quot;</span></span><br><span class="line">      <span class="string">bind_dn</span> <span class="string">=</span> <span class="string">&quot;cn=admin,dc=rancherldap,dc=com&quot;</span></span><br><span class="line">      <span class="string">bind_password</span> <span class="string">=</span> <span class="string">&#x27;Rancher123&#x27;</span> </span><br><span class="line">      <span class="string">search_filter</span> <span class="string">=</span> <span class="string">&quot;(cn=%s)&quot;</span> </span><br><span class="line">      <span class="string">search_base_dns</span> <span class="string">=</span> [<span class="string">&quot;cn=group,ou=rancher,dc=rancherldap,dc=com&quot;</span>] </span><br><span class="line">      [<span class="string">servers.attributes</span>] </span><br><span class="line">      <span class="string">name</span> <span class="string">=</span> <span class="string">&quot;givenName&quot;</span> </span><br><span class="line">      <span class="string">surname</span> <span class="string">=</span> <span class="string">&quot;sn&quot;</span> </span><br><span class="line">      <span class="string">username</span> <span class="string">=</span> <span class="string">&quot;cn&quot;</span> </span><br><span class="line">      <span class="string">member_of</span> <span class="string">=</span> <span class="string">&quot;memberOf&quot;</span> </span><br><span class="line">      <span class="string">email</span> <span class="string">=</span> <span class="string">&quot;email&quot;</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>port</code>设置为636 SSL加密端口</li>
<li><code>use_ssl</code>设置为true，<code>ssl_skip_verify</code>设置为false，开启SSL认证</li>
<li><code>root_ca_cert</code>、<code>client_cert</code>、<code>client_key</code>配置证书路径</li>
</ul>
<ol start="3">
<li>配置好之后启动监控。</li>
</ol>
<h4 id="LDAP-SSL验证"><a href="#LDAP-SSL验证" class="headerlink" title="LDAP SSL验证"></a>LDAP SSL验证</h4><p>登录Grafana，左侧进入Server Admin - LDAP，在LDAP Connection下可以看到，已经连上了636 SSL加密端口。</p>
<p>并且在Test user mapping下，搜索存在的LDAP用户，可以查到用户信息。</p>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/grafana-ssl-1.png" alt="grafana-ssl-1"></p>
<p>尝试用LDAP用户登录，可以正常登录查看数据。</p>
<p><img src="/images/mk/Rancher2.6%20Monitoring%20Grafana%E5%AF%B9%E6%8E%A5LDAP.assets/grafana-ssl-2.png" alt="grafana-ssl-2"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过上述的配置，我们可以很顺利的对接企业内部的LDAP作为 Grafana 用户管理系统，从而使得我们能够直接利用现有的用户进行统一的用户管理和权限认证。当然我们也可以去对接其他的用户管理系统，例如 okta、saml、github、basic等等，我们可以根据具体的需求参考 Grafana 官方文档进行配置即可。</p>
<blockquote>
<p>Grafana配置参考：<a href="https://grafana.com/docs/grafana/next/setup-grafana/configure-security/configure-authentication/ldap/">https://grafana.com/docs/grafana/next/setup-grafana/configure-security/configure-authentication/ldap/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>monitoring</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>grafana</tag>
        <tag>ldap</tag>
        <tag>monitoring</tag>
      </tags>
  </entry>
  <entry>
    <title>Rancher对接NFS</title>
    <url>/2020/08/13/Rancher%E5%AF%B9%E6%8E%A5NFS/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在rancher部署的k8s集群上，使用NFS存储对接k8s storage class</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>Rancher: v2.4.5</li>
<li>Kubernetes: v1.18.6</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="在NFS节点安装nfs相关软件包"><a href="#在NFS节点安装nfs相关软件包" class="headerlink" title="在NFS节点安装nfs相关软件包"></a>在NFS节点安装nfs相关软件包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## CentOS7/8</span></span><br><span class="line">yum install -y nfs-utils</span><br><span class="line"></span><br><span class="line"><span class="comment">## ubuntu</span></span><br><span class="line">apt install -y nfs-kernel-server</span><br></pre></td></tr></table></figure>

<h3 id="设置NFS挂载配置"><a href="#设置NFS挂载配置" class="headerlink" title="设置NFS挂载配置"></a>设置NFS挂载配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;/nfs/   172.16.0.0/16(rw,sync,no_subtree_check,no_root_squash)&#x27;</span> &gt;&gt; /etc/exports</span><br></pre></td></tr></table></figure>

<h3 id="创建NFS目录"><a href="#创建NFS目录" class="headerlink" title="创建NFS目录"></a>创建NFS目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /nfs</span><br></pre></td></tr></table></figure>

<h3 id="启动NFS"><a href="#启动NFS" class="headerlink" title="启动NFS"></a>启动NFS</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl start nfs-server</span><br></pre></td></tr></table></figure>



<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="其他节点下载客户端工具包"><a href="#其他节点下载客户端工具包" class="headerlink" title="其他节点下载客户端工具包"></a>其他节点下载客户端工具包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## CentOS7/8</span></span><br><span class="line">yum install nfs-utils</span><br><span class="line"></span><br><span class="line"><span class="comment">## ubuntu</span></span><br><span class="line">apt install -y nfs-common</span><br></pre></td></tr></table></figure>

<h3 id="查看挂载路径"><a href="#查看挂载路径" class="headerlink" title="查看挂载路径"></a>查看挂载路径</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># showmount -e 172.16.0.195</span></span><br><span class="line">Export list <span class="keyword">for</span> 172.16.0.195:</span><br><span class="line">/nfs 172.16.0.0/16</span><br></pre></td></tr></table></figure>

<h3 id="挂载NFS"><a href="#挂载NFS" class="headerlink" title="挂载NFS"></a>挂载NFS</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 挂载</span></span><br><span class="line">mount -t nfs 172.16.0.195:/nfs /mnt</span><br><span class="line"><span class="comment">## 写入数据，查看nfs是否有写入成功</span></span><br><span class="line">touch /mnt/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>



<h2 id="Rancher对接NFS"><a href="#Rancher对接NFS" class="headerlink" title="Rancher对接NFS"></a>Rancher对接NFS</h2><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><ul>
<li>已安装好kubernetes环境</li>
<li>所有worker节点已安装nfs客户端工具</li>
</ul>
<h3 id="配置应用商店"><a href="#配置应用商店" class="headerlink" title="配置应用商店"></a>配置应用商店</h3><p>全局-&gt;工具-&gt;商店设置，开启“Helm”应用商店</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/catalog-1.png" alt="catalog-1"></p>
<h3 id="启动nfs-client-provisioner"><a href="#启动nfs-client-provisioner" class="headerlink" title="启动nfs-client-provisioner"></a>启动nfs-client-provisioner</h3><p>添加两个应答：</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>参数·</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>nfs.server</td>
<td>172.16.0.195</td>
<td>NFS服务器IP地址</td>
</tr>
<tr>
<td>nfs.path</td>
<td>/path</td>
<td>NFS挂载路径</td>
</tr>
</tbody></table>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/catalog-2.png" alt="catalog-2"></p>
<p>设置好之后点击启动，查看应用状态</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/catalog-3.png" alt="catalog-3"></p>
<p>查看存储类</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/sc-1.png" alt="sc-1"></p>
<h3 id="验证NFS"><a href="#验证NFS" class="headerlink" title="验证NFS"></a>验证NFS</h3><p>创建工作负载，添加PVC</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/pvc-1.png" alt="pvc-1"></p>
<p>选择nfs存储类</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/pvc-2.png" alt="pvc-2"></p>
<p>设置挂载路径</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/pvc-3.png" alt="pvc-3"></p>
<p>进入pod，touch一个文件</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/cli-1.png" alt="cli-1"></p>
<p>nfs服务器上查看该文件</p>
<p><img src="/images/mk/Rancher%E5%AF%B9%E6%8E%A5NFS.assets/cli-2.png" alt="cli-2"></p>
]]></content>
      <categories>
        <category>rancher</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title>SUSE12 安装docker-ce19.03.13版本</title>
    <url>/2020/10/28/SUSE12-%E5%AE%89%E8%A3%85docker-ce19-03-13%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<p>官方不支持SUSE系统进行类似yum、apt-get方式安装docker-ce，可以按照以下方式进行安装。</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>SUSE</td>
<td>SUSE Linux Enterprise Server 12 SP2/SP5</td>
</tr>
<tr>
<td>Docker-ce</td>
<td>19.03.13</td>
</tr>
</tbody></table>
<h2 id="1、下载docker-ce软件压缩包"><a href="#1、下载docker-ce软件压缩包" class="headerlink" title="1、下载docker-ce软件压缩包"></a>1、下载docker-ce软件压缩包</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://download.docker.com/linux/static/stable/x86_64/docker-19.03.13.tgz</span><br></pre></td></tr></table></figure>



<h2 id="2、解压到-usr-local-bin目录下"><a href="#2、解压到-usr-local-bin目录下" class="headerlink" title="2、解压到/usr/local/bin目录下"></a>2、解压到/usr/local/bin目录下</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf docker-19.03.13.tgz</span><br><span class="line">cp docker&#x2F;* &#x2F;usr&#x2F;local&#x2F;bin&#x2F;.</span><br></pre></td></tr></table></figure>



<h2 id="3、编辑docker-service文件"><a href="#3、编辑docker-service文件" class="headerlink" title="3、编辑docker.service文件"></a>3、编辑docker.service文件</h2><p>新建/usr/lib/systemd/system/docker.service文件，添加如下参数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /usr/lib/systemd/system/docker.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">BindsTo=containerd.service</span><br><span class="line">After=network-online.target containerd.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Requires=docker.socket</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line"><span class="comment"># the default is not to use systemd for cgroups because the delegate issues still</span></span><br><span class="line"><span class="comment"># exists and systemd currently does not support the cgroup feature set required</span></span><br><span class="line"><span class="comment"># for containers run by docker</span></span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class="line">ExecReload=/bin/<span class="built_in">kill</span> -s HUP <span class="variable">$MAINPID</span></span><br><span class="line">TimeoutSec=0</span><br><span class="line">RestartSec=2</span><br><span class="line">Restart=always</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that StartLimit* options were moved from &quot;Service&quot; to &quot;Unit&quot; in systemd 229.</span></span><br><span class="line"><span class="comment"># Both the old, and new location are accepted by systemd 229 and up, so using the old location</span></span><br><span class="line"><span class="comment"># to make them work for either version of systemd.</span></span><br><span class="line">StartLimitBurst=3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.</span></span><br><span class="line"><span class="comment"># Both the old, and new name are accepted by systemd 230 and up, so using the old name to make</span></span><br><span class="line"><span class="comment"># this option work for either version of systemd.</span></span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"></span><br><span class="line"><span class="comment"># Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="comment"># in the kernel. We recommend using cgroups to do container-local accounting.</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"></span><br><span class="line"><span class="comment"># Comment TasksMax if your systemd version does not support it.</span></span><br><span class="line"><span class="comment"># Only systemd 226 and above support this option.</span></span><br><span class="line">TasksMax=infinity</span><br><span class="line"></span><br><span class="line"><span class="comment"># set delegate yes so that systemd does not reset the cgroups of docker containers</span></span><br><span class="line">Delegate=yes</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill only the docker process, not all processes in the cgroup</span></span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>



<h2 id="4、编辑docker-socket文件"><a href="#4、编辑docker-socket文件" class="headerlink" title="4、编辑docker.socket文件"></a>4、编辑docker.socket文件</h2><p>新建/usr/lib/systemd/system/docker.socket文件，添加如下参数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /usr/lib/systemd/system/docker.socket</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Socket <span class="keyword">for</span> the API</span><br><span class="line">PartOf=docker.service</span><br><span class="line"></span><br><span class="line">[Socket]</span><br><span class="line">ListenStream=/var/run/docker.sock</span><br><span class="line">SocketMode=0660</span><br><span class="line">SocketUser=root</span><br><span class="line">SocketGroup=docker</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=sockets.target</span><br></pre></td></tr></table></figure>





<h2 id="5、编辑containerd-service文件"><a href="#5、编辑containerd-service文件" class="headerlink" title="5、编辑containerd.service文件"></a>5、编辑containerd.service文件</h2><p>新建/usr/lib/systemd/system/containerd.service文件，添加如下参数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /usr/lib/systemd/system/containerd.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=containerd container runtime</span><br><span class="line">Documentation=https://containerd.io</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/containerd</span><br><span class="line"></span><br><span class="line">Type=notify</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=always</span><br><span class="line"><span class="comment"># Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="comment"># in the kernel. We recommend using cgroups to do container-local accounting.</span></span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line"><span class="comment"># Comment TasksMax if your systemd version does not supports it.</span></span><br><span class="line"><span class="comment"># Only systemd 226 and above support this version.</span></span><br><span class="line">TasksMax=infinity</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>



<h2 id="6、启动docker"><a href="#6、启动docker" class="headerlink" title="6、启动docker"></a>6、启动docker</h2><p>systemctl start docker报错：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># systemctl start docker</span></span><br><span class="line">A dependency job <span class="keyword">for</span> docker.service failed. See <span class="string">&#x27;journalctl -xe&#x27;</span> <span class="keyword">for</span> details.</span><br></pre></td></tr></table></figure>

<p>解决：需要创建docker用户和组</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd docker</span><br><span class="line">groupadd docker</span><br><span class="line">usermod -aG docker docker</span><br></pre></td></tr></table></figure>

<p>再次启动docker</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start docker &amp;&amp; systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>



<h2 id="7、测试创建容器"><a href="#7、测试创建容器" class="headerlink" title="7、测试创建容器"></a>7、测试创建容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it --rm alpine sh</span><br></pre></td></tr></table></figure>


<hr>
<h2 id="8、官方安装方式"><a href="#8、官方安装方式" class="headerlink" title="8、官方安装方式"></a>8、官方安装方式</h2><p>突然找到，官方也有类似软件包安装方法。。。。</p>
<p>参考地址：<a href="https://software.opensuse.org/download.html?project=Virtualization:containers&amp;package=docker">https://software.opensuse.org/download.html?project=Virtualization%3Acontainers&amp;package=docker</a></p>
]]></content>
      <categories>
        <category>SUSE</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>SUSE</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu安装k8s（纯操作）</title>
    <url>/2020/01/04/Ubuntu-18%E5%AE%89%E8%A3%85k8s%EF%BC%88%E7%BA%AF%E6%93%8D%E4%BD%9C%EF%BC%89/</url>
    <content><![CDATA[<h2 id="1-hostname"><a href="#1-hostname" class="headerlink" title="1 hostname"></a>1 hostname</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hostnamectl set-hostname knode1</span><br></pre></td></tr></table></figure>



<h2 id="2-etc-hosts"><a href="#2-etc-hosts" class="headerlink" title="2 /etc/hosts"></a>2 /etc/hosts</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">172.31.27.5 knode1</span><br><span class="line">172.31.23.162 knode2</span><br><span class="line">172.31.21.12 knode3</span><br></pre></td></tr></table></figure>



<h2 id="3-禁用systemd-resolved"><a href="#3-禁用systemd-resolved" class="headerlink" title="3 禁用systemd-resolved"></a>3 禁用systemd-resolved</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl disable systemd-resolved.service</span><br><span class="line">systemctl stop systemd-resolved.service</span><br><span class="line">rm -rf &#x2F;etc&#x2F;resolv.conf ; touch &#x2F;etc&#x2F;resolv.conf</span><br><span class="line">cat &lt;&lt; EOF &gt; &#x2F;etc&#x2F;resolv.conf</span><br><span class="line">nameserver 8.8.8.8</span><br><span class="line">nameserver 114.114.114.114</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>



<h2 id="4-关闭防火墙（不建议）"><a href="#4-关闭防火墙（不建议）" class="headerlink" title="4 关闭防火墙（不建议）"></a>4 关闭防火墙（不建议）</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ufw disable</span><br></pre></td></tr></table></figure>



<h2 id="5-修改时区和语言"><a href="#5-修改时区和语言" class="headerlink" title="5 修改时区和语言"></a>5 修改时区和语言</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -sf &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime</span><br><span class="line">sudo echo &#39;LANG&#x3D;&quot;en_US.UTF-8&quot;&#39; &gt;&gt; &#x2F;etc&#x2F;profile;source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure>



<h2 id="6-关闭swap"><a href="#6-关闭swap" class="headerlink" title="6 关闭swap"></a>6 关闭swap</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sed -i <span class="string">&#x27;/ swap / s/^\(.*\)$/#\1/g&#x27;</span> /etc/fstab</span><br></pre></td></tr></table></figure>


<h2 id="7-kernel性能调优"><a href="#7-kernel性能调优" class="headerlink" title="7 kernel性能调优"></a>7 kernel性能调优</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &gt;&gt; &#x2F;etc&#x2F;sysctl.conf&lt;&lt;EOF</span><br><span class="line">net.ipv4.ip_forward&#x3D;1</span><br><span class="line">watchdog_thresh&#x3D;30</span><br><span class="line">net.bridge.bridge-nf-call-iptables&#x3D;1</span><br><span class="line">net.ipv4.neigh.default.gc_thresh1&#x3D;4096</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2&#x3D;6144</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3&#x3D;8192</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables&#x3D;1</span><br><span class="line">net.ipv4.tcp_tw_recycle&#x3D;0</span><br><span class="line">vm.swappiness&#x3D;0</span><br><span class="line">vm.overcommit_memory&#x3D;1</span><br><span class="line">vm.panic_on_oom&#x3D;0</span><br><span class="line">fs.inotify.max_user_instances&#x3D;8192</span><br><span class="line">fs.inotify.max_user_watches&#x3D;1048576</span><br><span class="line">fs.file-max&#x3D;52706963</span><br><span class="line">fs.nr_open&#x3D;52706963</span><br><span class="line">net.ipv6.conf.all.disable_ipv6&#x3D;1</span><br><span class="line">net.netfilter.nf_conntrack_max&#x3D;2310720</span><br><span class="line">EOF</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>



<h2 id="8-安装docker"><a href="#8-安装docker" class="headerlink" title="8 安装docker"></a>8 安装docker</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">国内源</span><br><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br><span class="line">cat &gt; /etc/apt/sources.list &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span></span><br><span class="line"><span class="string">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">sudo curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">sudo add-apt-repository <span class="string">&quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable&quot;</span></span><br><span class="line">sudo apt-get -y update</span><br><span class="line">sudo apt-get -y install docker-ce=<span class="variable">$&#123;install_version&#125;</span> docker-ce-cli=<span class="variable">$&#123;install_version&#125;</span> --allow-downgrades;</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">sudo apt-mark hold docker-ce docker-ce-cli</span><br><span class="line"><span class="comment">## https://dockerhub.azk8s.cn/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">国外</span><br><span class="line"><span class="comment">## 移除旧包</span></span><br><span class="line">sudo apt-get remove docker docker-engine docker.io containerd runc</span><br><span class="line"><span class="comment">## 安装相关依赖</span></span><br><span class="line">sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent  software-properties-common ifupdown -y</span><br><span class="line"><span class="comment">## 安装秘钥</span></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line"><span class="comment">## 设置repo</span></span><br><span class="line">sudo add-apt-repository <span class="string">&quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu <span class="subst">$(lsb_release -cs)</span> stable&quot;</span></span><br><span class="line"><span class="comment">## 安装</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install docker-ce docker-ce-cli containerd.io -y</span><br><span class="line"><span class="comment"># 启动docker</span></span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line"><span class="comment">## 锁定docker版本</span></span><br><span class="line">sudo apt-mark hold docker-ce docker-ce-cli</span><br><span class="line"><span class="comment">## 安装特定版本</span></span><br><span class="line">apt-cache madison docker-ce</span><br><span class="line">sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io</span><br></pre></td></tr></table></figure>
<p>国内镜像加速</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span></span><br><span class="line"><span class="string">  &quot;log-driver&quot;: &quot;json-file&quot;,</span></span><br><span class="line"><span class="string">  &quot;log-opts&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;max-size&quot;: &quot;100m&quot;,</span></span><br><span class="line"><span class="string">    &quot;max-file&quot;: &quot;3&quot;</span></span><br><span class="line"><span class="string">  &#125;,</span></span><br><span class="line"><span class="string">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span></span><br><span class="line"><span class="string">  &quot;storage-opts&quot;: [</span></span><br><span class="line"><span class="string">    &quot;overlay2.override_kernel_check=true&quot;</span></span><br><span class="line"><span class="string">  ],</span></span><br><span class="line"><span class="string">  &quot;registry-mirrors&quot;: [&quot;https://uyah70su.mirror.aliyuncs.com&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>


<h2 id="9-解决ubuntu警告No-swap-limit-support"><a href="#9-解决ubuntu警告No-swap-limit-support" class="headerlink" title="9 解决ubuntu警告No swap limit support"></a>9 解决ubuntu警告No swap limit support</h2><p>Ubuntu\Debian系统下，默认cgroups未开启swap account功能，这样会导致设置容器内存或者swap资源限制不生效。可以通过以下命令解决:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo sed -i &#39;s&#x2F;en[[:alnum:]]*&#x2F;eth0&#x2F;g&#39; &#x2F;etc&#x2F;network&#x2F;interfaces;</span><br><span class="line">sudo sed -i &#39;s&#x2F;GRUB_CMDLINE_LINUX&#x3D;&quot;\(.*\)&quot;&#x2F;GRUB_CMDLINE_LINUX&#x3D;&quot;net.ifnames&#x3D;0 cgroup_enable&#x3D;memory swapaccount&#x3D;1 biosdevname&#x3D;0 \1&quot;&#x2F;g&#39; &#x2F;etc&#x2F;default&#x2F;grub;</span><br><span class="line">sudo update-grub;</span><br></pre></td></tr></table></figure>



<h2 id="10-安装kubeadm"><a href="#10-安装kubeadm" class="headerlink" title="10 安装kubeadm"></a>10 安装kubeadm</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curl</span><br><span class="line">curl -s https:&#x2F;&#x2F;packages.cloud.google.com&#x2F;apt&#x2F;doc&#x2F;apt-key.gpg | sudo apt-key add -</span><br><span class="line">cat &lt;&lt;EOF | sudo tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;kubernetes.list</span><br><span class="line">deb https:&#x2F;&#x2F;apt.kubernetes.io&#x2F; kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure>

<p>如果网络比较慢，可以使用阿里的源</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line">curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - </span><br><span class="line">cat &lt;&lt;<span class="string">EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span></span><br><span class="line"><span class="string">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span></span><br><span class="line"><span class="string">EOF</span>  </span><br><span class="line">apt-get update</span><br><span class="line"><span class="comment">## 查看可安装版本</span></span><br><span class="line">apt policy kubeadm</span><br><span class="line"><span class="comment">## 安装</span></span><br><span class="line">apt-get install -y kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure>


<h2 id="11-Master安装"><a href="#11-Master安装" class="headerlink" title="11 Master安装"></a>11 Master安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm init   --apiserver-advertise-address&#x3D;172.31.27.5   --service-cidr&#x3D;10.96.0.0&#x2F;12   --pod-network-cidr&#x3D;10.244.0.0&#x2F;16</span><br><span class="line">## 使用阿里源 --image-repository registry.aliyuncs.com&#x2F;google_containers</span><br><span class="line">  mkdir -p $HOME&#x2F;.kube</span><br><span class="line">  sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</span><br><span class="line"></span><br><span class="line">## kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure>



<h2 id="12-Node节点注册"><a href="#12-Node节点注册" class="headerlink" title="12 Node节点注册"></a>12 Node节点注册</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm join 172.31.27.5:6443 --token m9luq4.92yahwonslm8b6xj \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:cb705c09703f492af8db0ec9576737567aec78dcc4fac27a46bad08d6e46ced4</span><br></pre></td></tr></table></figure>



<h2 id="13-网络插件安装"><a href="#13-网络插件安装" class="headerlink" title="13 网络插件安装"></a>13 网络插件安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 二选一</span><br><span class="line"># 1 flannel</span><br><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;coreos&#x2F;flannel&#x2F;master&#x2F;Documentation&#x2F;kube-flannel.yml</span><br><span class="line"></span><br><span class="line"># 2 calico</span><br><span class="line">kubectl apply -f https:&#x2F;&#x2F;docs.projectcalico.org&#x2F;manifests&#x2F;calico.yaml</span><br></pre></td></tr></table></figure>



<h2 id="14-部署Dashboard"><a href="#14-部署Dashboard" class="headerlink" title="14 部署Dashboard"></a>14 部署Dashboard</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;dashboard&#x2F;v2.0.0-beta8&#x2F;aio&#x2F;deploy&#x2F;recommended.yaml</span><br><span class="line"></span><br><span class="line"># 修改NodePort</span><br><span class="line"></span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>canal网络添加黑洞路由</title>
    <url>/2021/07/23/canal%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E9%BB%91%E6%B4%9E%E8%B7%AF%E7%94%B1/</url>
    <content><![CDATA[<h2 id="问题概述"><a href="#问题概述" class="headerlink" title="问题概述"></a>问题概述</h2><p>由于canal是通过明细路由将数据转发到对应的pod容器网卡上，当访问的pod的IP不存在时，或者当pod访问外部服务在回包的过程中pod已经不存在没有对应的明细路由时，会导致该数据包进入到主机时，找不到对应的明细路由，最终通过默认网关转发到主机外部（交换机）。此时就会在交换机上可以看到源IP是pod IP、Mac地址是物理主机的Mac地址的数据包。</p>
<h2 id="问题影响"><a href="#问题影响" class="headerlink" title="问题影响"></a>问题影响</h2><p>正常情况下，该数据包通过默认路由走到网关后，网关会将该数据包丢弃。但是由于思科ACI网络的GARP学习机制，会导致交换机学习到错误的MAC-IP的地址，造成频繁的MAC-IP地址学习，影响交换机使用的性能，严重时会影响到整个ACI网络发送错误的数据包到错误的主机上。</p>
<h2 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h2><p>基于上述问题，我们可以通过添加黑洞路由来解决这个问题</p>
<p>先查看主机flannel.1网卡的IP</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip a flannel.1</span></span><br><span class="line">Command <span class="string">&quot;flannel.1&quot;</span> is unknown, try <span class="string">&quot;ip address help&quot;</span>.</span><br><span class="line">root@node01:~<span class="comment"># ifconfig flannel.1</span></span><br><span class="line">flannel.1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1450</span><br><span class="line">        inet 10.42.0.0  netmask 255.255.255.255  broadcast 0.0.0.0</span><br><span class="line">        ether a2:a1:5d:bc:b8:0c  txqueuelen 0  (Ethernet)</span><br><span class="line">        RX packets 14124739  bytes 15160299170 (15.1 GB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 12848009  bytes 4268398360 (4.2 GB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>

<p>添加黑洞路由</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip route add blackhole 10.42.0.0/24</span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/canal%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E9%BB%91%E6%B4%9E%E8%B7%AF%E7%94%B1.assets/route-1.png" alt="route-1"></p>
<p>上述操作在每个节点上都添加上对应的黑洞路由</p>
<h2 id="效果验证"><a href="#效果验证" class="headerlink" title="效果验证"></a>效果验证</h2><p>验证访问不存在的pod IP是否能在主机网卡上抓到目的IP为该pod IP的数据包</p>
<p>10.42.0.21 ping 一个不存在的pod IP：10.42.1.200</p>
<p><img src="/images/mk/canal%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E9%BB%91%E6%B4%9E%E8%B7%AF%E7%94%B1.assets/ping-1.png" alt="ping-1"></p>
<p>添加黑洞路由前抓包</p>
<p><img src="/images/mk/canal%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E9%BB%91%E6%B4%9E%E8%B7%AF%E7%94%B1.assets/tcpdump-1.png" alt="tcpdump-1"></p>
<p>添加黑洞路由</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ip route add blackhole 10.42.1.0&#x2F;24</span><br></pre></td></tr></table></figure>

<p>再次抓包</p>
<p><img src="/images/mk/canal%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0%E9%BB%91%E6%B4%9E%E8%B7%AF%E7%94%B1.assets/tcpdump-2.png" alt="tcpdump-2"></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>添加黑洞路由可以禁止pod数据包通过默认路由发往外部交换机</p>
<h2 id="最终版"><a href="#最终版" class="headerlink" title="最终版"></a>最终版</h2><p>通过如上方法在每个节点上添加黑洞路由的方式可以避免pod包路由到交换机上，但是因为每个主机的pod子网段是不同的，所以每次添加节点都得手动添加对应子网的黑洞路由，而且主机重启后路由就丢失了，需要重新添加，那有没有一劳永逸的方法呢？答案是肯定的。</p>
<p>直接添加B类子网的黑洞路由就可以了。也就是说，直接添加集群层面的pod网段的路由，并写入到网络配置文件中，这样每次重启主机或者重启网络都会自动加载黑洞路由，就不用去手动维护这个路由了。</p>
<p>参考CentOS7，方法如下：</p>
<ol>
<li><p>确认集群的pod CIDR，例如Rancher创建的集群默认pod的CIDR是<code>10.42.0.0/16</code></p>
</li>
<li><p>新建路由配置文件</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/route-eth0</span><br></pre></td></tr></table></figure>

<p>键入如下路由规则</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">blackhole 10.42.0.0/16 </span><br></pre></td></tr></table></figure>

<ol start="3">
<li>保存后重启网络即可</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure>

<p>查看路由</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip route|grep blackhole</span></span><br><span class="line">blackhole 10.42.0.0/16 </span><br></pre></td></tr></table></figure>

<p>至此添加成功！</p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>canal</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>ceph对接k8s storage class</title>
    <url>/2021/01/07/ceph%E5%AF%B9%E6%8E%A5k8s%20storage%20class/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>对接ceph的rbd和cephfs到k8s中提供持久化存储</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th>主机名</th>
<th>IP</th>
<th>role</th>
<th>操作系统</th>
</tr>
</thead>
<tbody><tr>
<td>ceph-01</td>
<td>172.16.31.11</td>
<td>mon osd</td>
<td>CentOS7.8</td>
</tr>
<tr>
<td>ceph-02</td>
<td>172.16.31.12</td>
<td>Osd</td>
<td>CentOS7.8</td>
</tr>
<tr>
<td>ceph-03</td>
<td>172.16.31.13</td>
<td>osd</td>
<td>CentOS7.8</td>
</tr>
</tbody></table>
<p>这个是官网的图 </p>
<p><img src="https://docs.ceph.com/en/mimic/_images/7c79c29c18fe63f3e72dc8af9524487f9068e450166d6cc79775bd37c8191317.png" alt="架构"></p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="安装ceph"><a href="#安装ceph" class="headerlink" title="安装ceph"></a>安装ceph</h3><h4 id="主机名设置"><a href="#主机名设置" class="headerlink" title="主机名设置"></a>主机名设置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## ceph-01</span></span><br><span class="line">hostnamectl set-hostname ceph-01</span><br><span class="line"><span class="comment">## ceph-02</span></span><br><span class="line">hostnamectl set-hostname ceph-01</span><br><span class="line"><span class="comment">## ceph-03</span></span><br><span class="line">hostnamectl set-hostname ceph-01</span><br></pre></td></tr></table></figure>

<h4 id="添加主机映射"><a href="#添加主机映射" class="headerlink" title="添加主机映射"></a>添加主机映射</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; <span class="string">EOF &gt;&gt; /etc/hosts</span></span><br><span class="line"><span class="string">172.16.31.11 ceph-01</span></span><br><span class="line"><span class="string">172.16.31.12 ceph-02</span></span><br><span class="line"><span class="string">172.16.31.13 ceph-03</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld &amp;&amp; systemctl stop firewalld</span><br><span class="line">setenforce 0 &amp;&amp; sed -i <span class="string">&#x27;s/^SELINUX=.*/SELINUX=disabled/&#x27;</span> /etc/selinux/config </span><br><span class="line">iptables -F &amp;&amp; iptables -X &amp;&amp; iptables -Z</span><br></pre></td></tr></table></figure>

<h4 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y ntpdate</span><br><span class="line">ntpdate</span><br></pre></td></tr></table></figure>

<h4 id="ssh无密钥访问"><a href="#ssh无密钥访问" class="headerlink" title="ssh无密钥访问"></a>ssh无密钥访问</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## ceph-01节点执行</span></span><br><span class="line">ssh-keygen </span><br><span class="line"></span><br><span class="line">ssh-copy-id ceph-01</span><br><span class="line"></span><br><span class="line">ssh-copy-id ceph-02</span><br><span class="line"></span><br><span class="line">ssh-copy-id ceph-03</span><br></pre></td></tr></table></figure>

<h4 id="准备repo"><a href="#准备repo" class="headerlink" title="准备repo"></a>准备repo</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install epel-release -y</span><br><span class="line">cat &lt;&lt; <span class="string">EOF &gt; /etc/yum.repos.d/ceph-deploy.repo</span></span><br><span class="line"><span class="string">[ceph-noarch]</span></span><br><span class="line"><span class="string">name=Ceph noarch packages</span></span><br><span class="line"><span class="string">baseurl=https://download.ceph.com/rpm-luminous/el7/noarch</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=1</span></span><br><span class="line"><span class="string">type=rpm-md</span></span><br><span class="line"><span class="string">gpgkey=https://download.ceph.com/keys/release.asc</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>国内用户可以用阿里的仓库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line">cat &lt;&lt; <span class="string">EOF &gt; /etc/yum.repos.d/ceph-deploy.repo</span></span><br><span class="line"><span class="string">[ceph-noarch]</span></span><br><span class="line"><span class="string">name=Ceph noarch packages</span></span><br><span class="line"><span class="string">baseurl=https://mirrors.aliyun.com/ceph/rpm-luminous/el7/noarch/</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<h4 id="安装ceph-deploy软件包"><a href="#安装ceph-deploy软件包" class="headerlink" title="安装ceph-deploy软件包"></a>安装ceph-deploy软件包</h4><p>ceph-1节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install ceph-deploy yum-plugin-priorities python2-pip bash-completion -y</span><br></pre></td></tr></table></figure>

<p>其他节点安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install yum-plugin-priorities python2-pip bash-completion -y</span><br></pre></td></tr></table></figure>



<h4 id="创建一个ceph目录"><a href="#创建一个ceph目录" class="headerlink" title="创建一个ceph目录"></a>创建一个ceph目录</h4><p>ceph-01节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir ceph-cluster</span><br><span class="line"><span class="built_in">cd</span> ceph-cluster</span><br></pre></td></tr></table></figure>

<h4 id="初始化ceph集群"><a href="#初始化ceph集群" class="headerlink" title="初始化ceph集群"></a>初始化ceph集群</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy new ceph-01</span><br></pre></td></tr></table></figure>

<h4 id="（可选）修改网络接口"><a href="#（可选）修改网络接口" class="headerlink" title="（可选）修改网络接口"></a>（可选）修改网络接口</h4><p>如果有两个网卡，可以将管理和存储网分离</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public_network = 172.16.0.0/16</span><br><span class="line">cluster_network = 192.168.31.0/24</span><br></pre></td></tr></table></figure>

<h4 id="安装ceph软件包"><a href="#安装ceph软件包" class="headerlink" title="安装ceph软件包"></a>安装ceph软件包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy install ceph-01 ceph-02 ceph-03</span><br></pre></td></tr></table></figure>

<p>国内加速可以指定阿里云镜像地址，先在所有节点添加这个仓库</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; <span class="string">EOF &gt; /etc/yum.repos.d/ceph-luminous.repo</span></span><br><span class="line"><span class="string">[ceph]</span></span><br><span class="line"><span class="string">name=Ceph packages for x86_64</span></span><br><span class="line"><span class="string">baseurl=http://mirrors.aliyun.com/ceph/rpm-luminous/el7/x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>然后执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy install ceph-01 ceph-02 ceph-03 --no-adjust-repos</span><br></pre></td></tr></table></figure>

<h4 id="创建mon"><a href="#创建mon" class="headerlink" title="创建mon"></a>创建mon</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy mon create-initial</span><br></pre></td></tr></table></figure>

<p>执行完后会创建*.keyring 密钥环</p>
<h4 id="复制配置和秘钥到对应的节点上"><a href="#复制配置和秘钥到对应的节点上" class="headerlink" title="复制配置和秘钥到对应的节点上"></a>复制配置和秘钥到对应的节点上</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy admin ceph-01 ceph-02 ceph-03 </span><br></pre></td></tr></table></figure>

<h4 id="部署mgr"><a href="#部署mgr" class="headerlink" title="部署mgr"></a>部署mgr</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy mgr create ceph-01</span><br></pre></td></tr></table></figure>

<p>mgr是ceph-12.x版本(luminous)新增的组件</p>
<h4 id="部署osd"><a href="#部署osd" class="headerlink" title="部署osd"></a>部署osd</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy osd create --data /dev/sdb ceph-01</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph-02</span><br><span class="line">ceph-deploy osd create --data /dev/sdb ceph-03</span><br></pre></td></tr></table></figure>

<h4 id="检查集群状态"><a href="#检查集群状态" class="headerlink" title="检查集群状态"></a>检查集群状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph health</span><br><span class="line">ceph -s</span><br></pre></td></tr></table></figure>



<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><h4 id="创建pool"><a href="#创建pool" class="headerlink" title="创建pool"></a>创建pool</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd pool create <span class="built_in">test</span> 8 8</span><br><span class="line"><span class="built_in">echo</span> `date` &gt; date.txt</span><br><span class="line">rados put test-object-1 date.txt --pool=<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h5 id="上传到存储池中"><a href="#上传到存储池中" class="headerlink" title="上传到存储池中"></a>上传到存储池中</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> `date` &gt; date.txt</span><br><span class="line">rados put test-object-1 date.txt --pool=<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h5 id="查看存储池和对象映射"><a href="#查看存储池和对象映射" class="headerlink" title="查看存储池和对象映射"></a>查看存储池和对象映射</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados -p <span class="built_in">test</span> ls</span><br><span class="line">ceph osd map <span class="built_in">test</span> test-object-1</span><br></pre></td></tr></table></figure>

<h5 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rados rm test-object-1 --pool=<span class="built_in">test</span></span><br><span class="line">ceph osd pool rm <span class="built_in">test</span> <span class="built_in">test</span> --yes-i-really-really-mean-it</span><br></pre></td></tr></table></figure>

<p>这里删不掉的话，需要添加这个配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mon_allow_pool_delete = <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>然后重启mon</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy --overwrite-conf admin ceph-01 ceph-02 ceph-03</span><br><span class="line">systemctl restart ceph-mon@ceph-01.service</span><br><span class="line"><span class="comment">## 再执行删除</span></span><br><span class="line">ceph osd pool rm <span class="built_in">test</span> <span class="built_in">test</span> --yes-i-really-really-mean-it</span><br></pre></td></tr></table></figure>





<h3 id="ceph-rbd对接kubernetes"><a href="#ceph-rbd对接kubernetes" class="headerlink" title="ceph rbd对接kubernetes"></a>ceph rbd对接kubernetes</h3><p>参考github连接：<a href="https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#ceph-rbd">https://kubernetes.io/zh/docs/concepts/storage/storage-classes/#ceph-rbd</a></p>
<h4 id="创建pool-1"><a href="#创建pool-1" class="headerlink" title="创建pool"></a>创建pool</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd pool create kube-pool 64 64</span><br></pre></td></tr></table></figure>

<h4 id="导入admin-keyring"><a href="#导入admin-keyring" class="headerlink" title="导入admin keyring"></a>导入admin keyring</h4><p>获取admin keyring</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph auth get-key client.admin</span><br></pre></td></tr></table></figure>

<p>将key换成上一步输出的结果</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create secret generic ceph-secret  -n kube-system \</span><br><span class="line">  --<span class="built_in">type</span>=<span class="string">&quot;kubernetes.io/rbd&quot;</span> \</span><br><span class="line">  --from-literal=key=<span class="string">&#x27;AQDYuPZfdjykCxAAXApI8weHFiZdEPcoc8EaRA==&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="创建-user-secret"><a href="#创建-user-secret" class="headerlink" title="创建 user secret"></a>创建 user secret</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph auth add client.kube mon <span class="string">&#x27;allow r&#x27;</span> osd <span class="string">&#x27;allow rwx pool=kube-pool&#x27;</span></span><br><span class="line">ceph auth get-key client.kube</span><br><span class="line">kubectl create secret generic ceph-secret-user -n kube-system  --from-literal=key=<span class="string">&#x27;AQAH2vZfe8wWIhAA0w81hjSAoqmjayS5SmWuVQ==&#x27;</span>  --<span class="built_in">type</span>=kubernetes.io/rbd</span><br></pre></td></tr></table></figure>

<h4 id="创建StorageClass"><a href="#创建StorageClass" class="headerlink" title="创建StorageClass"></a>创建StorageClass</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ceph-rbd</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/rbd</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">monitors:</span> <span class="number">172.16</span><span class="number">.31</span><span class="number">.11</span><span class="string">:6789</span></span><br><span class="line">  <span class="attr">adminId:</span> <span class="string">admin</span></span><br><span class="line">  <span class="attr">adminSecretName:</span> <span class="string">ceph-secret</span></span><br><span class="line">  <span class="attr">adminSecretNamespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">pool:</span> <span class="string">kube-pool</span></span><br><span class="line">  <span class="attr">userId:</span> <span class="string">kube</span></span><br><span class="line">  <span class="attr">userSecretName:</span> <span class="string">ceph-secret-user</span></span><br><span class="line">  <span class="attr">userSecretNamespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">fsType:</span> <span class="string">ext4</span></span><br><span class="line">  <span class="attr">imageFormat:</span> <span class="string">&quot;2&quot;</span></span><br><span class="line">  <span class="attr">imageFeatures:</span> <span class="string">&quot;layering&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="worker节点安装ceph-common"><a href="#worker节点安装ceph-common" class="headerlink" title="worker节点安装ceph-common"></a>worker节点安装ceph-common</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt; <span class="string">EOF &gt; /etc/yum.repos.d/ceph-luminous.repo</span></span><br><span class="line"><span class="string">[ceph]</span></span><br><span class="line"><span class="string">name=Ceph packages for x86_64</span></span><br><span class="line"><span class="string">baseurl=http://mirrors.aliyun.com/ceph/rpm-luminous/el7/x86_64</span></span><br><span class="line"><span class="string">enabled=1</span></span><br><span class="line"><span class="string">gpgcheck=0</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line">yum install -y ceph-common</span><br></pre></td></tr></table></figure>

<h4 id="创建PVC"><a href="#创建PVC" class="headerlink" title="创建PVC"></a>创建PVC</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: rbd-1</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">  storageClassName: ceph-rbd</span><br></pre></td></tr></table></figure>

<h4 id="创建deployment"><a href="#创建deployment" class="headerlink" title="创建deployment"></a>创建deployment</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: test-rbd</span><br><span class="line">  name: test-rbd</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: test-rbd</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: test-rbd</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: zerchin/network</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: test-rbd</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: /data</span><br><span class="line">          name: rbd</span><br><span class="line">      volumes:</span><br><span class="line">      - name: rbd</span><br><span class="line">        persistentVolumeClaim:</span><br><span class="line">          claimName: rbd-1</span><br></pre></td></tr></table></figure>

<h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><h5 id="问题1：rbd未加载报错"><a href="#问题1：rbd未加载报错" class="headerlink" title="问题1：rbd未加载报错"></a>问题1：rbd未加载报错</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">MountVolume.WaitForAttach failed <span class="keyword">for</span> volume <span class="string">&quot;pvc-8d8a8ed9-bcdb-4de8-a725-9121fcb89c84&quot;</span> : rbd: map failed <span class="built_in">exit</span> status 2, rbd output: libkmod: ERROR ../libkmod/libkmod.c:586 kmod_search_moddep: could not open moddep file <span class="string">&#x27;/lib/modules/4.4.247-1.el7.elrepo.x86_64/modules.dep.bin&#x27;</span> modinfo: ERROR: Module <span class="built_in">alias</span> rbd not found. modprobe: ERROR: ../libkmod/libkmod.c:586 kmod_search_moddep() could not open moddep file <span class="string">&#x27;/lib/modules/4.4.247-1.el7.elrepo.x86_64/modules.dep.bin&#x27;</span> modprobe: FATAL: Module rbd not found <span class="keyword">in</span> directory /lib/modules/4.4.247-1.el7.elrepo.x86_64 rbd: failed to load rbd kernel module (1) rbd: sysfs write failed In some cases useful info is found <span class="keyword">in</span> syslog - try <span class="string">&quot;dmesg | tail&quot;</span>. rbd: map failed: (2) No such file or directory</span><br></pre></td></tr></table></figure>

<p><strong>原因</strong></p>
<p>主要就是没有加载rbd模块，需要到所有的worker节点上加载rbd模块</p>
<p><strong>解决</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe rbd</span><br></pre></td></tr></table></figure>

<p>参考：<a href="https://forums.cnrancher.com/q_445.html">https://forums.cnrancher.com/q_445.html</a></p>
<h5 id="问题2：挂载失败"><a href="#问题2：挂载失败" class="headerlink" title="问题2：挂载失败"></a>问题2：挂载失败</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">MountVolume.WaitForAttach failed <span class="keyword">for</span> volume <span class="string">&quot;pvc-aa0d2e46-3df3-4c70-a318-ad95d4d0810a&quot;</span> : rbd: map failed <span class="built_in">exit</span> status 110, rbd output: rbd: sysfs write failed In some cases useful info is found <span class="keyword">in</span> syslog - try <span class="string">&quot;dmesg | tail&quot;</span>. rbd: map failed: (110) Connection timed out</span><br></pre></td></tr></table></figure>

<p><strong>解决</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd crush tunables hammer</span><br></pre></td></tr></table></figure>

<p>参考：<a href="https://github.com/rancher/rancher/issues/13198#issuecomment-391920740">https://github.com/rancher/rancher/issues/13198#issuecomment-391920740</a></p>
<h5 id="问题3：ceph-HEALTH-WARN"><a href="#问题3：ceph-HEALTH-WARN" class="headerlink" title="问题3：ceph HEALTH_WARN"></a>问题3：ceph HEALTH_WARN</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">HEALTH_WARN application not enabled on 1 pool(s)</span><br></pre></td></tr></table></figure>

<p><strong>解决</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph health detail</span><br><span class="line">ceph osd pool application <span class="built_in">enable</span> kube-pool rbd</span><br></pre></td></tr></table></figure>



<h3 id="部署cephfs文件系统"><a href="#部署cephfs文件系统" class="headerlink" title="部署cephfs文件系统"></a>部署cephfs文件系统</h3><p>k8s默认没有cephfs的provisioner，所以需要手动部署一个provisioner去对接cephfs</p>
<p>参考github链接：<a href="https://github.com/kubernetes-retired/external-storage/tree/master/ceph/cephfs">https://github.com/kubernetes-retired/external-storage/tree/master/ceph/cephfs</a></p>
<h4 id="部署mds（元数据服务）"><a href="#部署mds（元数据服务）" class="headerlink" title="部署mds（元数据服务）"></a>部署mds（元数据服务）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy mds create ceph-01</span><br></pre></td></tr></table></figure>

<h4 id="创建两个存储池，用来存放实际的数据以及元数据"><a href="#创建两个存储池，用来存放实际的数据以及元数据" class="headerlink" title="创建两个存储池，用来存放实际的数据以及元数据"></a>创建两个存储池，用来存放实际的数据以及元数据</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd pool create cephfs_data 64</span><br><span class="line">ceph osd pool create cephfs_metadata 64</span><br></pre></td></tr></table></figure>

<h4 id="创建cephfs文件系统"><a href="#创建cephfs文件系统" class="headerlink" title="创建cephfs文件系统"></a>创建cephfs文件系统</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph fs new cephfs cephfs_metadata cephfs_data</span><br></pre></td></tr></table></figure>

<h4 id="查看mds状态"><a href="#查看mds状态" class="headerlink" title="查看mds状态"></a>查看mds状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph mds <span class="built_in">stat</span></span><br><span class="line">ceph -s</span><br></pre></td></tr></table></figure>

<h4 id="部署provisioner"><a href="#部署provisioner" class="headerlink" title="部署provisioner"></a>部署provisioner</h4><p>这里有两种方式部署provisioner，其中一种是直接<code>docker run</code>的方式部署，另一种是通过<code>deployment</code>的方式部署到k8s中</p>
<h5 id="docker-run方式部署ceph-provisioner"><a href="#docker-run方式部署ceph-provisioner" class="headerlink" title="docker run方式部署ceph-provisioner"></a>docker run方式部署ceph-provisioner</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -tid -v /root/.kube:/kube -v /var/run/kubernetes:/var/run/kubernetes --privileged --net=host --name ceph-provisioner quay.io/external_storage/cephfs-provisioner   /usr/<span class="built_in">local</span>/bin/cephfs-provisioner   -master=https://172.16.0.99:6443   -kubeconfig=/kube/config -id=cephfs-provisioner-1 -disable-ceph-namespace-isolation</span><br></pre></td></tr></table></figure>

<h5 id="deployment方式部署到k8s中"><a href="#deployment方式部署到k8s中" class="headerlink" title="deployment方式部署到k8s中"></a>deployment方式部署到k8s中</h5><p>rbac相关yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumes&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;persistentvolumeclaims&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;update&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;storage.k8s.io&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;storageclasses&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;events&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;services&quot;</span>]</span><br><span class="line">    <span class="attr">resourceNames:</span> [<span class="string">&quot;kube-dns&quot;</span>,<span class="string">&quot;coredns&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;list&quot;</span>, <span class="string">&quot;get&quot;</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;secrets&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;get&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span> [<span class="string">&quot;endpoints&quot;</span>]</span><br><span class="line">    <span class="attr">verbs:</span> [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;patch&quot;</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cephfs</span></span><br></pre></td></tr></table></figure>

<p>ceph-provisioner-deployment.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">  <span class="attr">strategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Recreate</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cephfs-provisioner</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">&quot;quay.io/external_storage/cephfs-provisioner:latest&quot;</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_NAME</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">ceph.com/cephfs</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">PROVISIONER_SECRET_NAMESPACE</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">cephfs</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">&quot;/usr/local/bin/cephfs-provisioner&quot;</span></span><br><span class="line">        <span class="attr">args:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">&quot;-id=cephfs-provisioner-1&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">&quot;-disable-ceph-namespace-isolation&quot;</span></span><br><span class="line">      <span class="attr">serviceAccount:</span> <span class="string">cephfs-provisioner</span></span><br></pre></td></tr></table></figure>

<p>保存上述两个文件，并执行<code>kubectl apply</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f cephfs-provisioner-rbac.yaml</span><br><span class="line">kubectl apply -f cephfs-provisioner-deployment.yaml</span><br></pre></td></tr></table></figure>



<h4 id="导入秘钥"><a href="#导入秘钥" class="headerlink" title="导入秘钥"></a>导入秘钥</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph auth get-key client.admin &gt; /tmp/secret</span><br><span class="line">kubectl create ns cephfs</span><br><span class="line">kubectl create secret generic ceph-secret-admin --from-file=/tmp/secret --namespace=cephfs</span><br></pre></td></tr></table></figure>

<h4 id="创建Storage-class"><a href="#创建Storage-class" class="headerlink" title="创建Storage class"></a>创建Storage class</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">ceph.com/cephfs</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">    <span class="attr">monitors:</span> <span class="number">172.16</span><span class="number">.31</span><span class="number">.11</span><span class="string">:6789</span></span><br><span class="line">    <span class="attr">adminId:</span> <span class="string">admin</span></span><br><span class="line">    <span class="attr">adminSecretName:</span> <span class="string">ceph-secret-admin</span></span><br><span class="line">    <span class="attr">adminSecretNamespace:</span> <span class="string">&quot;cephfs&quot;</span></span><br><span class="line">    <span class="attr">claimRoot:</span> <span class="string">/pvc-volumes</span></span><br></pre></td></tr></table></figure>

<h4 id="创建pvc"><a href="#创建pvc" class="headerlink" title="创建pvc"></a>创建pvc</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cephfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">cephfs</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure>

<h4 id="创建deployment-1"><a href="#创建deployment-1" class="headerlink" title="创建deployment"></a>创建deployment</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">test-cephfs</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-cephfs</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">test-cephfs</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">test-cephfs</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">zerchin/network</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">test-rbd</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">cephfs</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cephfs</span></span><br><span class="line">        <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">          <span class="attr">claimName:</span> <span class="string">cephfs</span></span><br></pre></td></tr></table></figure>

<h4 id="常见问题-1"><a href="#常见问题-1" class="headerlink" title="常见问题"></a>常见问题</h4><h5 id="问题：无法挂载cephfs"><a href="#问题：无法挂载cephfs" class="headerlink" title="问题：无法挂载cephfs"></a>问题：无法挂载cephfs</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">MountVolume.SetUp failed <span class="keyword">for</span> volume <span class="string">&quot;pvc-e4373999-8380-4211-99c5-5d096f234b35&quot;</span> : CephFS: mount failed: mount failed: <span class="built_in">exit</span> status 5 Mounting <span class="built_in">command</span>: mount Mounting arguments: -t ceph -o &lt;masked&gt;,&lt;masked&gt; 172.16.29.5:6789:/pvc-volumes/kubernetes/kubernetes-dynamic-pvc-b3e72054-4dc7-11eb-abdd-f21be6c36b31 /var/lib/kubelet/pods/5986dc99-b707-4ea9-b6b2-ae7ffd457c99/volumes/kubernetes.io~cephfs/pvc-e4373999-8380-4211-99c5-5d096f234b35 Output: modprobe: ERROR: ../libkmod/libkmod.c:586 kmod_search_moddep() could not open moddep file <span class="string">&#x27;/lib/modules/4.4.247-1.el7.elrepo.x86_64/modules.dep.bin&#x27;</span> modprobe: FATAL: Module ceph not found <span class="keyword">in</span> directory /lib/modules/4.4.247-1.el7.elrepo.x86_64 failed to load ceph kernel module (1) mount error 5 = Input/output error</span><br></pre></td></tr></table></figure>

<p>此时手动在后台使用mount.ceph挂载对应的目录也挂载不上</p>
<p><strong>原因</strong></p>
<p>在 cephfs_provisoner.py 的实现中，默认添加了对 cephfs namespace 的支持，因此在对 volume 授权时会添加对 namespace 相关的权限设置。因为，我们使用的 ceph 版本 luminous 没有对 namespace 进行支持，所以，在使用时产生了创建的 volume 挂载到 pod 内后没有读写权限”input/output error”的问题。 此时，你在 cephfs 端查看卷的读写权限时，你可以看到目录读写权限都是问号。于是我们修改了这部分逻辑，去掉了 namespace 相关的部分。</p>
<p><strong>解决</strong></p>
<p>设置ceph-provisioner启动时添加该参数<code>-disable-ceph-namespace-isolation</code></p>
<p>参考：<a href="https://www.infoq.cn/article/jqhjzvvl11escvfydruc">https://www.infoq.cn/article/jqhjzvvl11escvfydruc</a></p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><h4 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h4><p>添加多个mon</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy mon add ceph-02 ceph-03</span><br></pre></td></tr></table></figure>

<p>当ceph集群有多个mon时，ceph会同步mon并形成仲裁，检查仲裁状态命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph quorum_status --format json-pretty</span><br></pre></td></tr></table></figure>

<p>添加mgr</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy mgr create ceph-02 ceph-03</span><br></pre></td></tr></table></figure>

<p>查看集群状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph -s</span><br></pre></td></tr></table></figure>



<h4 id="节点清理ceph"><a href="#节点清理ceph" class="headerlink" title="节点清理ceph"></a>节点清理ceph</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ceph-deploy purge [ceph-node]</span><br><span class="line">ceph-deploy purgedata [ceph-node]</span><br><span class="line">ceph-deploy forgetkeys</span><br><span class="line">rm ceph.*</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>helm2升级至helm3</title>
    <url>/2020/12/07/helm2%E5%8D%87%E7%BA%A7%E8%87%B3helm3/</url>
    <content><![CDATA[<h2 id="helm2升级至helm3"><a href="#helm2升级至helm3" class="headerlink" title="helm2升级至helm3"></a>helm2升级至helm3</h2><p>参考github：<a href="https://github.com/helm/helm/releases/tag/v3.4.1">https://github.com/helm/helm/releases/tag/v3.4.1</a></p>
<p>可以从rancher国内仓库下载helm3工具</p>
<h3 id="下载helm3最新版本"><a href="#下载helm3最新版本" class="headerlink" title="下载helm3最新版本"></a>下载helm3最新版本</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;rancher-mirror.cnrancher.com&#x2F;helm&#x2F;v3.4.1&#x2F;helm-v3.4.1-linux-amd64.tar.gz</span><br><span class="line">tar -zxvf helm-v3.4.1-linux-amd64.tar.gz</span><br><span class="line">cp linux-amd64&#x2F;helm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;helm3</span><br></pre></td></tr></table></figure>

<p>确认helm版本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm3 version</span></span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">version.BuildInfo&#123;Version:<span class="string">&quot;v3.4.1&quot;</span>, GitCommit:<span class="string">&quot;c4e74854886b2efe3321e185578e6db9be0a6e29&quot;</span>, GitTreeState:<span class="string">&quot;clean&quot;</span>, GoVersion:<span class="string">&quot;go1.14.11&quot;</span>&#125;</span><br></pre></td></tr></table></figure>



<h3 id="安装helm-2to3插件"><a href="#安装helm-2to3插件" class="headerlink" title="安装helm-2to3插件"></a>安装helm-2to3插件</h3><p>参考：<a href="https://helm.sh/blog/migrate-from-helm-v2-to-helm-v3/">https://helm.sh/blog/migrate-from-helm-v2-to-helm-v3/</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm3 plugin install https://github.com/helm/helm-2to3</span><br></pre></td></tr></table></figure>

<p>输出如下结果则安装成功</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Installed plugin: 2to3</span><br></pre></td></tr></table></figure>



<h3 id="查看helm3插件"><a href="#查看helm3插件" class="headerlink" title="查看helm3插件"></a>查看helm3插件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm3 plugin list</span></span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">NAME    VERSION DESCRIPTION                                                               </span><br><span class="line">2to3    0.7.0   migrate and cleanup Helm v2 configuration and releases in-place to Helm v3</span><br></pre></td></tr></table></figure>



<h3 id="迁移helm2配置至helm3"><a href="#迁移helm2配置至helm3" class="headerlink" title="迁移helm2配置至helm3"></a>迁移helm2配置至helm3</h3><p>这一步会将repos、plugins、Chart starters迁移到helm3中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm3 2to3 move config</span></span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">2020/12/07 16:25:32 WARNING: Helm v3 configuration may be overwritten during this operation.</span><br><span class="line">2020/12/07 16:25:32 </span><br><span class="line">[Move config/confirm] Are you sure you want to move the v2 configuration? [y/N]: y</span><br><span class="line">2020/12/07 16:25:35 </span><br><span class="line">Helm v2 configuration will be moved to Helm v3 configuration.</span><br><span class="line">2020/12/07 16:25:35 [Helm 2] Home directory: /root/.helm</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Config directory: /root/.config/helm</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Data directory: /root/.<span class="built_in">local</span>/share/helm</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Cache directory: /root/.cache/helm</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Create config folder <span class="string">&quot;/root/.config/helm&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Config folder <span class="string">&quot;/root/.config/helm&quot;</span> created.</span><br><span class="line">2020/12/07 16:25:35 [Helm 2] repositories file <span class="string">&quot;/root/.helm/repository/repositories.yaml&quot;</span> will copy to [Helm 3] config folder <span class="string">&quot;/root/.config/helm/repositories.yaml&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 [Helm 2] repositories file <span class="string">&quot;/root/.helm/repository/repositories.yaml&quot;</span> copied successfully to [Helm 3] config folder <span class="string">&quot;/root/.config/helm/repositories.yaml&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Create cache folder <span class="string">&quot;/root/.cache/helm&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] cache folder <span class="string">&quot;/root/.cache/helm&quot;</span> created.</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] Create data folder <span class="string">&quot;/root/.local/share/helm&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 [Helm 3] data folder <span class="string">&quot;/root/.local/share/helm&quot;</span> created.</span><br><span class="line">2020/12/07 16:25:35 [Helm 2] starters <span class="string">&quot;/root/.helm/starters&quot;</span> will copy to [Helm 3] data folder <span class="string">&quot;/root/.local/share/helm/starters&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 [Helm 2] starters <span class="string">&quot;/root/.helm/starters&quot;</span> copied successfully to [Helm 3] data folder <span class="string">&quot;/root/.local/share/helm/starters&quot;</span> .</span><br><span class="line">2020/12/07 16:25:35 Helm v2 configuration was moved successfully to Helm v3 configuration.</span><br></pre></td></tr></table></figure>

<p>看到<code>successfully</code>则说明迁移成功，使用<code>helm3</code>命令查看<code>repo</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm3 repo list</span></span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">NAME            URL                                              </span><br><span class="line"><span class="built_in">local</span>           http://127.0.0.1:8879/charts                     </span><br><span class="line">jetstack        https://charts.jetstack.io                       </span><br><span class="line">rancher-stable  https://releases.rancher.com/server-charts/stable</span><br></pre></td></tr></table></figure>

<p>可以看到，repo已经迁移成功</p>
<h3 id="迁移helm2-release到helm3"><a href="#迁移helm2-release到helm3" class="headerlink" title="迁移helm2 release到helm3"></a>迁移helm2 release到helm3</h3><p>首先查看helm2中的release</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm list</span></span><br><span class="line">NAME            REVISION        UPDATED                         STATUS          CHART                   APP VERSION     NAMESPACE    </span><br><span class="line">cert-manager    1               Mon Dec  7 14:49:16 2020        DEPLOYED        cert-manager-v0.8.1     v0.8.1          cert-manager </span><br><span class="line">rancher         1               Mon Dec  7 14:51:20 2020        DEPLOYED        rancher-2.2.9           v2.2.9          cattle-system</span><br></pre></td></tr></table></figure>

<p>迁移rancher</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm3 2to3 convert rancher</span></span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">WARNING: <span class="string">&quot;kubernetes-charts.storage.googleapis.com&quot;</span> is deprecated <span class="keyword">for</span> <span class="string">&quot;stable&quot;</span> and will be deleted Nov. 13, 2020.</span><br><span class="line">WARNING: You should switch to <span class="string">&quot;https://charts.helm.sh/stable&quot;</span> via:</span><br><span class="line">WARNING: helm repo add <span class="string">&quot;stable&quot;</span> <span class="string">&quot;https://charts.helm.sh/stable&quot;</span> --force-update</span><br><span class="line">2020/12/07 16:33:31 Release <span class="string">&quot;rancher&quot;</span> will be converted from Helm v2 to Helm v3.</span><br><span class="line">2020/12/07 16:33:31 [Helm 3] Release <span class="string">&quot;rancher&quot;</span> will be created.</span><br><span class="line">2020/12/07 16:33:31 [Helm 3] ReleaseVersion <span class="string">&quot;rancher.v1&quot;</span> will be created.</span><br><span class="line">2020/12/07 16:33:31 [Helm 3] ReleaseVersion <span class="string">&quot;rancher.v1&quot;</span> created.</span><br><span class="line">2020/12/07 16:33:31 [Helm 3] Release <span class="string">&quot;rancher&quot;</span> created.</span><br><span class="line">2020/12/07 16:33:31 Release <span class="string">&quot;rancher&quot;</span> was converted successfully from Helm v2 to Helm v3.</span><br><span class="line">2020/12/07 16:33:31 Note: The v2 release information still remains and should be removed to avoid conflicts with the migrated v3 release.</span><br><span class="line">2020/12/07 16:33:31 v2 release information should only be removed using `helm 2to3` cleanup and when all releases have been migrated over.</span><br></pre></td></tr></table></figure>

<p>使用helm3查看release list（helm3 需要设置命名空间）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># helm3 list -n cattle-system </span></span><br><span class="line">WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /root/.kube/config</span><br><span class="line">NAME    NAMESPACE     REVISION  UPDATED                                 STATUS    CHART         APP VERSION</span><br><span class="line">rancher cattle-system 1         2020-12-07 15:49:04.20697732 +0000 UTC  deployed  rancher-2.2.9 v2.2.9</span><br></pre></td></tr></table></figure>

<p>如果还有其他应用，需要一个个迁移过来</p>
<h3 id="清理helm2数据"><a href="#清理helm2数据" class="headerlink" title="清理helm2数据"></a>清理helm2数据</h3><p><strong>注意！！！</strong>这一步将会<strong>删除</strong>tiller pod以及helm2在主机上相关文件，执行之后<strong>无法还原</strong>，如果不确定可以先不执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm3 2to3 cleanup</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>helm</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>istio访问异常问题处理</title>
    <url>/2020/04/29/istio%E8%AE%BF%E9%97%AE%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<h2 id="问题简述"><a href="#问题简述" class="headerlink" title="问题简述"></a>问题简述</h2><p>通过istio实现灰度发布，浏览器访问报404错误，但是通过curl传递一个Host请求头就能访问成功。</p>
<h2 id="问题复现"><a href="#问题复现" class="headerlink" title="问题复现"></a>问题复现</h2><h4 id="Rancher-UI界面启动Istio，并开启ingress网关"><a href="#Rancher-UI界面启动Istio，并开启ingress网关" class="headerlink" title="Rancher UI界面启动Istio，并开启ingress网关"></a>Rancher UI界面启动Istio，并开启ingress网关</h4><p><img src="/images/mk/istio_access_error/enable-istio.png" alt="enable-istio"></p>
<h4 id="命名空间启动Istio自动注入"><a href="#命名空间启动Istio自动注入" class="headerlink" title="命名空间启动Istio自动注入"></a>命名空间启动Istio自动注入</h4><p><img src="/images/mk/istio_access_error/ns-istio-injection.png" alt="ns-istio-injection"></p>
<h4 id="部署nginx应用"><a href="#部署nginx应用" class="headerlink" title="部署nginx应用"></a>部署nginx应用</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">###deploy-nginx-v1.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-v1</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">satomic/nginx:v1</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">80tcp02</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="meta">---      </span></span><br><span class="line"><span class="comment">##deploy-nginx-v2.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-v2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">satomic/nginx:v2</span></span><br><span class="line">        <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">80tcp02</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">service:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">80tcp02</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="meta">---                </span></span><br><span class="line"><span class="comment">##gw.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mynginx-gateway</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">istio:</span> <span class="string">ingressgateway</span> <span class="comment"># use istio default controller</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;web1.com&#x27;</span></span><br><span class="line">    <span class="attr">port:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">##vs-nginx.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mynginx-gateway</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;web1.com&#x27;</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">exact:</span> <span class="string">/index.html</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">dr-nginx-v1</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">50</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">dr-nginx-v2</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">50</span></span><br><span class="line"><span class="comment">##dr-nginx.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DestinationRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">dr-nginx-v1</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">dr-nginx-v2</span></span><br><span class="line">  <span class="attr">trafficPolicy:</span></span><br><span class="line">    <span class="attr">loadBalancer:</span></span><br><span class="line">      <span class="attr">simple:</span> <span class="string">ROUND_ROBIN</span></span><br></pre></td></tr></table></figure>



<h4 id="浏览器访问：http-web1-com-31380-index-html，访问报错"><a href="#浏览器访问：http-web1-com-31380-index-html，访问报错" class="headerlink" title="浏览器访问：http://web1.com:31380/index.html，访问报错"></a>浏览器访问：<a href="http://web1.com:31380/index.html%EF%BC%8C%E8%AE%BF%E9%97%AE%E6%8A%A5%E9%94%99">http://web1.com:31380/index.html，访问报错</a></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># windows添加主机映射，C:\Windows\System32\drivers\etc\hosts</span></span><br><span class="line">172.16.0.211 web1.com</span><br></pre></td></tr></table></figure>

<p><em>172.16.0.211 为访问主机，31380则是ingressGateway使用NodePort映射 端口</em></p>
<p><img src="/images/mk/istio_access_error/error-1.png" alt="error-1"></p>
<h4 id="curl访问，直接curl访问失败，带上Host请求头，访问成功"><a href="#curl访问，直接curl访问失败，带上Host请求头，访问成功" class="headerlink" title="curl访问，直接curl访问失败，带上Host请求头，访问成功"></a>curl访问，直接curl访问失败，带上Host请求头，访问成功</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Linux添加主机映射，/etc/hosts</span></span><br><span class="line">172.16.0.211 web1.com</span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/istio_access_error/ok-1.png" alt="ok-1"></p>
<h2 id="排查思路"><a href="#排查思路" class="headerlink" title="排查思路"></a>排查思路</h2><h4 id="查看默认发送的请求头"><a href="#查看默认发送的请求头" class="headerlink" title="查看默认发送的请求头"></a>查看默认发送的请求头</h4><figure class="highlight"><table><tr><td class="code"><pre><span class="line">[root@node02 ~]# curl -v http://web1.com:31380/index.html</span><br><span class="line">* About to connect() to web1.com port 31380 (#0)</span><br><span class="line">*   Trying 172.16.0.211...</span><br><span class="line">* Connected to web1.com (172.16.0.211) port 31380 (#0)</span><br><span class="line">&gt; GET /index.html HTTP/1.1</span><br><span class="line">&gt; User-Agent: curl/7.29.0</span><br><span class="line">&gt; Host: web1.com:31380</span><br><span class="line">&gt; Accept: */*</span><br><span class="line">&gt; </span><br><span class="line">&lt; HTTP/1.1 404 Not Found</span><br><span class="line">&lt; date: Wed, 29 Apr 2020 04:28:41 GMT</span><br><span class="line">&lt; server: istio-envoy</span><br><span class="line">&lt; content-length: 0</span><br><span class="line">&lt; </span><br><span class="line">* Connection #0 to host web1.com left intact</span><br></pre></td></tr></table></figure>

<p>可以看到请求的<code>Host</code>是<code>web1.com:31380</code>，而我们<code>virtualservice</code>的hosts写的是<code>web.com</code>，所以请求的地址不对，自然就没法访问</p>
<h2 id="问题处理"><a href="#问题处理" class="headerlink" title="问题处理"></a>问题处理</h2><p>既然请求的Host不对，那么就要修改成相对应的Host才能访问，可以有以下几种处理方式。</p>
<h4 id="1-请求头-Request-Header-手动指定Host字段"><a href="#1-请求头-Request-Header-手动指定Host字段" class="headerlink" title="1 请求头(Request Header)手动指定Host字段"></a>1 请求头(Request Header)手动指定Host字段</h4><p>如果是应用内部自己调用，例如代码或者脚本，可以手动指定Host请求头，但是这种就无法再浏览器上访问</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">[root@node02 ~]# curl -v -H Host:web1.com http://web1.com:31380/index.html</span><br><span class="line">* About to connect() to web1.com port 31380 (#0)</span><br><span class="line">*   Trying 172.16.0.211...</span><br><span class="line">* Connected to web1.com (172.16.0.211) port 31380 (#0)</span><br><span class="line">&gt; GET /index.html HTTP/1.1</span><br><span class="line">&gt; User-Agent: curl/7.29.0</span><br><span class="line">&gt; Accept: */*</span><br><span class="line">&gt; Host:web1.com</span><br><span class="line">&gt; </span><br><span class="line">&lt; HTTP/1.1 200 OK</span><br><span class="line">&lt; server: istio-envoy</span><br><span class="line">&lt; date: Wed, 29 Apr 2020 04:37:21 GMT</span><br><span class="line">&lt; content-type: text/html</span><br><span class="line">&lt; content-length: 7</span><br><span class="line">&lt; last-modified: Wed, 25 Mar 2020 15:18:37 GMT</span><br><span class="line">&lt; etag: &quot;5e7b764d-7&quot;</span><br><span class="line">&lt; accept-ranges: bytes</span><br><span class="line">&lt; x-envoy-upstream-service-time: 1</span><br><span class="line">&lt; </span><br><span class="line">app v2</span><br><span class="line">* Connection #0 to host web1.com left intact</span><br></pre></td></tr></table></figure>



<h4 id="2-在VirtualService中设置authority来支持port访问"><a href="#2-在VirtualService中设置authority来支持port访问" class="headerlink" title="2 在VirtualService中设置authority来支持port访问"></a>2 在VirtualService中设置<code>authority</code>来支持port访问</h4><p>istio目前暂时还不支持直接添加DOMAIN+PORT，可以通过设置<code>authority</code>来支持PORT访问</p>
<p>在gateway和virtualservice设置hosts为<code>&quot;*&quot;</code>，并在virtualservice设置<code>authority</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## gateway</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## virtualservice</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">authority:</span></span><br><span class="line">        <span class="attr">exact:</span> <span class="string">&quot;web2.com:31380&quot;</span></span><br></pre></td></tr></table></figure>

<p>完整示例</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">##gw.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mynginx-gateway</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">istio:</span> <span class="string">ingressgateway</span> <span class="comment"># use istio default controller</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">    <span class="attr">port:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTP</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">##vs-nginx.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">mynginx-gateway</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line">  <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">exact:</span> <span class="string">/index.html</span></span><br><span class="line">      <span class="attr">authority:</span></span><br><span class="line">        <span class="attr">exact:</span> <span class="string">&quot;web2.com:31380&quot;</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">dr-nginx-v1</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">50</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">destination:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">subset:</span> <span class="string">dr-nginx-v2</span></span><br><span class="line">      <span class="attr">weight:</span> <span class="number">50</span></span><br></pre></td></tr></table></figure>

<p>kubectl apply刷新配置后，就可以在浏览器上访问了</p>
<p><img src="/images/mk/istio_access_error/ok-2.png" alt="ok-2"></p>
<p>并且我们也可以看到，Host请求头是web1.com:31380，如果使用web1.com Host请求头访问，则会失败</p>
<figure class="highlight http"><table><tr><td class="code"><pre><span class="line">[root@node02 ~]# curl -v http://web1.com:31380/index.html</span><br><span class="line">* About to connect() to web1.com port 31380 (#0)</span><br><span class="line">*   Trying 172.16.0.211...</span><br><span class="line">* Connected to web1.com (172.16.0.211) port 31380 (#0)</span><br><span class="line">&gt; GET /index.html HTTP/1.1</span><br><span class="line">&gt; User-Agent: curl/7.29.0</span><br><span class="line">&gt; Host: web1.com:31380</span><br><span class="line">&gt; Accept: */*</span><br><span class="line">&gt; </span><br><span class="line">&lt; HTTP/1.1 200 OK</span><br><span class="line">&lt; server: istio-envoy</span><br><span class="line">&lt; date: Wed, 29 Apr 2020 05:34:12 GMT</span><br><span class="line">&lt; content-type: text/html</span><br><span class="line">&lt; content-length: 7</span><br><span class="line">&lt; last-modified: Wed, 25 Mar 2020 15:18:37 GMT</span><br><span class="line">&lt; etag: &quot;5e7b764d-7&quot;</span><br><span class="line">&lt; accept-ranges: bytes</span><br><span class="line">&lt; x-envoy-upstream-service-time: 1</span><br><span class="line">&lt; </span><br><span class="line">app v2</span><br><span class="line">* Connection #0 to host web1.com left intact</span><br><span class="line">[root@node02 ~]# curl -v -H Host:web1.com http://web1.com:31380/index.html</span><br><span class="line">* About to connect() to web1.com port 31380 (#0)</span><br><span class="line">*   Trying 172.16.0.211...</span><br><span class="line">* Connected to web1.com (172.16.0.211) port 31380 (#0)</span><br><span class="line">&gt; GET /index.html HTTP/1.1</span><br><span class="line">&gt; User-Agent: curl/7.29.0</span><br><span class="line">&gt; Accept: */*</span><br><span class="line">&gt; Host:web1.com</span><br><span class="line">&gt; </span><br><span class="line">&lt; HTTP/1.1 404 Not Found</span><br><span class="line">&lt; date: Wed, 29 Apr 2020 05:34:25 GMT</span><br><span class="line">&lt; server: istio-envoy</span><br><span class="line">&lt; content-length: 0</span><br><span class="line">&lt; </span><br><span class="line">* Connection #0 to host web1.com left intact</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="3-设置ingressGateway使用LoadBalancer"><a href="#3-设置ingressGateway使用LoadBalancer" class="headerlink" title="3 设置ingressGateway使用LoadBalancer"></a>3 设置ingressGateway使用LoadBalancer</h4><p>ingressGateway使用LoadBancer，设置好对应的地址即可</p>
<p><img src="/images/mk/istio_access_error/use-loadbalancer.png" alt="use-loadbalancer"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>相关issue参考：<a href="https://github.com/istio/istio/issues/11828">https://github.com/istio/istio/issues/11828</a></p>
<p>官方istio VirtualService设置选项：<a href="https://istio.io/zh/docs/reference/config/networking/virtual-service/#HTTPMatchRequest">https://istio.io/zh/docs/reference/config/networking/virtual-service/#HTTPMatchRequest</a></p>
]]></content>
      <categories>
        <category>istio</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>istio</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s≥1.18版本查看yaml取消显示manageFields字段的方法</title>
    <url>/2021/05/12/k8s%E2%89%A51.18%E7%89%88%E6%9C%AC%E6%9F%A5%E7%9C%8Byaml%E5%8F%96%E6%B6%88%E6%98%BE%E7%A4%BAmanageFields%E5%AD%97%E6%AE%B5%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>当k8s版本≥1.18时，通过<code>kubectl get &lt;resources&gt; -oyaml</code>查看资源的yaml配置信息时，会有一个manageFields字段，影响对配置的阅读，如下：</p>
<p><img src="/images/mk/k8s%E2%89%A51.18%E7%89%88%E6%9C%AC%E6%9F%A5%E7%9C%8Byaml%E5%8F%96%E6%B6%88%E6%98%BE%E7%A4%BAmanageFields%E5%AD%97%E6%AE%B5%E7%9A%84%E6%96%B9%E6%B3%95.assets/yaml-1.png" alt="yaml-1"></p>
<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>这是之前一个叫做 “Server-side Apply” 的功能，在 1.18.0 版本中，功能由 Alpha 进入到了 Beta，也在 Api-Server 中默认打开，而这些奇怪的字段就叫做 “managedFields” 。 如果实在是不想有这些字段，可以在 Api-Server 配置中 Feature-gate 将这个功能关掉 (字段名字就叫做 “Server-side Apply” )。</p>
<p>Server side Apply：Server side Apply协助用户、控制器通过声明式配置的方式管理他们的资源。它发送完整描述的目标（A fully specified intent）， 声明式地创建和/或修改 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/kubernetes-objects/">对象</a>。</p>
<p>具体可以参考官方文档：<a href="https://kubernetes.io/zh/docs/reference/using-api/server-side-apply/">https://kubernetes.io/zh/docs/reference/using-api/server-side-apply/</a></p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>在kube-apiserver的配置中，设置<code>ServerSideApply=false</code>即可</p>
<p>例如，如果是rancher的集群，编辑cluster.yaml文件，在如下位置添加这个配置</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kube-api:</span></span><br><span class="line">      <span class="attr">extra_args:</span></span><br><span class="line">        <span class="attr">feature-gates:</span> <span class="string">ServerSideApply=false</span></span><br></pre></td></tr></table></figure>

<p>等待集群更新完之后，重建工作负载，manageFields配置就不会再显示了</p>
<p><img src="/images/mk/k8s%E2%89%A51.18%E7%89%88%E6%9C%AC%E6%9F%A5%E7%9C%8Byaml%E5%8F%96%E6%B6%88%E6%98%BE%E7%A4%BAmanageFields%E5%AD%97%E6%AE%B5%E7%9A%84%E6%96%B9%E6%B3%95.assets/yaml-2.png" alt="yaml-2"></p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s使用log-pilot获取pod日志，并对接到kafka</title>
    <url>/2020/08/20/k8s%E4%BD%BF%E7%94%A8log-pilot%E8%8E%B7%E5%8F%96pod%E6%97%A5%E5%BF%97%EF%BC%8C%E5%B9%B6%E5%AF%B9%E6%8E%A5%E5%88%B0kafka/</url>
    <content><![CDATA[<p>利用log-pilot + kafka 搭建k8s日志系统</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>Kubernetes</td>
<td>v1.18.6</td>
</tr>
<tr>
<td>Rancher</td>
<td>v2.4.5</td>
</tr>
</tbody></table>
<h2 id="安装kafka"><a href="#安装kafka" class="headerlink" title="安装kafka"></a>安装kafka</h2><p>安装log-pilot前，需要先安装kafka</p>
<ol>
<li>通过Rancher应用商店安装kafka</li>
</ol>
<p>)</p>
<ol start="2">
<li>获取kafkaBroken地址</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl -n kafka get svc -o wide </span></span><br><span class="line">NAME                          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE     SELECTOR</span><br><span class="line">kafka-cp-kafka                ClusterIP   10.43.180.111   &lt;none&gt;        9092/TCP            2m31s   app=cp-kafka,release=kafka</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>



<h2 id="安装log-pilot"><a href="#安装log-pilot" class="headerlink" title="安装log-pilot"></a>安装log-pilot</h2><p>log-pilot支持docker run的方式启动，也支持在k8s中通过daemonsest的方式启动</p>
<p>k8s启动yaml：<a href="https://github.com/AliyunContainerService/log-pilot/tree/master/examples">https://github.com/AliyunContainerService/log-pilot/tree/master/examples</a></p>
<p>log-pilot安装参考：<a href="https://www.cnblogs.com/uglyliu/p/12382214.html">https://www.cnblogs.com/uglyliu/p/12382214.html</a></p>
<ol>
<li>下载官方的yaml文件，修改kafka-broken地址</li>
</ol>
<p><a href="https://github.com/AliyunContainerService/log-pilot/blob/master/examples/pilot-kafka-kubernetes.yml">https://github.com/AliyunContainerService/log-pilot/blob/master/examples/pilot-kafka-kubernetes.yml</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  namespace: pilot</span><br><span class="line">  name: log-pilot</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: log-pilot</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: log-pilot</span><br><span class="line">  updateStrategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: log-pilot</span><br><span class="line">    spec:</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: node-role.kubernetes.io&#x2F;master</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      containers:</span><br><span class="line">      - name: log-pilot</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com&#x2F;acs&#x2F;log-pilot:0.9.5-fluentd</span><br><span class="line">        env:</span><br><span class="line">          - name: &quot;LOGGING_OUTPUT&quot;</span><br><span class="line">            value: &quot;kafka&quot;</span><br><span class="line">          - name: &quot;KAFKA_BROKERS&quot;</span><br><span class="line">            value: &quot;10.43.180.111:9092&quot;     ## 修改为对应的broken地址，多个地址以逗号分隔</span><br><span class="line">          - name: &quot;NODE_NAME&quot;</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                fieldPath: spec.nodeName</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: sock</span><br><span class="line">          mountPath: &#x2F;var&#x2F;run&#x2F;docker.sock</span><br><span class="line">        - name: root</span><br><span class="line">          mountPath: &#x2F;host</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: pos</span><br><span class="line">          mountPath: &#x2F;pilot&#x2F;pos</span><br><span class="line">        - name: localtime</span><br><span class="line">          mountPath: &#x2F;etc&#x2F;localtime</span><br><span class="line">        securityContext:</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - SYS_ADMIN</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: sock</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;var&#x2F;run&#x2F;docker.sock</span><br><span class="line">      - name: root</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;</span><br><span class="line">      - name: pos</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      - name: localtime</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;etc&#x2F;localtime</span><br></pre></td></tr></table></figure>

<p>官方的yaml使用的是extensions/v1beta1，适用于k8s &lt;=1.15版本，k8s&gt;=1.16版本就要改成apps/v1</p>
<ol start="2">
<li>部署log-pilot</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">创建命名空间</span><br><span class="line"># kubectl create ns pilot</span><br><span class="line">namespace&#x2F;pilot created</span><br><span class="line"></span><br><span class="line">执行该文件</span><br><span class="line"># kubectl apply  -f log-pilot.yaml </span><br><span class="line">daemonset.apps&#x2F;log-pilot created</span><br><span class="line"></span><br><span class="line">查看是否启动成功</span><br><span class="line"># kubectl -n pilot get pod -o wide</span><br><span class="line">NAME              READY   STATUS    RESTARTS   AGE   IP           NODE          NOMINATED NODE   READINESS GATES</span><br><span class="line">log-pilot-fcddx   1&#x2F;1     Running   0          70s   10.42.1.13   ubuntu001     &lt;none&gt;           &lt;none&gt;</span><br><span class="line">log-pilot-sktpt   1&#x2F;1     Running   0          70s   10.42.0.22   xie-node001   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">log-pilot-td4z8   1&#x2F;1     Running   0          70s   10.42.2.21   ubuntu002     &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>



<h2 id="收集pod日志"><a href="#收集pod日志" class="headerlink" title="收集pod日志"></a>收集pod日志</h2><p>有两种收集方式：</p>
<ol>
<li>通过抓取pod 控制台输出</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">env:</span><br><span class="line">- name: aliyun_logs_mylog</span><br><span class="line">  value: stdout</span><br><span class="line">- name: aliyun_logs_mylog_tags</span><br><span class="line">  value: &quot;topic&#x3D;k8s-mylog&quot; </span><br></pre></td></tr></table></figure>



<ol start="2">
<li>通过读取某个日志文件路径</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">env:</span><br><span class="line">- name: aliyun_logs_mylog</span><br><span class="line">  value: &#x2F;var&#x2F;log&#x2F;xxx.log</span><br><span class="line">- name: aliyun_logs_mylog_tags</span><br><span class="line">  value: &quot;topic&#x3D;k8s-mylog&quot;</span><br></pre></td></tr></table></figure>



<p>参数说明：</p>
<p><code>aliyun_logs_mylog</code>：收集带有aliyun_logs关键字的pod的日志，对应的值如果为stdout，则会收集控制台输出，如果值为某个日志文件路径，则收集该文件的日志</p>
<p><code>aliyun_logs_mylog_tags</code>：对接kafka一定要配置这个tag，如果是其他的可以不定义这个。值为设置对应的topic</p>
<p><code>aliyun_logs_mylog_format</code>：如果日志是json格式，可以设置这个参数，值为json，但是如果日志格式不是json而设置了这个参数，则无法收集到日志</p>
]]></content>
      <categories>
        <category>log-pilot</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>log-pilot</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s对接Samba&amp;CIFS文件共享存储</title>
    <url>/2021/03/17/k8s%E5%AF%B9%E6%8E%A5Samba&amp;CIFS%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>kubernetes提供CSI驱动将外部存储提供给pod中使用，例如我们可以通过CSI驱动对接Samba/CIFS共享文件存储</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ul>
<li>Kubernetes 1.16+</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="安装SMB-CSI驱动（二选一）"><a href="#安装SMB-CSI驱动（二选一）" class="headerlink" title="安装SMB CSI驱动（二选一）"></a>安装SMB CSI驱动（二选一）</h3><p>通过kubectl安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -skSL https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/v0.6.0/deploy/install-driver.sh | bash -s v0.6.0 --</span><br></pre></td></tr></table></figure>

<p>通过helm安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add csi-driver-smb https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/charts</span><br><span class="line">helm install csi-driver-smb csi-driver-smb/csi-driver-smb --namespace kube-system</span><br></pre></td></tr></table></figure>

<p>查看pod状态是否正常</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n kube-system get pod |grep csi-smb</span><br></pre></td></tr></table></figure>



<h3 id="在kubernetes集群中安装Samba服务（可选）"><a href="#在kubernetes集群中安装Samba服务（可选）" class="headerlink" title="在kubernetes集群中安装Samba服务（可选）"></a>在kubernetes集群中安装Samba服务（可选）</h3><p>首先创建一个secret保存用户和密码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create secret generic smbcreds --from-literal username=rancher --from-literal password=<span class="string">&quot;rancher&quot;</span></span><br></pre></td></tr></table></figure>

<p>接着创建Samba服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/csi-driver-smb/master/deploy/example/smb-provisioner/smb-server.yaml</span><br></pre></td></tr></table></figure>

<p>查看Samba服务状态是否正常</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod |grep smb</span><br></pre></td></tr></table></figure>



<h3 id="创建storage-class"><a href="#创建storage-class" class="headerlink" title="创建storage class"></a>创建storage class</h3><p>新建<code>storage-class.yaml</code>文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">smb</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">smb.csi.k8s.io</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">source:</span> <span class="string">&quot;//smb-server.default.svc.cluster.local/share&quot;</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">&quot;smbcreds&quot;</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">&quot;default&quot;</span></span><br><span class="line">  <span class="attr">createSubDir:</span> <span class="string">&quot;false&quot;</span>  <span class="comment"># optional: create a sub dir for new volume</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Retain</span>  <span class="comment"># only retain is supported</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span></span><br><span class="line"><span class="attr">mountOptions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">dir_mode=0777</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">file_mode=0777</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">uid=1001</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">gid=1001</span></span><br></pre></td></tr></table></figure>

<p>其中<code>csi.storage.k8s.io/node-stage-secret-name</code>对应的是上一步创建的secret</p>
<p>创建storage class</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f storage-class.yaml</span><br></pre></td></tr></table></figure>



<h3 id="部署应用"><a href="#部署应用" class="headerlink" title="部署应用"></a>部署应用</h3><p>创建一个statefulset类型的应用，并挂载Samba卷</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">statefulset-smb</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">statefulset-smb</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">&quot;kubernetes.io/os&quot;:</span> <span class="string">linux</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">statefulset-smb</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">mcr.microsoft.com/oss/nginx/nginx:1.19.5</span></span><br><span class="line">          <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;/bin/bash&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&quot;-c&quot;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">set</span> <span class="string">-euo</span> <span class="string">pipefail;</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span> <span class="string">echo</span> <span class="string">$(date)</span> <span class="string">&gt;&gt;</span> <span class="string">/mnt/smb/outfile;</span> <span class="string">sleep</span> <span class="number">1</span><span class="string">;</span> <span class="string">done</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">persistent-storage</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/mnt/smb</span></span><br><span class="line">  <span class="attr">updateStrategy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">RollingUpdate</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">persistent-storage</span></span><br><span class="line">        <span class="attr">annotations:</span></span><br><span class="line">          <span class="attr">volume.beta.kubernetes.io/storage-class:</span> <span class="string">smb</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">accessModes:</span> [<span class="string">&quot;ReadWriteOnce&quot;</span>]</span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">storage:</span> <span class="string">10Gi</span></span><br></pre></td></tr></table></figure>

<p>创建该应用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f statefulset-smb.yaml</span><br></pre></td></tr></table></figure>

<p>查看应用状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod</span><br></pre></td></tr></table></figure>

<p>在pod中执行<code>df -h</code>查看Samba挂载情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl exec -it statefulset-smb-0 sh</span></span><br><span class="line">kubectl <span class="built_in">exec</span> [POD] [COMMAND] is DEPRECATED and will be removed <span class="keyword">in</span> a future version. Use kubectl <span class="built_in">exec</span> [POD] -- [COMMAND] instead.</span><br><span class="line"><span class="comment"># df -h</span></span><br><span class="line">Filesystem                                    Size  Used Avail Use% Mounted on</span><br><span class="line">overlay                                        40G   19G   20G  50% /</span><br><span class="line">tmpfs                                          64M     0   64M   0% /dev</span><br><span class="line">tmpfs                                         3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/ubuntu--vg-ubuntu--lv              40G   19G   20G  50% /etc/hosts</span><br><span class="line">//smb-server.default.svc.cluster.local/share   40G   21G   20G  52% /mnt/smb</span><br><span class="line">shm                                            64M     0   64M   0% /dev/shm</span><br><span class="line">tmpfs                                         3.9G   12K  3.9G   1% /run/secrets/kubernetes.io/serviceaccount</span><br><span class="line">tmpfs                                         3.9G     0  3.9G   0% /proc/acpi</span><br><span class="line">tmpfs                                         3.9G     0  3.9G   0% /proc/scsi</span><br><span class="line">tmpfs                                         3.9G     0  3.9G   0% /sys/firmware</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>可以看到，<code>/mnt/smb</code>目录挂载了<code>//smb-server.default.svc.cluster.local/share</code>  Samba文件存储</p>
<h3 id="对接-Windows-共享文件夹"><a href="#对接-Windows-共享文件夹" class="headerlink" title="对接 Windows 共享文件夹"></a>对接 Windows 共享文件夹</h3><p>创建新的storage class yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">smb-windows</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">smb.csi.k8s.io</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">source:</span> <span class="string">&quot;//172.16.30.8/share&quot;</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">&quot;smbcreds&quot;</span></span><br><span class="line">  <span class="attr">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">&quot;default&quot;</span></span><br><span class="line">  <span class="attr">createSubDir:</span> <span class="string">&quot;false&quot;</span>  <span class="comment"># optional: create a sub dir for new volume</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Retain</span>  <span class="comment"># only retain is supported</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span></span><br><span class="line"><span class="attr">mountOptions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">dir_mode=0777</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">file_mode=0777</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">uid=1001</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">gid=1001</span></span><br></pre></td></tr></table></figure>

<p>其中<code>source</code>填写对应的Windows主机的IP地址和共享文件路径</p>
<p>创建storage class</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f storage-class-win.yaml</span><br></pre></td></tr></table></figure>

<p>其他的操作都一样，正常创建工作负载对接PVC即可</p>
<blockquote>
<p>参考：<a href="https://github.com/kubernetes-csi/csi-driver-smb">https://github.com/kubernetes-csi/csi-driver-smb</a></p>
</blockquote>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka对接Rancher日志</title>
    <url>/2020/11/26/kafka%E5%AF%B9%E6%8E%A5Rancher%E6%97%A5%E5%BF%97/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Rancher应用商店自带的kafka可以方便的对接Rancher日志，但是不支持sasl认证。</p>
<p>如果有认证需求，可以使用bitnami仓库的kafka，这个kafka带有相关的认证参数，可以很方便的开启sasl相关的认证。</p>
<blockquote>
<p>参考：<a href="https://github.com/bitnami/charts/tree/master/bitnami/kafka">https://github.com/bitnami/charts/tree/master/bitnami/kafka</a></p>
</blockquote>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>kubernetes</td>
<td>v1.19.3</td>
</tr>
<tr>
<td>Rancher</td>
<td>v2.4.8 | v2.5.2</td>
</tr>
<tr>
<td>kafka</td>
<td>2.6.0</td>
</tr>
<tr>
<td>kafka-chart</td>
<td>11.8.9</td>
</tr>
<tr>
<td>helm</td>
<td>3.4.0</td>
</tr>
</tbody></table>
<h2 id="正常对接kafka集群"><a href="#正常对接kafka集群" class="headerlink" title="正常对接kafka集群"></a>正常对接kafka集群</h2><p>如果是需要开启SASL认证，可以直接跳到后面<strong>开启SASL认证方式</strong>的内容</p>
<h3 id="1、helm添加bitnami库"><a href="#1、helm添加bitnami库" class="headerlink" title="1、helm添加bitnami库"></a>1、helm添加bitnami库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure>



<h3 id="2、下载-kafka-对应的chart压缩文件"><a href="#2、下载-kafka-对应的chart压缩文件" class="headerlink" title="2、下载 kafka 对应的chart压缩文件"></a>2、下载 kafka 对应的chart压缩文件</h3><p>bitnami库国内可能访问不太友好，需要翻一下墙。。。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm pull bitnami/kafka --version 11.8.9</span><br></pre></td></tr></table></figure>

<p>上述命令会下载一个<code>kafka-11.8.9-tgz</code>的压缩文件，解压该文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf kafka-11.8.9-tgz</span><br></pre></td></tr></table></figure>

<p>查看解压目录内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd kafka/</span></span><br><span class="line"><span class="comment"># ls</span></span><br><span class="line">charts  Chart.yaml  files  README.md  requirements.lock  requirements.yaml  templates  values-production.yaml  values.yaml</span><br></pre></td></tr></table></figure>

<p>可以看到有两个values文件，分别是<code>values.yaml</code>和<code>values-production.yaml</code>，</p>
<p>其中<code>values.yaml</code>会启动一个最简单的kafka集群，</p>
<p>而<code>values-production.yaml</code>中的配置会包含更多面向生产的配置，例如启用持久化存储，启用sasl相关认证等。</p>
<h3 id="3、启动kafka集群"><a href="#3、启动kafka集群" class="headerlink" title="3、启动kafka集群"></a>3、启动kafka集群</h3><p>最简化启动kafka集群，可以添加这两个参数，取消持久化存储</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create ns kafka</span><br><span class="line"><span class="comment">## 进入到kafka目录下再执行下面的命令</span></span><br><span class="line">helm install kafka -n kafka -f values.yaml --<span class="built_in">set</span> persistence.enabled=<span class="literal">false</span> --<span class="built_in">set</span> zookeeper.persistence.enabled=<span class="literal">false</span> .</span><br></pre></td></tr></table></figure>

<p>或者如果k8s有持久化存储，可以设置storage Class，将<code>xxx</code>替换为对应的storage Class</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">helm install kafka -n kafka -f values.yaml --set global.storageClass&#x3D;xxx .</span><br></pre></td></tr></table></figure>

<p>执行完<code>helm install</code>后会输出以下内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME: kafka</span><br><span class="line">LAST DEPLOYED: Wed Nov 25 17:04:50 2020</span><br><span class="line">NAMESPACE: kafka</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line">** Please be patient <span class="keyword">while</span> the chart is being deployed **</span><br><span class="line"></span><br><span class="line">Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:</span><br><span class="line"></span><br><span class="line">    kafka.kafka.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:</span><br><span class="line"></span><br><span class="line">    kafka-0.kafka-headless.kafka.svc.cluster.local:9092</span><br><span class="line"></span><br><span class="line">To create a pod that you can use as a Kafka client run the following commands:</span><br><span class="line"></span><br><span class="line">    kubectl run kafka-client --restart=<span class="string">&#x27;Never&#x27;</span> --image docker.io/bitnami/kafka:2.6.0-debian-10-r57 --namespace kafka --<span class="built_in">command</span> -- sleep infinity</span><br><span class="line">    kubectl <span class="built_in">exec</span> --tty -i kafka-client --namespace kafka -- bash</span><br><span class="line"></span><br><span class="line">    PRODUCER:</span><br><span class="line">        kafka-console-producer.sh \</span><br><span class="line">            </span><br><span class="line">            --broker-list kafka-0.kafka-headless.kafka.svc.cluster.local:9092 \</span><br><span class="line">            --topic <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">    CONSUMER:</span><br><span class="line">        kafka-console-consumer.sh \</span><br><span class="line">            </span><br><span class="line">            --bootstrap-server kafka.kafka.svc.cluster.local:9092 \</span><br><span class="line">            --topic <span class="built_in">test</span> \</span><br><span class="line">            --from-beginning</span><br></pre></td></tr></table></figure>

<p>查看pod、svc状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod,svc -n kafka</span></span><br><span class="line">NAME                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/kafka-0             0/1     Pending   0          34s</span><br><span class="line">pod/kafka-client        1/1     Running   0          3d21h</span><br><span class="line">pod/kafka-zookeeper-0   1/1     Running   0          34s</span><br><span class="line"></span><br><span class="line">NAME                               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">service/kafka                      ClusterIP   10.43.97.41     &lt;none&gt;        9092/TCP                     34s</span><br><span class="line">service/kafka-headless             ClusterIP   None            &lt;none&gt;        9092/TCP,9093/TCP            34s</span><br><span class="line">service/kafka-zookeeper            ClusterIP   10.43.127.105   &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   34s</span><br><span class="line">service/kafka-zookeeper-headless   ClusterIP   None            &lt;none&gt;        2181/TCP,2888/TCP,3888/TCP   34s</span><br></pre></td></tr></table></figure>



<h3 id="4、操作kafka集群"><a href="#4、操作kafka集群" class="headerlink" title="4、操作kafka集群"></a>4、操作kafka集群</h3><p>根据helm创建成功的提示，我们可以创建客户端去执行kafka相关的操作</p>
<p>创建kafka-client的pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl run kafka-client --restart=<span class="string">&#x27;Never&#x27;</span> --image docker.io/bitnami/kafka:2.6.0-debian-10-r57 --namespace kafka --<span class="built_in">command</span> -- sleep infinity</span><br></pre></td></tr></table></figure>

<p>进入到容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n kafka <span class="built_in">exec</span> -it kafka-client bash</span><br></pre></td></tr></table></figure>

<h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><p>kafka有生产者和消费者的概念，生产者会生产数据，消费者去消费生产者产生的数据，具体可以先了解一下相关的概念</p>
<p>首先生产者先生产数据，执行如下命令，可以进入到生产者的input端</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list kafka-0.kafka-headless.kafka.svc.cluster.local:9092 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p>例如我们输入<code>rancher run everywhere</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; rancher run everywhere</span><br></pre></td></tr></table></figure>

<h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><p>然后消费者消费数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server kafka.kafka.svc.cluster.local:9092 --topic <span class="built_in">test</span> --from-beginning</span><br></pre></td></tr></table></figure>

<p>输入上述命令，就可以查看到刚刚在生产者生产的数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rancher run everything</span><br></pre></td></tr></table></figure>



<h3 id="5、对接Rancher-logging"><a href="#5、对接Rancher-logging" class="headerlink" title="5、对接Rancher logging"></a>5、对接Rancher logging</h3><p> 首先在Rancher上创建一个项目，并部署一个nginx应用</p>
<p><a href="https://imgchr.com/i/D0Ss2D"><img src="https://s3.ax1x.com/2020/11/26/D0Ss2D.png" alt="D0Ss2D.png"></a></p>
<p>接着在跳转到工具 -&gt; 日志，选择Kafka</p>
<p>有两种方式连接到kafka集群，分别是zookeeper和broker，这里以zookeeper访问端点类型为例</p>
<p><a href="https://imgchr.com/i/D0ScKH"><img src="https://s3.ax1x.com/2020/11/26/D0ScKH.png" alt="D0ScKH.png"></a></p>
<p>参数解释：</p>
<p>**<code>访问地址</code>**：<a href="http://kafka-zookeeper.kafka:2181，这里填写对应的访问地址，由于选择的是zookeeper，所以填写zookeeper相关的service访问地址，也可以写clusterIP，默认端口是2181">http://kafka-zookeeper.kafka:2181，这里填写对应的访问地址，由于选择的是zookeeper，所以填写zookeeper相关的service访问地址，也可以写clusterIP，默认端口是2181</a></p>
<p>**<code>主题</code>**：rancher，日志将会发送到这个主题上</p>
<p>其他参数：</p>
<p>**<code>刷新时间间隔</code>**：默认60s，如果是测试环境，可以设置为10s更快的查看效果</p>
<hr>
<p>点击测试按钮，等待结果返回验证通过后，点击保存按钮，Rancher会在System项目下创建相应的fluentd工作负载，到这里日志对接基本没问题了</p>
<h3 id="6、验证效果"><a href="#6、验证效果" class="headerlink" title="6、验证效果"></a>6、验证效果</h3><p>访问nginx应用，然后等待对应的刷新时间间隔后，在kafka-client中查看是否能消费到数据</p>
<p><a href="https://imgchr.com/i/D0Sr8O"><img src="https://s3.ax1x.com/2020/11/26/D0Sr8O.png" alt="D0Sr8O.png"></a></p>
<h2 id="开启SASL认证方式"><a href="#开启SASL认证方式" class="headerlink" title="开启SASL认证方式"></a>开启SASL认证方式</h2><p><code>values-production.yaml</code>中的配置会包含更多面向生产的配置，例如启用持久化存储，启用sasl相关认证等，所以可以直接使用这个配置文件进行创建kafka集群，会自动sasl相关认证的功能</p>
<h3 id="1、helm-安装kafka"><a href="#1、helm-安装kafka" class="headerlink" title="1、helm 安装kafka"></a>1、helm 安装kafka</h3><p>这里为了方便都关闭了,取消了持久化存储，关闭了相关metric，设置生产环境按需开启</p>
<p>其中<code>autoCreateTopicsEnable</code>设置为true，作用是开启自动创建topic功能，如果关闭这个，则需要手动创建topic才能对接rancher，生产环境也建议关闭掉</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install kafka -n kafka -f values-production.yaml --<span class="built_in">set</span> persistence.enabled=<span class="literal">false</span> --<span class="built_in">set</span> zookeeper.persistence.enabled=<span class="literal">false</span> --<span class="built_in">set</span> metrics.kafka.enabled=<span class="literal">false</span> --<span class="built_in">set</span> metrics.jmx.enabled=<span class="literal">false</span> --<span class="built_in">set</span> zookeeper.metrics.enabled=<span class="literal">false</span> --<span class="built_in">set</span> autoCreateTopicsEnable=<span class="literal">true</span> .</span><br></pre></td></tr></table></figure>

<p>执行完<code>helm install</code>后会输出以下内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME: kafka</span><br><span class="line">LAST DEPLOYED: Wed Nov 25 18:49:35 2020</span><br><span class="line">NAMESPACE: kafka</span><br><span class="line">STATUS: deployed</span><br><span class="line">REVISION: 1</span><br><span class="line">TEST SUITE: None</span><br><span class="line">NOTES:</span><br><span class="line">** Please be patient while the chart is being deployed **</span><br><span class="line"></span><br><span class="line">Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:</span><br><span class="line"></span><br><span class="line">    kafka.kafka.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:</span><br><span class="line"></span><br><span class="line">    kafka-0.kafka-headless.kafka.svc.cluster.local:9092</span><br><span class="line">    kafka-1.kafka-headless.kafka.svc.cluster.local:9092</span><br><span class="line">    kafka-2.kafka-headless.kafka.svc.cluster.local:9092</span><br><span class="line"></span><br><span class="line">You need to configure your Kafka client to access using SASL authentication. To do so, you need to create the &#39;kafka_jaas.conf&#39; and &#39;client.properties&#39; configuration files by executing these commands:</span><br><span class="line"></span><br><span class="line">    - kafka_jaas.conf:</span><br><span class="line"></span><br><span class="line">cat &gt; kafka_jaas.conf &lt;&lt;EOF</span><br><span class="line">KafkaClient &#123;</span><br><span class="line">org.apache.kafka.common.security.scram.ScramLoginModule required</span><br><span class="line">username&#x3D;&quot;user&quot;</span><br><span class="line">password&#x3D;&quot;$(kubectl get secret kafka-jaas -n kafka -o jsonpath&#x3D;&#39;&#123;.data.client-passwords&#125;&#39; | base64 --decode | cut -d , -f 1)&quot;;</span><br><span class="line">&#125;;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">    - client.properties:</span><br><span class="line"></span><br><span class="line">cat &gt; client.properties &lt;&lt;EOF</span><br><span class="line">security.protocol&#x3D;SASL_PLAINTEXT</span><br><span class="line">sasl.mechanism&#x3D;SCRAM-SHA-256</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">To create a pod that you can use as a Kafka client run the following commands:</span><br><span class="line"></span><br><span class="line">    kubectl run kafka-client --restart&#x3D;&#39;Never&#39; --image docker.io&#x2F;bitnami&#x2F;kafka:2.6.0-debian-10-r57 --namespace kafka --command -- sleep infinity</span><br><span class="line">    kubectl cp --namespace kafka &#x2F;path&#x2F;to&#x2F;client.properties kafka-client:&#x2F;tmp&#x2F;client.properties</span><br><span class="line">    kubectl cp --namespace kafka &#x2F;path&#x2F;to&#x2F;kafka_jaas.conf kafka-client:&#x2F;tmp&#x2F;kafka_jaas.conf</span><br><span class="line">    kubectl exec --tty -i kafka-client --namespace kafka -- bash</span><br><span class="line">    export KAFKA_OPTS&#x3D;&quot;-Djava.security.auth.login.config&#x3D;&#x2F;tmp&#x2F;kafka_jaas.conf&quot;</span><br><span class="line"></span><br><span class="line">    PRODUCER:</span><br><span class="line">        kafka-console-producer.sh \</span><br><span class="line">            --producer.config &#x2F;tmp&#x2F;client.properties \</span><br><span class="line">            --broker-list kafka-0.kafka-headless.kafka.svc.cluster.local:9092,kafka-1.kafka-headless.kafka.svc.cluster.local:9092,kafka-2.kafka-headless.kafka.svc.cluster.local:9092 \</span><br><span class="line">            --topic test</span><br><span class="line"></span><br><span class="line">    CONSUMER:</span><br><span class="line">        kafka-console-consumer.sh \</span><br><span class="line">            --consumer.config &#x2F;tmp&#x2F;client.properties \</span><br><span class="line">            --bootstrap-server kafka.kafka.svc.cluster.local:9092 \</span><br><span class="line">            --topic test \</span><br><span class="line">            --from-beginning</span><br></pre></td></tr></table></figure>

<p>可以看到，已经在k8s集群中创建了3个节点的kafka集群</p>
<h3 id="2、创建kafka-client端"><a href="#2、创建kafka-client端" class="headerlink" title="2、创建kafka client端"></a>2、创建kafka client端</h3><p>由于设置了sasl认证，所以需要创建<code>client.properties</code>和<code>kafka_jaas.conf</code>两个文件，并拷贝到client端，client端使用这两个配置文件才能对kafka集群进行相关操作</p>
<p>创建kafka_jaas.conf</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; kafka_jaas.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">KafkaClient &#123;</span></span><br><span class="line"><span class="string">org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class="line"><span class="string">username=&quot;user&quot;</span></span><br><span class="line"><span class="string">password=&quot;$(kubectl get secret kafka-jaas -n kafka -o jsonpath=&#x27;&#123;.data.client-passwords&#125;&#x27; | base64 --decode | cut -d , -f 1)&quot;;</span></span><br><span class="line"><span class="string">&#125;;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>创建kafka_jaas.conf</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &gt; kafka_jaas.conf &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">KafkaClient &#123;</span></span><br><span class="line"><span class="string">org.apache.kafka.common.security.scram.ScramLoginModule required</span></span><br><span class="line"><span class="string">username=&quot;user&quot;</span></span><br><span class="line"><span class="string">password=&quot;$(kubectl get secret kafka-jaas -n kafka -o jsonpath=&#x27;&#123;.data.client-passwords&#125;&#x27; | base64 --decode | cut -d , -f 1)&quot;;</span></span><br><span class="line"><span class="string">&#125;;</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>拷贝到client端内</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl run kafka-client --restart=<span class="string">&#x27;Never&#x27;</span> --image docker.io/bitnami/kafka:2.6.0-debian-10-r57 --namespace kafka --<span class="built_in">command</span> -- sleep infinity</span><br><span class="line">kubectl cp --namespace kafka client.properties kafka-client:/tmp/client.properties</span><br><span class="line">kubectl cp --namespace kafka kafka_jaas.conf kafka-client:/tmp/kafka_jaas.conf</span><br></pre></td></tr></table></figure>



<h3 id="3、Rancher对接Kafka"><a href="#3、Rancher对接Kafka" class="headerlink" title="3、Rancher对接Kafka"></a>3、Rancher对接Kafka</h3><p>SASL认证，只支持通过broker连接入口，所以需要配置broker相关参数</p>
<p><a href="https://imgchr.com/i/D0Syxe"><img src="https://s3.ax1x.com/2020/11/26/D0Syxe.png" alt="D0Syxe.png"></a></p>
<p><strong>kafka配置</strong></p>
<p>访问端点类型：选择Broker</p>
<p>访问地址：填写kafka serviceIP地址，这里填写<code>http://kafka.kafka:9092</code></p>
<p>主题：日志发送的主题</p>
<p><strong>SSL配置</strong></p>
<p>如果SASL类型为Scram，则不用配置SSL，反之当SASL类型为Plain时，需要配置SSL</p>
<p><strong>SASL配置</strong></p>
<p>用户名：默认是user，可以在values.yaml中，通过配置<code>auth.jaas.clientUsers</code>修改</p>
<p>密码：默认是随机值，可以通过<code>kubectl get secret kafka-jaas -n kafka -o jsonpath=&#39;&#123;.data.client-passwords&#125;&#39; | base64 --decode | cut -d , -f 1</code>这个命令查看，另外也可以通过配置<code>auth.jaas.clientPasswords</code>来修改</p>
<p>类型：Scram</p>
<p>安全机制：sha256</p>
<hr>
<p>点击测试按钮，等待结果返回验证通过后，点击保存按钮，Rancher会在System项目下创建相应的fluentd工作负载，到这里日志对接基本没问题了</p>
<h3 id="4、验证效果"><a href="#4、验证效果" class="headerlink" title="4、验证效果"></a>4、验证效果</h3><p>通过kafka-client查看日志是否对接成功</p>
<p>进入kafka-client pod bash环境</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it kafka-client -n kafka -- bash</span><br></pre></td></tr></table></figure>

<p>由于开启了认证，需要export相关环境变量</p>
<p>最后通过kafka-console-consumer.sh命令查看日志是否发送过来了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KAFKA_OPTS=<span class="string">&quot;-Djava.security.auth.login.config=/tmp/kafka_jaas.conf&quot;</span></span><br><span class="line"></span><br><span class="line">kafka-console-consumer.sh  --consumer.config /tmp/client.properties  --bootstrap-server kafka.kafka.svc.cluster.local:9092  --topic rancher  --from-beginning</span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<p><a href="https://imgchr.com/i/D0Sgrd"><img src="https://s3.ax1x.com/2020/11/26/D0Sgrd.png" alt="D0Sgrd.png"></a></p>
<h2 id="kafka-client相关命令"><a href="#kafka-client相关命令" class="headerlink" title="kafka-client相关命令"></a>kafka-client相关命令</h2><p>查看topic 列表</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper kafka-zookeeper:2181 --list</span><br></pre></td></tr></table></figure>



<p>创建topic</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --zookeeper kafka-zookeeper:2181 --topic rancher --create --partitions 1 --replication-factor 1</span><br></pre></td></tr></table></figure>



<p>删除topic</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --delete --zookeeper kafka-zookeeper:2181 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p>如果<code>delete.topic.enable=true</code>，则会直接删除topic，如果<code>delete.topic.enable=false</code>，则只是把这个 topic 标记为删除(marked for deletion)，重启 Kafka Server 后删除</p>
<p>生产者生产数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-console-producer.sh  --producer.config /tmp/client.properties  --broker-list kafka-0.kafka-headless.kafka.svc.cluster.local:9092,kafka-1.kafka-headless.kafka.svc.cluster.local:9092,kafka-2.kafka-headless.kafka.svc.cluster.local:9092  --topic rancher</span><br></pre></td></tr></table></figure>



<p>消费者消费生产者的数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-console-consumer.sh --consumer.config /tmp/client.properties --bootstrap-server kafka.kafka.svc.cluster.local:9092 --topic rancher --from-beginning</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>rancher</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kubelet CPU 使用率过高问题排查</title>
    <url>/2020/11/29/kubelet-CPU-%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BF%87%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>客户的k8s集群环境，发现所有的worker节点的kubelet进程的CPU使用率长时间占用过高，通过pidstat可以看到CPU使用率高达100%。针对此问题，客户在Rancher客户门户系统进行工单提问，请求Rancher工程师对kubelet进程的异常进行问题排查。</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/kubelet%20cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BF%87%E9%AB%98/kubelet-cpu-used.png" alt="image-20201128234823968"></p>
<h2 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>kubernetes</td>
<td>v1.18.8</td>
</tr>
<tr>
<td>docker</td>
<td>18.09.9</td>
</tr>
<tr>
<td>rancher</td>
<td>v2.4.8-ent</td>
</tr>
<tr>
<td>CentOS</td>
<td>7.6</td>
</tr>
<tr>
<td>kernel</td>
<td>4.4.227-1.el7.elrepo.x86_64</td>
</tr>
</tbody></table>
<h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><h3 id="使用strace工具对kubelet进程进行跟踪"><a href="#使用strace工具对kubelet进程进行跟踪" class="headerlink" title="使用strace工具对kubelet进程进行跟踪"></a>使用strace工具对kubelet进程进行跟踪</h3><ol>
<li>由于kubelet进程CPU使用率异常，可以使用strace工具对kubelet进程动态跟踪进程的调用情况，首先使用<code>strace -cp &lt;PID&gt;</code>命令统计kubelet进程在某段时间内的每个系统调用的时间、调用和错误情况.</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/kubelet%20cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BF%87%E9%AB%98/kubelet-futex-error.png" alt="kubelet_futex_error"></p>
<p>从上图可以看到，执行系统调用过程中，futex抛出了五千多个errors，这肯定是不正常的，而且这个函数占用的时间也达到了99%，所以需要更深层次的查看kubelet进程相关的调用。</p>
<ol start="2">
<li>由于<code>strace -cp</code>命令只能查看进程的整体调用情况，所以我们可以通过<code>strace -tt -p &lt;PID&gt;</code>命令打印每个系统调用的时间戳，如下：</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/kubelet%20cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BF%87%E9%AB%98/kubelet_strace.png" alt="kubelet_strace.png"></p>
<p>从strace输出的结果来看，在执行futex相关的系统调用时，有大量的Connect timed out，并返回了<code>-1 </code>和<code>ETIMEDOUT</code>的error，所以才会在<code>strace -cp</code>中看到了那么多的error。</p>
<p>futex是一种用户态和内核态混合的同步机制，当futex变量告诉进程有竞争发生时，会执行系统调用去完成相应的处理，例如wait或者wake up，从官方的文档了解到，futex有这么几个参数：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">futex(<span class="keyword">uint32_t</span> *uaddr, <span class="keyword">int</span> futex_op, <span class="keyword">uint32_t</span> val,</span><br><span class="line">                 <span class="keyword">const</span> struct timespec *timeout,   <span class="comment">/* or: uint32_t val2 */</span></span><br><span class="line">                 <span class="keyword">uint32_t</span> *uaddr2, <span class="keyword">uint32_t</span> val3);</span><br></pre></td></tr></table></figure>

<p>官方文档给出<code>ETIMEDOUT</code>的解释：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ETIMEDOUT</span><br><span class="line">       The operation in futex_op employed the timeout specified in</span><br><span class="line">       timeout, and the timeout expired before the operation</span><br><span class="line">       completed.</span><br></pre></td></tr></table></figure>

<p>意思就是在指定的timeout时间中，未能完成相应的操作，其中<code>futex_op</code>对应上述输出结果的<code>FUTEX_WAIT_PRIVATE</code>和<code>FUTEX_WAIT_PRIVATE</code>，可以看到基本都是发生在<code>FUTEX_WAIT_PRIVATE</code>时发生的超时。</p>
<p>从目前的系统调用层面可以判断，futex无法顺利进入睡眠状态，但是futex做了哪些操作还是不清楚，还无法判断kubeletCPU飙高的原因，所以我们需要进一步从kubelet的函数调用中去看到底是执行了卡在了哪个地方。</p>
<blockquote>
<p>FUTEX_PRIVATE_FLAG：这个参数告诉内核futex是进程专用的，不与其他进程共享，这里的FUTEX_WAIT_PRIVATE和FUTEX_WAKE_PRIVATE就是其中的两种FLAG；</p>
<p>futex相关说明1：<a href="https://man7.org/linux/man-pages/man7/futex.7.html">https://man7.org/linux/man-pages/man7/futex.7.html</a> </p>
<p>fuex相关说明2： <a href="https://man7.org/linux/man-pages/man2/futex.2.html">https://man7.org/linux/man-pages/man2/futex.2.html</a></p>
</blockquote>
<h3 id="使用go-pprof工具对kubelet函数调用进行分析"><a href="#使用go-pprof工具对kubelet函数调用进行分析" class="headerlink" title="使用go pprof工具对kubelet函数调用进行分析"></a>使用go pprof工具对kubelet函数调用进行分析</h3><p>早期的k8s版本，可以直接通过<code>debug/pprof</code> 接口获取debug数据，后面考虑到相关安全性的问题，取消了这个接口，参考<a href="https://github.com/kubernetes/kubernetes/issues/81023">CVE-2019-11248</a>，我们可以通过kubectl开启proxy进行相关数据指标的获取</p>
<ol>
<li>首先使用<code>kubectl proxy</code>命令启动API server代理</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl proxy --address=<span class="string">&#x27;0.0.0.0&#x27;</span>  --accept-hosts=<span class="string">&#x27;^*$&#x27;</span></span><br></pre></td></tr></table></figure>

<p>这里需要注意，如果使用的是Rancher UI上copy的kubeconfig文件，则需要使用指定了master IP的context，如果是RKE或者其他工具安装则可以忽略</p>
<ol start="2">
<li>构建golang环境。go pprof需要在golang环境下使用，本地如果没有安装golang，则可以通过docker快速构建golang环境</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -itd --name golang-env --net host golang bash</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>使用go pprof工具导出采集的指标，这里替换127.0.0.1为apiserver节点的IP，默认端口是8001，如果docker run的环境跑在apiserver所在的节点上，可以使用127.0.0.1。另外，还要替换NODENAME为对应的节点名称。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it golang-env bash</span><br><span class="line">go tool pprof -seconds=60 -raw -output=kubelet.pprof http://127.0.0.1:8001/api/v1/nodes/<span class="variable">$&#123;NODENAME&#125;</span>/proxy/debug/pprof/profile</span><br></pre></td></tr></table></figure>

<p>这里等待60s后，会将这60s内相关的函数调用输出到当前目录的kubelet.pprof文件中。</p>
<ol start="4">
<li>输出好的pprof文件不方便查看，需要转换成火焰图，推荐使用FlameGraph工具生成svg图</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/brendangregg/FlameGraph.git</span><br><span class="line"><span class="built_in">cd</span> FlameGraph/</span><br><span class="line">./stackcollapse-go.pl kubelet.pprof &gt; kubelet.out</span><br><span class="line">./flamegraph.pl kubelet.out &gt; kubelet.svg</span><br></pre></td></tr></table></figure>

<p>转换成火焰图后，就可以在浏览器很直观的看到函数相关调用和具体调用时间比了。</p>
<ol start="5">
<li>分析火焰图</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/kubelet%20cpu%E4%BD%BF%E7%94%A8%E7%8E%87%E8%BF%87%E9%AB%98/kubelet_flame2.png" alt="image-20201129033348406"></p>
<p> 从kubelet的火焰图可以看到，调用时间最长的函数是<code>k8s.io/kubernetes/vendor/github.com/google/cadvisor/manager.(*containerData).housekeeping</code>，其中cAdvisor是kubelet内置的指标采集工具，主要是负责对节点机器上的资源及容器进行实时监控和性能数据采集，包括CPU使用情况、内存使用情况、网络吞吐量及文件系统使用情况。</p>
<p>​    深入函数调用可以发现<code>k8s.io/kubernetes/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs.(*Manager).GetStats</code>这个函数占用<code>k8s.io/kubernetes/vendor/github.com/google/cadvisor/manager.(*containerData).housekeeping</code>这个函数的时间是最长的，说明在获取容器CGroup相关状态时占用了较多的时间。</p>
<ol start="6">
<li>既然这个函数占用时间长，那么我们就分析一下这个函数具体干了什么事儿</li>
</ol>
<p>查看源代码：<a href="https://github.com/kubernetes/kubernetes/blob/ded8a1e2853aef374fc93300fe1b225f38f19d9d/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go#L162">https://github.com/kubernetes/kubernetes/blob/ded8a1e2853aef374fc93300fe1b225f38f19d9d/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go#L162</a></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *MemoryGroup)</span> <span class="title">GetStats</span><span class="params">(path <span class="keyword">string</span>, stats *cgroups.Stats)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="comment">// Set stats from memory.stat.</span></span><br><span class="line">	statsFile, err := os.Open(filepath.Join(path, <span class="string">&quot;memory.stat&quot;</span>))</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">if</span> os.IsNotExist(err) &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> statsFile.Close()</span><br><span class="line"></span><br><span class="line">	sc := bufio.NewScanner(statsFile)</span><br><span class="line">	<span class="keyword">for</span> sc.Scan() &#123;</span><br><span class="line">		t, v, err := fscommon.GetCgroupParamKeyValue(sc.Text())</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			<span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;failed to parse memory.stat (%q) - %v&quot;</span>, sc.Text(), err)</span><br><span class="line">		&#125;</span><br><span class="line">		stats.MemoryStats.Stats[t] = v</span><br><span class="line">	&#125;</span><br><span class="line">	stats.MemoryStats.Cache = stats.MemoryStats.Stats[<span class="string">&quot;cache&quot;</span>]</span><br><span class="line"></span><br><span class="line">	memoryUsage, err := getMemoryData(path, <span class="string">&quot;&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	stats.MemoryStats.Usage = memoryUsage</span><br><span class="line">	swapUsage, err := getMemoryData(path, <span class="string">&quot;memsw&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	stats.MemoryStats.SwapUsage = swapUsage</span><br><span class="line">	kernelUsage, err := getMemoryData(path, <span class="string">&quot;kmem&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	stats.MemoryStats.KernelUsage = kernelUsage</span><br><span class="line">	kernelTCPUsage, err := getMemoryData(path, <span class="string">&quot;kmem.tcp&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	stats.MemoryStats.KernelTCPUsage = kernelTCPUsage</span><br><span class="line"></span><br><span class="line">	useHierarchy := strings.Join([]<span class="keyword">string</span>&#123;<span class="string">&quot;memory&quot;</span>, <span class="string">&quot;use_hierarchy&quot;</span>&#125;, <span class="string">&quot;.&quot;</span>)</span><br><span class="line">	value, err := fscommon.GetCgroupParamUint(path, useHierarchy)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> value == <span class="number">1</span> &#123;</span><br><span class="line">		stats.MemoryStats.UseHierarchy = <span class="literal">true</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	pagesByNUMA, err := getPageUsageByNUMA(path)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	stats.MemoryStats.PageUsageByNUMA = pagesByNUMA</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从代码中可以看到，进程会去读取<code>memory.stat</code>这个文件，这个文件存放了cgroup内存使用情况。也就是说，在读取这个文件花费了大量的时间。这时候，如果我们手动去查看这个文件，会是什么效果？</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># time cat /sys/fs/cgroup/memory/memory.stat &gt;/dev/null</span></span><br><span class="line">real 0m9.065s</span><br><span class="line">user 0m0.000s</span><br><span class="line">sys 0m9.064s</span><br></pre></td></tr></table></figure>

<p>从这里可以看出端倪了，读取这个文件花费了9s，显然是不正常的，难怪kubeletCPU使用飙高，原来是堵在这里了。</p>
<p>基于上述结果，我们在cAdvisor的GitHub上查找到一个<a href="https://github.com/google/cadvisor/issues/1774">issue</a>，从该issue中可以得知，该问题跟slab memory 缓存有一定的关系。从该issue中得知，受影响的机器的内存会逐渐被使用，通过/proc/meminfo看到使用的内存是slab memory，该内存是内核缓存的内存页，并且其中绝大部分都是dentry缓存。从这里我们可以判断出，当CGroup中的进程生命周期结束后，由于缓存的原因，还存留在slab memory中，导致其类似僵尸CGroup一样无法被释放。</p>
<p>也就是每当创建一个memory CGroup，在内核内存空间中，就会为其创建分配一份内存空间，该内存包含当前CGroup相关的cache（dentry、inode），也就是目录和文件索引的缓存，该缓存本质上是为了提高读取的效率。但是当CGroup中的所有进程都退出时，存在内核内存空间的缓存并没有清理掉。</p>
<p>内核通过伙伴算法进行内存分配，每当有进程申请内存空间时，会为其分配至少一个内存页面，也就是最少会分配4k内存，每次释放内存，也是按照最少一个页面来进行释放。当请求分配的内存大小为几十个字节或几百个字节时，4k对其来说是一个巨大的内存空间，在Linux中，为了解决这个问题，引入了slab内存分配管理机制，用来处理这种小量的内存请求，这就会导致，当CGroup中的所有进程都退出时，不会轻易回收这部分的内存，而这部分内存中的缓存数据，还会被读取到stats中，从而导致影响读取的性能。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ol>
<li>清理节点缓存，这是一个临时的解决方法，暂时清空节点内存缓存，能够缓解kubelet CPU使用率，但是后面缓存上来了，CPU使用率又会升上来。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> 2 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>升级内核版本</p>
<p>2.1. 其实这个主要还是内核的问题，在GitHub上这个<a href="https://github.com/torvalds/linux/commit/205b20cc5a99cdf197c32f4dbee2b09c699477f0">commit</a>中有提到，在5.2+以上的内核版本中，优化了CGroup stats相关的查询性能，如果想要更好的解决该问题，建议可以参考自己操作系统和环境，合理的升级内核版本。</p>
<p>2.2. 另外Redhat在<a href="https://bugzilla.redhat.com/show_bug.cgi?id=1795049">kernel-4.18.0-176</a>版本中也优化了相关CGroup的性能问题，而CentOS 8/RHEL 8默认使用的内核版本就是4.18，如果目前您使用的操作系统是RHEL7/CentOS7，则可以尝试逐渐替换新的操作系统，使用这个4.18.0-176版本以上的内核，毕竟新版本内核总归是对容器相关的体验会好很多。</p>
</li>
</ol>
<blockquote>
<p>kernel相关commit：<a href="https://github.com/torvalds/linux/commit/205b20cc5a99cdf197c32f4dbee2b09c699477f0">https://github.com/torvalds/linux/commit/205b20cc5a99cdf197c32f4dbee2b09c699477f0</a></p>
<p>redhat kernel bug fix：<a href="https://bugzilla.redhat.com/show_bug.cgi?id=1795049">https://bugzilla.redhat.com/show_bug.cgi?id=1795049</a></p>
</blockquote>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx-ingress升级失败问题排查</title>
    <url>/2020/04/09/nginx-ingress%E5%8D%87%E7%BA%A7%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>rancher自带的nginx-ingress-controller版本是0.25.1，不支持session-cookie-samesite选项，需要升级nginx-ingress-controller至0.29版本。</p>
<h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><h3 id="升级镜像版本"><a href="#升级镜像版本" class="headerlink" title="升级镜像版本"></a>升级镜像版本</h3><p>在Rancher UI界面，对nginx-ingress-controller进行升级操作，</p>
<p>镜像选择<code>quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.29.0</code></p>
<p>如果是国内用户，下载不到，可以选择用国内源的镜像<code>quay-mirror.qiniu.com/nginx-ingress-controller:0.29.0</code></p>
<h3 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h3><p>升级之后，<code>nginx-ingress-controller</code>组件一直起不来，查看日志信息，报以下错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unexpected error storing fake SSL Cert: could not create PEM certificate file &#x2F;etc&#x2F;ingress-controller&#x2F;ssl&#x2F;default-fake-certificate.pem: open &#x2F;etc&#x2F;ingress-controller&#x2F;ssl&#x2F;default-fake-certificate.pem: permission denied</span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/nginx-ingress-upgrade-failed/error.png" alt="error"></p>
<h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><p>从日志中可以看到是权限问题，查看官方说明，0.29版本访问用户为<code>www-data -&gt; 101</code>，而0.25版本默认为33，所以要对runAsUser进行修改</p>
<p>编辑yaml文件，修改<code>runAsUser</code>的值，33改为101即可</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">securityContext:</span></span><br><span class="line">   <span class="attr">capabilities:</span></span><br><span class="line">     <span class="attr">add:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">NET_BIND_SERVICE</span></span><br><span class="line">     <span class="attr">drop:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">   <span class="attr">runAsUser:</span> <span class="number">101</span>	<span class="comment">## 只修改此选项</span></span><br></pre></td></tr></table></figure>



<p>修改完后保存自动重新部署，可以看到已经能够正常启动了</p>
<p><img src="/images/mk/nginx-ingress-upgrade-failed/recovery.png" alt="recovery"></p>
<blockquote>
<ul>
<li>runAsUser：可以指定Pod或容器的访问权限，参考：<a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">https://kubernetes.io/docs/tasks/configure-pod-container/security-context/</a></li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>ingress</category>
      </categories>
      <tags>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx-ingress基于gRPC协议通信</title>
    <url>/2020/06/22/nginx-ingress%E5%9F%BA%E4%BA%8EgRPC%E5%8D%8F%E8%AE%AE%E9%80%9A%E4%BF%A1/</url>
    <content><![CDATA[<p>此文档演示如何通过nginx-ingress将流量路由到gRPC服务上。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th>环境</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>kubernetes</td>
<td>1.17.4</td>
</tr>
<tr>
<td>Rancher</td>
<td>v2.4.5</td>
</tr>
<tr>
<td>nginx-ingress</td>
<td>0.25.1</td>
</tr>
</tbody></table>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>以下gRPC应用基于ingress自带的示例，您也可以使用自己的gRPC应用进行测试</p>
<p>地址：<a href="https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/grpc">https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/grpc</a></p>
<ol>
<li>部署一个gRPC应用</li>
</ol>
<p>该应用程序通过go实现gRPC服务，并监听50051端口</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat  app.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fortune-teller-app</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">fortune-teller-app</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">k8s-app:</span> <span class="string">fortune-teller-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">k8s-app:</span> <span class="string">fortune-teller-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fortune-teller-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/kubernetes-ingress-controller/grpc-fortune-teller:0.1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">50051</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">grpc</span></span><br></pre></td></tr></table></figure>



<ol start="2">
<li>部署service，通过selector选择对应label的pod</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat svc.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fortune-teller-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">fortune-teller-app</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">50051</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">50051</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">grpc</span></span><br></pre></td></tr></table></figure>



<ol start="3">
<li>部署ingress</li>
</ol>
<p>这里主要设置这个参数来使用gRPC协议：<code>nginx.ingress.kubernetes.io/backend-protocol: &quot;GRPC&quot;</code> </p>
<p>还配置了SSL证书，默认使用ingress颁发的证书</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat ingress.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">kubernetes.io/ingress.class:</span> <span class="string">&quot;nginx&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">&quot;true&quot;</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">&quot;GRPC&quot;</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fortune-ingress</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">fortune-teller.stack.build</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">fortune-teller-service</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="string">grpc</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">secretName:</span> <span class="string">fortune-teller.stack.build</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">fortune-teller.stack.build</span></span><br></pre></td></tr></table></figure>



<ol start="4">
<li>kubectl执行以上文件</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl apply -f app.yaml </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f svc.yaml </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl apply -f ingress.yaml </span></span><br></pre></td></tr></table></figure>



<ol start="4">
<li>使用grpcurl测试应用</li>
</ol>
<p>grpcurl命令下载地址如下：<a href="https://github.com/fullstorydev/grpcurl/releases">https://github.com/fullstorydev/grpcurl/releases</a></p>
<p>例如下载 grpcurl_1.6.1_linux_x86_64.tar.gz</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># wget https://github.com/fullstorydev/grpcurl/releases/download/v1.6.1/grpcurl_1.6.1_linux_x86_64.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tar -zxvf grpcurl_1.6.1_linux_x86_64.tar.gz</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cp grpcurl /usr/local/bin/grpcurl</span></span><br></pre></td></tr></table></figure>

<p>测试基于ingress访问gRPC应用（示例中，message的值会不一样）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># grpcurl -insecure fortune-teller.stack.build:443 build.stack.fortune.FortuneTeller/Predict</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;message&quot;</span>: <span class="string">&quot;[We] use bad software and bad machines for the wrong things.\n\t\t-- R. W. Hamming&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ingress</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>openstack（queens）部署Zun服务</title>
    <url>/2018/10/04/openstack%EF%BC%88queens%EF%BC%89%E9%83%A8%E7%BD%B2Zun%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<p>Zun是OpenStack中提供容器服务的组件<br>以下纯安装过程，基于OpenStack queens版本</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>controller：192.168.152.101<br>compute：192.168.152.102</p>
<h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><p><strong>controller节点</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# mysql -uroot -p000000</span><br><span class="line">Welcome to the MariaDB monitor. Commands end with ; or \\g.</span><br><span class="line">Your MariaDB connection id is 125</span><br><span class="line">Server version: 10.1.20-MariaDB MariaDB Server</span><br><span class="line">Copyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line">Type &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.</span><br><span class="line">MariaDB [(none)]&gt; CREATE DATABASE zun;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">MariaDB [(none)]&gt; grant all privileges on zun.* to &#39;zun&#39;@&#39;localhost&#39;</span><br><span class="line">identified by &#39;000000&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">MariaDB [(none)]&gt; grant all privileges on zun.* to &#39;zun&#39;@&#39;%&#39; identified by</span><br><span class="line">&#39;000000&#39;;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure>
<h2 id="创建openstack用户、服务、端点"><a href="#创建openstack用户、服务、端点" class="headerlink" title="创建openstack用户、服务、端点"></a>创建openstack用户、服务、端点</h2><p><strong>controller节点</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# . admin-openrc</span><br><span class="line">[root@controller ~]# openstack user create --domain default</span><br><span class="line">--password-prompt zun</span><br><span class="line">User Password:</span><br><span class="line">Repeat User Password:</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 30f17f5a1baf48febb4260d6526267e4 |</span><br><span class="line">| name | zun |</span><br><span class="line">| options | &#123;&#125; |</span><br><span class="line">| password_expires_at | None |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">[root@controller ~]# openstack role add --project service --user zun</span><br><span class="line">admin</span><br><span class="line">[root@controller ~]# openstack service create --name zun --description</span><br><span class="line">&quot;Container Service&quot; container</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">| description | Container Service |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 8f23b99db9d8456a8a51535903322275 |</span><br><span class="line">| name | zun |</span><br><span class="line">| type | container |</span><br><span class="line">+-------------+----------------------------------+</span><br><span class="line">[root@controller ~]# openstack endpoint create --region RegionOne container</span><br><span class="line">public http:&#x2F;&#x2F;controller:9517&#x2F;v1</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 8a5b474912a340d3993d094e21bcdc51 |</span><br><span class="line">| interface | public |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | 8f23b99db9d8456a8a51535903322275 |</span><br><span class="line">| service_name | zun |</span><br><span class="line">| service_type | container |</span><br><span class="line">| url | http:&#x2F;&#x2F;controller:9517&#x2F;v1 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]# openstack endpoint create --region RegionOne container</span><br><span class="line">internal http:&#x2F;&#x2F;controller:9517&#x2F;v1</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 7ecfa6c448fe4a769617b26439e48598 |</span><br><span class="line">| interface | internal |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | 8f23b99db9d8456a8a51535903322275 |</span><br><span class="line">| service_name | zun |</span><br><span class="line">| service_type | container |</span><br><span class="line">| url | http:&#x2F;&#x2F;controller:9517&#x2F;v1 |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">[root@controller ~]# openstack endpoint create --region RegionOne container</span><br><span class="line">admin http:&#x2F;&#x2F;controller:9517&#x2F;v1</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+--------------+----------------------------------+</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | cfba36a4071b4cf187990ccea63b2161 |</span><br><span class="line">| interface | admin |</span><br><span class="line">| region | RegionOne |</span><br><span class="line">| region_id | RegionOne |</span><br><span class="line">| service_id | 8f23b99db9d8456a8a51535903322275 |</span><br><span class="line">| service_name | zun |</span><br><span class="line">| service_type | container |</span><br><span class="line">| url | http:&#x2F;&#x2F;controller:9517&#x2F;v1 |</span><br><span class="line">+--------------+----------------------------------+</span><br></pre></td></tr></table></figure>
<h2 id="3-在controller节点上安装zun服务"><a href="#3-在controller节点上安装zun服务" class="headerlink" title="3. 在controller节点上安装zun服务"></a>3. 在controller节点上安装zun服务</h2><h3 id="3-1-创建用户、组"><a href="#3-1-创建用户、组" class="headerlink" title="3.1 创建用户、组"></a>3.1 创建用户、组</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# groupadd --system zun</span><br><span class="line">[root@controller ~]# useradd --home-dir &quot;&#x2F;var&#x2F;lib&#x2F;zun&quot; --create-home --system</span><br><span class="line">--shell &#x2F;bin&#x2F;false -g zun zun</span><br></pre></td></tr></table></figure>
<h3 id="3-2-创建目录"><a href="#3-2-创建目录" class="headerlink" title="3.2 创建目录"></a>3.2 创建目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# mkdir -p &#x2F;etc&#x2F;zun</span><br><span class="line">[root@controller ~]# chown zun:zun &#x2F;etc&#x2F;zun</span><br></pre></td></tr></table></figure>
<h3 id="3-3-安装zun"><a href="#3-3-安装zun" class="headerlink" title="3.3 安装zun"></a>3.3 安装zun</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# yum install python-pip -y</span><br><span class="line">[root@controller ~]# cd &#x2F;var&#x2F;lib&#x2F;zun&#x2F;</span><br><span class="line">[root@controller zun]# git clone -b stable&#x2F;queens</span><br><span class="line">https:&#x2F;&#x2F;git.openstack.org&#x2F;openstack&#x2F;zun.git</span><br><span class="line">Cloning into &#39;zun&#39;...</span><br><span class="line">remote: Counting objects: 18434, done.</span><br><span class="line">remote: Compressing objects: 100% (10147&#x2F;10147), done.</span><br><span class="line">remote: Total 18434 (delta 14071), reused 11745 (delta 7946)</span><br><span class="line">Receiving objects: 100% (18434&#x2F;18434), 2.55 MiB | 194.00 KiB&#x2F;s, done.</span><br><span class="line">Resolving deltas: 100% (14071&#x2F;14071), done.</span><br><span class="line">[root@controller zun]# chown -R zun:zun zun</span><br><span class="line">[root@controller zun]# cd zun</span><br><span class="line">[root@controller zun]# pip install -r requirements.txt</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): PyYAML&gt;&#x3D;3.10 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 5))</span><br><span class="line">Collecting eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2 (from -r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;e4&#x2F;32&#x2F;88ee8694dd3985d1615287faa47e458d44a6263ffb59cf71ef70b94df6f9&#x2F;eventlet-0.20.0-py2.py3-none-any.whl</span><br><span class="line">(387kB)</span><br><span class="line">100% |████████████████████████████████| 389kB 246kB&#x2F;s</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">keystonemiddleware&gt;&#x3D;4.17.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 7))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">jsonpatch!&#x3D;1.20,&gt;&#x3D;1.16 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 8))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pbr!&#x3D;2.1.0,&gt;&#x3D;2.0.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 9))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages</span><br><span class="line">(from -r requirements.txt (line 10))</span><br><span class="line">Collecting python-etcd&gt;&#x3D;0.4.3 (from -r requirements.txt (line 11))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;a1&#x2F;da&#x2F;616a4d073642da5dd432e5289b7c1cb0963cc5dde23d1ecb8d726821ab41&#x2F;python-etcd-0.4.5.tar.gz</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-glanceclient&gt;&#x3D;2.8.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 12))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-neutronclient&gt;&#x3D;6.3.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 13))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-novaclient&gt;&#x3D;9.1.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 14))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-cinderclient&gt;&#x3D;3.3.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 15))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.i18n&gt;&#x3D;3.15.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 16))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.log&gt;&#x3D;3.36.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 17))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.concurrency&gt;&#x3D;3.25.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 18))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.config&gt;&#x3D;5.1.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 19))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.messaging&gt;&#x3D;5.29.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 20))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.middleware&gt;&#x3D;3.31.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 21))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.policy&gt;&#x3D;1.30.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 22))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.privsep&gt;&#x3D;1.23.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 23))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.serialization!&#x3D;2.19.1,&gt;&#x3D;2.18.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">-r requirements.txt (line 24))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.versionedobjects&gt;&#x3D;1.31.2 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 26))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.context&gt;&#x3D;2.19.2</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 27))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.utils&gt;&#x3D;3.33.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 28))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.db&gt;&#x3D;4.27.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 29))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): os-vif!&#x3D;1.8.0,&gt;&#x3D;1.7.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 30))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): os-brick&gt;&#x3D;2.2.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): six&gt;&#x3D;1.10.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 32))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): WSME&gt;&#x3D;0.8.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 33))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">SQLAlchemy!&#x3D;1.1.5,!&#x3D;1.1.6,!&#x3D;1.1.7,!&#x3D;1.1.8,&gt;&#x3D;1.0.10 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 34))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): stevedore&gt;&#x3D;1.20.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 35))</span><br><span class="line">Collecting docker&gt;&#x3D;2.4.2 (from -r requirements.txt (line 36))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;f6&#x2F;8e&#x2F;597e81a41598afac5c68180d778bc8513bc763c66158875ddb060371b6f9&#x2F;docker-3.4.0-py2.py3-none-any.whl</span><br><span class="line">(122kB)</span><br><span class="line">100% |████████████████████████████████| 122kB 151kB&#x2F;s</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): netaddr&gt;&#x3D;0.7.18 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 37))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): neutron-lib&gt;&#x3D;1.13.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 38))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): websockify&gt;&#x3D;0.8.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 39))</span><br><span class="line">Collecting websocket-client&lt;&#x3D;0.40.0,&gt;&#x3D;0.33.0 (from -r requirements.txt (line</span><br><span class="line">40))</span><br><span class="line">Retrying (Retry(total&#x3D;4, connect&#x3D;None, read&#x3D;None, redirect&#x3D;None)) after</span><br><span class="line">connection broken by</span><br><span class="line">&#39;NewConnectionError(&#39;&lt;pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection</span><br><span class="line">object at 0x7f2604899c10&gt;: Failed to establish a new connection: [Errno -3]</span><br><span class="line">Temporary failure in name resolution&#39;,)&#39;: &#x2F;simple&#x2F;websocket-client&#x2F;</span><br><span class="line">Retrying (Retry(total&#x3D;3, connect&#x3D;None, read&#x3D;None, redirect&#x3D;None)) after</span><br><span class="line">connection broken by</span><br><span class="line">&#39;NewConnectionError(&#39;&lt;pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection</span><br><span class="line">object at 0x7f260411ff10&gt;: Failed to establish a new connection: [Errno -3]</span><br><span class="line">Temporary failure in name resolution&#39;,)&#39;: &#x2F;simple&#x2F;websocket-client&#x2F;</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;a7&#x2F;2b&#x2F;0039154583cb0489c8e18313aa91ccd140ada103289c5c5d31d80fd6d186&#x2F;websocket_client-0.40.0.tar.gz</span><br><span class="line">(196kB)</span><br><span class="line">100% |████████████████████████████████| 204kB 134kB&#x2F;s</span><br><span class="line">Collecting enum-compat (from eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2-&gt;-r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;95&#x2F;6e&#x2F;26bdcba28b66126f66cf3e4cd03bcd63f7ae330d29ee68b1f6b623550bfa&#x2F;enum-compat-0.0.2.tar.gz</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): greenlet&gt;&#x3D;0.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2-&gt;-r requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): jsonpointer&gt;&#x3D;1.9 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from jsonpatch!&#x3D;1.20,&gt;&#x3D;1.16-&gt;-r</span><br><span class="line">requirements.txt (line 8))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): WebOb&gt;&#x3D;1.2dev in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Mako&gt;&#x3D;0.4.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): WebTest&gt;&#x3D;1.3.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): logutils&gt;&#x3D;0.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): singledispatch in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): urllib3&gt;&#x3D;1.7.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-etcd&gt;&#x3D;0.4.3-&gt;-r requirements.txt</span><br><span class="line">(line 11))</span><br><span class="line">Collecting dnspython&gt;&#x3D;1.13.0 (from python-etcd&gt;&#x3D;0.4.3-&gt;-r requirements.txt</span><br><span class="line">(line 11))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;a6&#x2F;72&#x2F;209e18bdfedfd78c6994e9ec96981624a5ad7738524dd474237268422cb8&#x2F;dnspython-1.15.0-py2.py3-none-any.whl</span><br><span class="line">(177kB)</span><br><span class="line">100% |████████████████████████████████| 184kB 110kB&#x2F;s</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): monotonic&gt;&#x3D;0.6 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): PasteDeploy&gt;&#x3D;1.5.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Routes&gt;&#x3D;2.3.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Collecting Paste&gt;&#x3D;2.0.2 (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;a4&#x2F;d2&#x2F;ac41e1b414ff1ed70c81e493bf9da42fbeeb53774ed1557b4729242a18ab&#x2F;Paste-2.0.3-py2-none-any.whl</span><br><span class="line">(625kB)</span><br><span class="line">100% |████████████████████████████████| 634kB 144kB&#x2F;s</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Babel!&#x3D;2.4.0,&gt;&#x3D;2.3.4</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt</span><br><span class="line">(line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): requests&gt;&#x3D;2.14.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt</span><br><span class="line">(line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">retrying!&#x3D;1.3.0,&gt;&#x3D;1.2.3 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt (line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): os-win&gt;&#x3D;3.0.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt</span><br><span class="line">(line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): simplegeneric in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from WSME&gt;&#x3D;0.8.0-&gt;-r requirements.txt (line</span><br><span class="line">33))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pytz in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from WSME&gt;&#x3D;0.8.0-&gt;-r requirements.txt (line</span><br><span class="line">33))</span><br><span class="line">Collecting docker-pycreds&gt;&#x3D;0.3.0 (from docker&gt;&#x3D;2.4.2-&gt;-r requirements.txt</span><br><span class="line">(line 36))</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;ea&#x2F;bf&#x2F;7e70aeebc40407fbdb96fa9f79fc8e4722ea889a99378303e3bcc73f4ab5&#x2F;docker_pycreds-0.3.0-py2.py3-none-any.whl</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">backports.ssl-match-hostname&gt;&#x3D;3.5; python_version &lt; &quot;3.5&quot; in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from docker&gt;&#x3D;2.4.2-&gt;-r requirements.txt</span><br><span class="line">(line 36))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): ipaddress&gt;&#x3D;1.0.16;</span><br><span class="line">python_version &lt; &quot;3.3&quot; in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">docker&gt;&#x3D;2.4.2-&gt;-r requirements.txt (line 36))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): enum34 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">enum-compat-&gt;eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2-&gt;-r requirements.txt</span><br><span class="line">(line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): MarkupSafe&gt;&#x3D;0.9.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">Mako&gt;&#x3D;0.4.0-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt</span><br><span class="line">(line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): waitress&gt;&#x3D;0.8.5 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">WebTest&gt;&#x3D;1.3.1-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r</span><br><span class="line">requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): beautifulsoup4 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">WebTest&gt;&#x3D;1.3.1-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r</span><br><span class="line">requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): repoze.lru&gt;&#x3D;0.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">Routes&gt;&#x3D;2.3.1-&gt;oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): setuptools in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">waitress&gt;&#x3D;0.8.5-&gt;WebTest&gt;&#x3D;1.3.1-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r</span><br><span class="line">requirements.txt (line 10))</span><br><span class="line">Installing collected packages: enum-compat, eventlet, dnspython, python-etcd,</span><br><span class="line">websocket-client, docker-pycreds, docker, Paste</span><br><span class="line">Running setup.py install for enum-compat ... done</span><br><span class="line">Found existing installation: eventlet 0.20.1</span><br><span class="line">Uninstalling eventlet-0.20.1:</span><br><span class="line">Successfully uninstalled eventlet-0.20.1</span><br><span class="line">Running setup.py install for python-etcd ... done</span><br><span class="line">Running setup.py install for websocket-client ... done</span><br><span class="line">Found existing installation: Paste 1.7.5.1</span><br><span class="line">Uninstalling Paste-1.7.5.1:</span><br><span class="line">Successfully uninstalled Paste-1.7.5.1</span><br><span class="line">Successfully installed Paste-2.0.3 dnspython-1.15.0 docker-3.4.0</span><br><span class="line">docker-pycreds-0.3.0 enum-compat-0.0.2 eventlet-0.20.0 python-etcd-0.4.5</span><br><span class="line">websocket-client-0.40.0</span><br><span class="line">You are using pip version 8.1.2, however version 10.0.1 is available.</span><br><span class="line">You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.</span><br><span class="line">[root@controller zun]# python setup.py install</span><br></pre></td></tr></table></figure>
<h3 id="3-4-生成示例配置文件"><a href="#3-4-生成示例配置文件" class="headerlink" title="3.4 生成示例配置文件"></a>3.4 生成示例配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller zun]# su -s &#x2F;bin&#x2F;sh -c &quot;oslo-config-generator --config-file</span><br><span class="line">etc&#x2F;zun&#x2F;zun-config-generator.conf&quot; zun</span><br><span class="line">[root@controller zun]# su -s &#x2F;bin&#x2F;sh -c &quot;cp etc&#x2F;zun&#x2F;zun.conf.sample</span><br><span class="line">&#x2F;etc&#x2F;zun&#x2F;zun.conf&quot; zun</span><br></pre></td></tr></table></figure>
<h3 id="3-5-复制api-paste-ini配置文件"><a href="#3-5-复制api-paste-ini配置文件" class="headerlink" title="3.5 复制api-paste.ini配置文件"></a>3.5 复制api-paste.ini配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller zun]# su -s &#x2F;bin&#x2F;sh -c &quot;cp etc&#x2F;zun&#x2F;api-paste.ini &#x2F;etc&#x2F;zun&quot;</span><br><span class="line">zun</span><br></pre></td></tr></table></figure>
<h3 id="3-6-编辑配置文件-在合适位置添加以下内容"><a href="#3-6-编辑配置文件-在合适位置添加以下内容" class="headerlink" title="3.6 编辑配置文件,在合适位置添加以下内容"></a>3.6 编辑配置文件,在合适位置添加以下内容</h3><h1 id="vi-etc-zun-zun-conf"><a href="#vi-etc-zun-zun-conf" class="headerlink" title="vi /etc/zun/zun.conf"></a>vi <strong>/etc/zun/zun.conf</strong></h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[DEFAULT]</span><br><span class="line">transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:000000@controller</span><br><span class="line">[api]</span><br><span class="line">host_ip &#x3D; 172.24.19.10</span><br><span class="line">port &#x3D; 9517</span><br><span class="line">[database]</span><br><span class="line">connection &#x3D; mysql+pymysql:&#x2F;&#x2F;zun:000000@controller&#x2F;zun</span><br><span class="line">[keystone_auth]</span><br><span class="line">memcached_servers &#x3D; controller:11211</span><br><span class="line">www_authenticate_uri &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">project_domain_name &#x3D; default</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">user_domain_name &#x3D; default</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">username &#x3D; zun</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_type &#x3D; password</span><br><span class="line">auth_version &#x3D; v3</span><br><span class="line">auth_protocol &#x3D; http</span><br><span class="line">service_token_roles_required &#x3D; True</span><br><span class="line">endpoint_type &#x3D; internalURL</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">memcached_servers &#x3D; controller:11211</span><br><span class="line">www_authenticate_uri &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">project_domain_name &#x3D; default</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">user_domain_name &#x3D; default</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">username &#x3D; zun</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_type &#x3D; password</span><br><span class="line">auth_version &#x3D; v3</span><br><span class="line">auth_protocol &#x3D; http</span><br><span class="line">service_token_roles_required &#x3D; True</span><br><span class="line">endpoint_type &#x3D; internalURL</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;zun&#x2F;tmp</span><br><span class="line">[oslo_messaging_notifications]</span><br><span class="line">driver &#x3D; messaging</span><br><span class="line">[websocket_proxy]</span><br><span class="line">wsproxy_host &#x3D; 172.24.19.10</span><br><span class="line">wsproxy_port &#x3D; 6784</span><br></pre></td></tr></table></figure>
<h3 id="3-7-填充数据库"><a href="#3-7-填充数据库" class="headerlink" title="3.7 填充数据库"></a>3.7 填充数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller zun]# su -s &#x2F;bin&#x2F;sh -c &quot;zun-db-manage upgrade&quot; zun</span><br><span class="line">INFO [alembic.runtime.migration] Context impl MySQLImpl.</span><br><span class="line">INFO [alembic.runtime.migration] Will assume non-transactional DDL.</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade -&gt; a9a92eebd9a8,</span><br><span class="line">create_table_zun_service</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade a9a92eebd9a8 -&gt; 9fe371393a24,</span><br><span class="line">create_table_container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 9fe371393a24 -&gt; 5971a6844738,</span><br><span class="line">add container_id column to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 5971a6844738 -&gt; 93fbb05b77b9,</span><br><span class="line">add memory field to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 93fbb05b77b9 -&gt; 63a08e32cc43,</span><br><span class="line">add task state to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 63a08e32cc43 -&gt; 1192ba19a6e9,</span><br><span class="line">Add cpu workdir ports hostname labels to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 1192ba19a6e9 -&gt; 72c6947c6636,</span><br><span class="line">create_table_image</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 72c6947c6636 -&gt; c5565cbaa3de,</span><br><span class="line">Insert status_reason to Container table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade c5565cbaa3de -&gt; 43e1088c3389,</span><br><span class="line">add image_pull_policy column</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 43e1088c3389 -&gt; 4a0c4f7a4a33,</span><br><span class="line">add meta addresses to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 4a0c4f7a4a33 -&gt; 531e4a890480,</span><br><span class="line">add host to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 531e4a890480 -&gt; bbcfa910a8a5,</span><br><span class="line">add_restart_policy_column</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade bbcfa910a8a5 -&gt; ad43a2179cf2,</span><br><span class="line">add_status_detail</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade ad43a2179cf2 -&gt; d1ef05fd92c8,</span><br><span class="line">add tty stdin_open</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade d1ef05fd92c8 -&gt; 5458f8394206,</span><br><span class="line">add image driver field</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 5458f8394206 -&gt; 6fd4f7582eb0,</span><br><span class="line">Add resource provider table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 6fd4f7582eb0 -&gt; 7975b7f0f792,</span><br><span class="line">Add resource class table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 7975b7f0f792 -&gt; 09f196622a3f,</span><br><span class="line">create inventory table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 09f196622a3f -&gt; e4d145e195f4,</span><br><span class="line">Create allocation table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade e4d145e195f4 -&gt; 8192905fd835,</span><br><span class="line">add uuid_to_resource_class</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 8192905fd835 -&gt; eeac0d191f5a,</span><br><span class="line">add compute node table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade eeac0d191f5a -&gt; 53a8b515057e,</span><br><span class="line">Add memory info to compute node</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 53a8b515057e -&gt; 4bf34495d060,</span><br><span class="line">Add container number info to compute node</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 4bf34495d060 -&gt; ce9944b346cb,</span><br><span class="line">combine tty and stdin_open</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade ce9944b346cb -&gt; 8c3d80e18eb5,</span><br><span class="line">Add container cpus,cpu_used to compute node</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 8c3d80e18eb5 -&gt; 04ba87af76bb,</span><br><span class="line">Add container host operating system info</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 04ba87af76bb -&gt; 17ab8b533cc8,</span><br><span class="line">Add container hosts label info</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 17ab8b533cc8 -&gt; 5359d23b2322,</span><br><span class="line">add websocket_url and websocket_token</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 5359d23b2322 -&gt; 174cafda0857,</span><br><span class="line">add security groups</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 174cafda0857 -&gt; 648c25faa0be,</span><br><span class="line">add mem used to compute node</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 648c25faa0be -&gt; 75315e219cfb,</span><br><span class="line">Add auto_remove to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 75315e219cfb -&gt; a251f1f61217,</span><br><span class="line">create capsule table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade a251f1f61217 -&gt; 945569b3669f,</span><br><span class="line">add runtime column</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 945569b3669f -&gt; 10d65e285a59,</span><br><span class="line">create volume_mapping table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 10d65e285a59 -&gt; 37bce72463e3,</span><br><span class="line">add pci device</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 37bce72463e3 -&gt; bcd6410d645e,</span><br><span class="line">add host to capsule</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade bcd6410d645e -&gt; fc27c7415d9c,</span><br><span class="line">change the properties of meta_labels</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade fc27c7415d9c -&gt; ff7b9665d504,</span><br><span class="line">add pci stats to compute node</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade ff7b9665d504 -&gt; f046346d1d87,</span><br><span class="line">add timestamp to pci device</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade f046346d1d87 -&gt; d2affd5b4172</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade d2affd5b4172 -&gt; cf46a28f46bc,</span><br><span class="line">add container_actions table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade cf46a28f46bc -&gt; b6bfca998431,</span><br><span class="line">add container_actions_events table</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade b6bfca998431 -&gt; 8b0082d9e7c1,</span><br><span class="line">drop foreign key of container_actions container_uuid</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 8b0082d9e7c1 -&gt; 10c9668a816d,</span><br><span class="line">add volumes info and addresses to capsule</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 10c9668a816d -&gt; 71f8b4cf1dbf,</span><br><span class="line">upgrade</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 71f8b4cf1dbf -&gt; d9714eadbdc2,</span><br><span class="line">add disk to container</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade d9714eadbdc2 -&gt; 6ff4d35f4334,</span><br><span class="line">change properties of restart policy in capsule</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade 6ff4d35f4334 -&gt; fb9ad4a050f8,</span><br><span class="line">drop_container_actions_foreign_key</span><br><span class="line">INFO [alembic.runtime.migration] Running upgrade fb9ad4a050f8 -&gt; 50829990c965,</span><br><span class="line">add ondelete to container_actions_events foreign key</span><br></pre></td></tr></table></figure>
<h3 id="3-8-创建启动文件"><a href="#3-8-创建启动文件" class="headerlink" title="3.8 创建启动文件"></a>3.8 创建启动文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-api.service</span><br><span class="line">[Unit]</span><br><span class="line">Description &#x3D; OpenStack Container Service API</span><br><span class="line">[Service]</span><br><span class="line">ExecStart &#x3D; &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">User &#x3D; zun</span><br><span class="line">[Install]</span><br><span class="line">WantedBy &#x3D; multi-user.target</span><br><span class="line"># vi **&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-wsproxy.service**</span><br><span class="line">[Unit]</span><br><span class="line">Description &#x3D; OpenStack Container Service Websocket Proxy</span><br><span class="line">[Service]</span><br><span class="line">ExecStart &#x3D; &#x2F;usr&#x2F;bin&#x2F;zun-wsproxy</span><br><span class="line">User &#x3D; zun</span><br><span class="line">[Install]</span><br><span class="line">WantedBy &#x3D; multi-user.target</span><br></pre></td></tr></table></figure>
<h3 id="3-9-启动服务"><a href="#3-9-启动服务" class="headerlink" title="3.9 启动服务"></a>3.9 启动服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller zun]# systemctl start zun-api zun-wsproxy</span><br><span class="line">[root@controller zun]# systemctl enable zun-api zun-wsproxy</span><br><span class="line">Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;zun-api.service</span><br><span class="line">to &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-api.service.</span><br><span class="line">Created symlink from</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;zun-wsproxy.service to</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-wsproxy.service.</span><br><span class="line">[root@controller zun]# systemctl status zun-api zun-wsproxy</span><br><span class="line">● zun-api.service - OpenStack Container Service API</span><br><span class="line">Loaded: loaded (&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-api.service; enabled; vendor preset:</span><br><span class="line">disabled)</span><br><span class="line">Active: active (running) since Wed 2018-06-20 07:28:15 EDT; 10s ago</span><br><span class="line">Main PID: 4126 (zun-api)</span><br><span class="line">CGroup: &#x2F;system.slice&#x2F;zun-api.service</span><br><span class="line">├─4126 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4148 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4149 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4150 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4151 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4152 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4153 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4154 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4155 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4156 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4157 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4158 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4159 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4160 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4161 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">├─4162 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">└─4163 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-api</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.336 4154 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4154) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.338 4155 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4155) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.339 4156 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4156) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.340 4157 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4157) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.342 4158 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4158) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.344 4159 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4159) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.345 4160 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4160) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.347 4161 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4161) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.348 4162 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4162) wsgi starting up on http....10:9517</span><br><span class="line">Jun 20 07:28:18 controller zun-api[4126]: 2018-06-20 07:28:18.349 4163 INFO</span><br><span class="line">eventlet.wsgi.server [-] (4163) wsgi starting up on http....10:9517</span><br><span class="line">● zun-wsproxy.service - OpenStack Container Service Websocket Proxy</span><br><span class="line">Loaded: loaded (&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-wsproxy.service; enabled; vendor preset:</span><br><span class="line">disabled)</span><br><span class="line">Active: active (running) since Wed 2018-06-20 07:28:15 EDT; 10s ago</span><br><span class="line">Main PID: 4127 (zun-wsproxy)</span><br><span class="line">CGroup: &#x2F;system.slice&#x2F;zun-wsproxy.service</span><br><span class="line">└─4127 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-wsproxy</span><br><span class="line">Jun 20 07:28:15 controller systemd[1]: Started OpenStack Container Service</span><br><span class="line">Websocket Proxy.</span><br><span class="line">Jun 20 07:28:15 controller systemd[1]: Starting OpenStack Container Service</span><br><span class="line">Websocket Proxy...</span><br><span class="line">Jun 20 07:28:18 controller zun-wsproxy[4127]: 2018-06-20 07:28:18.298 4127 INFO</span><br><span class="line">zun.cmd.wsproxy [-] start websocket proxy</span><br><span class="line">Jun 20 07:28:18 controller zun-wsproxy[4127]: 2018-06-20 07:28:18.299 4127 INFO</span><br><span class="line">zun.websocket.websocketproxy [-] WebSocket server settings:</span><br><span class="line">Jun 20 07:28:18 controller zun-wsproxy[4127]: 2018-06-20 07:28:18.299 4127 INFO</span><br><span class="line">zun.websocket.websocketproxy [-] - Listen on 172.24...10:6784</span><br><span class="line">Jun 20 07:28:18 controller zun-wsproxy[4127]: 2018-06-20 07:28:18.299 4127 INFO</span><br><span class="line">zun.websocket.websocketproxy [-] - Flash security p... server</span><br><span class="line">Jun 20 07:28:18 controller zun-wsproxy[4127]: 2018-06-20 07:28:18.299 4127 INFO</span><br><span class="line">zun.websocket.websocketproxy [-] - SSL&#x2F;TLS support</span><br><span class="line">Jun 20 07:28:18 controller zun-wsproxy[4127]: 2018-06-20 07:28:18.300 4127 INFO</span><br><span class="line">zun.websocket.websocketproxy [-] - proxying from 17...ne:None</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full..</span><br></pre></td></tr></table></figure>
<p><strong>以下操作在compute节点上执行</strong></p>
<h2 id="4-在compute节点上安装docker-ce"><a href="#4-在compute节点上安装docker-ce" class="headerlink" title="4 在compute节点上安装docker-ce"></a>4 在compute节点上安装docker-ce</h2><h3 id="4-1-卸载旧版本的docker"><a href="#4-1-卸载旧版本的docker" class="headerlink" title="4.1 卸载旧版本的docker"></a>4.1 卸载旧版本的docker</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# yum remove docker docker-common docker-selinux docker-engine -y </span><br></pre></td></tr></table></figure>
<h3 id="4-2-安装依赖包"><a href="#4-2-安装依赖包" class="headerlink" title="4.2 安装依赖包"></a>4.2 安装依赖包</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# yum install -y yum-utils device-mapper-persistent-data lvm2</span><br></pre></td></tr></table></figure>
<h3 id="4-3-添加yum阿里源"><a href="#4-3-添加yum阿里源" class="headerlink" title="4.3 添加yum阿里源"></a>4.3 添加yum阿里源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# yum-config-manager --add-repo https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">adding repo from: https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">grabbing file https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;docker-ce&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo to &#x2F;etc&#x2F;yum.repos.d&#x2F;docker-ce.repo</span><br><span class="line">repo saved to &#x2F;etc&#x2F;yum.repos.d&#x2F;docker-ce.repo </span><br></pre></td></tr></table></figure>
<h3 id="4-4-更新yum源"><a href="#4-4-更新yum源" class="headerlink" title="4.4 更新yum源"></a>4.4 更新yum源</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# yum makecache fast</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line">* base: mirrors.cn99.com</span><br><span class="line">* extras: mirrors.cn99.com</span><br><span class="line">* updates: mirrors.cn99.com</span><br><span class="line">base | 3.6 kB 00:00:00</span><br><span class="line">centos-ceph-luminous | 2.9 kB 00:00:00</span><br><span class="line">centos-openstack-queens | 2.9 kB 00:00:00</span><br><span class="line">centos-qemu-ev | 2.9 kB 00:00:00</span><br><span class="line">docker-ce-stable | 2.9 kB 00:00:00</span><br><span class="line">extras | 3.4 kB 00:00:00</span><br><span class="line">updates | 3.4 kB 00:00:00</span><br><span class="line">docker-ce-stable&#x2F;x86_64&#x2F;primary_db | 13 kB 00:00:00</span><br><span class="line">Metadata Cache Created</span><br></pre></td></tr></table></figure>
<h3 id="4-5-安装docker-ce"><a href="#4-5-安装docker-ce" class="headerlink" title="4.5 安装docker-ce"></a>4.5 安装docker-ce</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# yum install docker-ce -y </span><br></pre></td></tr></table></figure>
<h3 id="4-6-启动docker-ce"><a href="#4-6-启动docker-ce" class="headerlink" title="4.6 启动docker-ce"></a>4.6 启动docker-ce</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# systemctl start docker</span><br><span class="line">sys[root@compute ~]# systemctl enable docker</span><br><span class="line">Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;docker.service</span><br><span class="line">to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service.</span><br></pre></td></tr></table></figure>
<h3 id="4-7-添加内核配置参数"><a href="#4-7-添加内核配置参数" class="headerlink" title="4.7 添加内核配置参数"></a>4.7 添加内核配置参数</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br><span class="line">[root@compute ~]# sysctl -p</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables &#x3D; 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables &#x3D; 1</span><br><span class="line">net.ipv4.ip_forward &#x3D; 1</span><br></pre></td></tr></table></figure>
<h2 id="5-在controller节点上添加kuryr-libnetwork用户"><a href="#5-在controller节点上添加kuryr-libnetwork用户" class="headerlink" title="5 在controller节点上添加kuryr-libnetwork用户"></a>5 在controller节点上添加kuryr-libnetwork用户</h2><h3 id="5-1-创建kuryr用户"><a href="#5-1-创建kuryr用户" class="headerlink" title="5.1 创建kuryr用户"></a>5.1 创建kuryr用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# source admin-openrc</span><br><span class="line">[root@controller ~]# openstack user create --domain default --password-prompt</span><br><span class="line">kuryr</span><br><span class="line">User Password:</span><br><span class="line">Repeat User Password:</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+---------------------+----------------------------------+</span><br><span class="line">| domain_id | default |</span><br><span class="line">| enabled | True |</span><br><span class="line">| id | 41dc08dfaec64b8c808fc4dcb4d29bfe |</span><br><span class="line">| name | kuryr |</span><br><span class="line">| options | &#123;&#125; |</span><br><span class="line">| password_expires_at | None |</span><br><span class="line">+---------------------+----------------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="5-2-添加角色"><a href="#5-2-添加角色" class="headerlink" title="5.2 添加角色"></a>5.2 添加角色</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# openstack role add --project service --user kuryr admin</span><br></pre></td></tr></table></figure>
<h2 id="6-在compute节点安装kuryr-libnetwork"><a href="#6-在compute节点安装kuryr-libnetwork" class="headerlink" title="6 在compute节点安装kuryr-libnetwork"></a>6 在compute节点安装kuryr-libnetwork</h2><h3 id="6-1-创建用户"><a href="#6-1-创建用户" class="headerlink" title="6.1 创建用户"></a>6.1 创建用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# groupadd --system kuryr</span><br><span class="line">[root@compute ~]# useradd --home-dir &quot;&#x2F;var&#x2F;lib&#x2F;kuryr&quot; --create-home --system</span><br><span class="line">--shell &#x2F;bin&#x2F;false -g kuryr kuryr</span><br></pre></td></tr></table></figure>
<h3 id="6-2-创建目录"><a href="#6-2-创建目录" class="headerlink" title="6.2 创建目录"></a>6.2 创建目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# mkdir -p &#x2F;etc&#x2F;kuryr</span><br><span class="line">[root@compute ~]# chown kuryr:kuryr &#x2F;etc&#x2F;kuryr</span><br></pre></td></tr></table></figure>
<h3 id="6-3-安装kuryr-libnetwork"><a href="#6-3-安装kuryr-libnetwork" class="headerlink" title="6.3 安装kuryr-libnetwork"></a>6.3 安装kuryr-libnetwork</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute ~]# yum install -y python-pip</span><br><span class="line">[root@compute ~]# cd &#x2F;var&#x2F;lib&#x2F;kuryr</span><br><span class="line">[root@compute ~]# cd &#x2F;var&#x2F;lib&#x2F;kuryr</span><br><span class="line">[root@compute kuryr]# git clone -b stable&#x2F;queens</span><br><span class="line">https:&#x2F;&#x2F;git.openstack.org&#x2F;openstack&#x2F;kuryr-libnetwork.git</span><br><span class="line">Cloning into &#39;kuryr-libnetwork&#39;...</span><br><span class="line">error: RPC failed; result&#x3D;6, HTTP code &#x3D; 0</span><br><span class="line">fatal: The remote end hung up unexpectedly</span><br><span class="line">[root@compute kuryr]# git clone -b stable&#x2F;queens</span><br><span class="line">https:&#x2F;&#x2F;git.openstack.org&#x2F;openstack&#x2F;kuryr-libnetwork.git</span><br><span class="line">Cloning into &#39;kuryr-libnetwork&#39;...</span><br><span class="line">remote: Counting objects: 4730, done.</span><br><span class="line">remote: Compressing objects: 100% (2175&#x2F;2175), done.</span><br><span class="line">remote: Total 4730 (delta 3263), reused 3817 (delta 2463)</span><br><span class="line">Receiving objects: 100% (4730&#x2F;4730), 1.65 MiB | 101.00 KiB&#x2F;s, done.</span><br><span class="line">Resolving deltas: 100% (3263&#x2F;3263), done.</span><br><span class="line">[root@compute kuryr]# chown -R kuryr:kuryr kuryr-libnetwork</span><br><span class="line">[root@compute kuryr]# cd kuryr-libnetwork</span><br><span class="line">[root@compute kuryr-libnetwork]# pip install -r requirements.txt</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Babel!&#x3D;2.4.0,&gt;&#x3D;2.3.4</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 5))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">Flask!&#x3D;0.11,&lt;1.0,&gt;&#x3D;0.10 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): ipaddress&gt;&#x3D;1.0.16 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 7))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">jsonschema&lt;3.0.0,&gt;&#x3D;2.6.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 8))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): kuryr-lib&gt;&#x3D;0.5.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 9))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): neutron-lib&gt;&#x3D;1.11.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">os-client-config&gt;&#x3D;1.28.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 11))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.concurrency&gt;&#x3D;3.20.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 12))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.config&gt;&#x3D;4.6.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 13))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.log&gt;&#x3D;3.30.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 14))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.utils&gt;&#x3D;3.31.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 15))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pbr!&#x3D;2.1.0,&gt;&#x3D;2.0.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 16))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-neutronclient&gt;&#x3D;6.3.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 17))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): six&gt;&#x3D;1.10.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 18))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pytz in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from Babel!&#x3D;2.4.0,&gt;&#x3D;2.3.4-&gt;-r</span><br><span class="line">requirements.txt (line 5))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): itsdangerous&gt;&#x3D;0.21 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from Flask!&#x3D;0.11,&lt;1.0,&gt;&#x3D;0.10-&gt;-r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): click&gt;&#x3D;2.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from Flask!&#x3D;0.11,&lt;1.0,&gt;&#x3D;0.10-&gt;-r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Jinja2&gt;&#x3D;2.4 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from Flask!&#x3D;0.11,&lt;1.0,&gt;&#x3D;0.10-&gt;-r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Werkzeug&gt;&#x3D;0.7 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from Flask!&#x3D;0.11,&lt;1.0,&gt;&#x3D;0.10-&gt;-r</span><br><span class="line">requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): repoze.lru in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from jsonschema&lt;3.0.0,&gt;&#x3D;2.6.0-&gt;-r</span><br><span class="line">requirements.txt (line 8))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): keystoneauth1&gt;&#x3D;3.4.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from kuryr-lib&gt;&#x3D;0.5.0-&gt;-r</span><br><span class="line">requirements.txt (line 9))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.i18n&gt;&#x3D;3.15.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from kuryr-lib&gt;&#x3D;0.5.0-&gt;-r requirements.txt</span><br><span class="line">(line 9))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pyroute2&gt;&#x3D;0.4.21;</span><br><span class="line">sys_platform !&#x3D; &quot;win32&quot; in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">kuryr-lib&gt;&#x3D;0.5.0-&gt;-r requirements.txt (line 9))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): MarkupSafe&gt;&#x3D;0.23 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">Jinja2&gt;&#x3D;2.4-&gt;Flask!&#x3D;0.11,&lt;1.0,&gt;&#x3D;0.10-&gt;-r requirements.txt (line 6))</span><br><span class="line">You are using pip version 8.1.2, however version 10.0.1 is available.</span><br><span class="line">You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.</span><br><span class="line">[root@compute kuryr-libnetwork]# python setup.py install</span><br></pre></td></tr></table></figure>
<h3 id="6-4-生成示例配置文件"><a href="#6-4-生成示例配置文件" class="headerlink" title="6.4 生成示例配置文件"></a>6.4 生成示例配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# su -s &#x2F;bin&#x2F;sh -c</span><br><span class="line">&quot;.&#x2F;tools&#x2F;generate_config_file_samples.sh&quot; kuryr</span><br><span class="line">[root@compute kuryr-libnetwork]# su -s &#x2F;bin&#x2F;sh -c &quot;cp etc&#x2F;kuryr.conf.sample</span><br><span class="line">&#x2F;etc&#x2F;kuryr&#x2F;kuryr.conf&quot; kuryr</span><br></pre></td></tr></table></figure>
<h3 id="6-5-编辑配置文件，添加以下内容"><a href="#6-5-编辑配置文件，添加以下内容" class="headerlink" title="6.5 编辑配置文件，添加以下内容"></a>6.5 编辑配置文件，添加以下内容</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;kuryr&#x2F;kuryr.conf</span><br><span class="line">[DEFAULT]</span><br><span class="line">bindir &#x3D; &#x2F;usr&#x2F;libexec&#x2F;kuryr</span><br><span class="line">[neutron]</span><br><span class="line">www_authenticate_uri &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:35357</span><br><span class="line">username &#x3D; kuryr</span><br><span class="line">user_domain_name &#x3D; default</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">project_domain_name &#x3D; default</span><br><span class="line">auth_type &#x3D; password</span><br></pre></td></tr></table></figure>
<h3 id="6-6-创建启动文件"><a href="#6-6-创建启动文件" class="headerlink" title="6.6 创建启动文件"></a>6.6 创建启动文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;kuryr-libnetwork.service</span><br><span class="line">[Unit]</span><br><span class="line">Description &#x3D; Kuryr-libnetwork - Docker network plugin for Neutron</span><br><span class="line">[Service]</span><br><span class="line">ExecStart &#x3D; &#x2F;usr&#x2F;bin&#x2F;kuryr-server --config-file &#x2F;etc&#x2F;kuryr&#x2F;kuryr.conf</span><br><span class="line">CapabilityBoundingSet &#x3D; CAP_NET_ADMIN</span><br><span class="line">[Install]</span><br><span class="line">WantedBy &#x3D; multi-user.target</span><br></pre></td></tr></table></figure>
<h3 id="6-7-启动服务"><a href="#6-7-启动服务" class="headerlink" title="6.7 启动服务"></a>6.7 启动服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# systemctl enable kuryr-libnetwork</span><br><span class="line">Created symlink from</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;kuryr-libnetwork.service to</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;kuryr-libnetwork.service.</span><br><span class="line">[root@compute kuryr-libnetwork]# systemctl start kuryr-libnetwork</span><br><span class="line">[root@compute kuryr-libnetwork]# systemctl restart docker</span><br></pre></td></tr></table></figure>
<h3 id="6-8-验证"><a href="#6-8-验证" class="headerlink" title="6.8 验证"></a>6.8 验证</h3><h4 id="6-8-1-创建kuryr网络"><a href="#6-8-1-创建kuryr网络" class="headerlink" title="6.8.1 创建kuryr网络"></a>6.8.1 创建kuryr网络</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# docker network create --driver kuryr</span><br><span class="line">--ipam-driver kuryr --subnet 10.10.0.0&#x2F;16 --gateway&#x3D;10.10.0.1 test_net</span><br><span class="line">9ab4903d7e7056070da97a667cbb7b2c0801ee25bb9f38fafab6798f087c2dae</span><br></pre></td></tr></table></figure>
<h4 id="6-8-2-查看网络"><a href="#6-8-2-查看网络" class="headerlink" title="6.8.2 查看网络"></a>6.8.2 查看网络</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# docker network ls</span><br><span class="line">NETWORK ID NAME DRIVER SCOPE</span><br><span class="line">3eadaa82b6d7 bridge bridge local</span><br><span class="line">8c9b9f0285cc host host local</span><br><span class="line">e340dd89e780 none null local</span><br><span class="line">9ab4903d7e70 test_net kuryr local</span><br></pre></td></tr></table></figure>
<h4 id="6-8-3-创建容器"><a href="#6-8-3-创建容器" class="headerlink" title="6.8.3 创建容器"></a>6.8.3 创建容器</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# docker run --net test_net cirros ifconfig</span><br><span class="line">Unable to find image &#39;cirros:latest&#39; locally</span><br><span class="line">latest: Pulling from library&#x2F;cirros</span><br><span class="line">480d57c7bf4d: Pull complete</span><br><span class="line">0f45bfe9a805: Pull complete</span><br><span class="line">5aa6c26e64dc: Pull complete</span><br><span class="line">Digest: sha256:e67f6f4a0521e326ba2dd697950046aba5ce836edda79cb818d45a56841c7ca2</span><br><span class="line">Status: Downloaded newer image for cirros:latest</span><br><span class="line">eth0 Link encap:Ethernet HWaddr 02:42:9D:F5:4C:8A</span><br><span class="line">inet addr:10.10.0.10 Bcast:10.10.255.255 Mask:255.255.0.0</span><br><span class="line">UP BROADCAST RUNNING MULTICAST MTU:1450 Metric:1</span><br><span class="line">RX packets:16 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">TX packets:8 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">collisions:0 txqueuelen:1000</span><br><span class="line">RX bytes:1296 (1.2 KiB) TX bytes:648 (648.0 B)</span><br><span class="line">lo Link encap:Local Loopback</span><br><span class="line">inet addr:127.0.0.1 Mask:255.0.0.0</span><br><span class="line">UP LOOPBACK RUNNING MTU:65536 Metric:1</span><br><span class="line">RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">collisions:0 txqueuelen:1000</span><br><span class="line">RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure>
<h2 id="7-在compute节点安装zun服务"><a href="#7-在compute节点安装zun服务" class="headerlink" title="7 在compute节点安装zun服务"></a>7 在compute节点安装zun服务</h2><h3 id="7-1-创建用户"><a href="#7-1-创建用户" class="headerlink" title="7.1 创建用户"></a>7.1 创建用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# groupadd --system zun</span><br><span class="line">[root@compute kuryr-libnetwork]# useradd --home-dir &quot;&#x2F;var&#x2F;lib&#x2F;zun&quot;</span><br><span class="line">--create-home --system --shell &#x2F;bin&#x2F;false -g zun zun</span><br></pre></td></tr></table></figure>
<h3 id="7-2-创建目录"><a href="#7-2-创建目录" class="headerlink" title="7.2 创建目录"></a>7.2 创建目录</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# mkdir -p &#x2F;etc&#x2F;zun</span><br><span class="line">[root@compute kuryr-libnetwork]# chown zun:zun &#x2F;etc&#x2F;zun</span><br></pre></td></tr></table></figure>
<h3 id="7-3-安装zun"><a href="#7-3-安装zun" class="headerlink" title="7.3 安装zun"></a>7.3 安装zun</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute kuryr-libnetwork]# cd &#x2F;var&#x2F;lib&#x2F;zun</span><br><span class="line">[root@compute zun]# git clone -b stable&#x2F;queens</span><br><span class="line">https:&#x2F;&#x2F;git.openstack.org&#x2F;openstack&#x2F;zun.git</span><br><span class="line">Cloning into &#39;zun&#39;...</span><br><span class="line">remote: Counting objects: 18434, done.</span><br><span class="line">remote: Compressing objects: 100% (10103&#x2F;10103), done.</span><br><span class="line">remote: Total 18434 (delta 14071), reused 11790 (delta 7990)</span><br><span class="line">Receiving objects: 100% (18434&#x2F;18434), 2.56 MiB | 98.00 KiB&#x2F;s, done.</span><br><span class="line">Resolving deltas: 100% (14071&#x2F;14071), done.</span><br><span class="line">[root@compute zun]# chown -R zun:zun zun</span><br><span class="line">[root@compute zun]# cd zun</span><br><span class="line">[root@compute zun]# pip install -r requirements.txt</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): PyYAML&gt;&#x3D;3.10 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 5))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages</span><br><span class="line">(from -r requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">keystonemiddleware&gt;&#x3D;4.17.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 7))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">jsonpatch!&#x3D;1.20,&gt;&#x3D;1.16 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 8))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pbr!&#x3D;2.1.0,&gt;&#x3D;2.0.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 9))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages</span><br><span class="line">(from -r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): python-etcd&gt;&#x3D;0.4.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 11))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-glanceclient&gt;&#x3D;2.8.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 12))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-neutronclient&gt;&#x3D;6.3.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 13))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-novaclient&gt;&#x3D;9.1.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 14))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-cinderclient&gt;&#x3D;3.3.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 15))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.i18n&gt;&#x3D;3.15.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 16))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.log&gt;&#x3D;3.36.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 17))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.concurrency&gt;&#x3D;3.25.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 18))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.config&gt;&#x3D;5.1.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 19))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.messaging&gt;&#x3D;5.29.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 20))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.middleware&gt;&#x3D;3.31.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 21))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.policy&gt;&#x3D;1.30.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 22))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.privsep&gt;&#x3D;1.23.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 23))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.serialization!&#x3D;2.19.1,&gt;&#x3D;2.18.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">-r requirements.txt (line 24))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">oslo.versionedobjects&gt;&#x3D;1.31.2 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 26))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.context&gt;&#x3D;2.19.2</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 27))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.utils&gt;&#x3D;3.33.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 28))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.db&gt;&#x3D;4.27.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 29))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): os-vif!&#x3D;1.8.0,&gt;&#x3D;1.7.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 30))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): os-brick&gt;&#x3D;2.2.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): six&gt;&#x3D;1.10.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 32))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): WSME&gt;&#x3D;0.8.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 33))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">SQLAlchemy!&#x3D;1.1.5,!&#x3D;1.1.6,!&#x3D;1.1.7,!&#x3D;1.1.8,&gt;&#x3D;1.0.10 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 34))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): stevedore&gt;&#x3D;1.20.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 35))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): docker&gt;&#x3D;2.4.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 36))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): netaddr&gt;&#x3D;0.7.18 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 37))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): neutron-lib&gt;&#x3D;1.13.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 38))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): websockify&gt;&#x3D;0.8.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r requirements.txt (line 39))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">websocket-client&lt;&#x3D;0.40.0,&gt;&#x3D;0.33.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from -r</span><br><span class="line">requirements.txt (line 40))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): enum-compat in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2-&gt;-r requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): greenlet&gt;&#x3D;0.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2-&gt;-r requirements.txt (line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): jsonpointer&gt;&#x3D;1.9 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from jsonpatch!&#x3D;1.20,&gt;&#x3D;1.16-&gt;-r</span><br><span class="line">requirements.txt (line 8))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): WebOb&gt;&#x3D;1.2dev in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Mako&gt;&#x3D;0.4.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): WebTest&gt;&#x3D;1.3.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): logutils&gt;&#x3D;0.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): singledispatch in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): urllib3&gt;&#x3D;1.7.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-etcd&gt;&#x3D;0.4.3-&gt;-r requirements.txt</span><br><span class="line">(line 11))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): dnspython&gt;&#x3D;1.13.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-etcd&gt;&#x3D;0.4.3-&gt;-r requirements.txt</span><br><span class="line">(line 11))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): monotonic&gt;&#x3D;0.6 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): PasteDeploy&gt;&#x3D;1.5.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Routes&gt;&#x3D;2.3.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Paste&gt;&#x3D;2.0.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r</span><br><span class="line">requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): Babel!&#x3D;2.4.0,&gt;&#x3D;2.3.4</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt</span><br><span class="line">(line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): requests&gt;&#x3D;2.14.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt</span><br><span class="line">(line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">retrying!&#x3D;1.3.0,&gt;&#x3D;1.2.3 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt (line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): os-win&gt;&#x3D;3.0.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from os-brick&gt;&#x3D;2.2.0-&gt;-r requirements.txt</span><br><span class="line">(line 31))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pytz in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from WSME&gt;&#x3D;0.8.0-&gt;-r requirements.txt (line</span><br><span class="line">33))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): simplegeneric in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from WSME&gt;&#x3D;0.8.0-&gt;-r requirements.txt (line</span><br><span class="line">33))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): docker-pycreds&gt;&#x3D;0.3.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from docker&gt;&#x3D;2.4.2-&gt;-r requirements.txt</span><br><span class="line">(line 36))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">backports.ssl-match-hostname&gt;&#x3D;3.5; python_version &lt; &quot;3.5&quot; in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from docker&gt;&#x3D;2.4.2-&gt;-r requirements.txt</span><br><span class="line">(line 36))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): ipaddress&gt;&#x3D;1.0.16;</span><br><span class="line">python_version &lt; &quot;3.3&quot; in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">docker&gt;&#x3D;2.4.2-&gt;-r requirements.txt (line 36))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): numpy in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from websockify&gt;&#x3D;0.8.0-&gt;-r</span><br><span class="line">requirements.txt (line 39))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): enum34 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">enum-compat-&gt;eventlet!&#x3D;0.18.3,!&#x3D;0.20.1,&lt;0.21.0,&gt;&#x3D;0.18.2-&gt;-r requirements.txt</span><br><span class="line">(line 6))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): MarkupSafe&gt;&#x3D;0.9.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">Mako&gt;&#x3D;0.4.0-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r requirements.txt</span><br><span class="line">(line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): waitress&gt;&#x3D;0.8.5 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">WebTest&gt;&#x3D;1.3.1-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r</span><br><span class="line">requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): beautifulsoup4 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">WebTest&gt;&#x3D;1.3.1-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r</span><br><span class="line">requirements.txt (line 10))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): repoze.lru&gt;&#x3D;0.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">Routes&gt;&#x3D;2.3.1-&gt;oslo.service!&#x3D;1.28.1,&gt;&#x3D;1.24.0-&gt;-r requirements.txt (line 25))</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): setuptools in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">waitress&gt;&#x3D;0.8.5-&gt;WebTest&gt;&#x3D;1.3.1-&gt;pecan!&#x3D;1.0.2,!&#x3D;1.0.3,!&#x3D;1.0.4,!&#x3D;1.2,&gt;&#x3D;1.0.0-&gt;-r</span><br><span class="line">requirements.txt (line 10))</span><br><span class="line">You are using pip version 8.1.2, however version 10.0.1 is available.</span><br><span class="line">You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.</span><br><span class="line">[root@compute zun]# python setup.py install</span><br></pre></td></tr></table></figure>
<h3 id="7-4-生成示例配置文件"><a href="#7-4-生成示例配置文件" class="headerlink" title="7.4 生成示例配置文件"></a>7.4 生成示例配置文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># su -s &#x2F;bin&#x2F;sh -c &quot;oslo-config-generator --config-file</span><br><span class="line">etc&#x2F;zun&#x2F;zun-config-generator.conf&quot; zun</span><br><span class="line"># su -s &#x2F;bin&#x2F;sh -c &quot;cp etc&#x2F;zun&#x2F;zun.conf.sample &#x2F;etc&#x2F;zun&#x2F;zun.conf&quot; zun</span><br><span class="line"># su -s &#x2F;bin&#x2F;sh -c &quot;cp etc&#x2F;zun&#x2F;rootwrap.conf &#x2F;etc&#x2F;zun&#x2F;rootwrap.conf&quot; zun</span><br><span class="line"># su -s &#x2F;bin&#x2F;sh -c &quot;mkdir -p &#x2F;etc&#x2F;zun&#x2F;rootwrap.d&quot; zun</span><br><span class="line"># su -s &#x2F;bin&#x2F;sh -c &quot;cp etc&#x2F;zun&#x2F;rootwrap.d&#x2F;* &#x2F;etc&#x2F;zun&#x2F;rootwrap.d&#x2F;&quot; zun</span><br></pre></td></tr></table></figure>
<h3 id="7-5-配置zun用户"><a href="#7-5-配置zun用户" class="headerlink" title="7.5 配置zun用户"></a>7.5 配置zun用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># echo &quot;zun ALL&#x3D;(root) NOPASSWD: &#x2F;usr&#x2F;local&#x2F;bin&#x2F;zun-rootwrap \\</span><br><span class="line">&#x2F;etc&#x2F;zun&#x2F;rootwrap.conf *&quot; | sudo tee &#x2F;etc&#x2F;sudoers.d&#x2F;zun-rootwrap</span><br></pre></td></tr></table></figure>
<h3 id="7-6-编辑配置文件，添加以下内容"><a href="#7-6-编辑配置文件，添加以下内容" class="headerlink" title="7.6 编辑配置文件，添加以下内容"></a>7.6 编辑配置文件，添加以下内容</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;zun&#x2F;zun.conf</span><br><span class="line">[DEFAULT]</span><br><span class="line">transport_url &#x3D; rabbit:&#x2F;&#x2F;openstack:000000@controller</span><br><span class="line">[DEFAULT]</span><br><span class="line">state_path &#x3D; &#x2F;var&#x2F;lib&#x2F;zun</span><br><span class="line">[database]</span><br><span class="line">connection &#x3D; mysql+pymysql:&#x2F;&#x2F;zun:000000@controller&#x2F;zun</span><br><span class="line">[keystone_auth]</span><br><span class="line">memcached_servers &#x3D; controller:11211</span><br><span class="line">www_authenticate_uri &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">project_domain_name &#x3D; default</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">user_domain_name &#x3D; default</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">username &#x3D; zun</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_type &#x3D; password</span><br><span class="line">auth_version &#x3D; v3</span><br><span class="line">auth_protocol &#x3D; http</span><br><span class="line">service_token_roles_required &#x3D; True</span><br><span class="line">endpoint_type &#x3D; internalURL</span><br><span class="line">[keystone_authtoken]</span><br><span class="line">memcached_servers &#x3D; controller:11211</span><br><span class="line">www_authenticate_uri&#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">project_domain_name &#x3D; default</span><br><span class="line">project_name &#x3D; service</span><br><span class="line">user_domain_name &#x3D; default</span><br><span class="line">password &#x3D; 000000</span><br><span class="line">username &#x3D; zun</span><br><span class="line">auth_url &#x3D; http:&#x2F;&#x2F;controller:5000</span><br><span class="line">auth_type &#x3D; password</span><br><span class="line">[websocket_proxy]</span><br><span class="line">base_url &#x3D; ws:&#x2F;&#x2F;controller:6784&#x2F;</span><br><span class="line">[oslo_concurrency]</span><br><span class="line">lock_path &#x3D; &#x2F;var&#x2F;lib&#x2F;zun&#x2F;tmp</span><br></pre></td></tr></table></figure>
<h3 id="7-7-配置docker和kuryr"><a href="#7-7-配置docker和kuryr" class="headerlink" title="7.7 配置docker和kuryr"></a>7.7 配置docker和kuryr</h3><h4 id="7-7-1-创建docker配置文件夹"><a href="#7-7-1-创建docker配置文件夹" class="headerlink" title="7.7.1 创建docker配置文件夹"></a>7.7.1 创建docker配置文件夹</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute zun]# mkdir -p &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d</span><br></pre></td></tr></table></figure>
<h4 id="7-7-2-创建docker配置文件"><a href="#7-7-2-创建docker配置文件" class="headerlink" title="7.7.2 创建docker配置文件"></a>7.7.2 创建docker配置文件</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;docker.service.d&#x2F;docker.conf</span><br><span class="line">[Service]</span><br><span class="line">ExecStart&#x3D;</span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd --group zun -H tcp:&#x2F;&#x2F;compute:2375 -H</span><br><span class="line">unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock --cluster-store etcd:&#x2F;&#x2F;controller:2379</span><br></pre></td></tr></table></figure>
<h4 id="7-7-3-重启docker"><a href="#7-7-3-重启docker" class="headerlink" title="7.7.3 重启docker"></a>7.7.3 重启docker</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute zun]# systemctl daemon-reload</span><br><span class="line">[root@compute zun]# systemctl restart docker</span><br></pre></td></tr></table></figure>
<h4 id="7-7-4-编辑kuryr配置文件，添加以下内容"><a href="#7-7-4-编辑kuryr配置文件，添加以下内容" class="headerlink" title="7.7.4 编辑kuryr配置文件，添加以下内容"></a>7.7.4 编辑kuryr配置文件，添加以下内容</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;kuryr&#x2F;kuryr.conf</span><br><span class="line">[DEFAULT]</span><br><span class="line">capability_scope &#x3D; global</span><br></pre></td></tr></table></figure>
<h4 id="7-7-5-重启kuryr"><a href="#7-7-5-重启kuryr" class="headerlink" title="7.7.5 重启kuryr"></a>7.7.5 重启kuryr</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute zun]# systemctl restart kuryr-libnetwork</span><br></pre></td></tr></table></figure>
<h3 id="7-8-创建启动文件"><a href="#7-8-创建启动文件" class="headerlink" title="7.8 创建启动文件"></a>7.8 创建启动文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vi &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-compute.service</span><br><span class="line">[Unit]</span><br><span class="line">Description &#x3D; OpenStack Container Service Compute Agent</span><br><span class="line">[Service]</span><br><span class="line">ExecStart &#x3D; &#x2F;usr&#x2F;bin&#x2F;zun-compute</span><br><span class="line">User &#x3D; zun</span><br><span class="line">[Install]</span><br><span class="line">WantedBy &#x3D; multi-user.target</span><br></pre></td></tr></table></figure>
<h3 id="7-9-启动zun-compute"><a href="#7-9-启动zun-compute" class="headerlink" title="7.9 启动zun-compute"></a>7.9 启动zun-compute</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@compute zun]# systemctl start zun-compute</span><br><span class="line">[root@compute zun]# systemctl enable zun-compute</span><br><span class="line">Created symlink from</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;zun-compute.service to</span><br><span class="line">&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-compute.service.</span><br><span class="line">[root@compute zun]# systemctl status zun-compute</span><br><span class="line">● zun-compute.service - OpenStack Container Service Compute Agent</span><br><span class="line">Loaded: loaded (&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;zun-compute.service; enabled; vendor preset:</span><br><span class="line">disabled)</span><br><span class="line">Active: active (running) since Wed 2018-06-20 11:06:37 EDT; 13s ago</span><br><span class="line">Main PID: 4923 (zun-compute)</span><br><span class="line">CGroup: &#x2F;system.slice&#x2F;zun-compute.service</span><br><span class="line">└─4923 &#x2F;usr&#x2F;bin&#x2F;python &#x2F;usr&#x2F;bin&#x2F;zun-compute</span><br><span class="line">Jun 20 11:06:37 compute systemd[1]: Started OpenStack Container Service Compute</span><br><span class="line">Agent.</span><br><span class="line">Jun 20 11:06:37 compute systemd[1]: Starting OpenStack Container Service Compute</span><br><span class="line">Agent...</span><br><span class="line">Jun 20 11:06:39 compute zun-compute[4923]: 2018-06-20 11:06:39.902 4923 INFO</span><br><span class="line">zun.cmd.compute [-] Starting server in PID 4923</span><br><span class="line">Jun 20 11:06:39 compute zun-compute[4923]: 2018-06-20 11:06:39.913 4923 INFO</span><br><span class="line">zun.container.driver [-] Loading container driver &#39;docke...Driver&#39;</span><br><span class="line">Jun 20 11:06:40 compute zun-compute[4923]: 2018-06-20 11:06:40.104 4923 INFO</span><br><span class="line">zun.container.driver [-] Loading container driver &#39;docke...Driver&#39;</span><br><span class="line">Jun 20 11:06:40 compute zun-compute[4923]: 2018-06-20 11:06:40.530 4923 WARNING</span><br><span class="line">zun.compute.compute_node_tracker [-] No compute node ... found.</span><br><span class="line">Jun 20 11:06:40 compute zun-compute[4923]: 2018-06-20 11:06:40.563 4923 INFO</span><br><span class="line">zun.compute.compute_node_tracker [-] Node created for :compute</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br></pre></td></tr></table></figure>
<h3 id="7-10-验证"><a href="#7-10-验证" class="headerlink" title="7.10 验证"></a>7.10 验证</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">controller节点验证</span><br><span class="line">[root@controller ~]# pip install python-zunclient&#x3D;&#x3D;1.1.0</span><br><span class="line">Collecting python-zunclient&#x3D;&#x3D;1.1.0</span><br><span class="line">Downloading</span><br><span class="line">https:&#x2F;&#x2F;files.pythonhosted.org&#x2F;packages&#x2F;5a&#x2F;9d&#x2F;95cd86eaf2c3a721abc28d8d3f1747f789b3e028a8ddf5098da9e69111f8&#x2F;python_zunclient-1.1.0-py2-none-any.whl</span><br><span class="line">(122kB)</span><br><span class="line">100% |████████████████████████████████| 122kB 86kB&#x2F;s</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">websocket-client&lt;&#x3D;0.40.0,&gt;&#x3D;0.33.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): osc-lib&gt;&#x3D;1.8.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): PyYAML&gt;&#x3D;3.10 in</span><br><span class="line">&#x2F;usr&#x2F;lib64&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.i18n&gt;&#x3D;3.15.3 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): oslo.utils&gt;&#x3D;3.33.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): docker&gt;&#x3D;2.4.2 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): keystoneauth1&gt;&#x3D;3.3.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">python-openstackclient&gt;&#x3D;3.12.0 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): pbr!&#x3D;2.1.0,&gt;&#x3D;2.0.0 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">PrettyTable&lt;0.8,&gt;&#x3D;0.7.1 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): six in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">websocket-client&lt;&#x3D;0.40.0,&gt;&#x3D;0.33.0-&gt;python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">backports.ssl_match_hostname in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">websocket-client&lt;&#x3D;0.40.0,&gt;&#x3D;0.33.0-&gt;python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): docker-pycreds&gt;&#x3D;0.3.0</span><br><span class="line">in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">docker&gt;&#x3D;2.4.2-&gt;python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): ipaddress&gt;&#x3D;1.0.16;</span><br><span class="line">python_version &lt; &quot;3.3&quot; in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">docker&gt;&#x3D;2.4.2-&gt;python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade):</span><br><span class="line">requests!&#x3D;2.18.0,&gt;&#x3D;2.14.2 in &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">docker&gt;&#x3D;2.4.2-&gt;python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Requirement already satisfied (use --upgrade to upgrade): urllib3&#x3D;&#x3D;1.21.1 in</span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages (from</span><br><span class="line">requests!&#x3D;2.18.0,&gt;&#x3D;2.14.2-&gt;docker&gt;&#x3D;2.4.2-&gt;python-zunclient&#x3D;&#x3D;1.1.0)</span><br><span class="line">Installing collected packages: python-zunclient</span><br><span class="line">Successfully installed python-zunclient-1.1.0</span><br><span class="line">You are using pip version 8.1.2, however version 10.0.1 is available.</span><br><span class="line">You should consider upgrading via the &#39;pip install --upgrade pip&#39; command.</span><br><span class="line">[root@controller ~]# . admin-openrc</span><br><span class="line">[root@controller ~]# openstack appcontainer service list</span><br><span class="line">+----+---------+-------------+-------+----------+-----------------+---------------------------+---------------------------+</span><br><span class="line">| Id | Host | Binary | State | Disabled | Disabled Reason | Created At |</span><br><span class="line">Updated At |</span><br><span class="line">+----+---------+-------------+-------+----------+-----------------+---------------------------+---------------------------+</span><br><span class="line">| 1 | compute | zun-compute | down | False | None | 2018-06-20</span><br><span class="line">15:06:40+00:00 | 2018-06-20 15:08:40+00:00 |</span><br><span class="line">+----+---------+-------------+-------+----------+-----------------+---------------------------+---------------------------+</span><br></pre></td></tr></table></figure>
<h3 id="8-在controller节点启动一个容器实例"><a href="#8-在controller节点启动一个容器实例" class="headerlink" title="8 在controller节点启动一个容器实例"></a>8 在controller节点启动一个容器实例</h3><h4 id="8-1-查看网络"><a href="#8-1-查看网络" class="headerlink" title="8.1 查看网络"></a>8.1 查看网络</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# openstack network list</span><br><span class="line">+--------------------------------------+--------------------+--------------------------------------+</span><br><span class="line">| ID | Name | Subnets |</span><br><span class="line">+--------------------------------------+--------------------+--------------------------------------+</span><br><span class="line">| 13c3ecb4-8f1b-46bc-b6dd-b11c0e9b918d | kuryr-net-9ab4903d |</span><br><span class="line">e5c0a1bf-5357-4423-9b7f-8092eff6e3d8 |</span><br><span class="line">| 5cdbccc3-7414-4830-b70d-a798221ee9e4 | provider |</span><br><span class="line">9bb47dec-a69c-4be1-a509-7dd4448aea70 |</span><br><span class="line">| 8e4e0de6-6a55-42cd-b3ab-5f11a02c4ca9 | selfservice |</span><br><span class="line">af931610-c2fc-4db4-9fa2-eab89efbba61 |</span><br><span class="line">+--------------------------------------+--------------------+--------------------------------------+</span><br></pre></td></tr></table></figure>
<h4 id="8-2-获取网络id"><a href="#8-2-获取网络id" class="headerlink" title="8.2 获取网络id"></a>8.2 获取网络id</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# export NET_ID&#x3D;$(openstack network list | awk &#39;&#x2F;</span><br><span class="line">selfservice &#x2F; &#123; print $2 &#125;&#39;)</span><br></pre></td></tr></table></figure>
<h4 id="8-3-创建容器"><a href="#8-3-创建容器" class="headerlink" title="8.3 创建容器"></a>8.3 创建容器</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@controller ~]# openstack appcontainer run --name container --net</span><br><span class="line">network&#x3D;$NET_ID cirros</span><br><span class="line">+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| Field | Value |</span><br><span class="line">+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">| addresses | None |</span><br><span class="line">| links | [&#123;u&#39;href&#39;:</span><br><span class="line">u&#39;http:&#x2F;&#x2F;controller:9517&#x2F;v1&#x2F;containers&#x2F;145f41f2-dc5f-4b04-9226-6ae248b6061f&#39;,</span><br><span class="line">u&#39;rel&#39;: u&#39;self&#39;&#125;, &#123;u&#39;href&#39;:</span><br><span class="line">u&#39;http:&#x2F;&#x2F;controller:9517&#x2F;containers&#x2F;145f41f2-dc5f-4b04-9226-6ae248b6061f&#39;,</span><br><span class="line">u&#39;rel&#39;: u&#39;bookmark&#39;&#125;] |</span><br><span class="line">| image | cirros |</span><br><span class="line">| labels | &#123;&#125; |</span><br><span class="line">| disk | 0 |</span><br><span class="line">| security_groups | None |</span><br><span class="line">| image_pull_policy | None |</span><br><span class="line">| user_id | a07017719a364efa913cae79bbddbe19 |</span><br><span class="line">| uuid | 145f41f2-dc5f-4b04-9226-6ae248b6061f |</span><br><span class="line">| hostname | None |</span><br><span class="line">| environment | &#123;&#125; |</span><br><span class="line">| memory | None |</span><br><span class="line">| project_id | 14774f73585d4ed48d5198c778645baa |</span><br><span class="line">| status | Error |</span><br><span class="line">| workdir | None |</span><br><span class="line">| auto_remove | False |</span><br><span class="line">| status_detail | None |</span><br><span class="line">| host | None |</span><br><span class="line">| image_driver | None |</span><br><span class="line">| task_state | None |</span><br><span class="line">| status_reason | No valid host was found. Is the appropriate service running?</span><br><span class="line">|</span><br><span class="line">| name | container |</span><br><span class="line">| restart_policy | None |</span><br><span class="line">| ports | None |</span><br><span class="line">| command | None |</span><br><span class="line">| runtime | None |</span><br><span class="line">| cpu | None |</span><br><span class="line">| interactive | False |</span><br><span class="line">+-------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<h4 id="8-4-查看容器列表"><a href="#8-4-查看容器列表" class="headerlink" title="8.4 查看容器列表"></a>8.4 查看容器列表</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># openstack appcontainer list</span><br></pre></td></tr></table></figure>
<h4 id="8-5-执行sh命令"><a href="#8-5-执行sh命令" class="headerlink" title="8.5 执行sh命令"></a>8.5 执行sh命令</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># openstack appcontainer exec --interactive container &#x2F;bin&#x2F;sh</span><br></pre></td></tr></table></figure>
<h4 id="8-6-验证网络"><a href="#8-6-验证网络" class="headerlink" title="8.6 验证网络"></a>8.6 验证网络</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ping -c 4 openstack.org;exit</span><br></pre></td></tr></table></figure>
<h4 id="8-7-停止容器"><a href="#8-7-停止容器" class="headerlink" title="8.7 停止容器"></a>8.7 停止容器</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># openstack appcontainer stop container</span><br></pre></td></tr></table></figure>
<h4 id="8-8-删除容器"><a href="#8-8-删除容器" class="headerlink" title="8.8 删除容器"></a>8.8 删除容器</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># openstack appcontainer delete container</span><br></pre></td></tr></table></figure>
<h2 id="9-安装zun-ui"><a href="#9-安装zun-ui" class="headerlink" title="9 安装zun-ui"></a>9 安装zun-ui</h2><h3 id="9-1-下载zun源文件"><a href="#9-1-下载zun源文件" class="headerlink" title="9.1 下载zun源文件"></a>9.1 下载zun源文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># git clone https:&#x2F;&#x2F;github.com&#x2F;openstack&#x2F;zun-ui</span><br></pre></td></tr></table></figure>
<h3 id="9-2-复制文件"><a href="#9-2-复制文件" class="headerlink" title="9.2 复制文件"></a>9.2 复制文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cp &#x2F;zun-ui&#x2F;zun_ui&#x2F;enabled&#x2F;_1330_project_container_panelgroup.py</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;openstack-dashboard&#x2F;openstack_dashboard&#x2F;local&#x2F;enabled&#x2F;</span><br><span class="line"># cp &#x2F;zun-ui&#x2F;zun_ui&#x2F;enabled&#x2F;_1331_project_container_containers_panel.py</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;openstack-dashboard&#x2F;openstack_dashboard&#x2F;local&#x2F;enabled&#x2F;</span><br><span class="line"># cp.&#x2F;zun-ui&#x2F;zun_ui&#x2F;enabled&#x2F;_2330_project_container_panelgroup.py</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;openstack-dashboard&#x2F;openstack_dashboard&#x2F;local&#x2F;enabled&#x2F;</span><br><span class="line"># cp &#x2F;zun-ui&#x2F;zun_ui&#x2F;enabled&#x2F;_2331_project_container_images_panel.py</span><br><span class="line">openstack_dashboard&#x2F;local&#x2F;enabled</span><br><span class="line"># cp &#x2F;zun-ui&#x2F;zun_ui&#x2F;enabled&#x2F;_0330_cloud_shell.py</span><br><span class="line">&#x2F;usr&#x2F;share&#x2F;openstack-dashboard&#x2F;openstack_dashboard&#x2F;local&#x2F;enabled&#x2F;</span><br></pre></td></tr></table></figure>
<h3 id="9-3-安装ui模块"><a href="#9-3-安装ui模块" class="headerlink" title="9.3 安装ui模块"></a>9.3 安装ui模块</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># pip install zun-ui</span><br></pre></td></tr></table></figure>
<h3 id="9-4-重启服务"><a href="#9-4-重启服务" class="headerlink" title="9.4 重启服务"></a>9.4 重启服务</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># systemctl restart httpd memcached</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title>pod资源限制和QoS探索</title>
    <url>/2021/01/31/pod%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%E5%92%8CQoS%E6%8E%A2%E7%B4%A2/</url>
    <content><![CDATA[<h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>默认情况下，k8s不会对pod的资源使用进行限制，也就是说，pod可以无限使用主机的资源，例如CPU、内存等。为了保障k8s整体环境运行的稳定性，一般情况下，建议是对pod的资源使用进行限制，将其限制在一个范围内，防止起过度使用主机资源造成节点负载过大，导致其上面运行的其他应用受到影响。</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ul>
<li><p>已有的k8s环境（这里安装的是k8s-v1.18.12版本）</p>
</li>
<li><p>k8s集群安装了metrics-server服务（这里借助rancher搭建k8s集群，默认安装了该服务）</p>
</li>
</ul>
<h2 id="何为CGroup"><a href="#何为CGroup" class="headerlink" title="何为CGroup"></a>何为CGroup</h2><p>参考Wiki，<strong>cgroups</strong>其名称源自<strong>控制组群</strong>（英语：control groups）的简写，是Linux内核的一个功能，用来限制、控制与分离一个进程组的资源（如CPU、内存、磁盘输入输出等）。</p>
<p>也就是说，通过设置CGroup，可以达到对资源的控制，例如限制内存、CPU的使用。在k8s中，对pod的资源限制就是通过CGroup这个技术来实现的。</p>
<h2 id="内存限制"><a href="#内存限制" class="headerlink" title="内存限制"></a>内存限制</h2><h3 id="pod示例"><a href="#pod示例" class="headerlink" title="pod示例"></a>pod示例</h3><p>首先创建一个pod，并设置内存限制</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>内存单位：E、P、T、G、M、K、Ei、Pi、Ti、Gi、Mi、Ki</p>
<p>其中M = 1000 x 1000，Mi = 1024 x 1024</p>
<p>limit必须要≥request</p>
</blockquote>
<p>完整yaml参考</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-memory</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stress</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">polinux/stress</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;stress&quot;</span>]</span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--vm&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;--vm-bytes&quot;</span>, <span class="string">&quot;150M&quot;</span>, <span class="string">&quot;--vm-hang&quot;</span>, <span class="string">&quot;1&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node01</span>		<span class="comment">## 这里指定调度到某个节点上，方便接下来的操作</span></span><br></pre></td></tr></table></figure>

<p>这里设置了内存的limit为”200Mi”，内存的request为”100Mi”,并通过<code>stress</code>，指定分配150M的内存空间</p>
<p>接着我们运行该yaml</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f stress-memory.yaml</span><br></pre></td></tr></table></figure>

<p>等到pod运行起来后，我们看一下pod的详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod stress-memory -oyaml</span><br></pre></td></tr></table></figure>

<p>输出结果如下</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-memory</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">b84cf8e8-03b3-4365-b5b5-5d9f99969705</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">100Mi</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">qosClass:</span> <span class="string">Burstable</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>从上述输出中可以获取如下两个信息：</p>
<ul>
<li>pod的uid为<code>b84cf8e8-03b3-4365-b5b5-5d9f99969705</code></li>
<li>pod的QoSClass为<code>Burstable</code></li>
</ul>
<p>这里<strong>Burstable</strong>对应的就是pod在CGroup中的路径，我们进入到CGroup的memory目录下，并进入到<code>kubepods/Burstable</code>目录中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /sys/fs/cgroup/memory/kubepods/burstable/</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ls</span></span><br><span class="line">...</span><br><span class="line">podb84cf8e8-03b3-4365-b5b5-5d9f99969705</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>通过执行<code>ls</code>命令，能看到其中一个目录为<code>podb84cf8e8-03b3-4365-b5b5-5d9f99969705</code>，正好对应上面我们获得pod的uid，也就是说，对pod的资源限制，就是在这个CGroup目录下实现的</p>
<p>我们看一下这个目录下有什么文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> podb84cf8e8-03b3-4365-b5b5-5d9f99969705/</span><br><span class="line">ls -1</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">8c9adca52f2bfd9e1862f6abaac5b435bdaf233925b7d640edb28e36da0b9b39</span><br><span class="line">ca20137f7d5a42910e22425cca06443c16246c90ee9caa27814442e34a832b21</span><br><span class="line">cgroup.clone_children</span><br><span class="line">cgroup.event_control</span><br><span class="line">cgroup.procs</span><br><span class="line">memory.failcnt</span><br><span class="line">memory.force_empty</span><br><span class="line">memory.kmem.failcnt</span><br><span class="line">memory.kmem.limit_in_bytes</span><br><span class="line">memory.kmem.max_usage_in_bytes</span><br><span class="line">memory.kmem.slabinfo</span><br><span class="line">memory.kmem.tcp.failcnt</span><br><span class="line">memory.kmem.tcp.limit_in_bytes</span><br><span class="line">memory.kmem.tcp.max_usage_in_bytes</span><br><span class="line">memory.kmem.tcp.usage_in_bytes</span><br><span class="line">memory.kmem.usage_in_bytes</span><br><span class="line">memory.limit_in_bytes</span><br><span class="line">memory.max_usage_in_bytes</span><br><span class="line">memory.memsw.failcnt</span><br><span class="line">memory.memsw.limit_in_bytes</span><br><span class="line">memory.memsw.max_usage_in_bytes</span><br><span class="line">memory.memsw.usage_in_bytes</span><br><span class="line">memory.move_charge_at_immigrate</span><br><span class="line">memory.numa_stat</span><br><span class="line">memory.oom_control</span><br><span class="line">memory.pressure_level</span><br><span class="line">memory.soft_limit_in_bytes</span><br><span class="line">memory.stat</span><br><span class="line">memory.swappiness</span><br><span class="line">memory.usage_in_bytes</span><br><span class="line">memory.use_hierarchy</span><br><span class="line">notify_on_release</span><br><span class="line">tasks</span><br></pre></td></tr></table></figure>

<p>相关文件作用如下：</p>
<table>
<thead>
<tr>
<th>文件</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>cgroup.event_control</td>
<td>用于event_fd()接口</td>
</tr>
<tr>
<td>cgroup.procs</td>
<td>展示process列表</td>
</tr>
<tr>
<td>memory.failcnt</td>
<td>内存使用达到限制的次数</td>
</tr>
<tr>
<td>memory.force_empty</td>
<td>强制触发当前CGroup中的内存回收</td>
</tr>
<tr>
<td>memory.limit_in_bytes</td>
<td>内存限制的最大值</td>
</tr>
<tr>
<td>memory.max_usage_in_bytes</td>
<td>记录该CGroup中历史最大内存使用量</td>
</tr>
<tr>
<td>memory.move_charge_at_immigrate</td>
<td>设置/显示当前CGroup的进程移动到另一个CGroup时，当前已占用的内存是否迁移到新的CGroup中，默认为0，即不移动</td>
</tr>
<tr>
<td>memory.numa_stat</td>
<td>显示numa相关的内存信息</td>
</tr>
<tr>
<td>memory.oom_control</td>
<td>设置/显示oom相关信息，其中oom_kill_disable为0，则超过内存会被kill；oom_kill_disable为1则停止进程，直至额外的内存被释放，当进程被暂停时，under_oom返回1</td>
</tr>
<tr>
<td>memory.pressure_level</td>
<td>设置内存压力的通知事件，配合cgroup.event_control一起使用</td>
</tr>
<tr>
<td>memory.soft_limit_in_bytes</td>
<td>设置/显示内存的软限制，默认不限制</td>
</tr>
<tr>
<td>memory.stat</td>
<td>显示当前CGroup中内存使用情况</td>
</tr>
<tr>
<td>memory.swappiness</td>
<td>设置/显示vmscan的swappiness参数（参考sysctl的vm.swappiness）</td>
</tr>
<tr>
<td>memory.usage_in_bytes</td>
<td>显示当前内存使用情况</td>
</tr>
<tr>
<td>memory.use_hierarchy</td>
<td>如果该值为0，将会统计到root cgroup里；如果值为1，则统计到它的父cgroup里面</td>
</tr>
<tr>
<td>notify_on_release</td>
<td>是否在cgroup中最后一个任务退出时通知运行release agent,默认情况下是0,表示不运行。(release_agent在CGroup最顶层的目录)</td>
</tr>
<tr>
<td>tasks</td>
<td>控制的进程组（这里看不到对应进程，需要进入到子group中查看）</td>
</tr>
</tbody></table>
<blockquote>
<p> 不涉及内核内存（memory.kmem.*）和swap分区内存（memory.memsw.*），这里就不详细介绍</p>
</blockquote>
<p>主要关注这几个文件</p>
<ol>
<li><p><code>8c9adca52f2bfd9e1862f6abaac5b435bdaf233925b7d640edb28e36da0b9b39</code>和<code>ca20137f7d5a42910e22425cca06443c16246c90ee9caa27814442e34a832b21</code>：分别对应的是pod运行的主容器ID和pause容器ID</p>
</li>
<li><p><code>memory.usage_in_bytes</code>已使用的内存，例如我这里查看的结果是160817152，也就是153MB左右</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.usage_in_bytes</span></span><br><span class="line">160382976</span><br></pre></td></tr></table></figure>

<p>使用kubect top命令查看使用情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl top pod</span></span><br><span class="line">NAME            CPU(cores)   MEMORY(bytes)   </span><br><span class="line">stress-memory   13m          151Mi  </span><br></pre></td></tr></table></figure>

<ol start="3">
<li><code>memory.limit_in_bytes</code>：内存限制的最大值，等于我们设置的内存limit的值</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.limit_in_bytes</span></span><br><span class="line">160587776</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><code>memory.max_usage_in_bytes</code>：历史内存最大使用量，再查看一下该CGroup下内存历史最大使用量，正好200M</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.max_usage_in_bytes </span></span><br><span class="line">209715200</span><br></pre></td></tr></table></figure>



<h3 id="创建一个内存使用超出limit的pod"><a href="#创建一个内存使用超出limit的pod" class="headerlink" title="创建一个内存使用超出limit的pod"></a>创建一个内存使用超出limit的pod</h3><p>这时候我们将内存使用设置到250M，超出200M的限制</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-memory2</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stress</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">polinux/stress</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;stress&quot;</span>]</span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--vm&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;--vm-bytes&quot;</span>, <span class="string">&quot;250M&quot;</span>, <span class="string">&quot;--vm-hang&quot;</span>, <span class="string">&quot;1&quot;</span>]    <span class="comment">## 修改为250M，也就是分配250M内存</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;200Mi&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node01</span></span><br></pre></td></tr></table></figure>

<p>执行<code>kubectl create</code>命令，运行这个pod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create -f pod-memory-2.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod状态</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod </span></span><br><span class="line"><span class="string">NAME</span>             <span class="string">READY</span>   <span class="string">STATUS</span>      <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">stress-memory</span>    <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>     <span class="number">1</span>          <span class="string">10m6s</span></span><br><span class="line"><span class="string">stress-memory2</span>   <span class="number">0</span><span class="string">/1</span>     <span class="string">OOMKilled</span>   <span class="number">2</span>          <span class="string">26s</span></span><br></pre></td></tr></table></figure>

<p>此时会发现，pod在不断重启，并且<strong>stress-memory2</strong>这个pod的状态为OOMKilled，这个是怎么回事呢，我们可以进到pod对应的CGroup下查看内存使用情况，我们继续看一下目前pod的状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod stress-memory2 -oyaml</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">lastState:</span></span><br><span class="line">      <span class="attr">terminated:</span></span><br><span class="line">        <span class="attr">containerID:</span> <span class="string">docker://a7d686a3b56aa03b66fd4fed07217693d8e41d75529c02bae34769dca6f01f9e</span></span><br><span class="line">        <span class="attr">exitCode:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">finishedAt:</span> <span class="string">&quot;2021-01-18T14:13:21Z&quot;</span></span><br><span class="line">        <span class="attr">reason:</span> <span class="string">OOMKilled</span></span><br><span class="line">        <span class="attr">startedAt:</span> <span class="string">&quot;2021-01-18T14:13:21Z&quot;</span></span><br></pre></td></tr></table></figure>

<p>可以看到pod退出的原因是OOMKilled，什么是OOMKilled呢？简单来说，就是当进程申请的内存超出了已有的内存资源，那么为了保证主机的稳定运行，就会基于进程oom_score的值，有选择性的杀死某个进程。也就是说，在这个例子中，pod申请的内存为250Mi，超过了限制的200Mi，那么就会从该进程所在的CGroup中，杀死对应的进程，具体我们可以看一下该CGroup中内存情况：</p>
<p>通过<code>kubectl get pod stress-memory2 -oyaml</code>命令，获取pod uid，进入到对应的CGroup</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /sys/fs/cgroup/memory/kubepods/burstable/pod92c2a4c2-3b5c-4a9a-8a00-5d59575e96e7/</span><br></pre></td></tr></table></figure>

<p>首先看一下内存限制是多少</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.limit_in_bytes </span></span><br><span class="line">209715200</span><br></pre></td></tr></table></figure>

<p>再查看一下内存使用量，只有1M左右，这是因为此时pod状态不是运行状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.usage_in_bytes </span></span><br><span class="line">1093632</span><br></pre></td></tr></table></figure>

<p>再查看一下该CGroup下内存历史最大使用量，正好200M</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.max_usage_in_bytes </span></span><br><span class="line">209715200</span><br></pre></td></tr></table></figure>

<p>此时我们再看看内存使用量达到限制值的次数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat memory.failcnt </span></span><br><span class="line">531</span><br></pre></td></tr></table></figure>

<p>从以上信息可以得知，内存不断申请超出内存限制的值，导致进程被kill，最终导致pod退出</p>
<h3 id="只设置request"><a href="#只设置request" class="headerlink" title="只设置request"></a>只设置request</h3><p>设置request=100M，不设置limit，并设置pod使用内存150M</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-memory4</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stress</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">polinux/stress</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">&quot;stress&quot;</span>]</span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;--vm&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;--vm-bytes&quot;</span>, <span class="string">&quot;150M&quot;</span>, <span class="string">&quot;--vm-hang&quot;</span>, <span class="string">&quot;1&quot;</span>]</span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;100Mi&quot;</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node01</span></span><br></pre></td></tr></table></figure>

<p>执行<code>kubectl create</code>命令，运行这个pod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create -f pod-memory-4.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod状态</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod</span></span><br><span class="line"><span class="string">NAME</span>             <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">stress-memory3</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">79s</span></span><br></pre></td></tr></table></figure>

<p>查看pod内存使用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl top pod</span></span><br><span class="line">NAME             CPU(cores)   MEMORY(bytes)   </span><br><span class="line">stress-memory3   51m          150Mi  </span><br></pre></td></tr></table></figure>

<p>可以发现，pod内存使用时150Mi，说明只设置内存request，并不会对其限制其内存的使用</p>
<blockquote>
<p><strong>注意：</strong>如果只设置limit，则request=limit</p>
</blockquote>
<h3 id="内存资源限制的目的"><a href="#内存资源限制的目的" class="headerlink" title="内存资源限制的目的"></a>内存资源限制的目的</h3><ul>
<li><p>如果没有指定内存限制，则容器可以无限制的使用主机内存资源，当使用完主机的所有可用资源后，就会导致该节点调用OOMkilled，此时没有设置内存限制的pod对应的进程的score会更大，所以被kill的可能性更大。</p>
</li>
<li><p>为集群中的pod设置内存请求和限制，可以有效的利用集群上的内存资源，防止应用突发高峰期的时候内存猛涨影响其他应用的稳定运行</p>
</li>
</ul>
<h2 id="CPU限制"><a href="#CPU限制" class="headerlink" title="CPU限制"></a>CPU限制</h2><h3 id="pod示例-1"><a href="#pod示例-1" class="headerlink" title="pod示例"></a>pod示例</h3><p>首先创建一个pod，并设置CPU限制</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">resources:</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">  <span class="attr">requests:</span></span><br><span class="line">    <span class="attr">cpu:</span> <span class="string">&quot;0.5&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>CPU单位：小数值是可以使用。一个请求 0.5 CPU 的容器保证会获得请求 1 个 CPU 的容器的 CPU 的一半。 可以使用后缀 <code>m</code> 表示毫。例如 <code>100m</code> CPU、100 milliCPU 和 0.1 CPU 都相同。 精度不能超过 1m。</p>
</blockquote>
<p>完整yaml参考</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-cpu</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stress-cpu</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">vish/stress</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;0.9&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;0.5&quot;</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-cpus</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;2&quot;</span></span><br><span class="line">  <span class="attr">nodeName:</span> <span class="string">node01</span>		<span class="comment">## 这里指定调度到某个节点上，方便接下来的操作</span></span><br></pre></td></tr></table></figure>

<p>这里设置了CPU的limit为”1”，CPU的request为”0.5”，并通过stress指定分配2个进程去跑满2个CPU</p>
<p>接着我们运行该yaml</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f stress-cpu.yaml</span><br></pre></td></tr></table></figure>

<p>等到pod运行起来后，我们看一下pod的详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod stress-cpu -oyaml</span><br></pre></td></tr></table></figure>

<p>输出结果如下</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-cpu</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="number">10929272</span><span class="string">-932f-4b4d-85c8-046a9f0e39d8</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">900m</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">qosClass:</span> <span class="string">Burstable</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>

<p>结合之前的内存相关的实验，从输出的结果中可以得知pod uid为<strong>10929272-932f-4b4d-85c8-046a9f0e39d8</strong>，对应的CGroup路径为<code>kubepods/Burstable</code></p>
<p>在CGroup中可以看到cpu、cpuset、cpuacct三种跟CPU相关的CGroup，其中<code>cpu</code>用于对cpu使用率的划分；<code>cpuset</code>用于设置cpu的亲和性等，主要用于numa架构的os；<code>cpuacct</code>记录了cpu的部分信息。通过定义可以得知，k8s CPU限制在<code>cpu</code>这个目录中，我们进入到对应的pod的CGroup空间下，查看CGroup相关文件是如何工作的</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd /sys/fs/cgroup/cpu/kubepods/burstable/pod10929272-932f-4b4d-85c8-046a9f0e39d8/</span></span><br><span class="line">ls -1</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cgroup.clone_children</span><br><span class="line">cgroup.procs</span><br><span class="line">cpuacct.stat</span><br><span class="line">cpuacct.usage</span><br><span class="line">cpuacct.usage_percpu</span><br><span class="line">cpu.cfs_period_us</span><br><span class="line">cpu.cfs_quota_us</span><br><span class="line">cpu.rt_period_us</span><br><span class="line">cpu.rt_runtime_us</span><br><span class="line">cpu.shares</span><br><span class="line">cpu.stat</span><br><span class="line">d5b407752d32b7cd8937eb6a221b6f013522d00bb237134017ae5d8324ce9e30</span><br><span class="line">eba8c20349137130cdc0af0e9db2a086f6ea5d6f37ad118394b838adfc1325bd</span><br><span class="line">notify_on_release</span><br><span class="line">tasks</span><br></pre></td></tr></table></figure>

<p>相关文件作用如下：</p>
<table>
<thead>
<tr>
<th>文件</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td><code>cgroup.clone_children</code></td>
<td>子cgroup是否会继承父cgroup的配置，默认是0</td>
</tr>
<tr>
<td><code>cgroup.procs</code></td>
<td>树中当前节点的cgroup中的进程组ID，现在我们在根节点，这个文件中是会有现在系统中所有进程组ID</td>
</tr>
<tr>
<td><code>cpu.cfs_period_us</code></td>
<td>统计CPU使用时间的周期，单位是微秒（us）。<br />例如如果设置该CGroup中的进程访问CPU的限制为每1秒访问单个CPU0.2秒，则需要设置<code>cpu.cfs_period_us=200000</code>，<code>cpu.cfs_quota_us=1000000</code><br /></td>
</tr>
<tr>
<td><code>cpu.cfs_quota_us</code></td>
<td>周期内允许占用的CPU时间，即CGroup中的进程能使用cpu的最大时间，该值是硬限（-1为不限制）<br />一旦cgroup中的任务用完了配额指定的所有时间，它们就会在该时间段指定的剩余时间中受到限制，并且直到下一个时间段才允许运行。<code>cpu.cfs_quota_us</code>参数的上限为1秒，下限为1000微秒</td>
</tr>
<tr>
<td><code>cpu.rt_period_us</code></td>
<td>仅适用于实时调度任务，CPU使用时间的周期，单位是微秒（us），默认是1s（1000000us）</td>
</tr>
<tr>
<td><code>cpu.rt_runtime_us</code></td>
<td>仅适用于实时调度任务，此参数指定cgroup中的任务可以访问CPU资源的最长连续时间</td>
</tr>
<tr>
<td><code>cpu.shares</code></td>
<td><code>cpu.shares</code>是软限制，理解为CPU的相对权重。<br />例如，A、B、C三个进程的权重为100、200、300，那么在CPU满载的情况下，A进程最多使用1/6 CPU时间片；而如果CPU不是满载的情况，则各个进程允许使用超出相对权重的大小的CPU时间</td>
</tr>
<tr>
<td><code>cpu.stat</code></td>
<td>CPU时间统计信息，其中：<br /><code>nr_periods</code>—已经过去的周期间隔数（在cpu.cfs_period_us中指定）<br /><code>nr_throttled</code> — cgroup中的任务被限制的次数（即，由于它们已经用尽了配额所指定的所有可用时间，因此不允许运行）<br /><code>throttled_time</code> — cgroup中的任务已被限制的总持续时间（以纳秒为单位）</td>
</tr>
</tbody></table>
<blockquote>
<p>不涉及到cpuacct，这里就不详细介绍</p>
</blockquote>
<p>在CPU的CGroup中，可以使用两个调度程序来调度对CPU资源的访问：</p>
<ul>
<li><code>CFS</code>：完全公平调度程序，比例共享调度程序，根据任务或分配给cgroup的优先级/权重，在任务组（cgroup）之间按比例划分CPU时间。</li>
<li><code>RT</code>：实时调度程序，一种任务调度程序，它提供一种方法来指定实时任务可以使用的CPU时间。（不做讨论）</li>
</ul>
<p>这里主要讨论k8s是如何设置CFS调度算法去限制进程对CPU使用，主要关注这几个文件</p>
<ol>
<li><code>cpu.cfs_period_us</code>和<code>cpu.cfs_quota_us</code>，由这两个文件组成CPU硬限制，在这个例子中，我们设置CPUlimit的值为900m，所以<code>cfs_quota_us/cfs_period_us</code>等于<code>90000/100000</code>，也就是0.9个CPU</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat cpu.cfs_period_us </span></span><br><span class="line">100000</span><br><span class="line"><span class="comment"># cat cpu.cfs_quota_us </span></span><br><span class="line">90000</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>cpu.shares</code>，CPU软限制，在这个例子中我们设置了CPU request为500m，可以看出，CPU request对应了<code>cpu.shares</code>（此时软限制不会起到作用）</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat cpu.shares </span></span><br><span class="line">512</span><br></pre></td></tr></table></figure>

<p>此时查看podCPU使用情况，可以看到确实已经被限制住了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl top pod</span></span><br><span class="line">NAME         CPU(cores)   MEMORY(bytes)   </span><br><span class="line">stress-cpu   902m         0Mi </span><br></pre></td></tr></table></figure>

<h3 id="request之CPU软限制"><a href="#request之CPU软限制" class="headerlink" title="request之CPU软限制"></a>request之CPU软限制</h3><p>在前面讲内存限制的时候说到，如果只设置request，则limit没有限制。</p>
<p>如果CPU只设置request，此时limit也是没有限制。但是不同于内存，CPU request的值会设置到<code>cpu.shares</code>中，也就是说，只设置了request的pod，会有一个CPU软限制。</p>
<p>此时正常情况下，当节点CPU资源充足的时候，设置了request的pod，还是可以正常的请求超出request值的CPU资源，可是当节点可分配的CPU资源不足时，那么CPU软限制就会起到作用，限制pod对CPU的访问。</p>
<p>下面我们测试一下CPU软限制是如何生效的</p>
<p>查看节点可分配的CPU大小</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe node node01</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">...</span><br><span class="line">Allocatable:</span><br><span class="line">  cpu:                4</span><br><span class="line">  ephemeral-storage:  57971659066</span><br><span class="line">  hugepages-2Mi:      0</span><br><span class="line">  memory:             8071996Ki</span><br><span class="line">  pods:               110</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">Allocated resources:</span><br><span class="line">  (Total limits may be over 100 percent, i.e., overcommitted.)</span><br><span class="line">  Resource           Requests    Limits</span><br><span class="line">  --------           --------    ------</span><br><span class="line">  cpu                380m (9%)   10m (0%)</span><br><span class="line">  memory             100Mi (1%)  190Mi (2%)</span><br><span class="line">  ephemeral-storage  0 (0%)      0 (0%)</span><br></pre></td></tr></table></figure>

<p>目前该节点可用CPU数量为4000m，已使用了380m，也就是剩余可用CPU为3620m</p>
<p>我们先创建一个CPU，设置request为0.5的pod，并通过stress指定分配2个进程去跑满2个CPU</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-cpu-1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stress-cpu</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">vish/stress</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;0.5&quot;</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-cpus</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;2&quot;</span></span><br></pre></td></tr></table></figure>

<p>执行<code>kubectl create</code>命令，运行这个pod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create -f stress-cpu-1.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod状态</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod</span></span><br><span class="line"><span class="string">NAME</span>             <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">stress-cpu</span>              <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">5s</span></span><br></pre></td></tr></table></figure>

<p>查看podCPU使用情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl top pod</span></span><br><span class="line">NAME         CPU(cores)   MEMORY(bytes)   </span><br><span class="line">stress-cpu   2001m        0Mi</span><br></pre></td></tr></table></figure>

<p>也可以使用top命令实时查看进程CPU使用情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># top</span></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                            </span><br><span class="line">30285 root      20   0    5824   3692   3120 R 200.0  0.0  56:18.95 stress </span><br></pre></td></tr></table></figure>

<p>此时我们可以看到，我们进程的CPU使用率达到了2001m，超过了request设置的值</p>
<p>这时候我们再启动一个pod，设置request为2.5的pod，并通过stress指定分配2个进程去跑满3个CPU</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">stress-cpu-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">stress-cpu</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">vish/stress</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;2.5&quot;</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-cpus</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;3&quot;</span></span><br></pre></td></tr></table></figure>

<p>执行<code>kubectl create</code>命令，运行这个pod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl create -f stress-cpu-2.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod状态</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pod</span></span><br><span class="line"><span class="string">NAME</span>           <span class="string">READY</span>   <span class="string">STATUS</span>    <span class="string">RESTARTS</span>   <span class="string">AGE</span></span><br><span class="line"><span class="string">stress-cpu</span>     <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">15m</span></span><br><span class="line"><span class="string">stress-cpu-2</span>   <span class="number">1</span><span class="string">/1</span>     <span class="string">Running</span>   <span class="number">0</span>          <span class="string">8s</span></span><br></pre></td></tr></table></figure>

<p>查看podCPU使用情况，此时由于pod占用了大量的CPU资源，执行<code>kubectl</code>会卡住无法执行，可以通过<code>top</code>命令查看CPU使用情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># top</span></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                            </span><br><span class="line">20732 root      20   0    5568   3688   3120 R 300.0  0.0   6:04.80 stress                                                                                             </span><br><span class="line">30285 root      20   0    5824   3692   3120 R  96.2  0.0  63:57.08 stress </span><br></pre></td></tr></table></figure>

<p>我们再来回顾一下，首先这台主机可用CPU资源3620m，总的CPU资源为4个CPU（4000m），其中380m的CPU资源已分配给其他pod使用，但是并没有满负载，所以总的资源我们可以按照4个CPU来算。</p>
<p>这里可以看到PID为30285的进程是之前我们创建的pod  <strong>stress-cpu</strong>，当时设置的request是0.5(500m)，并指定分配2个进程去跑满2个CPU(2000m)，也就是软限制在资源充足的情况下，使用率为200%(2000m)，超过了CPUrequest软限制。</p>
<p>后面我们又创建了一个request为2.5(2500m)，并指定分配3个进程去跑满3个CPU(3000m)的pod <strong>stress-cpu-2</strong>，此时CPU总的CPU使用需求为2+3=5CPU(5000m)，但是CPU的总资源只有4CPU（4000m），此时CPU软限制就会开始发挥作用。</p>
<p>我们查看一下对应的<code>cpu.shares</code>，<strong>stress-cpu</strong> pod 的<code>cpu.shares</code>的值为512，<strong>stress-cpu-2</strong> pod 的<code>cpu.shares</code>的值为2560。</p>
<p><code>cpu.shares</code>是软限制，理解为CPU的相对权重。根据之前表格中的算法，那么当CPU满负载的情况下（此时假设只有这两个pod正在满负载的运行）：</p>
<ul>
<li><strong>stress-cpu</strong>可以使用<code>4 x 512/(512+2560)≈0.666</code>(666m CPU)</li>
<li><strong>stress-cpu-2</strong>可以使用<code>4 x 2560/(512+2560)≈3.333</code>(3333m CPU)</li>
</ul>
<p>由这个公式可以得知，在软限制的前提下，<strong>stress-cpu-2</strong>可以跑满3333m CPU，但是我们只分配了3个进程去跑满CPU，也就是说，实际上<strong>stress-cpu-2</strong>可以跑到3000mCPU ，正好符合我们使用top看到的数据，占用了300%(3000m)，还剩余333m左右的CPU资源未使用，而这部分的资源可以被其他进程使用。那么可以思考一下，<strong>stress-cpu</strong>可以使用多少CPU资源？</p>
<p>其实从上面top命令的结果就可以知道，<strong>stress-cpu</strong>使用了近1000mCPU的资源，这是因为，当CPU满负载时，会相应的分配666mCPU的资源，此时<strong>stress-cpu-2</strong>并没有完全使用完，还剩余333mCPU未被使用，那么由于软限制的作用下，实际上是可以使用这部分未被使用的资源，也就是说，<strong>stress-cpu</strong>可以使用<code>666m + 333m = 999m</code>(CPU)，也就是符合使用top命令看到的96%CPU使用率。</p>
<h3 id="CPU资源限制的目的"><a href="#CPU资源限制的目的" class="headerlink" title="CPU资源限制的目的"></a>CPU资源限制的目的</h3><ul>
<li>如果没有指定CPU限制，则容器可以无限制的使用主机CPU资源。为集群中的pod设置CPU请求和限制，可以有效的利用集群上的CPU资源，防止应用突发高峰期的时候CPU猛涨影响其他应用的稳定运行</li>
</ul>
<h2 id="QoS"><a href="#QoS" class="headerlink" title="QoS"></a>QoS</h2><p>前面我们讲了如何通过设置资源的request和limit来限制pod对主机资源的使用，在前面几个例子中，我们看到，当我们设置了资源配额时，查看pod yaml可以看到<code>qosClass</code>的值为 Burstable，这是因为在k8s中，会为pod设置不同的QoS类型，以保证pod的资源可用，其中QoS有三个类型：</p>
<ul>
<li><code>Guaranteed</code>：Pod中的所有容器（包括init容器）都必须设置内存和CPU的请求(limit)和限制(request)，且请求和限制的值要相等。（如果只设置limit，则默认request=limit）；</li>
<li><code>Burstable</code>：Pod中至少有一个容器设置了内存和CPU请求，且不符合Guaranteed QoS类型的标准；</li>
<li><code>BestEffort</code>：Pod中所有的容器都没有设置任何内存和CPU的限制和请求。</li>
</ul>
<p>即会根据对应的请求和限制来设置QoS等级，接下来我们分别创建对应的QoS等级来感受一下</p>
<h3 id="Guaranteed"><a href="#Guaranteed" class="headerlink" title="Guaranteed"></a>Guaranteed</h3><p>定义：Pod中的所有容器（包括init容器）都必须设置内存和CPU的请求(limit)和限制(request)，且请求和限制的值要相等。其中如果只设置limit，则默认request=limit</p>
<p>举个例子：创建一个包含内存和CPU请求和限制的pod，其中内存的请求和限制都为300Mi，CPU的请求和限制都为500m</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-guaranteed</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-guaranteed</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zerchin/network</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;300Mi&quot;</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;300Mi&quot;</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br></pre></td></tr></table></figure>

<p>创建pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f pod-guaranteed.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod 详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod  pod-guaranteed -oyaml</span><br></pre></td></tr></table></figure>

<p>输出结果如下，可以看到pod的qosClass为<strong>Guaranteed</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-guaranteed</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">494e608c-d63e-41a9-925c-3ac7acf7b465</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">300Mi</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">500m</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">300Mi</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">qosClass:</span> <span class="string">Guaranteed</span></span><br></pre></td></tr></table></figure>

<p>根据前面的经验，这里<strong>Guaranteed</strong>对应的就是pod在CGroup中的路径，对应的CGroup路径如下：</p>
<ul>
<li>CPU：<code>/sys/fs/cgroup/memory/kubepods/pod494e608c-d63e-41a9-925c-3ac7acf7b465</code></li>
<li>内存：<code>/sys/fs/cgroup/cpu/kubepods/pod494e608c-d63e-41a9-925c-3ac7acf7b465</code></li>
</ul>
<h3 id="Burstable"><a href="#Burstable" class="headerlink" title="Burstable"></a>Burstable</h3><p>定义：Pod中至少有一个容器设置了内存和CPU请求，且不符合Guaranteed QoS类型的标准；</p>
<p>回顾一下我们前面我们在了解内存和CPU限制的时候，创建的pod都是<strong>Burstable</strong> Qos类型，包括：</p>
<ul>
<li>单一设置内存或CPU的request</li>
<li>同时设置了内存或CPU的request和limit，且request≠limit</li>
<li>同时设置了内存或CPU的request和limit，且request=limit</li>
</ul>
<p>上述这些都是pod中只含有单个容器，还有一种情况就是单个pod包含多个容器，如果一个容器指定了资源请求，另一个容器没有指定任何请求和限制，则也是属于<strong>Burstable</strong> Qos类型</p>
<p>举个例子：创建一个多容器的pod，其中一个容器设置了内存和CPU的请求和限制且值相等，另一个容器不限制资源</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-burstable</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-burstable-1</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zerchin/network</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;300Mi&quot;</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">&quot;300Mi&quot;</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">&quot;500m&quot;</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-burstable-2</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox:1.28</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">&quot;sh&quot;</span>, <span class="string">&quot;-c&quot;</span>, <span class="string">&quot;sleep 3600&quot;</span>]</span><br></pre></td></tr></table></figure>

<p>创建pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f pod-burstable.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod 详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod  pod-burstable -oyaml</span><br></pre></td></tr></table></figure>

<p>输出结果如下，可以看到pod的qosClass为<strong>Guaranteed</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-burstable</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">7d858afc-f88a-454e-85dc-81670a0ddb8b</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">qosClass:</span> <span class="string">Burstable</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h3 id="BestEffort"><a href="#BestEffort" class="headerlink" title="BestEffort"></a>BestEffort</h3><p>定义：pod中所有的容器都没有设置任何内存和CPU的限制和请求。</p>
<p>这个很好理解，我们创建个pod试试</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-besteffort</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-besteffort</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">zerchin/network</span></span><br></pre></td></tr></table></figure>

<p>创建pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f pod-besteffort.yaml</span><br></pre></td></tr></table></figure>

<p>查看pod 详细信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod  pod-besteffort -oyaml</span><br></pre></td></tr></table></figure>

<p>输出结果如下，可以看到pod的qosClass为<strong>BestEffort</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-besteffort</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">1316dbf7-01ed-415b-b901-2be9d650163c</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">qosClass:</span> <span class="string">BestEffort</span></span><br></pre></td></tr></table></figure>

<p>那么，在CGroup中对应的路径为<code>kubepods/besteffort/pod1316dbf7-01ed-415b-b901-2be9d650163c</code></p>
<h3 id="QoS优先级"><a href="#QoS优先级" class="headerlink" title="QoS优先级"></a>QoS优先级</h3><p>当集群资源被耗尽时，容器会被杀死，此时会根据QoS优先级对pod进行处理，即优先级高的会尽量被保护，而优先级低的会优先被杀死</p>
<p>三种Qos类型优先级（由高到低）：Guaranteed &gt; Burstable &gt; BestEffort</p>
<p>其中CPU属于可压缩资源，而内存属于不可压缩资源，这里我们主要讨论一下当内存耗尽时，是如何根据QoS优先级处理pod</p>
<ul>
<li><code>BestEffort</code>：<code>BestEffort</code>类型的pod没有设置资源限制，此类pod被认为是最低优先级，当系统内存不足时，这些pod会首先被杀死</li>
<li><code>Burstable </code>：<code>Burstable </code>类型的pod设置有部分资源的请求和限制，此类pod的优先级高于<code>BestEffort</code>类型的pod，当系统内存不足且系统中不存在<code>BestEffort</code>类型的pod时才会被杀死</li>
<li><code>Guaranteed </code>：<code>Guaranteed</code>类型的pod同时设置了CPU和内存的资源限制和请求，此类pod的优先级最高，只有在系统内存不足且系统系统中不存在<code>BestEffort</code>和<code>Burstable </code>的pod时才会被杀死</li>
</ul>
<h3 id="OOM-score"><a href="#OOM-score" class="headerlink" title="OOM score"></a>OOM score</h3><p>在前面讲内存限制时提到过，就是当进程申请的内存超出了已有的内存资源，那么为了保证主机的稳定运行，就会基于进程<code>oom_score</code>的值，有选择性的杀死某个进程，这个过程就是OOMKilled。</p>
<p>这里我们先了解一下什么是<code>oom_score</code>：</p>
<p>当系统内存资源被耗尽时，就需要释放部分内存保证主机的运行。而内存是被进程所占用的，所以释放内存实际上就是要杀死进程。那么系统是如何选择进程进行杀死的呢？答案就是基于<code>oom_score</code>的值选择可以杀死的进程。oom_score的值在0-1000范围，其中<code>oom_score</code>的值越高，则被杀死的可能性越大。</p>
<p><code>oom_score</code>的值还会受到<code>oom_score_adj</code>影响，最后的得分会加上<code>oom_score_adj</code>的值，也就是说，可以通过设置<code>oom_score_adj</code>的大小从而影响最终<code>oom_score</code>的大小。</p>
<p>其中正常情况下，<code>oom_score</code>是该进程消耗的内存百分比的10倍，通过<code>oom_score_adj</code>进行调整，例如如果某个进程使用了100%的内存，则得分为1000；如果使用0%的内存，则得分为0（其他例如root用户启动的进程会减去30这里不讨论）</p>
<p>那么我们来看看不同的QoS类型的score值是如何设置的</p>
<ul>
<li><p><code>BestEffort</code>：由于它的优先级最低，为了保证<code>BestEffort</code>类型的pod最先被杀死，所以设置<code>oom_score_adj</code>为1000，那么<code>BestEffort</code>类型pod的<code>oom_score</code>值为1000</p>
</li>
<li><p><code>Guaranteed</code>：由于它的优先级最高，为了保证<code>Guaranteed</code>类型的pod的不被杀死，所以设置<code>oom_score_adj</code>为-998，那么<code>Guaranteed</code>类型pod的<code>oom_score</code>值为0或者1</p>
</li>
<li><p><code>Burstable</code>：这里要分几种情况讨论</p>
<ul>
<li>如果总内存请求 &gt; 可用内存的99.8%，则设置<code>oom_score_adj</code>的值为2，否则将<code>oom_score_adj</code>设置为<code>1000 - 10 x 内存请求的百分比</code>，这样可以确保<code>Burstable</code>类型的pod的<code>oom_score</code> &gt; 1。</li>
<li>如果内存请求为0，则设置<code>oom_score_adj</code>的值为999。所以，如果<code>Burstable</code>类型的pod和<code>Guaranteed</code>类型的发生冲突时，保证<code>Burstable</code>类型的pod被杀死。</li>
<li>如果<code>Burstable</code>类型的pod使用的内存少于请求的内存，则其<code>oom_score</code>&lt;1000，因此，如果<code>BestEffort</code>类型的pod与使用少于请求内存的<code>Burstable</code>类型的pod发生冲突时，则<code>BestEffort</code>类型的pod将被杀死</li>
<li>如果<code>Burstable</code>类型的pod使用的内存大于内存请求时，<code>oom_score</code>=1000，否则<code>oom_score</code>&lt;1000</li>
<li>如果一个使用的内存多于请求内存的<code>Burstable</code>类型的pod，与另一个使用的内存少于请求内存的<code>Burstable</code>类型的pod发生冲突时，则前者将被杀死</li>
<li>如果<code>Burstable</code>类型的pod与多个进程发生冲突，则OOM分数的计算公式是一种启发式的，它不能保证“请求和限制”的保证</li>
</ul>
</li>
</ul>
<p>infra 容器（pause）或init 容器，<code>oom_score_adj</code>为-998</p>
<p>默认kubelet和docker的<code>oom_score_adj</code>为-999</p>
<p>基于上述oom_score，就能保证当系统资源耗尽时，首先被杀死的是<code>BestEffort</code>类型的pod，其次是<code>Burstable</code>类型的pod，最后才是<code>Guaranteed</code>类型的pod</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><blockquote>
<p>cpu软限/硬限制参考：<a href="https://www.cnblogs.com/meisilhr/p/14223869.html">https://www.cnblogs.com/meisilhr/p/14223869.html</a></p>
<p>cpu.shares参考：<a href="https://www.sohu.com/a/226413111_100111840">https://www.sohu.com/a/226413111_100111840</a></p>
<p>CGroup  memory参考：<a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt</a></p>
<p>CGroup memory参考：<a href="https://github.com/torvalds/linux/tree/master/Documentation/admin-guide/cgroup-v1">https://github.com/torvalds/linux/tree/master/Documentation/admin-guide/cgroup-v1</a></p>
<p>CGroup参考：<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-memory#ex-OOM-control-notifications">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-memory#ex-OOM-control-notifications</a></p>
<p>CGroup CPU参考：<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/sec-cpu</a></p>
<p>参考：<a href="https://fuckcloudnative.io/posts/understanding-resource-limits-in-kubernetes-cpu-time/">https://fuckcloudnative.io/posts/understanding-resource-limits-in-kubernetes-cpu-time/</a></p>
<p>QoS oom_score计算参考：<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md#compressible-resource-guarantees">https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md#compressible-resource-guarantees</a></p>
</blockquote>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>prometheus性能优化之RecordingRule</title>
    <url>/2021/02/04/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule/</url>
    <content><![CDATA[<h2 id="问题发现"><a href="#问题发现" class="headerlink" title="问题发现"></a>问题发现</h2><p>客户的k8s环境在查看grafana时发现某些图表无法展示2天的数据，如下：</p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/error.png" alt="error"></p>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul>
<li>rancher-v2.3.6</li>
<li>监控版本0.0.7</li>
</ul>
<h2 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2><p>首先先查看这个图表使用了哪些表达式</p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-1.png" alt="grafana-1"></p>
<p>接着带着这个表达式，到prometheus查看</p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/prom-1.png" alt="prom-1"></p>
<p>可以看到，查询这个表达式花费了37秒的时间，而这仅仅是其中一条表达式，由此可以得知grafana查看不到数据的原因是在获取prometheus的数据超时了</p>
<p>随着业务的扩大，prometheus中监控的数据会越来越多，查询的频率也在不断的增加，这就会导致当数据量达到一定程度时会影响prometheus查询的性能，尤其是如果有大量的表达式计算指标数据时，就会导致promql查询超时</p>
<p>根据客户反映，prometheus设置了30天的保存时间，集群比较大，数据指标也比较多，所以导致这个grafana使用表达式去查询数据指标的时候，使用了大量的时间去执行这个计算，最终导致返回超时</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>首先想到的是清理旧数据，让数据获取少一点，但是这个效果并不明显</p>
<p>既然是因为表达式计算的过程花费的时间长，那么我们可不可以事先将该表达式计算的结果存储下来，后面查询的时候就不用再进行二次计算，直接获取对应的指标数据呢？</p>
<p>当然是可以的，prometheus提供了这样的一种方法：Recording Rule</p>
<p><strong>Recording Rule</strong>：Recording Rule可以预先计算经常需要或计算量大的表达式，并将其结果保存为一组新的时间序列。这样，查询预先计算的结果通常比每次需要原始表达式都要快得多。这对于仪表板特别有用，仪表板每次刷新时都需要重复查询相同的表达式。</p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li>首先获取grafana中的表达式</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sum (rate (container_network_receive_bytes_total[5m]))by (node)</span><br><span class="line"></span><br><span class="line">sum (rate (container_network_transmit_bytes_total[5m])) by (node)</span><br><span class="line"></span><br><span class="line">sum (rate (wmi_container_network_receive_bytes_total[5m]))by (node)</span><br><span class="line"></span><br><span class="line">sum (rate (wmi_container_network_transmit_bytes_total[5m]))by (node)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>编写对应的prometheus rule 配置文件</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PrometheusRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">generation:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">exporter-kubernetes</span></span><br><span class="line">    <span class="attr">chart:</span> <span class="string">exporter-kubernetes-0.0.1</span></span><br><span class="line">    <span class="attr">heritage:</span> <span class="string">Tiller</span></span><br><span class="line">    <span class="attr">io.cattle.field/appId:</span> <span class="string">cluster-monitoring</span></span><br><span class="line">    <span class="attr">release:</span> <span class="string">cluster-monitoring</span></span><br><span class="line">    <span class="attr">source:</span> <span class="string">rancher-monitoring</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">custom</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cattle-prometheus</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">groups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">network_IO</span></span><br><span class="line">    <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">record:</span> <span class="string">custom_container_network_receive_bytes_total</span></span><br><span class="line">      <span class="attr">expr:</span> <span class="string">sum</span> <span class="string">(rate</span> <span class="string">(container_network_receive_bytes_total[5m]))by</span> <span class="string">(node)</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">record:</span> <span class="string">custom_container_network_transmit_bytes_total</span></span><br><span class="line">      <span class="attr">expr:</span> <span class="string">sum</span> <span class="string">(rate</span> <span class="string">(container_network_transmit_bytes_total[5m]))</span> <span class="string">by</span> <span class="string">(node)</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">record:</span> <span class="string">custom_wmi_container_network_receive_bytes_total</span></span><br><span class="line">      <span class="attr">expr:</span> <span class="string">sum</span> <span class="string">(rate</span> <span class="string">(wmi_container_network_receive_bytes_total[5m]))by</span> <span class="string">(node)</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">record:</span> <span class="string">custom_wmi_container_network_transmit_bytes_total</span></span><br><span class="line">      <span class="attr">expr:</span> <span class="string">sum</span> <span class="string">(rate</span> <span class="string">(wmi_container_network_transmit_bytes_total[5m]))by</span> <span class="string">(node)</span></span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li><code>spec.groups.name.rules.expr</code>：需要计算的表达式</li>
<li><code>spec.groups.name.rules.record</code>：为这个表达式重新命名</li>
</ul>
<p>运行该文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f prometheus-custom-rule.yaml</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>重建prometheus加载新的规则</li>
</ol>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/rancher-1.png" alt="rancher-1"></p>
<ol start="4">
<li>prometheus中查看rule是否生效</li>
</ol>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/prom-2.png" alt="prom-2"></p>
<p>使用新的record去查询，可以看到查询的时间花费了142ms，时间立刻缩短了</p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/prom-3.png" alt="prom-3"></p>
<ol start="5">
<li>接着我们到grafana中修改图表的表达式，将之前旧的表达式修改为新的指标</li>
</ol>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-2.png" alt="grafana-2"></p>
<ol start="6">
<li>导出一个新的json文件</li>
</ol>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-3.png" alt="grafana-3"></p>
<ol start="7">
<li>重新导入到grafana中</li>
</ol>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-4.png" alt="grafana-4"></p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-5.png" alt="grafana-5"></p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-6.png" alt="grafana-6"></p>
<p>查看数据，可以看到数据已经加载上去了</p>
<p><img src="/images/mk/prometheus%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8BRecordingRule.assets/grafana-7.png" alt="image-20210204002148724"></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>使用prometheus Recording rule可以简化监控指标，加速外部服务访问prometheus的速度，当如果有许多固定的查询规则，并且需要进行多种计算处理，例如Grafana相关的图表展示，则可以事先定义好对应的Recording rule，提高监控效率。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://www.jianshu.com/p/7545d27f1f28">https://www.jianshu.com/p/7545d27f1f28</a></li>
</ul>
]]></content>
      <categories>
        <category>prometheus</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>pve安装openwrt lede实现科学上网</title>
    <url>/2020/07/26/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>基于openwrt lede + ssr 插件 实现科学上网</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>需要有虚拟机的环境，如果有服务器，可以部署pve快速搭建一个虚拟环境，这里基于pve环境进行安装部署openwrt。（pve是一个轻量的虚拟化管理工具）</p>
<p>如果是个人电脑，安装VMware即可，除了创建虚拟机的步骤不太一样（需要导入磁盘），其他都一样</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="pve安装openwrt"><a href="#pve安装openwrt" class="headerlink" title="pve安装openwrt"></a>pve安装openwrt</h3><h4 id="下载固件"><a href="#下载固件" class="headerlink" title="下载固件"></a>下载固件</h4><p>首先下载openwrt的固件镜像：openwrt-koolshare-mod-v2.36-r14941-67f6fa0a30-x86-64-generic-squashfs-combined.vmdk</p>
<p><a href="/software/openwrt-lede/openwrt-koolshare-mod-v2.36-r14941-67f6fa0a30-x86-64-generic-squashfs-combined.vmdk">镜像下载地址</a></p>
<h4 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h4><p>点击右上角创建虚拟机</p>
<ol>
<li>填写虚拟机名称</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-1.png" alt="vm-1"></p>
<ol start="2">
<li>选择不适用任何介质</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-2.png" alt="vm-2"></p>
<ol start="3">
<li>默认需要选择一个硬盘，随便设置就好，后面用不到这个硬盘</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-3.png" alt="vm-3"></p>
<ol start="4">
<li>设置2核一般就够用了</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-4.png" alt="vm-4"></p>
<ol start="5">
<li>设置2048M（2G）内存</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-5.png" alt="vm-5"></p>
<ol start="6">
<li>选择默认的vmbr0网桥</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-6.png" alt="vm-6"></p>
<ol start="7">
<li>最后确认无误后，创建虚拟机</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vm-7.png" alt="vm-7"></p>
<h4 id="导入刚刚下载的固件镜像"><a href="#导入刚刚下载的固件镜像" class="headerlink" title="导入刚刚下载的固件镜像"></a>导入刚刚下载的固件镜像</h4><ol>
<li>登录pve后台，执行<code>qm importdisk</code>命令导入刚刚下载的固件镜像</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">qm importdisk 124 openwrt-koolshare-mod-v2.36-r14941-67f6fa0a30-x86-64-generic-squashfs-combined.vmdk <span class="built_in">local</span> --format vmdk</span><br></pre></td></tr></table></figure>

<p><code>124</code>是刚刚创建的虚拟机的ID</p>
<p><code>local</code>是对应的存储名称，可以通过<code>pvesm status</code>查看可用的存储，或者直接在web上查看</p>
<p><code>vmdk</code>是VMware的磁盘格式</p>
<p>执行该命令后，会得到如下输出，看到<code>Successfully imported disk</code>就说明导入成功了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">importing disk &#39;openwrt-koolshare-mod-v2.36-r14941-67f6fa0a30-x86-64-generic-squashfs-combined.vmdk&#39; to VM 124 ...</span><br><span class="line">Formatting &#39;&#x2F;var&#x2F;lib&#x2F;vz&#x2F;images&#x2F;124&#x2F;vm-124-disk-1.vmdk&#39;, fmt&#x3D;vmdk size&#x3D;734527488 compat6&#x3D;off hwversion&#x3D;undefined</span><br><span class="line">transferred: 0 bytes remaining: 734527488 bytes total: 734527488 bytes progression: 0.00 %</span><br><span class="line">transferred: 7785991 bytes remaining: 726741497 bytes total: 734527488 bytes progression: 1.06 %</span><br><span class="line">transferred: 15498529 bytes remaining: 719028959 bytes total: 734527488 bytes progression: 2.11 %</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">transferred: 728504362 bytes remaining: 6023126 bytes total: 734527488 bytes progression: 99.18 %</span><br><span class="line">transferred: 734527488 bytes remaining: 0 bytes total: 734527488 bytes progression: 100.00 %</span><br><span class="line">transferred: 734527488 bytes remaining: 0 bytes total: 734527488 bytes progression: 100.00 %</span><br><span class="line">Successfully imported disk as &#39;unused0:local:124&#x2F;vm-124-disk-1.vmdk&#39;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>打开UI，添加刚刚导入的磁盘</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vol-1.png" alt="vol-1"></p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vol-2.png" alt="vol-2"></p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vol-3.png" alt="vol-3"></p>
<ol start="3">
<li>删除<code>CD/DVD驱动器(ide2)</code>和<code>硬盘(scsi0)</code></li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vol-4.png" alt="vol-4"></p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vol-5.png" alt="vol-5"></p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/vol-6.png" alt="vol-6"></p>
<h4 id="设置启动项"><a href="#设置启动项" class="headerlink" title="设置启动项"></a>设置启动项</h4><p>手动设置硬盘引导启动</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/boot-1.png" alt="boot-1"></p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/boot-2.png" alt="boot-2"></p>
<h4 id="启动虚拟机"><a href="#启动虚拟机" class="headerlink" title="启动虚拟机"></a>启动虚拟机</h4><p>如果上述步骤操作顺利，就可以启动该虚拟机了</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/start-vm.png" alt="start-vm"></p>
<p>可以看到控制台在加载程序<img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/console-1.png" alt="console-1"></p>
<h4 id="设置IP地址"><a href="#设置IP地址" class="headerlink" title="设置IP地址"></a>设置IP地址</h4><p>当看到加载至br-lan时，回车进入到命令行</p>
<p>默认IP地址是192.169.1.1，这个地址无法访问，需要修改成pve的vmbr0的IP网络范围</p>
<p>编辑<code>/etc/config/network</code></p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/console-ip.png" alt="console-ip"></p>
<ul>
<li>修改IP地址：找到<code>192.168.1.1</code>，修改为对应的可访问的内网IP</li>
<li>[可选]修改子网掩码：如果不是C类地址，则需要修改为对应的子网掩码，默认不用修改</li>
</ul>
<p>参考如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">option ipaddr <span class="string">&#x27;172.16.33.1&#x27;</span>  </span><br><span class="line">option netmask <span class="string">&#x27;255.255.0.0&#x27;</span>  </span><br></pre></td></tr></table></figure>

<h4 id="重启网络"><a href="#重启网络" class="headerlink" title="重启网络"></a>重启网络</h4><p>执行如下命令重启网络</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/network restart</span><br></pre></td></tr></table></figure>

<p>看到这个样子说明重启成功了</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/restart-network.png" alt="restart-network"></p>
<h4 id="浏览器访问"><a href="#浏览器访问" class="headerlink" title="浏览器访问"></a>浏览器访问</h4><p>地址是修改的IP地址，例如我这里是<a href="http://172.16.33.1/">http://172.16.33.1</a></p>
<p>密码是：koolshare</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/web-1.png" alt="web-1"></p>
<h4 id="设置网络"><a href="#设置网络" class="headerlink" title="设置网络"></a>设置网络</h4><ol>
<li>编辑LAN接口</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/web-net-1.png" alt="web-net-1"></p>
<ol start="2">
<li>设置网关和DNS</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/web-net-2.png" alt="web-net-2"></p>
<p>修改完后点击右下角的<strong>保存并应用</strong></p>
<h4 id="安装ssr"><a href="#安装ssr" class="headerlink" title="安装ssr"></a>安装ssr</h4><ol>
<li>点击左边列表的<strong>库软</strong>，首先需要先更新一波</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/kuruan-update.png" alt="kuruan-update"></p>
<p>这里如果失败，大概率是网络没配置好，需要检查一下网络是否配置正确</p>
<ol start="2">
<li>下载ssr插件</li>
</ol>
<p>更新完后会看到很多插件可以安装，但是没有ssr相关的，可以手动下载插件进行离线安装</p>
<p><a href="/software/openwrt-lede/koolss_2.2.2.tar.gz">插件下载地址</a></p>
<ol start="3">
<li>屏蔽插件安全检测</li>
</ol>
<p>较新的openwrt版本有个安全检测机制，会导致插件无法直接安装上去</p>
<p>可以手动将这段检测代码删除，编辑<code>/koolshare/scripts/ks_tar_install.sh</code>这个文件，找到以下这段代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">detect_package</span></span>()&#123;                                                        </span><br><span class="line">        <span class="built_in">local</span> TEST_WORD=<span class="string">&quot;<span class="variable">$1</span>&quot;</span>                                         </span><br><span class="line">        <span class="built_in">local</span> ILLEGAL_KEYWORDS=<span class="string">&quot;ss|ssr|shadowsocks|shadowsocksr|v2ray|trojan|clash|wireguard|koolss|brook&quot;</span></span><br><span class="line">        <span class="built_in">local</span> KEY_MATCH=$(<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;TEST_WORD&#125;</span>&quot;</span> | grep -Eo <span class="string">&quot;<span class="variable">$ILLEGAL_KEYWORDS</span>&quot;</span>)                             </span><br><span class="line">                                                                                                          </span><br><span class="line">        <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$KEY_MATCH</span>&quot;</span> ]; <span class="keyword">then</span>                                                                      </span><br><span class="line">                echo_date =======================================================                         </span><br><span class="line">                echo_date <span class="string">&quot;...........................<span class="variable">$&#123;soft_name&#125;</span> ...........................&quot;</span>           </span><br><span class="line">                echo_date <span class="string">&quot;.....................koolshare.............................................&quot;</span>   </span><br><span class="line">                echo_date <span class="string">&quot;..............................&quot;</span>                                                </span><br><span class="line">                echo_date =======================================================                      </span><br><span class="line">                clean                                                                                  </span><br><span class="line">                <span class="built_in">exit</span> 1                                                                                 </span><br><span class="line">        <span class="keyword">fi</span>                                                                                             </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将其中的<code>local ILLEGAL_KEYWORDS</code>后的内容清空</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">detect_package</span></span>()&#123;                                                        </span><br><span class="line">        <span class="built_in">local</span> TEST_WORD=<span class="string">&quot;<span class="variable">$1</span>&quot;</span>                                             </span><br><span class="line">        <span class="built_in">local</span> ILLEGAL_KEYWORDS=<span class="string">&quot;&quot;</span>                                        </span><br><span class="line">        <span class="built_in">local</span> KEY_MATCH=$(<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$&#123;TEST_WORD&#125;</span>&quot;</span> | grep -Eo <span class="string">&quot;<span class="variable">$ILLEGAL_KEYWORDS</span>&quot;</span>)</span><br><span class="line">                                                                             </span><br><span class="line">        <span class="keyword">if</span> [ -n <span class="string">&quot;<span class="variable">$KEY_MATCH</span>&quot;</span> ]; <span class="keyword">then</span>                                         </span><br><span class="line">                echo_date =======================================================</span><br><span class="line">                echo_date <span class="string">&quot;...........................<span class="variable">$&#123;soft_name&#125;</span> ...........................&quot;</span></span><br><span class="line">                echo_date <span class="string">&quot;.....................koolshare.............................................&quot;</span></span><br><span class="line">                echo_date <span class="string">&quot;..............................&quot;</span>                                             </span><br><span class="line">                echo_date =======================================================                      </span><br><span class="line">                clean                                                                                  </span><br><span class="line">                <span class="built_in">exit</span> 1                                                                                 </span><br><span class="line">        <span class="keyword">fi</span>                                                                                             </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>安装ssr插件</li>
</ol>
<p>在<strong>离线安装</strong>这里选择下载好的ssr插件压缩包，执行上传并安装，这时候就能正常进行插件的安装了</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/ssr-plugin-install-3.png" alt="ssr-plugin-install-3"></p>
<h4 id="设置SSR"><a href="#设置SSR" class="headerlink" title="设置SSR"></a>设置SSR</h4><ol>
<li>点击koolss进入配置页面，打开<strong>koolss开关</strong>，在[节点管理]-[节点管理]下，添加SSR订阅地址</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/ssr-setup-1.png" alt="ssr-setup-1"></p>
<p>这里模式设定选择<strong>全局模式</strong>，混淆参数设定选择<strong>使用订阅设定</strong></p>
<p>设置完成后，点击<strong>保存订阅设置</strong>，然后再重新点击<strong>手动更新订阅</strong>，就会加载所有的节点了</p>
<ol start="2">
<li>选择可用的节点，在[节点管理]-[SSR节点]下，可以看到所有可用的节点，选择其中一个即可</li>
</ol>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/ssr-setup-2.png" alt="ssr-setup-2"></p>
<h4 id="客户端使用"><a href="#客户端使用" class="headerlink" title="客户端使用"></a>客户端使用</h4><p>设置网关为openwrt的地址即可，例如Windows设置如下：</p>
<p><img src="https://zerchin.gitee.io/picturebed/img/pve%E5%AE%89%E8%A3%85openwrt%20lede%E5%AE%9E%E7%8E%B0%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91.assets/client-windows.png" alt="client-windows"></p>
<!-- 参考视频：https://www.youtube.com/watch?v=pnbzj-87ZOM -->



<blockquote>
<p>固件下载地址：<a href="https://firmware.koolshare.cn/LEDE_X64_fw867">https://firmware.koolshare.cn/LEDE_X64_fw867</a></p>
<p>插件下载地址：<a href="https://github.com/hq450/fancyss_history_package/tree/master/fancyss_X64">https://github.com/hq450/fancyss_history_package/tree/master/fancyss_X64</a></p>
<p>可用的下载地址：<a href="https://bit.ly/2t8q6cS">https://bit.ly/2t8q6cS</a></p>
</blockquote>
]]></content>
      <categories>
        <category>pve</category>
      </categories>
      <tags>
        <tag>pve</tag>
        <tag>openwrt</tag>
      </tags>
  </entry>
  <entry>
    <title>pve嵌套虚拟化</title>
    <url>/2019/03/15/pve%E5%B5%8C%E5%A5%97%E8%99%9A%E6%8B%9F%E5%8C%96/</url>
    <content><![CDATA[<h1 id="pve嵌套虚拟化"><a href="#pve嵌套虚拟化" class="headerlink" title="pve嵌套虚拟化"></a>pve嵌套虚拟化</h1><p>默认情况下，pve没有开启嵌套虚拟化，如果虚拟机想使用虚拟化的功能，则需要手动开启嵌套虚拟化</p>
<h2 id="开启方法"><a href="#开启方法" class="headerlink" title="开启方法"></a>开启方法</h2><h3 id="Intel-CPU开启嵌套虚拟化"><a href="#Intel-CPU开启嵌套虚拟化" class="headerlink" title="Intel CPU开启嵌套虚拟化"></a>Intel CPU开启嵌套虚拟化</h3><ol>
<li>首先查看是否开启，为N则未开启</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /sys/module/kvm_intel/parameters/nested </span></span><br><span class="line">N</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>手动开启</li>
</ol>
<p>设置<code>nested=1</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;options kvm_intel nested=1&#x27;</span> &gt;/etc/modprobe.d/kvm-nested.conf</span><br></pre></td></tr></table></figure>

<p>需要重新加载kvm_intel内核模块，如果这时候有在运行的虚拟机，则需要先停止</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe -r kvm_intel</span><br><span class="line">modprobe kvm_intel</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>查看是否开启，结果输出为Y，则开启成功</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /sys/module/kvm_intel/parameters/nested</span><br><span class="line">Y</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>使用嵌套虚拟化</li>
</ol>
<p>创建虚拟机时，设置CPU为host模式即可</p>
<h3 id="AMD-CPU开启嵌套虚拟化"><a href="#AMD-CPU开启嵌套虚拟化" class="headerlink" title="AMD CPU开启嵌套虚拟化"></a>AMD CPU开启嵌套虚拟化</h3><p>方法一样，也是设置<code>nested=1</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;options kvm-amd nested=1&quot;</span> &gt; /etc/modprobe.d/kvm-amd.conf</span><br></pre></td></tr></table></figure>

<p>然后重新加载kvm-amd内核模块即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe -r kvm-amd</span><br><span class="line">modprobe kvm-amd</span><br></pre></td></tr></table></figure>

<p>查看是否开启</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /sys/module/kvm_amd/parameters/nested</span><br></pre></td></tr></table></figure>

<p>使用</p>
<p>在配置文件中添加该参数</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">args: -cpu host,+svm</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>proxmox</category>
      </categories>
      <tags>
        <tag>proxmox</tag>
      </tags>
  </entry>
  <entry>
    <title>selinux踩坑篇-docker容器无法启动</title>
    <url>/2021/05/07/selinux%E8%B8%A9%E5%9D%91%E7%AF%87-docker%E5%AE%B9%E5%99%A8%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/</url>
    <content><![CDATA[<h2 id="问题概述"><a href="#问题概述" class="headerlink" title="问题概述"></a>问题概述</h2><p>主机重启后，docker上的容器无法启动，报错如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker restart nginx-proxy</span></span><br><span class="line">Error response from daemon: Cannot restart container nginx-proxy: error creating overlay mount to /var/lib/docker/overlay2/7431ad53435c5cb52cc24ecc7263b580d4087e2c25e0d4c4c14c577a32ad3607/merged: invalid argument</span><br></pre></td></tr></table></figure>



<h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p>首先怀疑可能是镜像问题，于是尝试用同一个镜像去启动一个新的容器，可以正常启动成功，排除是镜像的问题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -itd --name test nginx:1.14</span></span><br><span class="line">17a4ab4080dc347828e34b576de2d1922d16f6a0929d9eb5f513313df0a32609</span><br></pre></td></tr></table></figure>

<p>接着看了docker的日志，没发现有用的信息</p>
<p>由于报错显示的是mount过程中出现了异常，所以接着排查了系统日志，发现如下报错</p>
<p><img src="/images/mk/selinux%E8%B8%A9%E5%9D%91%E7%AF%87-docker%E5%AE%B9%E5%99%A8%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8.assets/message-log.png" alt="message-log"></p>
<p>看到这段报错顿时有种熟悉感，<code>system_u:object_r</code>这种字符串很明显跟selinux有关，于是怀疑环境中肯定是开启了selinux导致容器挂载异常无法启动</p>
<p>于是看了下selinux的状态，发现是disabled的状态。看到selinux是disabled的状态时，差点将selinux排除在外，还好上面的的报错我很确定是跟selinux有关</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># getenforce </span></span><br><span class="line">Disabled</span><br></pre></td></tr></table></figure>

<p>为了验证是否跟selinux有关，我重新将selinux设置为启动状态，并重启了主机，果然容器可以启动成功</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker restart nginx-proxy</span></span><br><span class="line">nginx-proxy</span><br></pre></td></tr></table></figure>

<p>此时问题还未解决，因为selinux需要关闭，所以还需要进一步查看容器为什么无法启动</p>
<p>接着再把selinux给关掉，再重启主机，果然容器又无法启动了</p>
<p>由于新的容器可以启动成功，而旧的容器则无法启动，所以怀疑是不是容器配置有什么不一样的地方，于是查看了下容器的配置，果然在容器的配置中发现了异常</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/lib/docker/containers/&lt;container_id&gt;/</span><br><span class="line">cat config.v2.json</span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/selinux%E8%B8%A9%E5%9D%91%E7%AF%87-docker%E5%AE%B9%E5%99%A8%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8.assets/docker-config.png" alt="docker-config"></p>
<p>从上图中可以发现， MountLabel和ProcessLabel中都携带了selinux的参数，于是将这两个参数的值都设置为空，然后重启docker（直接修改配置无法生效，需要重启docker才能生效），容器启动成功了！</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vi config.v2.json</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="string">&quot;MountLabel&quot;</span>:<span class="string">&quot;&quot;</span>,<span class="string">&quot;ProcessLabel&quot;</span>:<span class="string">&quot;&quot;</span></span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># systemctl restart docker</span></span><br><span class="line"><span class="comment"># docker ps |grep nginx</span></span><br><span class="line">037bd8327183        nginx:1.14                      <span class="string">&quot;nginx -g &#x27;daemon of…&quot;</span>   About 18 hour ago   Up 11 seconds                           nginx-proxy</span><br></pre></td></tr></table></figure>

<p>至此问题解决</p>
<h2 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h2><p>该问题的主要原因是操作系统之前开启过selinux，在此前提下启动docker并创建了该容器，于是docker的启动参数中会携带某些selinux配置，随后又修改了/etc/selinux/config的配置，将selinux设置为disabled的状态，但是此时selinux的disabled还未生效，而要使selinux的disabled生效，需要重启主机。所以在重启主机前，selinux的状态还是开启的，容器都是能够正常运行。</p>
<p>当重启主机后，/etc/selinux/config下的配置就开始生效，selinux就会被设置为disabled的状态，此时容器的配置中还携带有selinux的配置，当启动容器时，会携带这些配置去访问selinux服务，此时selinux是不可用的状态，所以容器就会抛出异常无法启动。</p>
<p>解决方法：</p>
<ol>
<li>重新启用selinux，然后重启主机即可。selinux 主要作用就是最大限度地减小系统中服务进程可访问的资源，但是如果对selinux不是很懂的情况下，开启selinux可能还会引起其他问题，此时建议采用第二种方法</li>
<li>修改容器的配置，将 MountLabel 和 ProcessLabel 两个参数的值设置为空<code>&quot;MountLabel&quot;:&quot;&quot;,&quot;ProcessLabel&quot;:&quot;&quot;</code>，然后重启docker服务，容器即可修复</li>
</ol>
<!-- 参考：https://www.cnblogs.com/morgan363/p/13855461.html -->
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>selinux</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu12.04手动搭建ceph0.87(giant版本)单节点</title>
    <url>/2018/09/04/ubuntu12.04%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BAceph0.87(giant%E7%89%88%E6%9C%AC)%E5%8D%95%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>不通过ceph-deploy，手动创建服务的方式部署ceph</p>
<p>参考：<a href="http://docs.ceph.com/docs/giant/install/manual-deployment/">http://docs.ceph.com/docs/giant/install/manual-deployment/</a></p>
<p>这里已经提前下载安装好了ceph的安装包，除了ceph-deploy，因为要手动安装</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a><strong>环境</strong></h2><table>
<thead>
<tr>
<th>主机名</th>
<th>IP地址</th>
<th>系统</th>
<th>环境</th>
</tr>
</thead>
<tbody><tr>
<td>ceph01</td>
<td>192.168.100.101</td>
<td>ubuntu 12.04</td>
<td>ceph giant</td>
</tr>
</tbody></table>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># vi /etc/hostname</span></span><br><span class="line">ceph01</span><br></pre></td></tr></table></figure>

<h3 id="修改主机映射"><a href="#修改主机映射" class="headerlink" title="修改主机映射"></a>修改主机映射</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># vi /etc/hosts</span></span><br><span class="line">127.0.0.1       localhost</span><br><span class="line">127.0.1.1       ceph01</span><br><span class="line">192.168.100.101 ceph01</span><br></pre></td></tr></table></figure>

<h3 id="设置ssh无密钥登录"><a href="#设置ssh无密钥登录" class="headerlink" title="设置ssh无密钥登录"></a>设置ssh无密钥登录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ssh-keygen</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/root/.ssh/id_rsa):</span><br><span class="line">Created directory <span class="string">&#x27;/root/.ssh&#x27;</span>.</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">58:47:8d:56:db:90:aa:7c:be:8a:22:a6:d6:e4:c3:8d root@ceph01</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+--[ RSA 2048]----+</span></span><br><span class="line"><span class="string">|          .+o.   |</span></span><br><span class="line"><span class="string">|         .o o+   |</span></span><br><span class="line"><span class="string">|        ..... .  |</span></span><br><span class="line"><span class="string">|       o ..      |</span></span><br><span class="line"><span class="string">|      ..S.       |</span></span><br><span class="line"><span class="string">|   .    o .      |</span></span><br><span class="line"><span class="string">|  = o    o       |</span></span><br><span class="line"><span class="string">| .oE.. .  .      |</span></span><br><span class="line"><span class="string">|oo .... ....     |</span></span><br><span class="line"><span class="string">+-----------------+</span></span><br><span class="line"><span class="string">root@ceph01:~# ssh-copy-id ceph01</span></span><br><span class="line"><span class="string">Warning: Permanently added &#x27;</span>ceph01<span class="string">&#x27; (ECDSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">root@ceph01&#x27;</span>s password:</span><br><span class="line">Now try logging into the machine, with <span class="string">&quot;ssh &#x27;ceph01&#x27;&quot;</span>, and check <span class="keyword">in</span>:</span><br><span class="line">  ~/.ssh/authorized_keys</span><br><span class="line">to make sure we haven<span class="string">&#x27;t added extra keys that you weren&#x27;</span>t expecting.</span><br></pre></td></tr></table></figure>

<h3 id="编辑ceph配置文件"><a href="#编辑ceph配置文件" class="headerlink" title="编辑ceph配置文件"></a>编辑ceph配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># vi /etc/ceph/ceph.conf</span></span><br><span class="line">fsid = 53eaacda-3558-4881-8e35-67f3741072dd</span><br><span class="line">mon initial members = ceph01</span><br><span class="line">mon host = 192.168.100.101</span><br></pre></td></tr></table></figure>

<h3 id="为群集创建密钥环并生成监控密钥"><a href="#为群集创建密钥环并生成监控密钥" class="headerlink" title="为群集创建密钥环并生成监控密钥"></a>为群集创建密钥环并生成监控密钥</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon &#x27;allow *&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="生成管理员密钥环，生成client-admin用户并将用户添加到密钥环"><a href="#生成管理员密钥环，生成client-admin用户并将用户添加到密钥环" class="headerlink" title="生成管理员密钥环，生成client.admin用户并将用户添加到密钥环"></a>生成管理员密钥环，生成client.admin用户并将用户添加到密钥环</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon &#x27;allow *&#x27; --cap osd &#x27;allow *&#x27; --cap mds &#x27;allow&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="将client-admin密钥添加到ceph-mon-keyring。"><a href="#将client-admin密钥添加到ceph-mon-keyring。" class="headerlink" title="将client.admin密钥添加到ceph.mon.keyring。"></a>将client.admin密钥添加到ceph.mon.keyring。</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-authtool /tmp/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring</span></span><br></pre></td></tr></table></figure>

<h3 id="使用主机名，主机IP地址和FSID生成监控映射。将其另存为-tmp-monmap："><a href="#使用主机名，主机IP地址和FSID生成监控映射。将其另存为-tmp-monmap：" class="headerlink" title="使用主机名，主机IP地址和FSID生成监控映射。将其另存为/ tmp / monmap："></a>使用主机名，主机IP地址和FSID生成监控映射。将其另存为/ tmp / monmap：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># monmaptool --create --add ceph01 192.168.100.101 --fsid 53eaacda-3558-4881-8e35-67f3741072dd /tmp/monmap</span></span><br></pre></td></tr></table></figure>

<h3 id="在监视器主机上创建默认数据目录（或多个目录）。"><a href="#在监视器主机上创建默认数据目录（或多个目录）。" class="headerlink" title="在监视器主机上创建默认数据目录（或多个目录）。"></a>在监视器主机上创建默认数据目录（或多个目录）。</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># mkdir /var/lib/ceph/mon/ceph01</span></span><br></pre></td></tr></table></figure>

<h3 id="使用监视器映射和密钥环填充监视器守护程序。"><a href="#使用监视器映射和密钥环填充监视器守护程序。" class="headerlink" title="使用监视器映射和密钥环填充监视器守护程序。"></a>使用监视器映射和密钥环填充监视器守护程序。</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-mon --mkfs -i ceph01 --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring</span></span><br></pre></td></tr></table></figure>

<h3 id="考虑Ceph配置文件的设置。常见设置包括以下内容："><a href="#考虑Ceph配置文件的设置。常见设置包括以下内容：" class="headerlink" title="考虑Ceph配置文件的设置。常见设置包括以下内容："></a>考虑Ceph配置文件的设置。常见设置包括以下内容：</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">fsid = &#123;cluster-id&#125;</span><br><span class="line">mon initial members = &#123;hostname&#125;[, &#123;hostname&#125;]</span><br><span class="line">mon host = &#123;ip-address&#125;[, &#123;ip-address&#125;]</span><br><span class="line">public network = &#123;network&#125;[, &#123;network&#125;]</span><br><span class="line">cluster network = &#123;network&#125;[, &#123;network&#125;]</span><br><span class="line">auth cluster required = cephx</span><br><span class="line">auth service required = cephx</span><br><span class="line">auth client required = cephx</span><br><span class="line">osd journal size = &#123;n&#125;</span><br><span class="line">filestore xattr use omap = <span class="literal">true</span></span><br><span class="line">osd pool default size = &#123;n&#125;  <span class="comment"># Write an object n times.</span></span><br><span class="line">osd pool default min size = &#123;n&#125; <span class="comment"># Allow writing n copy in a degraded state.</span></span><br><span class="line">osd pool default pg num = &#123;n&#125;</span><br><span class="line">osd pool default pgp num = &#123;n&#125;</span><br><span class="line">osd crush chooseleaf <span class="built_in">type</span> = &#123;n&#125;</span><br><span class="line">例如：</span><br><span class="line">[global]</span><br><span class="line">fsid = 53eaacda-3558-4881-8e35-67f3741072dd</span><br><span class="line">mon initial members = ceph01</span><br><span class="line">mon host = 192.168.100.101</span><br><span class="line">auth cluster required = cephx</span><br><span class="line">auth service required = cephx</span><br><span class="line">auth client required = cephx</span><br><span class="line">osd journal size = 1024</span><br><span class="line">filestore xattr use omap = <span class="literal">true</span></span><br><span class="line">osd pool default size = 1</span><br><span class="line">osd pool default min size = 1</span><br><span class="line">osd pool default pg num = 333</span><br><span class="line">osd pool default pgp num = 333</span><br><span class="line">osd crush chooseleaf <span class="built_in">type</span> = 1</span><br></pre></td></tr></table></figure>

<h3 id="创建完成的文件"><a href="#创建完成的文件" class="headerlink" title="创建完成的文件"></a>创建完成的文件</h3><p>标记已创建监视器并准备启动：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># touch /var/lib/ceph/mon/ceph01/done</span></span><br></pre></td></tr></table></figure>

<h3 id="启动mon"><a href="#启动mon" class="headerlink" title="启动mon"></a>启动mon</h3><h4 id="对于Ubuntu，请使用Upstart："><a href="#对于Ubuntu，请使用Upstart：" class="headerlink" title="对于Ubuntu，请使用Upstart："></a>对于Ubuntu，请使用Upstart：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># start ceph-mon id=ceph01</span></span><br></pre></td></tr></table></figure>

<p>在这种情况下，要允许在每次重新启动时启动守护程序，您必须创建两个空文件，如下所示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># touch /var/lib/ceph/mon/ceph01/upstart</span></span><br></pre></td></tr></table></figure>

<h4 id="对于Debian-CentOS-RHEL，请使用sysvinit："><a href="#对于Debian-CentOS-RHEL，请使用sysvinit：" class="headerlink" title="对于Debian / CentOS / RHEL，请使用sysvinit："></a>对于Debian / CentOS / RHEL，请使用sysvinit：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/init.d/ceph start mon.ceph01</span></span><br></pre></td></tr></table></figure>

<h3 id="验证mon"><a href="#验证mon" class="headerlink" title="验证mon"></a>验证mon</h3><p>验证Ceph是否创建了默认池。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph osd lspools</span></span><br><span class="line">0 rbd,</span><br></pre></td></tr></table></figure>

<p>验证监视器是否正在运行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph  - s</span></span><br><span class="line">    cluster 53eaacda-3558-4881-8e35-67f3741072dd</span><br><span class="line">     health HEALTH_ERR 64 pgs stuck inactive; 64 pgs stuck unclean; no osds</span><br><span class="line">     monmap e1: 1 mons at &#123;ceph01=192.168.100.101:6789/0&#125;, election epoch 2, quorum 0 ceph01</span><br><span class="line">     osdmap e1: 0 osds: 0 up, 0 <span class="keyword">in</span></span><br><span class="line">      pgmap v2: 64 pgs, 1 pools, 0 bytes data, 0 objects</span><br><span class="line">            0 kB used, 0 kB / 0 kB avail</span><br><span class="line">                  64 creating</span><br></pre></td></tr></table></figure>

<h3 id="添加OSD"><a href="#添加OSD" class="headerlink" title="添加OSD"></a>添加OSD</h3><h4 id="精简模式"><a href="#精简模式" class="headerlink" title="精简模式"></a>精简模式</h4><h5 id="准备OSD"><a href="#准备OSD" class="headerlink" title="准备OSD"></a>准备OSD</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-disk prepare --cluster ceph --cluster-uuid 53eaacda-3558-4881-8e35-67f3741072dd --fs-type ext4 /dev/sdb</span></span><br></pre></td></tr></table></figure>

<h5 id="激活OSD"><a href="#激活OSD" class="headerlink" title="激活OSD"></a>激活OSD</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-disk activate /dev/sdb1</span></span><br></pre></td></tr></table></figure>

<h4 id="长模式"><a href="#长模式" class="headerlink" title="长模式"></a>长模式</h4><h5 id="生成uuid"><a href="#生成uuid" class="headerlink" title="生成uuid"></a>生成uuid</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># uuidgen</span></span><br></pre></td></tr></table></figure>

<h5 id="创建OSD"><a href="#创建OSD" class="headerlink" title="创建OSD"></a>创建OSD</h5><p>如果没有给出UUID，则在OSD启动时将自动设置。以下命令将输出OSD编号，将在后续步骤中使用该编号。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph osd create 72fb9a60-38a1-48b3-b1fe-6d3f7c26e9eb</span></span><br><span class="line">1</span><br></pre></td></tr></table></figure>

<h5 id="在新OSD上创建默认目录。"><a href="#在新OSD上创建默认目录。" class="headerlink" title="在新OSD上创建默认目录。"></a>在新OSD上创建默认目录。</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># mkdir /var/lib/ceph/osd/ceph-1/</span></span><br></pre></td></tr></table></figure>

<h5 id="如果OSD用于OS驱动器以外的驱动器，格式化并挂载到目录"><a href="#如果OSD用于OS驱动器以外的驱动器，格式化并挂载到目录" class="headerlink" title="如果OSD用于OS驱动器以外的驱动器，格式化并挂载到目录"></a>如果OSD用于OS驱动器以外的驱动器，格式化并挂载到目录</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># mkfs -t ext4 /dev/sdc</span></span><br><span class="line">root@ceph01:~<span class="comment"># mount -o user_xattr /dev/sdc /var/lib/ceph/osd/ceph-1/</span></span><br></pre></td></tr></table></figure>

<h5 id="初始化OSD数据目录"><a href="#初始化OSD数据目录" class="headerlink" title="初始化OSD数据目录"></a>初始化OSD数据目录</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph-osd -i 1 --mkfs --mkkey --osd-uuid 72fb9a60-38a1-48b3-b1fe-6d3f7c26e9eb</span></span><br></pre></td></tr></table></figure>

<p>在使用 –mkkey选项运行ceph -osd之前，该目录必须为空。此外，ceph -osd工具需要使用–cluster选项指定自定义集群名称。</p>
<h5 id="注册OSD验证密钥"><a href="#注册OSD验证密钥" class="headerlink" title="注册OSD验证密钥"></a>注册OSD验证密钥</h5><p>如果你的群集名称与ceph不同，使用自己的群集名称：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph auth add osd.1 osd &#x27;allow *&#x27; mon &#x27;allow profile osd&#x27; -i /var/lib/ceph/osd/ceph-1/keyring</span></span><br></pre></td></tr></table></figure>

<h5 id="将您的Ceph节点添加到CRUSH-map"><a href="#将您的Ceph节点添加到CRUSH-map" class="headerlink" title="将您的Ceph节点添加到CRUSH map"></a>将您的Ceph节点添加到CRUSH map</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph osd crush add-bucket ceph01 host</span></span><br></pre></td></tr></table></figure>

<h5 id="将Ceph节点置于根默认值下"><a href="#将Ceph节点置于根默认值下" class="headerlink" title="将Ceph节点置于根默认值下"></a>将Ceph节点置于根默认值下</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph osd crush move ceph01 root=default</span></span><br></pre></td></tr></table></figure>

<h5 id="将OSD添加到CRUSH映射，以便它可以开始接收数据"><a href="#将OSD添加到CRUSH映射，以便它可以开始接收数据" class="headerlink" title="将OSD添加到CRUSH映射，以便它可以开始接收数据"></a>将OSD添加到CRUSH映射，以便它可以开始接收数据</h5><p>你也可以反编译CRUSH map，将OSD添加到设备列表，将主机添加为存储桶（如果它尚未存在于CRUSH地图中），将设备添加为主机中的项目，为其分配权重，重新编译它并设置它。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph osd crush add osd.1 1.0 host=ceph01</span></span><br></pre></td></tr></table></figure>

<h5 id="启动OSD"><a href="#启动OSD" class="headerlink" title="启动OSD"></a>启动OSD</h5><p>将OSD添加到Ceph后，OSD就在你的配置中。但是，它还没有运行。OSD选单下和在。你必须先启动新的OSD才能开始接收数据。<br>1 对于Ubuntu，使用upstart</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># start ceph-osd id=1</span></span><br></pre></td></tr></table></figure>

<p>2 对于Debian / CentOS / RHEL，使用sysvinit：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/init.d/ceph start osd.1</span></span><br></pre></td></tr></table></figure>

<h5 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@ceph01:~<span class="comment"># ceph -w</span></span><br><span class="line">root@ceph01:~<span class="comment"># ceph osd tree</span></span><br><span class="line"><span class="comment"># id   weight      type name        up/down  reweight</span></span><br><span class="line">-1      0.03722   root default</span><br><span class="line">-2      0.03722             host ceph01</span><br><span class="line">0       0.01813                      osd.0        up     1</span><br><span class="line">1       0.01909                      osd.1        up     1</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ceph</category>
      </categories>
      <tags>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>使用kubernetes-event-exporter将k8s的事件导出到elasticsearch日志系统中</title>
    <url>/2020/09/08/%E4%BD%BF%E7%94%A8kubernetes-event-exporter%E5%B0%86k8s%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%AF%BC%E5%87%BA%E5%88%B0elasticsearch%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%AD/</url>
    <content><![CDATA[<p>使用kubernetes-event-exporter将k8s的事件导出到elasticsearch日志系统中</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><table>
<thead>
<tr>
<th></th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>kubernetes</td>
<td>v1.17.9</td>
</tr>
<tr>
<td>kubernetes-event-exporter</td>
<td>v0.9</td>
</tr>
<tr>
<td>elasticsearch</td>
<td>7.3.0</td>
</tr>
</tbody></table>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>github地址：<a href="https://github.com/opsgenie/kubernetes-event-exporter">https://github.com/opsgenie/kubernetes-event-exporter</a></p>
<ol>
<li>git 克隆镜像仓库</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># git clone https://github.com/opsgenie/kubernetes-event-exporter.git</span></span><br><span class="line">Cloning into <span class="string">&#x27;kubernetes-event-exporter&#x27;</span>...</span><br><span class="line">remote: Enumerating objects: <span class="number">518</span>, done.</span><br><span class="line">remote: Counting objects: <span class="number">100</span>% (<span class="number">518</span>/<span class="number">518</span>), done.</span><br><span class="line">remote: Compressing objects: <span class="number">100</span>% (<span class="number">426</span>/<span class="number">426</span>), done.</span><br><span class="line">remote: Total <span class="number">5759</span> (delta <span class="number">56</span>), reused <span class="number">466</span> (delta <span class="number">36</span>), pack<span class="literal">-reused</span> <span class="number">5241</span></span><br><span class="line">Receiving objects: <span class="number">100</span>% (<span class="number">5759</span>/<span class="number">5759</span>), <span class="number">7.65</span> MiB | <span class="number">4.25</span> MiB/s, done.</span><br><span class="line">Resolving deltas: <span class="number">100</span>% (<span class="number">2282</span>/<span class="number">2282</span>), done.</span><br></pre></td></tr></table></figure>



<ol start="2">
<li>配置01-config.yaml</li>
</ol>
<p>进到deploy目录，可以看到这三个yaml文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd kubernetes-event-exporter/deploy/</span></span><br><span class="line"><span class="comment"># ls</span></span><br><span class="line">00-roles.yaml  01-config.yaml  02-deployment.yaml</span><br></pre></td></tr></table></figure>

<p>其中00-roles.yaml是设置rbac权限</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat 00-roles.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">view</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">event-exporter</span></span><br></pre></td></tr></table></figure>

<p>01-config.yaml，配置接收者，默认是输出到本地路径</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat 01-config.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter-cfg</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.yaml:</span> <span class="string">|</span></span><br><span class="line">    <span class="attr">logLevel:</span> <span class="string">error</span></span><br><span class="line">    <span class="attr">logFormat:</span> <span class="string">json</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">      <span class="attr">routes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">receiver:</span> <span class="string">&quot;dump&quot;</span></span><br><span class="line">    <span class="attr">receivers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;dump&quot;</span></span><br><span class="line">        <span class="attr">file:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">&quot;/dev/stdout&quot;</span></span><br></pre></td></tr></table></figure>

<p>02-deployment.yaml，具体部署的pod应用</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat 02-deployment.yaml </span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">event-exporter</span></span><br><span class="line">        <span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">event-exporter</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">event-exporter</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">opsgenie/kubernetes-event-exporter:0.9</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">args:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">-conf=/data/config.yaml</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/data</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">cfg</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cfg</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">event-exporter-cfg</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">event-exporter</span></span><br><span class="line">      <span class="attr">version:</span> <span class="string">v1</span></span><br></pre></td></tr></table></figure>

<p>这里有三个yaml，这里我们需要修改01-config.yaml，设置接收者为elasticsearch</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat 01-config.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">event-exporter-cfg</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">config.yaml:</span> <span class="string">|</span></span><br><span class="line">    <span class="attr">logLevel:</span> <span class="string">error</span></span><br><span class="line">    <span class="attr">logFormat:</span> <span class="string">json</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">      <span class="attr">routes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">receiver:</span> <span class="string">&quot;dump&quot;</span>															<span class="comment"># 与下面的name对应</span></span><br><span class="line">    <span class="attr">receivers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">&quot;dump&quot;</span></span><br><span class="line">        <span class="attr">elasticsearch:</span>																	<span class="comment"># 设置接收者为es</span></span><br><span class="line">          <span class="attr">hosts:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">http://10.43.62.184:9200</span>										    		<span class="comment"># es地址</span></span><br><span class="line">          <span class="attr">index:</span> <span class="string">kube-events</span>																</span><br><span class="line">          <span class="attr">indexFormat:</span> <span class="string">&quot;kube-events-&#123;2020-09-08&#125;&quot;</span>					                	<span class="comment"># 索引格式</span></span><br><span class="line">          <span class="attr">useEventID:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>如果是es设置了tls，请参考官方文档设置相关tls参数：<a href="https://github.com/opsgenie/kubernetes-event-exporter#elasticsearch">https://github.com/opsgenie/kubernetes-event-exporter#elasticsearch</a></p>
<ol start="3">
<li>启动event-exporter</li>
</ol>
<p>依次执行这三个文件</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">kubectl apply <span class="operator">-f</span> <span class="number">00</span><span class="literal">-roles</span>.yaml </span><br><span class="line">kubectl apply <span class="operator">-f</span> <span class="number">01</span><span class="literal">-config</span>.yaml </span><br><span class="line">kubectl apply <span class="operator">-f</span> <span class="number">02</span><span class="literal">-deployment</span>.yaml </span><br></pre></td></tr></table></figure>



<ol start="4">
<li>查看pod状态</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl -n monitoring get pod</span></span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">event<span class="literal">-exporter</span><span class="literal">-7cfbbcff69</span><span class="literal">-xxg9t</span>   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">48</span>m</span><br></pre></td></tr></table></figure>


<ol start="5">
<li>查看elasticsearch</li>
</ol>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curl http://10.43.62.184:9200/_cat/indices?v</span></span><br><span class="line">health status index                  uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">green  open   .kibana_task_manager   Qb6qPAipQZiAb29B8VCJ3Q   <span class="number">1</span>   <span class="number">1</span>          <span class="number">2</span>            <span class="number">0</span>     <span class="number">59.2</span>kb         <span class="number">29.6</span>kb</span><br><span class="line">green  open   kube<span class="literal">-events</span><span class="literal">-8080</span><span class="literal">-09</span><span class="literal">-08</span> gbrvIqevRAGGjxIbR993mA   <span class="number">1</span>   <span class="number">1</span>         <span class="number">16</span>            <span class="number">0</span>      <span class="number">129</span>kb         <span class="number">56.2</span>kb</span><br><span class="line">green  open   .kibana_1              mVv0LHetQ1mcGbYnbaF3Fg   <span class="number">1</span>   <span class="number">1</span>          <span class="number">4</span>            <span class="number">0</span>     <span class="number">64.2</span>kb         <span class="number">32.1</span>kb</span><br></pre></td></tr></table></figure>



<p>对接成功</p>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>基于MinIO对象存储保障Rancher数据</title>
    <url>/2022/07/19/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Rancher 是一个企业级的 Kubernetes 容器管理平台，它简化了使用 Kubernetes 的流程，提供了完整的软件堆栈，适用于使用容器的团队。Rancher 解决了跨任何基础架构管理多个 Kubernetes 集群的运营和安全挑战，同时为 DevOps 团队提供了运行容器化工作负载的集成工具。</p>
<p>下图是 Rancher 官方提供的架构图：</p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-architecture.svg" alt="Architecture"></p>
<p>从图中我们可以得知 Rancher 的数据是存储与 etcd 中。</p>
<p>而我们知道，etcd 同时也是 Kubernetes 的关键组件，Kubernetes 集群通过 etcd 存储了集群的整个状态：包括集群、节点、运行中的工作负载、以及所有 Kubernetes 资源对象的元数据和状态信息。</p>
<p>在 Rancher 和 Kubernetes 集群上，每时每刻都有大量的数据进行读写，所以如何保障 etcd 中数据成为了我们需要解决的问题。</p>
<p><strong>本文将介绍如何通过 MinIO 对象存储的能力，来保障 Rancher 和 Kubernetes 数据。</strong></p>
<h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><ul>
<li>Rancher：2.6.6</li>
<li>k8s：v1.23.7</li>
</ul>
<h2 id="MinIO-快速部署"><a href="#MinIO-快速部署" class="headerlink" title="MinIO 快速部署"></a>MinIO 快速部署</h2><h3 id="MinIO-介绍"><a href="#MinIO-介绍" class="headerlink" title="MinIO 介绍"></a>MinIO 介绍</h3><p>MinIO 是开源的高性能对象存储系统，基于 Golang 实现，提供与 Amazon S3 兼容的 API 接口。</p>
<p><strong>MinIO优点</strong></p>
<ul>
<li><strong>云原生</strong>：符合一切云原生云的架构和构建过程，并且包含最新的云计算的全新的技术和概念。 其中包括支持Kubernetes 、微服和多租户的的容器技术。使对象存储对于 Kubernetes 更加友好。</li>
<li><strong>高性能</strong>：在标准硬件上，读/写速度上高达183 GB / 秒 和 171 GB / 秒。拥有更高的吞吐量和更低的延迟。</li>
<li><strong>可扩展</strong>：扩展从单个群集开始，该群集可以与其他MinIO群集联合以创建全局名称空间, 并在需要时可以跨越多个不同的数据中心。</li>
<li><strong>易操作</strong>：部署简单，简化了使用对象存储的流程，支持多种平台运行。</li>
</ul>
<h3 id="MinIO-部署"><a href="#MinIO-部署" class="headerlink" title="MinIO 部署"></a>MinIO 部署</h3><ol>
<li>一键生成 ssl 自签名证书脚本，将下面脚本保存到<code>create-cert.sh</code>文件中。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash -e</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">help</span> ()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; ================================================================ &#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-domain: 生成ssl证书需要的主域名，如不指定则默认为www.rancher.local，如果是ip访问服务，则可忽略；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-trusted-ip: 一般ssl证书只信任域名的访问请求，有时候需要使用ip去访问server，那么需要给ssl证书添加扩展IP，多个IP用逗号隔开；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-trusted-domain: 如果想多个域名访问，则添加扩展域名（SSL_TRUSTED_DOMAIN）,多个扩展域名用逗号隔开；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-size: ssl加密位数，默认2048；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-cn: 国家代码(2个字母的代号),默认CN;&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; 使用示例:&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; ./create_self-signed-cert.sh --ssl-domain=www.test.com --ssl-trusted-domain=www.test2.com \ &#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-trusted-ip=1.1.1.1,2.2.2.2,3.3.3.3 --ssl-size=2048 --ssl-date=3650&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; ================================================================&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span> <span class="keyword">in</span></span><br><span class="line">    -h|--<span class="built_in">help</span>) <span class="built_in">help</span>; <span class="built_in">exit</span>;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$1</span> == <span class="string">&#x27;&#x27;</span> ]];<span class="keyword">then</span></span><br><span class="line">    <span class="built_in">help</span>;</span><br><span class="line">    <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">CMDOPTS=<span class="string">&quot;$*&quot;</span></span><br><span class="line"><span class="keyword">for</span> OPTS <span class="keyword">in</span> <span class="variable">$CMDOPTS</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    key=$(<span class="built_in">echo</span> <span class="variable">$&#123;OPTS&#125;</span> | awk -F<span class="string">&quot;=&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> )</span><br><span class="line">    value=$(<span class="built_in">echo</span> <span class="variable">$&#123;OPTS&#125;</span> | awk -F<span class="string">&quot;=&quot;</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> )</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;<span class="variable">$key</span>&quot;</span> <span class="keyword">in</span></span><br><span class="line">        --ssl-domain) SSL_DOMAIN=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-trusted-ip) SSL_TRUSTED_IP=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-trusted-domain) SSL_TRUSTED_DOMAIN=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-size) SSL_SIZE=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-date) SSL_DATE=<span class="variable">$value</span> ;;</span><br><span class="line">        --ca-date) CA_DATE=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-cn) CN=<span class="variable">$value</span> ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CA相关配置</span></span><br><span class="line">CA_DATE=<span class="variable">$&#123;CA_DATE:-3650&#125;</span></span><br><span class="line">CA_KEY=<span class="variable">$&#123;CA_KEY:-cakey.pem&#125;</span></span><br><span class="line">CA_CERT=<span class="variable">$&#123;CA_CERT:-cacerts.pem&#125;</span></span><br><span class="line">CA_DOMAIN=cattle-ca</span><br><span class="line"></span><br><span class="line"><span class="comment"># ssl相关配置</span></span><br><span class="line">SSL_CONFIG=<span class="variable">$&#123;SSL_CONFIG:-<span class="variable">$PWD</span>/openssl.cnf&#125;</span></span><br><span class="line">SSL_DOMAIN=<span class="variable">$&#123;SSL_DOMAIN:-&#x27;www.rancher.local&#x27;&#125;</span></span><br><span class="line">SSL_DATE=<span class="variable">$&#123;SSL_DATE:-3650&#125;</span></span><br><span class="line">SSL_SIZE=<span class="variable">$&#123;SSL_SIZE:-2048&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 国家代码(2个字母的代号),默认CN;</span></span><br><span class="line">CN=<span class="variable">$&#123;CN:-CN&#125;</span></span><br><span class="line"></span><br><span class="line">SSL_KEY=<span class="variable">$SSL_DOMAIN</span>.key</span><br><span class="line">SSL_CSR=<span class="variable">$SSL_DOMAIN</span>.csr</span><br><span class="line">SSL_CERT=<span class="variable">$SSL_DOMAIN</span>.crt</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ---------------------------- \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m       | 生成 SSL Cert |       \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ---------------------------- \033[0m&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -e ./<span class="variable">$&#123;CA_KEY&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 1. 发现已存在CA私钥，备份&quot;</span><span class="variable">$&#123;CA_KEY&#125;</span><span class="string">&quot;为&quot;</span><span class="variable">$&#123;CA_KEY&#125;</span><span class="string">&quot;-bak，然后重新创建 \033[0m&quot;</span></span><br><span class="line">    mv <span class="variable">$&#123;CA_KEY&#125;</span> <span class="string">&quot;<span class="variable">$&#123;CA_KEY&#125;</span>&quot;</span>-bak</span><br><span class="line">    openssl genrsa -out <span class="variable">$&#123;CA_KEY&#125;</span> <span class="variable">$&#123;SSL_SIZE&#125;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 1. 生成新的CA私钥 <span class="variable">$&#123;CA_KEY&#125;</span> \033[0m&quot;</span></span><br><span class="line">    openssl genrsa -out <span class="variable">$&#123;CA_KEY&#125;</span> <span class="variable">$&#123;SSL_SIZE&#125;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -e ./<span class="variable">$&#123;CA_CERT&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 2. 发现已存在CA证书，先备份&quot;</span><span class="variable">$&#123;CA_CERT&#125;</span><span class="string">&quot;为&quot;</span><span class="variable">$&#123;CA_CERT&#125;</span><span class="string">&quot;-bak，然后重新创建 \033[0m&quot;</span></span><br><span class="line">    mv <span class="variable">$&#123;CA_CERT&#125;</span> <span class="string">&quot;<span class="variable">$&#123;CA_CERT&#125;</span>&quot;</span>-bak</span><br><span class="line">    openssl req -x509 -sha256 -new -nodes -key <span class="variable">$&#123;CA_KEY&#125;</span> -days <span class="variable">$&#123;CA_DATE&#125;</span> -out <span class="variable">$&#123;CA_CERT&#125;</span> -subj <span class="string">&quot;/C=<span class="variable">$&#123;CN&#125;</span>/CN=<span class="variable">$&#123;CA_DOMAIN&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 2. 生成新的CA证书 <span class="variable">$&#123;CA_CERT&#125;</span> \033[0m&quot;</span></span><br><span class="line">    openssl req -x509 -sha256 -new -nodes -key <span class="variable">$&#123;CA_KEY&#125;</span> -days <span class="variable">$&#123;CA_DATE&#125;</span> -out <span class="variable">$&#123;CA_CERT&#125;</span> -subj <span class="string">&quot;/C=<span class="variable">$&#123;CN&#125;</span>/CN=<span class="variable">$&#123;CA_DOMAIN&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 3. 生成Openssl配置文件 <span class="variable">$&#123;SSL_CONFIG&#125;</span> \033[0m&quot;</span></span><br><span class="line">cat &gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span> &lt;&lt;<span class="string">EOM</span></span><br><span class="line"><span class="string">[req]</span></span><br><span class="line"><span class="string">req_extensions = v3_req</span></span><br><span class="line"><span class="string">distinguished_name = req_distinguished_name</span></span><br><span class="line"><span class="string">[req_distinguished_name]</span></span><br><span class="line"><span class="string">[ v3_req ]</span></span><br><span class="line"><span class="string">basicConstraints = CA:FALSE</span></span><br><span class="line"><span class="string">keyUsage = nonRepudiation, digitalSignature, keyEncipherment</span></span><br><span class="line"><span class="string">extendedKeyUsage = clientAuth, serverAuth</span></span><br><span class="line"><span class="string">EOM</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="variable">$&#123;SSL_TRUSTED_IP&#125;</span> || -n <span class="variable">$&#123;SSL_TRUSTED_DOMAIN&#125;</span> || -n <span class="variable">$&#123;SSL_DOMAIN&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    cat &gt;&gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span> &lt;&lt;<span class="string">EOM</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string">[alt_names]</span></span><br><span class="line"><span class="string">EOM</span></span><br><span class="line">    IFS=<span class="string">&quot;,&quot;</span></span><br><span class="line">    dns=(<span class="variable">$&#123;SSL_TRUSTED_DOMAIN&#125;</span>)</span><br><span class="line">    dns+=(<span class="variable">$&#123;SSL_DOMAIN&#125;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!dns[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">      <span class="built_in">echo</span> DNS.$((i+<span class="number">1</span>)) = <span class="variable">$&#123;dns[$i]&#125;</span> &gt;&gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [[ -n <span class="variable">$&#123;SSL_TRUSTED_IP&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">        ip=(<span class="variable">$&#123;SSL_TRUSTED_IP&#125;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!ip[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">          <span class="built_in">echo</span> IP.$((i+<span class="number">1</span>)) = <span class="variable">$&#123;ip[$i]&#125;</span> &gt;&gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 4. 生成服务SSL KEY <span class="variable">$&#123;SSL_KEY&#125;</span> \033[0m&quot;</span></span><br><span class="line">openssl genrsa -out <span class="variable">$&#123;SSL_KEY&#125;</span> <span class="variable">$&#123;SSL_SIZE&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 5. 生成服务SSL CSR <span class="variable">$&#123;SSL_CSR&#125;</span> \033[0m&quot;</span></span><br><span class="line">openssl req -sha256 -new -key <span class="variable">$&#123;SSL_KEY&#125;</span> -out <span class="variable">$&#123;SSL_CSR&#125;</span> -subj <span class="string">&quot;/C=<span class="variable">$&#123;CN&#125;</span>/CN=<span class="variable">$&#123;SSL_DOMAIN&#125;</span>&quot;</span> -config <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 6. 生成服务SSL CERT <span class="variable">$&#123;SSL_CERT&#125;</span> \033[0m&quot;</span></span><br><span class="line">openssl x509 -sha256 -req -<span class="keyword">in</span> <span class="variable">$&#123;SSL_CSR&#125;</span> -CA <span class="variable">$&#123;CA_CERT&#125;</span> \</span><br><span class="line">    -CAkey <span class="variable">$&#123;CA_KEY&#125;</span> -CAcreateserial -out <span class="variable">$&#123;SSL_CERT&#125;</span> \</span><br><span class="line">    -days <span class="variable">$&#123;SSL_DATE&#125;</span> -extensions v3_req \</span><br><span class="line">    -extfile <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 7. 证书制作完成 \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 8. 以YAML格式输出结果 \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;----------------------------------------------------------&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ca_key: |&quot;</span></span><br><span class="line">cat <span class="variable">$CA_KEY</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ca_cert: |&quot;</span></span><br><span class="line">cat <span class="variable">$CA_CERT</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_key: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_KEY</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_csr: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_CSR</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_cert: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_CERT</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 9. 附加CA证书到Cert文件 \033[0m&quot;</span></span><br><span class="line">cat <span class="variable">$&#123;CA_CERT&#125;</span> &gt;&gt; <span class="variable">$&#123;SSL_CERT&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_cert: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_CERT</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 10. 重命名服务证书 \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.key tls.key&quot;</span></span><br><span class="line">cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.key tls.key</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.crt tls.crt&quot;</span></span><br><span class="line">cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.crt tls.crt</span><br></pre></td></tr></table></figure>

<p>执行如下命令生成证书，具体用法请参考 Rancher 生成<a href="https://docs.rancher.cn/docs/rancher2.5/installation/resources/advanced/self-signed-ssl/_index#41-%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90-ssl-%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6%E8%84%9A%E6%9C%AC">自签名证书</a>文档。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x create-cert.sh</span><br><span class="line">./create-tls.sh --ssl-domain=minio.zerchin.xyz --ssl-size=2048 --ssl-date=3650</span><br></pre></td></tr></table></figure>

<p>其中<code>--ssl-domain</code>为改为访问 minio 的域名。</p>
<ol start="2">
<li>创建minio文件夹。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /minio/data</span><br><span class="line">mkdir -p /minio/certs/CAs</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>将创建的证书复制到证书的目录下。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp tls.crt /minio/certs/public.crt</span><br><span class="line">cp tls.key /minio/certs/private.key</span><br><span class="line">cp cacerts.pem /minio/certs/CAs/cacerts.pem</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><code>docker run</code> 命令启动 MinIO。</li>
</ol>
<p>minio 支持单机部署和集群部署，这里使用单机部署的方式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -itd --net host --name minio --restart unless-stopped -v /minio/data:/data -v /minio/certs:/certs -e MINIO_ROOT_USER=admin -e MINIO_ROOT_PASSWORD=Rancher123 minio/minio server /data --console-address minio.zerchin.xyz:443 --address minio.zerchin.xyz:9000 --certs-dir /certs</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><p><code>MINIO_ROOT_USER</code>：设置管理员用户。</p>
</li>
<li><p><code>MINIO_ROOT_PASSWORD</code>：管理员用户密码。</p>
</li>
<li><p><code>--console-address</code>：MinIO管理平台地址，当检测到有证书时，自动配置为https。</p>
</li>
<li><p><code>--address</code>：实际数据传输的地址。</p>
</li>
<li><p><code>--certs-dir</code>：设置证书目录，默认是<code>$&#123;HOME&#125;/.minio/certs</code>这个目录，这里指定成我们挂载的目录。注意证书和秘钥的名字一定要是<code>public.crt</code>和<code>private.key</code>。如果有自签名CA证书，则需要放到该路径下的<code>CAs</code>目录。</p>
</li>
</ul>
<h3 id="MinIO-使用"><a href="#MinIO-使用" class="headerlink" title="MinIO 使用"></a>MinIO 使用</h3><ol>
<li>访问 MinIO。</li>
</ol>
<p>浏览器访问 <code>https://minio.zerchin.xyz</code>。</p>
<p>用户名和密码是上一步的<code>MINIO_ROOT_USER</code>和<code>MINIO_ROOT_PASSWORD</code>中的账号密码。</p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-login.png" alt="minio-login"></p>
<ol start="2">
<li>创建 Bucket，命名为 backup。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-create-bucket-1.png" alt="minio-create-bucket-1"></p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-create-bucket-2.png" alt="minio-create-bucket-2"></p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-create-bucket-3.png" alt="minio-create-bucket-3"></p>
<ol start="3">
<li>创建访问用户。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-create-user-1.png" alt="minio-create-user-1"></p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-create-user-2.png" alt="minio-create-user-2"></p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/minio-create-user-3.png" alt="minio-create-user-3"></p>
<h2 id="Rancher-k8s-etcd-对接-MinIO"><a href="#Rancher-k8s-etcd-对接-MinIO" class="headerlink" title="Rancher k8s etcd 对接 MinIO"></a>Rancher k8s etcd 对接 MinIO</h2><p>Rancher 有两种保存快照的方式，一种是直接将 etcd 快照备份文件保存在本地存储，另一种是将 etcd 快照备份文件保存在本地，同时拷贝到远端的 S3 存储上，这里我们选择第二种方式来对接 MinIO 对象存储。</p>
<h3 id="etcd-快照备份"><a href="#etcd-快照备份" class="headerlink" title="etcd 快照备份"></a>etcd 快照备份</h3><ol>
<li>编辑集群，在 <strong>Etcd备份存储</strong> 下，选择 s3。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-k8s-etcd-1.png" alt="rancher-k8s-etcd-1"></p>
<p>参数说明：</p>
<ul>
<li><p><code>S3 Bucket Name</code>：S3的桶名称。</p>
</li>
<li><p><code>S3 Folder</code>：桶下的文件夹。不填写则直接在桶的根目录下存储数据。</p>
</li>
<li><p><code>S3 Region Endpoint</code>：指定S3端点URL地址，这里对应前面<code>--address</code>暴露的地址</p>
</li>
<li><p><code>Access Key</code>：S3的accessKey</p>
</li>
<li><p><code>Secret Key</code>：S3的secretKey</p>
</li>
<li><p><code>自定义 CA 证书</code>：自定义证书认证，用于连接 S3 端点。</p>
</li>
</ul>
<p>点击保存，等待集群进行更新。</p>
<ol start="2">
<li><p>创建快照。</p>
<p>集群更新完毕后，我们进入集群，在<strong>Snapshots</strong>下，点击 <strong>立即创建快照</strong> 按钮，就会自动帮我们创建 etcd 快照，并保存到远程 MinIO 存储上。</p>
</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-k8s-etcd-2.png" alt="rancher-k8s-etcd-2"></p>
<ol start="3">
<li>验证快照是否存储在 MinIO 中。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-k8s-etcd-minio-1.png" alt="rancher-k8s-etcd-minio-1"></p>
<p>可以看到，对应的快照文件已经存储在 backup 桶 - k8s-etcd 目录 下面了，etcd 快照备份成功。</p>
<h3 id="etcd-快照恢复"><a href="#etcd-快照恢复" class="headerlink" title="etcd 快照恢复"></a>etcd 快照恢复</h3><ol>
<li>基于快照恢复 k8s 集群。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-k8s-etcd-restore-1.png" alt="rancher-k8s-etcd-restore-1"></p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-k8s-etcd-restore-2.png" alt="rancher-k8s-etcd-restore-2"></p>
<p>选择对应的 etcd 快照文件，点击Restore进行恢复，支持三种恢复方式，分别是：</p>
<ul>
<li>仅恢复 etcd 数据。</li>
<li>同时恢复 k8s 版本和 etcd 数据。</li>
<li>同时恢复集群配置、k8s 版本和 etcd 数据。</li>
</ul>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/rancher-k8s-etcd-restore-3.png" alt="rancher-k8s-etcd-restore-3"></p>
<p>左上角出现<strong>还原快照</strong>说明集群正在恢复中，等待集群恢复正常即可。</p>
<h2 id="Rancher-Backup"><a href="#Rancher-Backup" class="headerlink" title="Rancher Backup"></a>Rancher Backup</h2><p>从 Rancher v2.5 开始，<code>rancher-backup</code> operator 用来备份和恢复 Rancher。<code>rancher-backup</code> Helm chart 在<a href="https://github.com/rancher/charts/tree/release-v2.5/charts/rancher-backup">这里。</a></p>
<p>备份还原 operator 需要安装在 local 集群中，并且只对 Rancher 应用进行备份。备份和还原操作只在 local Kubernetes 集群中进行。</p>
<p>Rancher 版本必须是 v2.5.0 及以上，才能使用这种备份和恢复 Rancher 的方法。</p>
<blockquote>
<p>将备份恢复到新的 Rancher 设置时，新设置的版本应与进行备份的版本相同。</p>
</blockquote>
<h3 id="Rancher-Backup-部署"><a href="#Rancher-Backup-部署" class="headerlink" title="Rancher Backup 部署"></a>Rancher Backup 部署</h3><ol>
<li><p>安装Rancher Backup。</p>
<p>首先进入到local集群中（即rancher所在的集群），在 应用&amp;应用市场 - Charts 导航栏下，点击Rancher Backups 应用开始安装。</p>
</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/install-rancher-backup-1.png" alt="install-rancher-backup-1"></p>
<ol start="2">
<li>点击<strong>安装</strong>，这里安装的是 2.1.2 版本。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/install-rancher-backup-2.png" alt="install-rancher-backup-2"></p>
<ol start="3">
<li>这里选择安装到<code>System</code>项目，然后点击<strong>下一步</strong></li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/install-rancher-backup-3.png" alt="install-rancher-backup-3"></p>
<ol start="4">
<li>选择默认存储位置，先选择<strong>无默认存储位置</strong>，点击<strong>安装</strong>按钮后，开始安装。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/install-rancher-backup-4.png" alt="install-rancher-backup-4"></p>
<ol start="5">
<li>等待几分钟，等rancher backup的pod启动。（取决于拉取镜像的速度）</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/install-rancher-backup-5.png" alt="install-rancher-backup-5"></p>
<h3 id="创建第一个-Backup"><a href="#创建第一个-Backup" class="headerlink" title="创建第一个 Backup"></a>创建第一个 Backup</h3><ol>
<li>创建一个 secret，选择 Opaque 类型。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-secret-1.png" alt="backup-secret-1"></p>
<ol start="2">
<li>命名为 <code>minio-cerd</code>，新增两条数据，分别为 <code>accessKey</code> 和 <code>secretKey </code>，并保存。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-secret-2.png" alt="backup-secret-2"></p>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-secret-3.png" alt="backup-secret-3"></p>
<ol start="3">
<li>在Rancher备份 - Backups 导航栏下，点击右侧的<strong>创建</strong>按钮，创建第一个 <strong>Backup</strong>。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-1.png" alt="backup-1"></p>
<ol start="4">
<li>存储位置选择<strong>使用Amazon S3兼容的对象存储服务</strong>。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-2.png" alt="backup-2"></p>
<p>参数说明：</p>
<ul>
<li><p><code>凭证密文</code>：选择刚刚创建的minio密文。</p>
</li>
<li><p><code>存储桶名称</code>：S3 的桶名称。</p>
</li>
<li><p><code>文件夹</code>：桶下的文件夹。不填写则直接在桶的根目录下存储数据。</p>
</li>
<li><p><code>端点</code>：指定 S3 端点URL地址，这里对应前面<code>--address</code>暴露的地址</p>
</li>
<li><p><code>端点 CA</code>：自签名证书需要添加 CA 证书，这里要先用 base64 编码后再填写进来。</p>
</li>
</ul>
<ol start="5">
<li>保存后，会自动发起 rancher 备份请求，同时将备份数据文件保存到 S3 存储上，当显示 <strong>Completed</strong> 时说明已经备份成功。（记录其中的备份文件名，恢复的时候会用到）</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-3.png" alt="backup-3"></p>
<ol start="6">
<li>登录MinIO，查看备份文件已经保存进来了。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/backup-minio-1.png" alt="backup-minio-1"></p>
<h3 id="基于-Backup-恢复-Rancher"><a href="#基于-Backup-恢复-Rancher" class="headerlink" title="基于 Backup 恢复 Rancher"></a>基于 Backup 恢复 Rancher</h3><p>通过 Backup ，我们可以将 Rancher 恢复到新的 Kubernetes 集群上。</p>
<blockquote>
<p>这里要注意的是，在恢复数据过程中无需在新集群上安装 Rancher。如果将 Rancher 恢复到已安装 Rancher 的新集群之上，可能会导致问题。</p>
</blockquote>
<ol>
<li><p>安装RKE集群。</p>
<p>需要安装与当前 Rancher 集群相同版本，安装方法可以参考<a href="https://docs.rancher.cn/docs/rke/installation/_index">Rancher官方文档</a>，这里已经准备好了一个 RKE 集群，就不再赘述。</p>
</li>
</ol>
<ol start="2">
<li>添加 Rancher-Backup 对应的 Helm repo。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add rancher-charts https://charts.rancher.io</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>安装 rancher-backup  Helm chart，指定相同的 rancher-backup 版本，这里选择 2.1.2 版本。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install rancher-backup-crd rancher-charts/rancher-backup-crd -n cattle-resources-system --create-namespace --version 2.1.2</span><br><span class="line">helm install rancher-backup rancher-charts/rancher-backup -n cattle-resources-system --version 2.1.2</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>查看rancher-backup pod 状态是否就绪。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl -n cattle-resources-system get pods</span></span><br><span class="line">NAME                              READY   STATUS    RESTARTS   AGE</span><br><span class="line">rancher-backup-74779d9dfd-vjdth   1/1     Running   0          27s</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>编写<code>minio-cerd-secret.yaml</code>文件，配置 MinIO 访问秘钥。</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">minio-cred</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">cattle-resources-system</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">accessKey:</span> <span class="string">&lt;s3</span> <span class="string">access</span> <span class="string">key</span> <span class="string">base64</span> <span class="string">编码&gt;</span></span><br><span class="line">  <span class="attr">secretKey:</span> <span class="string">&lt;s3</span> <span class="string">secret</span> <span class="string">key</span> <span class="string">base64</span> <span class="string">编码&gt;</span></span><br></pre></td></tr></table></figure>

<p>执行kubectl命令添加该secret。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f minio-cerd-secret.yaml</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>编写Restore yaml文件，命名为<code>restore.yaml</code>。</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">resources.cattle.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Restore</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">restore-minio</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">backupFilename:</span> <span class="string">minio-backup-da0178a9-bf73-4b4d-a615-863bf7e46689-2022-07-18T17-46-43Z.tar.gz</span></span><br><span class="line">  <span class="attr">prune:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">storageLocation:</span></span><br><span class="line">    <span class="attr">s3:</span></span><br><span class="line">      <span class="attr">credentialSecretName:</span> <span class="string">minio-cred</span></span><br><span class="line">      <span class="attr">credentialSecretNamespace:</span> <span class="string">cattle-resources-system</span></span><br><span class="line">      <span class="attr">bucketName:</span> <span class="string">backup</span></span><br><span class="line">      <span class="attr">folder:</span> <span class="string">rancher-backup</span></span><br><span class="line">      <span class="attr">endpoint:</span> <span class="string">minio.zerchin.xyz:9000</span></span><br><span class="line">      <span class="attr">endpointCA:</span> <span class="string">|-</span></span><br><span class="line">        <span class="string">LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURGVENDQWYyZ0F3SUJBZ0lKQUp1Z1pWNVFN</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="string">...</span></span><br><span class="line">        <span class="string">L2xlRFdzNThVd3FvYWtVc0diQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K</span></span><br></pre></td></tr></table></figure>

<p>其中参数都跟 Backup 的参数一样，其中 <code>backupFilename</code> 参数需要指定具体的备份文件名，可以在 Backup 页面下查看，也可以在 MinIO 页面下查看。</p>
<p>运行该配置。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f restore.yaml</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>查看Restore状态。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get restore</span><br><span class="line">kubectl logs -n cattle-resources-system --tail 100 -f rancher-backup-xxx-xxx</span><br></pre></td></tr></table></figure>

<p>当restore crd状态变成Completed时，说明恢复完成了，如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get restores.resources.cattle.io </span></span><br><span class="line">NAME            BACKUP-SOURCE   BACKUP-FILE                                                                     AGE   STATUS</span><br><span class="line">restore-minio   S3              minio-backup-da0178a9-bf73-4b4d-a615-863bf7e46689-2022-07-18T17-46-43Z.tar.gz   74s   Completed</span><br></pre></td></tr></table></figure>



<ol start="8">
<li>接下来用Helm安装Rancher。</li>
</ol>
<p>使用与第一个集群上使用的相同版本的 Helm 来安装 Rancher。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install rancher rancher-stable/rancher -n cattle-system --<span class="built_in">set</span> xxx --<span class="built_in">set</span> xxx</span><br></pre></td></tr></table></figure>



<ol start="9">
<li>切换Rancher前端负载均衡/DNS解析到新的 Rancher 节点上。</li>
</ol>
<ol start="10">
<li>登录Rancher UI界面，访问正常，说明恢复成功。</li>
</ol>
<p><img src="/images/mk/%E5%9F%BA%E4%BA%8EMinIO%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BF%9D%E9%9A%9CRancher%E6%95%B0%E6%8D%AE.assets/restore-1.png" alt="restore-1"></p>
]]></content>
      <categories>
        <category>rancher</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>rancher</tag>
        <tag>etcd</tag>
        <tag>minio</tag>
      </tags>
  </entry>
  <entry>
    <title>基于pid寻找pod&amp;&amp;基于ID查找pod</title>
    <url>/2020/06/11/%E5%9F%BA%E4%BA%8Epid%E5%AF%BB%E6%89%BEpod-%E5%9F%BA%E4%BA%8EID%E6%9F%A5%E6%89%BEpod/</url>
    <content><![CDATA[<h2 id="基于pid寻找pod"><a href="#基于pid寻找pod" class="headerlink" title="基于pid寻找pod"></a>基于pid寻找pod</h2><h3 id="两种方法"><a href="#两种方法" class="headerlink" title="两种方法"></a>两种方法</h3><h4 id="第一种"><a href="#第一种" class="headerlink" title="第一种"></a>第一种</h4><ol>
<li><h5 id="查看对应pid"><a href="#查看对应pid" class="headerlink" title="查看对应pid"></a>查看对应pid</h5></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ps aux|grep prometheus 1000      </span></span><br><span class="line">5631  0.4  4.2 576752 327584 ?       Ssl  Jul08  47:46 /bin/prometheus --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries --config.file=/etc/prometheus/config_out/prometheus.env.yaml --storage.tsdb.path=/prometheus --storage.tsdb.retention.time=12h --web.enable-lifecycle --storage.tsdb.no-lockfile --web.route-prefix=/ --web.listen-address=127.0.0.1:9090</span><br></pre></td></tr></table></figure>



<ol start="2">
<li><h5 id="查看docker-ID"><a href="#查看docker-ID" class="headerlink" title="查看docker ID"></a>查看docker ID</h5></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># CID=$(cat /proc/5631/cgroup | awk -F &#x27;/&#x27; &#x27;&#123;print $5&#125;&#x27;) # echo $&#123;CID:7:8&#125; 59acd32c</span></span><br></pre></td></tr></table></figure>



<ol start="3">
<li><h5 id="查看pod-name"><a href="#查看pod-name" class="headerlink" title="查看pod name"></a>查看pod name</h5></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker inspect 59acd32c | jq &#x27;.[0].Config.Labels[&quot;io.kubernetes.pod.name&quot;]&#x27; &quot;prometheus-cluster-monitoring-0&quot;</span></span><br></pre></td></tr></table></figure>



<h4 id="第二种"><a href="#第二种" class="headerlink" title="第二种"></a>第二种</h4><ol>
<li><h5 id="查看pid"><a href="#查看pid" class="headerlink" title="查看pid"></a>查看pid</h5></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ps aux|grep prometheus 1000      </span></span><br><span class="line">5631  0.4  4.2 576752 327584 ?       Ssl  Jul08  47:46 /bin/prometheus --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries --config.file=/etc/prometheus/config_out/prometheus.env.yaml --storage.tsdb.path=/prometheus --storage.tsdb.retention.time=12h --web.enable-lifecycle --storage.tsdb.no-lockfile --web.route-prefix=/ --web.listen-address=127.0.0.1:9090</span><br></pre></td></tr></table></figure>



<ol start="2">
<li><h5 id="查看pod-ID"><a href="#查看pod-ID" class="headerlink" title="查看pod ID"></a>查看pod ID</h5></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cat /proc/5631/mountinfo | grep etc-hosts | awk -F / &#x27;&#123;print $6&#125;&#x27; 44a2f0f5-8ddc-40f9-96a5-c37e6bea55df</span></span><br></pre></td></tr></table></figure>



<ol start="3">
<li><h5 id="查看pod-name-1"><a href="#查看pod-name-1" class="headerlink" title="查看pod name"></a>查看pod name</h5></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker ps | grep 44a2f0f5-8ddc-40f9-96a5-c37e6bea55df | awk -F _ &#x27;&#123;print $3&#125;&#x27; | uniq prometheus-cluster-monitoring-0</span></span><br></pre></td></tr></table></figure>



<h2 id="基于ID查找pod"><a href="#基于ID查找pod" class="headerlink" title="基于ID查找pod"></a>基于ID查找pod</h2><p>OOM日志如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Nov 16 10:36:48 rancher-2 kernel: stress invoked oom-killer: gfp_mask=0x24000c0, order=0, oom_score_adj=994</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: stress cpuset=336506de688b4cb104c2ec6b2be5134cc66bac44ad2f3e0ad0a12f57623c6d50 mems_allowed=0</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: CPU: 1 PID: 3262 Comm: stress Not tainted 4.4.238-1.el7.elrepo.x86_64 <span class="comment">#1</span></span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Hardware name: Fedora Project OpenStack Nova, BIOS 1.9.1-5.el7_3.1 04/01/2014</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: 0000000000000286 c7146aedec18fc5b ffff8801f41afc60 ffffffff8134f22a</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: ffff8801f41afd38 ffff88016ec30000 ffff8801f41afcc8 ffffffff81211c8b</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: ffffffff8119996c ffff88016effc2c0 0000000000000000 0000000000000206</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Call Trace:</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff8134f22a&gt;] dump_stack+0x6d/0x93</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81211c8b&gt;] dump_header+0x57/0x1bb</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff8119996c&gt;] ? find_lock_task_mm+0x3c/0x80</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81211dfd&gt;] oom_kill_process.cold+0xe/0x30e</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81206c46&gt;] ? mem_cgroup_iter+0x146/0x320</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81208d78&gt;] mem_cgroup_out_of_memory+0x2c8/0x310</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff812099b3&gt;] mem_cgroup_oom_synchronize+0x2e3/0x310</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81204c60&gt;] ? get_mctgt_type+0x250/0x250</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff8119a30e&gt;] pagefault_out_of_memory+0x3e/0xb0</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81067882&gt;] mm_fault_error+0x62/0x150</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81068108&gt;] __do_page_fault+0x3d8/0x3e0</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff810681c3&gt;] trace_do_page_fault+0x43/0x140</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81061737&gt;] do_async_page_fault+0x37/0xb0</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [&lt;ffffffff81738778&gt;] async_page_fault+0x28/0x30</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Task <span class="keyword">in</span> /kubepods/burstable/podfc92664d-3ca9-4a37-8244-7bf1a04da201/336506de688b4cb104c2ec6b2be5134cc66bac44ad2f3e0ad0a12f57623c6d50 killed as a result of <span class="built_in">limit</span> of /kubepods/burstable/podfc92664d-3ca9-4a37-8244-7bf1a04da201</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: memory: usage 102400kB, <span class="built_in">limit</span> 102400kB, failcnt 14</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: memory+swap: usage 102400kB, <span class="built_in">limit</span> 9007199254740988kB, failcnt 0</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: kmem: usage 1940kB, <span class="built_in">limit</span> 9007199254740988kB, failcnt 0</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Memory cgroup stats <span class="keyword">for</span> /kubepods/burstable/podfc92664d-3ca9-4a37-8244-7bf1a04da201: cache:0KB rss:0KB rss_huge:0KB mapped_file:0KB dirty:0KB writeback:0KB swap:0KB inactive_anon:0KB active_anon:0KB inactive_file:0KB active_file:0KB unevictable:0KB</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Memory cgroup stats <span class="keyword">for</span> /kubepods/burstable/podfc92664d-3ca9-4a37-8244-7bf1a04da201/fa55a38258b1722eb5ba6bc5ea87f9f85107697ed3161d5e98526889b49778db: cache:0KB rss:44KB rss_huge:0KB mapped_file:0KB dirty:0KB writeback:0KB swap:0KB inactive_anon:0KB active_anon:44KB inactive_file:0KB active_file:0KB unevictable:0KB</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Memory cgroup stats <span class="keyword">for</span> /kubepods/burstable/podfc92664d-3ca9-4a37-8244-7bf1a04da201/336506de688b4cb104c2ec6b2be5134cc66bac44ad2f3e0ad0a12f57623c6d50: cache:0KB rss:100416KB rss_huge:75776KB mapped_file:0KB dirty:0KB writeback:0KB swap:0KB inactive_anon:0KB active_anon:100392KB inactive_file:0KB active_file:0KB unevictable:0KB</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [ pid ]   uid  tgid total_vm      rss nr_ptes nr_pmds swapents oom_score_adj name</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [ 2608]     0  2608      255        1       4       2        0          -998 pause</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: [ 3149]     0  3149    28361    25755      56       5        0           994 stress</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Memory cgroup out of memory: Kill process 3149 (stress) score 1979 or sacrifice child</span><br><span class="line">Nov 16 10:36:48 rancher-2 kernel: Killed process 3149 (stress) total-vm:113444kB, anon-rss:99904kB, file-rss:3116kB</span><br><span class="line">Nov 16 10:36:48 rancher-2 containerd: time=<span class="string">&quot;2020-11-16T10:36:48.794443229+08:00&quot;</span> level=info msg=<span class="string">&quot;shim reaped&quot;</span> id=336506de688b4cb104c2ec6b2be5134cc66bac44ad2f3e0ad0a12f57623c6d50</span><br><span class="line">Nov 16 10:36:48 rancher-2 dockerd: time=<span class="string">&quot;2020-11-16T10:36:48.804531348+08:00&quot;</span> level=info msg=<span class="string">&quot;ignoring event&quot;</span> module=libcontainerd namespace=moby topic=/tasks/delete <span class="built_in">type</span>=<span class="string">&quot;*events.TaskDelete&quot;</span></span><br><span class="line">Nov 16 10:37:05 rancher-2 containerd: time=<span class="string">&quot;2020-11-16T10:37:05.032807429+08:00&quot;</span> level=info msg=<span class="string">&quot;shim containerd-shim started&quot;</span> address=/containerd-shim/94327bd1be610aca06fccb2e695d8824d414327a214de3f259d5a8da5ded5188.sock debug=<span class="literal">false</span> pid=3801</span><br></pre></td></tr></table></figure>

<p>可以看到/kubepods/burstable/podfc92664d-3ca9-4a37-8244-7bf1a04da201，其中fc92664d-3ca9-4a37-8244-7bf1a04da201就是<code>pod ID</code>，然后就可以根据pod ID查找pod</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker ps |grep fc92664d-3ca9-4a37-8244-7bf1a04da201 |awk <span class="string">&#x27;&#123;print $10&#125;&#x27;</span> |awk -F <span class="string">&#x27;_&#x27;</span> <span class="string">&#x27;&#123;print &quot;namespace: &quot;$4 &quot;\nname: &quot;$3&#125;&#x27;</span></span><br><span class="line">namespace: default</span><br><span class="line">name: memory-demo-2</span><br><span class="line">接着查看CGroup显示的限制，例如：kernel: memory: usage 102400kB, <span class="built_in">limit</span> 102400kB, failcnt 14 。其中内存使用达到102400kB，限制的值为102400kB，且内存超过限制的次数达到14次。</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>基于证书签名请求快速构建kubeconfig</title>
    <url>/2022/06/29/%E5%9F%BA%E4%BA%8E%E8%AF%81%E4%B9%A6%E7%AD%BE%E5%90%8D%E8%AF%B7%E6%B1%82%E5%BF%AB%E9%80%9F%E6%9E%84%E5%BB%BAkubeconfig/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Kubernetes 提供 <code>certificates.k8s.io</code> API，可让你配置由你控制的证书颁发机构（CA） 签名的 TLS 证书。 你的工作负载可以使用这些 CA 和证书来建立信任。</p>
<h2 id="请求签名流程"><a href="#请求签名流程" class="headerlink" title="请求签名流程"></a>请求签名流程</h2><p>CertificateSigningRequest 资源类型允许客户使用它申请发放 X.509 证书。</p>
<p>首先我们需要创建一个CSR证书请求文件，并通过CertificateSigningRequest资源对象的<code>spec.request</code>提交到k8s中。</p>
<p>创建完成的CertificateSigningRequest，要先通过批准，然后才能签名。这里会根据 <code>spec.signerName</code> 字段所选的签名者自动或者人工批准，人工批准的话需要手动执行<code>kube certificate approve</code>命令，本文也是采用的这种方法。同样我们也可以驳回证书签名请求。</p>
<p>对于已批准的证书会通过证书签名控制器自动创建证书并更新到CertificateSigningRequest资源对象的<code>status.certificate</code> 字段中。如果不满足签名条件或者驳回的话，这个字段就会一直为空。</p>
<p>注意：为了减少集群中遗留的过时的 CertificateSigningRequest 资源的数量， 垃圾收集控制器将会周期性地运行。 此垃圾收集器会清除在一段时间内没有改变过状态的 CertificateSigningRequests：</p>
<ul>
<li>已批准的请求：1小时后自动删除</li>
<li>已拒绝的请求：1小时后自动删除</li>
<li>已失败的请求：1小时后自动删除</li>
<li>挂起的请求：24小时后自动删除</li>
<li>所有请求：在颁发的证书过期后自动删除</li>
</ul>
<h2 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h2><h3 id="创建密钥"><a href="#创建密钥" class="headerlink" title="创建密钥"></a>创建密钥</h3><h4 id="基于openssl生成PKI私钥和CSR证书请求"><a href="#基于openssl生成PKI私钥和CSR证书请求" class="headerlink" title="基于openssl生成PKI私钥和CSR证书请求"></a>基于openssl生成PKI私钥和CSR证书请求</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out zerchin.key 2048</span><br><span class="line">openssl req -new -key zerchin.key -out zerchin.csr</span><br></pre></td></tr></table></figure>

<p>其中，CN 是用户名，O 是该用户归属的组。如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Organization Name (eg, company) [Default Company Ltd]:rancher</span><br><span class="line">Common Name (eg, your name or your server<span class="string">&#x27;s hostname) []:zerchin</span></span><br></pre></td></tr></table></figure>

<h4 id="获取CSR文件的base64编码"><a href="#获取CSR文件的base64编码" class="headerlink" title="获取CSR文件的base64编码"></a>获取CSR文件的base64编码</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat zerchin.csr | base64 | tr -d <span class="string">&quot;\n&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="创建CertificateSigningRequest"><a href="#创建CertificateSigningRequest" class="headerlink" title="创建CertificateSigningRequest"></a>创建CertificateSigningRequest</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span> <span class="string">&gt;</span> <span class="string">certificateSigningRequest.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">certificates.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CertificateSigningRequest</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">zerchin</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">request:</span> <span class="string">`cat</span> <span class="string">zerchin.csr</span> <span class="string">|</span> <span class="string">base64</span> <span class="string">|</span> <span class="string">tr</span> <span class="string">-d</span> <span class="string">&quot;\n&quot;</span><span class="string">`</span></span><br><span class="line">  <span class="attr">signerName:</span> <span class="string">kubernetes.io/kube-apiserver-client</span></span><br><span class="line">  <span class="attr">expirationSeconds:</span> <span class="number">86400</span>  <span class="comment"># one day</span></span><br><span class="line">  <span class="attr">usages:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">client</span> <span class="string">auth</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>其中：</p>
<p><code>signerName</code>：Kubernetes提供了四种内置的签名者，这里我们使用<code>kubernetes.io/kube-apiserver-client</code>，签名的证书被apiserver视为客户证书。</p>
<p><code>expirationSeconds</code>：过期时间，这个过期时间指的是签发等待的时间，过了这个时间就不能签发了，可以重新再次发起。该参数在 k8s 1.22+ 版本支持，低于此版本可以去掉这个参数。</p>
<p><code>usages</code>：必须是<code>client auth</code></p>
<p><code>request</code>：是CSR文件内容的base64 编码值。</p>
<h3 id="批准证书签名请求"><a href="#批准证书签名请求" class="headerlink" title="批准证书签名请求"></a>批准证书签名请求</h3><h4 id="获取CSR列表"><a href="#获取CSR列表" class="headerlink" title="获取CSR列表"></a>获取CSR列表</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get csr</span><br><span class="line">NAME      AGE   SIGNERNAME                            REQUESTOR    CONDITION</span><br><span class="line">zerchin   14s   kubernetes.io/kube-apiserver-client   user-vmhf2   Pending</span><br></pre></td></tr></table></figure>

<h4 id="获取证书签名请求列表"><a href="#获取证书签名请求列表" class="headerlink" title="获取证书签名请求列表"></a>获取证书签名请求列表</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get certificatesigningrequests.certificates.k8s.io </span><br><span class="line">NAME      AGE   SIGNERNAME                            REQUESTOR    CONDITION</span><br><span class="line">zerchin   9s    kubernetes.io/kube-apiserver-client   user-vmhf2   Pending</span><br></pre></td></tr></table></figure>

<h4 id="批准CSR"><a href="#批准CSR" class="headerlink" title="批准CSR"></a>批准CSR</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl certificate approve zerchin</span><br><span class="line">certificatesigningrequest.certificates.k8s.io/zerchin approved</span><br></pre></td></tr></table></figure>

<p>查看csr和certificate的状态，一定要有<code>Approved</code> 和<code>Issued</code>两个状态</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl get csr</span><br><span class="line">NAME      AGE   SIGNERNAME                            REQUESTOR    CONDITION</span><br><span class="line">zerchin   52s   kubernetes.io/kube-apiserver-client   user-vmhf2   Approved,Issued</span><br><span class="line">$ kubectl get certificatesigningrequests.certificates.k8s.io </span><br><span class="line">NAME      AGE   SIGNERNAME                            REQUESTOR    CONDITION</span><br><span class="line">zerchin   56s   kubernetes.io/kube-apiserver-client   user-vmhf2   Approved,Issued</span><br></pre></td></tr></table></figure>

<h4 id="从CertificateSigningRequest中导出颁发的证书"><a href="#从CertificateSigningRequest中导出颁发的证书" class="headerlink" title="从CertificateSigningRequest中导出颁发的证书"></a>从CertificateSigningRequest中导出颁发的证书</h4><p>证书的内容使用 base64 编码，存放在字段 <code>status.certificate</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get csr zerchin -o jsonpath=<span class="string">&#x27;&#123;.status.certificate&#125;&#x27;</span>| base64 -d &gt; zerchin.crt</span><br></pre></td></tr></table></figure>



<h3 id="构建kubeconfig文件"><a href="#构建kubeconfig文件" class="headerlink" title="构建kubeconfig文件"></a>构建kubeconfig文件</h3><h4 id="新建一个kubeconfig文件"><a href="#新建一个kubeconfig文件" class="headerlink" title="新建一个kubeconfig文件"></a>新建一个kubeconfig文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">touch zerchin-kubeconfig</span><br></pre></td></tr></table></figure>

<h4 id="设置k8s集群"><a href="#设置k8s集群" class="headerlink" title="设置k8s集群"></a>设置k8s集群</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl --kubeconfig zerchin-kubeconfig config set-cluster k8s --server=https://192.168.2.12:6443 --certificate-authority=/etc/kubernetes/ssl/kube-ca.pem --embed-certs=<span class="literal">true</span></span><br><span class="line">Cluster <span class="string">&quot;k8s&quot;</span> <span class="built_in">set</span>.</span><br></pre></td></tr></table></figure>

<h4 id="设置用户"><a href="#设置用户" class="headerlink" title="设置用户"></a>设置用户</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl --kubeconfig zerchin-kubeconfig config set-credentials zerchin --client-key=./zerchin.key --client-certificate=./zerchin.crt --embed-certs=<span class="literal">true</span></span><br><span class="line">User <span class="string">&quot;zerchin&quot;</span> <span class="built_in">set</span>.</span><br></pre></td></tr></table></figure>

<h4 id="设置context"><a href="#设置context" class="headerlink" title="设置context"></a>设置context</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl --kubeconfig zerchin-kubeconfig config set-context zerchin --cluster=k8s --user=zerchin </span><br><span class="line">Context <span class="string">&quot;zerchin&quot;</span> created.</span><br></pre></td></tr></table></figure>

<h4 id="切换context"><a href="#切换context" class="headerlink" title="切换context"></a>切换context</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl --kubeconfig zerchin-kubeconfig config use-context zerchin</span><br><span class="line">Switched to context <span class="string">&quot;zerchin&quot;</span>.</span><br></pre></td></tr></table></figure>



<h3 id="创建角色并绑定到该用户上"><a href="#创建角色并绑定到该用户上" class="headerlink" title="创建角色并绑定到该用户上"></a>创建角色并绑定到该用户上</h3><h4 id="创建role"><a href="#创建role" class="headerlink" title="创建role"></a>创建role</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl create role zerchin-role --verb=create --verb=get --verb=list --verb=update --verb=delete --resource=pods</span><br><span class="line">role.rbac.authorization.k8s.io/zerchin-role created</span><br></pre></td></tr></table></figure>

<h4 id="创建rolebinding"><a href="#创建rolebinding" class="headerlink" title="创建rolebinding"></a>创建rolebinding</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl create rolebinding zerchin-role-binding --role=zerchin-role --user=zerchin</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/zerchin-role-binding created</span><br></pre></td></tr></table></figure>



<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>执行kubectl命令进行验证，首先验证一下pod的权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl --kubeconfig zerchin-kubeconfig get pods</span><br><span class="line">NAME                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">test-776cfb6994-9rhbx         1/1     Running   0          22h</span><br><span class="line">test-776cfb6994-g6xfh         1/1     Running   0          22h</span><br></pre></td></tr></table></figure>

<p>看一下node的权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ kubectl --kubeconfig zerchin-kubeconfig get nodes</span><br><span class="line">Error from server (Forbidden): nodes is forbidden: User <span class="string">&quot;zerchin&quot;</span> cannot list resource <span class="string">&quot;nodes&quot;</span> <span class="keyword">in</span> API group <span class="string">&quot;&quot;</span> at the cluster scope</span><br></pre></td></tr></table></figure>

<p>可以看到，我们可以正常执行kubectl命令去查看pod，但是没有其他资源的权限，验证成功。</p>
<h3 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h3><ol>
<li><p>批准CSR之后，如果无法从CertificateSigningRequest中导出颁发的证书（<code>.status.certificate</code>路径不存在），并且执行<code>kubectl get csr</code>查看只有一个<code>Approved</code>状态，没有<code>Issued</code>状态，那么大概率是controller-manager没有挂载CA证书进来，需要先挂载进来后再次签发。</p>
<p>Rancher/RKE集群可以参考这个如下配置添加CA证书挂载，编辑<code>cluster.yml</code>文件，在<code>kube-controller</code>下添加此配置参数：</p>
</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">kube-controller:</span> </span><br><span class="line">    <span class="attr">extra_args:</span> </span><br><span class="line">      <span class="attr">cluster-signing-cert-file:</span> <span class="string">&quot;/etc/kubernetes/ssl/kube-ca.pem&quot;</span></span><br><span class="line">      <span class="attr">cluster-signing-key-file:</span> <span class="string">&quot;/etc/kubernetes/ssl/kube-ca-key.pem&quot;</span></span><br></pre></td></tr></table></figure>





<blockquote>
<p>参考文档：</p>
<p><a href="https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/certificate-signing-requests/">https://kubernetes.io/zh-cn/docs/reference/access-authn-authz/certificate-signing-requests/</a></p>
<p><a href="https://kubernetes.io/zh-cn/docs/tasks/tls/managing-tls-in-a-cluster/">https://kubernetes.io/zh-cn/docs/tasks/tls/managing-tls-in-a-cluster/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>安装kubectl ingress-nginx</title>
    <url>/2020/07/02/%E5%AE%89%E8%A3%85kubectl-ingress-nginx/</url>
    <content><![CDATA[<p>通过ingress-nginx插件查看ingress配置信息</p>
<blockquote>
<p>参考官网：<a href="https://kubernetes.github.io/ingress-nginx/kubectl-plugin/">https://kubernetes.github.io/ingress-nginx/kubectl-plugin/</a></p>
</blockquote>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><table>
<thead>
<tr>
<th>软件</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>k8s</td>
<td>不挑</td>
</tr>
<tr>
<td>ingress-nginx</td>
<td>不挑</td>
</tr>
</tbody></table>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="1、安装krew"><a href="#1、安装krew" class="headerlink" title="1、安装krew"></a>1、安装krew</h3><p>ingress-nginx插件需要通过krew安装，首先需要安装krew工具</p>
<p>执行以下脚本安装krew</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(</span><br><span class="line">  <span class="built_in">set</span> -x; <span class="built_in">cd</span> <span class="string">&quot;<span class="subst">$(mktemp -d)</span>&quot;</span> &amp;&amp;</span><br><span class="line">  curl -fsSLO <span class="string">&quot;https://github.com/kubernetes-sigs/krew/releases/latest/download/krew.tar.gz&quot;</span> &amp;&amp;</span><br><span class="line">  tar zxvf krew.tar.gz &amp;&amp;</span><br><span class="line">  KREW=./krew-<span class="string">&quot;<span class="subst">$(uname | tr &#x27;[:upper:]&#x27; &#x27;[:lower:]&#x27;)</span>_<span class="subst">$(uname -m | sed -e &#x27;s/x86_64/amd64/&#x27; -e &#x27;s/arm.*$/arm/&#x27;)</span>&quot;</span> &amp;&amp;</span><br><span class="line">  <span class="string">&quot;<span class="variable">$KREW</span>&quot;</span> install krew</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>/etc/profile 设置PATH</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;<span class="variable">$&#123;KREW_ROOT:-<span class="variable">$HOME</span>/.krew&#125;</span>/bin:<span class="variable">$PATH</span>&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>参考：<a href="https://krew.sigs.k8s.io/docs/user-guide/setup/install/">https://krew.sigs.k8s.io/docs/user-guide/setup/install/</a></p>
</blockquote>
<h3 id="2、krew安装ingress-nginx插件"><a href="#2、krew安装ingress-nginx插件" class="headerlink" title="2、krew安装ingress-nginx插件"></a>2、krew安装ingress-nginx插件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl krew install ingress-nginx</span><br></pre></td></tr></table></figure>

<h3 id="3、验证"><a href="#3、验证" class="headerlink" title="3、验证"></a>3、验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx --<span class="built_in">help</span></span><br></pre></td></tr></table></figure>


<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>默认是在default命名空间下查找<code>ingress-nginx-controller</code> deployment，Rancher安装的ingress-nginx是使用daemonset部署的，不知道通过daemonset查找，但是可以通过pod或者标签选择器查找，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx backends -n ingress-nginx --pod nginx-ingress-controller-rplw2  --list</span><br><span class="line"><span class="comment">## 或者</span></span><br><span class="line">kubectl ingress-nginx backends -n ingress-nginx -l app=ingress-nginx  --list</span><br></pre></td></tr></table></figure>

<h3 id="backends"><a href="#backends" class="headerlink" title="backends"></a>backends</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 只列出backends</span></span><br><span class="line">kubectl ingress-nginx backends -n ingress-nginx -l app=ingress-nginx  --list</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看某个backend的详细信息</span></span><br><span class="line">kubectl ingress-nginx backends -n ingress-nginx -l app=ingress-nginx  --backend default-nginx-test-http-nginx-test</span><br><span class="line"></span><br><span class="line"><span class="comment">## 查看所有backends</span></span><br><span class="line">kubectl ingress-nginx backends -n ingress-nginx -l app=ingress-nginx</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="cert-查看证书"><a href="#cert-查看证书" class="headerlink" title="cert 查看证书"></a>cert 查看证书</h3><p>如果ingress设置了ssl，可以通过cert命令查看证书，例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx certs -l app=ingress-nginx  -n ingress-nginx --host test3.zerchin.xyz</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里的–host指定的是域名，不是backend list的名字</p>
</blockquote>
<h3 id="conf-查看配置"><a href="#conf-查看配置" class="headerlink" title="conf 查看配置"></a>conf 查看配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">### 默认不带参数，查看所有配置，等同于进入pod查看/etc/nginx/nginx.conf</span></span><br><span class="line">kubectl ingress-nginx conf -l app=ingress-nginx  -n ingress-nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">### 查看单个ingress的配置，这里查看的是server下的配置</span></span><br><span class="line">kubectl ingress-nginx conf -l app=ingress-nginx  -n ingress-nginx --host nginx.zerchin.xyz</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="exec-执行命令"><a href="#exec-执行命令" class="headerlink" title="exec 执行命令"></a>exec 执行命令</h3><p>默认带有一个exec参数，可以执行相关命令，但是这个感觉没有自带的<code>kubectl exec</code> 好用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx <span class="built_in">exec</span> -l app=ingress-nginx  -n ingress-nginx  <span class="built_in">pwd</span></span><br><span class="line">/etc/nginx</span><br></pre></td></tr></table></figure>


<h3 id="service"><a href="#service" class="headerlink" title="service"></a>service</h3><p>由于Rancher部署的ingress-nginx没有对应service，暂时看不到</p>
<h3 id="ingresses"><a href="#ingresses" class="headerlink" title="ingresses"></a>ingresses</h3><p>提供所有入口定义的简短摘要，类似kubectl get ingress</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx ingresses --all-namespaces --host nginx.zerchin.xyz</span><br><span class="line">NAMESPACE   INGRESS NAME   HOST+PATH            ADDRESSES      TLS   SERVICE      SERVICE PORT      ENDPOINTS</span><br><span class="line">default     nginx          nginx.zerchin.xyz/   47.242.45.56   NO    nginx-test   http-nginx-test   4</span><br></pre></td></tr></table></figure>

<h3 id="lint"><a href="#lint" class="headerlink" title="lint"></a>lint</h3><p>检查kubernetes资源中可能存在的问题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx lint --all-namespaces --show-all -v</span><br><span class="line">Checking ingresses...</span><br><span class="line">✓ default/nginx</span><br><span class="line">✓ default/<span class="built_in">test</span></span><br><span class="line">✓ default/test3-ssl</span><br><span class="line">Checking deployments...</span><br><span class="line">✓ cattle-prometheus/exporter-kube-state-cluster-monitoring</span><br><span class="line">✓ cattle-prometheus/grafana-cluster-monitoring</span><br><span class="line">✓ cattle-prometheus/prometheus-operator-monitoring-operator</span><br><span class="line">✓ cattle-system/cattle-cluster-agent</span><br><span class="line">✓ default/busybox</span><br><span class="line">✓ default/nginx-test</span><br><span class="line">✓ default/proxy-nginx</span><br><span class="line">✓ default/<span class="built_in">test</span></span><br><span class="line">✓ ingress-nginx/default-http-backend</span><br><span class="line">✓ kube-system/coredns</span><br><span class="line">✓ kube-system/coredns-autoscaler</span><br><span class="line">✓ kube-system/metrics-server</span><br><span class="line">✓ local-path-storage/local-path-provisioner</span><br><span class="line">✓ nfs-client-provisioner/nfs-client-provisioner</span><br><span class="line">✓ p-6bwf5-pipeline/docker-registry</span><br><span class="line">✓ p-6bwf5-pipeline/example-helloserver</span><br><span class="line">✓ p-6bwf5-pipeline/jenkins</span><br><span class="line">✓ p-6bwf5-pipeline/minio</span><br><span class="line">✓ p-x25kp-pipeline/docker-registry</span><br><span class="line">✓ p-x25kp-pipeline/example-nginx</span><br><span class="line">✓ p-x25kp-pipeline/jenkins</span><br><span class="line">✓ p-x25kp-pipeline/minio</span><br></pre></td></tr></table></figure>

<h3 id="logs"><a href="#logs" class="headerlink" title="logs"></a>logs</h3><p>查看日志，等同于kubectl logs命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 常用这个</span></span><br><span class="line">kubectl ingress-nginx  logs -n ingress-nginx -l app=ingress-nginx --tail 100 -f</span><br><span class="line"></span><br><span class="line"><span class="comment">## 其他参数</span></span><br><span class="line"><span class="comment">## 返回特定时间</span></span><br><span class="line">--since</span><br><span class="line">--since-time</span><br></pre></td></tr></table></figure>

<h3 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h3><p>等同于<code>kubectl exec -it xxx -- bash</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl ingress-nginx  ssh -n ingress-nginx -l app=ingress-nginx</span><br><span class="line">bash-5.0$ </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>ingress</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>快速搭建OpenLDAP环境并对接Rancher认证</title>
    <url>/2021/04/29/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>如果企业内部有使用LDAP进行用户身份验证，则可以通过配置Rancher与OpenLDAP服务器通信以对用户进行身份验证。</p>
<p>本文将介绍如何通过docker快速搭建OpenLDAP环境，并对接Rancher认证功能</p>
<p>主要用到两个镜像：</p>
<ul>
<li><code>osixia/openldap:1.5.0</code>：LDAP服务端</li>
<li><code>osixia/phpldapadmin:0.9.0</code>：LDAP web管理工具</li>
</ul>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="安装OpenLDAP服务"><a href="#安装OpenLDAP服务" class="headerlink" title="安装OpenLDAP服务"></a>安装OpenLDAP服务</h3><ol>
<li><p>基于<code>osixia/openldap:1.5.0</code>镜像，创建OpenLDAP服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -p 389:389 -p 636:636 --name openldap -itd --env LDAP_ORGANISATION=<span class="string">&quot;rancher&quot;</span> --env LDAP_DOMAIN=<span class="string">&quot;rancherldap.com&quot;</span> --env LDAP_ADMIN_PASSWORD=<span class="string">&quot;Rancher123&quot;</span>   osixia/openldap:1.5.0</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<p>缺省ldap使用389端口，加密使用636端口</p>
<p><code>LDAP_ORGANISATION</code>：Organisation名称，默认是<code>Example Inc.</code></p>
<p><code>LDAP_DOMAIN</code>：LDAP domain，例如默认是<code>example.org</code>，则domain为<code>dc=example,dc=org</code></p>
<p><code>LDAP_ADMIN_PASSWORD</code>：admin用户密码</p>
</li>
</ol>
<ol start="2">
<li><p>创建<code>osixia/phpldapadmin:0.9.0</code>镜像，创建Web服务</p>
<p>phpldapadmin是一个基于Web的管理LDAP的工具，可以更加直观的查看和管理LDAP信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -p 6443:443 --env PHPLDAPADMIN_LDAP_HOSTS=172.16.21.12 -itd --name phpldapadmin osixia/phpldapadmin:0.9.0</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<p><code>PHPLDAPADMIN_LDAP_HOSTS</code>：LDAP服务地址，这里如果是将openLDAP容器启动在相同主机上则填写本机的IP地址即可</p>
</li>
<li><p>docker-compose（可选)</p>
<p>也可以通过docker-compose去创建OpenLDAP环境</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2.3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">openldap:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">osixia/openldap:1.5.0</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">openldap</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_ORGANISATION=rancher</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_DOMAIN=rancherldap.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_ADMIN_PASSWORD=Rancher123</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">389</span><span class="string">:389</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">636</span><span class="string">:636</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./slapd:/etc/ldap/slapd.d</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./data:/var/lib/ldap</span></span><br><span class="line">  <span class="attr">phpldapadmin:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">osixia/phpldapadmin:0.9.0</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">phpldapadmin</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">PHPLDAPADMIN_LDAP_HOSTS=openldap</span></span><br><span class="line">    <span class="attr">links:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">openldap:openldap</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">openldap</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">6443</span><span class="string">:443</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./phpldapadmin-certs:/container/service/phpldapadmin/assets/apache2/certs</span></span><br></pre></td></tr></table></figure>

<p>将上诉文件保存到<code>docker-compose.yml</code>中，然后执行<code>docker-compose up -d</code>命令即可</p>
<p>运行成功后，会在跟<code>docker-compose.yml</code>文件相同的目录下创建三个目录<code>slapd</code>、<code>data</code>、<code>phpldapadmin-certs</code></p>
<p>默认admin domain账号为：<code>cn=admin,dc=rancherldap,dc=com</code>，密码为：<code>Rancher123</code></p>
</li>
<li><p>进入openldap容器中，执行<code>ldapsearch</code>命令尝试搜索</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> openldap ldapsearch -x -H ldap://localhost -b dc=rancherldap,dc=com -D <span class="string">&quot;cn=admin,dc=rancherldap,dc=com&quot;</span> -w Rancher123</span><br></pre></td></tr></table></figure>

<p>可以得到如下输出结果，则说明部署成功</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># extended LDIF</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># LDAPv3</span></span><br><span class="line"><span class="comment"># base &lt;dc=rancherldap,dc=com&gt; with scope subtree</span></span><br><span class="line"><span class="comment"># filter: (objectclass=*)</span></span><br><span class="line"><span class="comment"># requesting: ALL</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># rancherldap.com</span></span><br><span class="line">dn: dc=rancherldap,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line">o: rancher</span><br><span class="line">dc: rancherldap</span><br><span class="line"></span><br><span class="line"><span class="comment"># search result</span></span><br><span class="line">search: 2</span><br><span class="line">result: 0 Success</span><br><span class="line"></span><br><span class="line"><span class="comment"># numResponses: 2</span></span><br><span class="line"><span class="comment"># numEntries: 1</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="基于phpldapadmin的web工具创建用户"><a href="#基于phpldapadmin的web工具创建用户" class="headerlink" title="基于phpldapadmin的web工具创建用户"></a>基于phpldapadmin的web工具创建用户</h3><p>浏览器访问：<code>https://&lt;IP&gt;:6443</code>，点击左侧login登录</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/login-1.png" alt="login-1"></p>
<p>其中账号密码如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cn=admin,dc=rancherldap,dc=com</span><br><span class="line">Rancher123</span><br></pre></td></tr></table></figure>

<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/login-2.png" alt="login-2"></p>
<p>登录进去后，可以看到domain相关信息</p>
<h4 id="创建Organisational-Unit"><a href="#创建Organisational-Unit" class="headerlink" title="创建Organisational Unit"></a>创建Organisational Unit</h4><p>点击<code>dc=rancherldap,dc=com</code>，在其目录下点击<code>Create a child entry</code>创建子条目</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/ou-1.png" alt="ou-1"></p>
<p>点击 <code>Generic: Organisational Unit</code></p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/ou-2.png" alt="ou-2"></p>
<p>填写OU名称，例如这里填写rancher，填好之后点击<code>Create Object</code>创建该对象</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/ou-3.png" alt="ou-3"></p>
<p>点击Commit二次确认</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/ou-4.png" alt="ou-4"></p>
<p>创建成功后，就可以在左侧中看到我们创建的OU对象</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/ou-5.png" alt="ou-5"></p>
<h4 id="创建Group"><a href="#创建Group" class="headerlink" title="创建Group"></a>创建Group</h4><p>在<code>ou=rancher</code>下，点击<code>Create a child entry</code>创建子条目，点击 <code>Generic: Posix Group</code>创建Group对象</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/group-1.png" alt="image-20210429155116459"></p>
<p>填写Group名称，例如这里填写<code>group</code>，</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/group-2.png" alt="group-2"></p>
<p>填好之后点击<code>Create Object</code>创建该对象，点击Commit二次确认，创建成功后，就可以在左侧中看到我们创建的Group对象</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/group-3.png" alt="group-3"></p>
<h4 id="创建User"><a href="#创建User" class="headerlink" title="创建User"></a>创建User</h4><p>在<code>cn=group</code>下，点击<code>Create a child entry</code>创建子条目，点击 <code>Generic: User Account</code>创建User对象</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/user-1.png" alt="user-1"></p>
<p>填写对应的user信息，填写First name和Last name，会自动生成Common Name和User ID，其中UserID为后续Rancher登录的用户名</p>
<p>填写Password，后续登录Rancher使用该密码</p>
<p>选择刚刚创建的group</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/user-2.png" alt="user-2"></p>
<p>填好之后点击<code>Create Object</code>创建该对象，点击Commit二次确认，创建成功后，就可以在左侧中看到我们创建的USer对象</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/user-3.png" alt="user-3"></p>
<p>同理，我们用相同的方法再创建一个test用户</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/user-4.png" alt="user-4"></p>
<h3 id="对接Rancher认证"><a href="#对接Rancher认证" class="headerlink" title="对接Rancher认证"></a>对接Rancher认证</h3><h4 id="对接OpenLDAP"><a href="#对接OpenLDAP" class="headerlink" title="对接OpenLDAP"></a>对接OpenLDAP</h4><p>在Rancher UI中，点击 全局-安全-认证，选择OpenLDAP</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/rancher-1.png" alt="rancher-1"></p>
<p>参数说明：</p>
<p><code>主机名或 IP 地址</code>：OpenLDAP服务器的IP地址</p>
<p><code>端口</code>：默认端口是389</p>
<p><code>服务帐户专有名称</code>：<code>cn=admin,dc=rancherldap,dc=com</code>，这里填写admin用户的domain</p>
<p><code>服务账号密码</code>：admin用户的密码</p>
<p><code>用户搜索起点</code>：例如刚刚创建的OU为rancher，则这里的搜索起点为<code>ou=rancher,dc=rancherldap,dc=com</code></p>
<p><code>用户名</code>：这个用户会成为管理员，用户名需要基于<code>User Name</code>填写，例如我们刚刚创建的adminuser，则这里填写<code>auser</code></p>
<p><code>密码</code>：该用户的密码</p>
<p>参数填写完之后，点击启用OpenLDAP认证，开启OpenLDAP认证</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/rancher-2.png" alt="rancher-2"></p>
<h4 id="测试LDAP用户登录"><a href="#测试LDAP用户登录" class="headerlink" title="测试LDAP用户登录"></a>测试LDAP用户登录</h4><p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/rancher-3.png" alt="rancher-3"></p>
<p>登录成功，默认该用户没有权限</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/rancher-4.png" alt="rancher-4"></p>
<h3 id="OpenLDAP启用TLS"><a href="#OpenLDAP启用TLS" class="headerlink" title="OpenLDAP启用TLS"></a>OpenLDAP启用TLS</h3><p>上述情况下，对接LDAP使用389端口，我们可以使用此端口进行LDAP连接。 但是该端口是非安全和未加密的连接，容易造成安全问题，暴露用户相关信息，一般建议是389仅用在内网或者测试环境。</p>
<p>针对这个情况，我们可以使用LDAP的另一个tls加密端口：636端口，来对接LDAP。</p>
<h4 id="创建自签名证书"><a href="#创建自签名证书" class="headerlink" title="创建自签名证书"></a>创建自签名证书</h4><p>在<code>docker-compose.yml</code>同级目录下，新建一个目录，命名为<code>certs</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir certs</span><br><span class="line"><span class="built_in">cd</span> certs</span><br></pre></td></tr></table></figure>

<p>新建一个文件<code>create-cert.sh</code>，复制如下脚本至该文件中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash -e</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">help</span> ()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; ================================================================ &#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-domain: 生成ssl证书需要的主域名，如不指定则默认为www.rancher.local，如果是ip访问服务，则可忽略；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-trusted-ip: 一般ssl证书只信任域名的访问请求，有时候需要使用ip去访问server，那么需要给ssl证书添加扩展IP，多个IP用逗号隔开；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-trusted-domain: 如果想多个域名访问，则添加扩展域名（SSL_TRUSTED_DOMAIN）,多个扩展域名用逗号隔开；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-size: ssl加密位数，默认2048；&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-cn: 国家代码(2个字母的代号),默认CN;&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; 使用示例:&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; ./create_self-signed-cert.sh --ssl-domain=www.test.com --ssl-trusted-domain=www.test2.com \ &#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; --ssl-trusted-ip=1.1.1.1,2.2.2.2,3.3.3.3 --ssl-size=2048 --ssl-date=3650&#x27;</span></span><br><span class="line">    <span class="built_in">echo</span>  <span class="string">&#x27; ================================================================&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span> <span class="keyword">in</span></span><br><span class="line">    -h|--<span class="built_in">help</span>) <span class="built_in">help</span>; <span class="built_in">exit</span>;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$1</span> == <span class="string">&#x27;&#x27;</span> ]];<span class="keyword">then</span></span><br><span class="line">    <span class="built_in">help</span>;</span><br><span class="line">    <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">CMDOPTS=<span class="string">&quot;$*&quot;</span></span><br><span class="line"><span class="keyword">for</span> OPTS <span class="keyword">in</span> <span class="variable">$CMDOPTS</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    key=$(<span class="built_in">echo</span> <span class="variable">$&#123;OPTS&#125;</span> | awk -F<span class="string">&quot;=&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> )</span><br><span class="line">    value=$(<span class="built_in">echo</span> <span class="variable">$&#123;OPTS&#125;</span> | awk -F<span class="string">&quot;=&quot;</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> )</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;<span class="variable">$key</span>&quot;</span> <span class="keyword">in</span></span><br><span class="line">        --ssl-domain) SSL_DOMAIN=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-trusted-ip) SSL_TRUSTED_IP=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-trusted-domain) SSL_TRUSTED_DOMAIN=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-size) SSL_SIZE=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-date) SSL_DATE=<span class="variable">$value</span> ;;</span><br><span class="line">        --ca-date) CA_DATE=<span class="variable">$value</span> ;;</span><br><span class="line">        --ssl-cn) CN=<span class="variable">$value</span> ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CA相关配置</span></span><br><span class="line">CA_DATE=<span class="variable">$&#123;CA_DATE:-3650&#125;</span></span><br><span class="line">CA_KEY=<span class="variable">$&#123;CA_KEY:-cakey.pem&#125;</span></span><br><span class="line">CA_CERT=<span class="variable">$&#123;CA_CERT:-cacerts.pem&#125;</span></span><br><span class="line">CA_DOMAIN=cattle-ca</span><br><span class="line"></span><br><span class="line"><span class="comment"># ssl相关配置</span></span><br><span class="line">SSL_CONFIG=<span class="variable">$&#123;SSL_CONFIG:-<span class="variable">$PWD</span>/openssl.cnf&#125;</span></span><br><span class="line">SSL_DOMAIN=<span class="variable">$&#123;SSL_DOMAIN:-&#x27;www.rancher.local&#x27;&#125;</span></span><br><span class="line">SSL_DATE=<span class="variable">$&#123;SSL_DATE:-3650&#125;</span></span><br><span class="line">SSL_SIZE=<span class="variable">$&#123;SSL_SIZE:-2048&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 国家代码(2个字母的代号),默认CN;</span></span><br><span class="line">CN=<span class="variable">$&#123;CN:-CN&#125;</span></span><br><span class="line"></span><br><span class="line">SSL_KEY=<span class="variable">$SSL_DOMAIN</span>.key</span><br><span class="line">SSL_CSR=<span class="variable">$SSL_DOMAIN</span>.csr</span><br><span class="line">SSL_CERT=<span class="variable">$SSL_DOMAIN</span>.crt</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ---------------------------- \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m       | 生成 SSL Cert |       \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ---------------------------- \033[0m&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -e ./<span class="variable">$&#123;CA_KEY&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 1. 发现已存在CA私钥，备份&quot;</span><span class="variable">$&#123;CA_KEY&#125;</span><span class="string">&quot;为&quot;</span><span class="variable">$&#123;CA_KEY&#125;</span><span class="string">&quot;-bak，然后重新创建 \033[0m&quot;</span></span><br><span class="line">    mv <span class="variable">$&#123;CA_KEY&#125;</span> <span class="string">&quot;<span class="variable">$&#123;CA_KEY&#125;</span>&quot;</span>-bak</span><br><span class="line">    openssl genrsa -out <span class="variable">$&#123;CA_KEY&#125;</span> <span class="variable">$&#123;SSL_SIZE&#125;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 1. 生成新的CA私钥 <span class="variable">$&#123;CA_KEY&#125;</span> \033[0m&quot;</span></span><br><span class="line">    openssl genrsa -out <span class="variable">$&#123;CA_KEY&#125;</span> <span class="variable">$&#123;SSL_SIZE&#125;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -e ./<span class="variable">$&#123;CA_CERT&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 2. 发现已存在CA证书，先备份&quot;</span><span class="variable">$&#123;CA_CERT&#125;</span><span class="string">&quot;为&quot;</span><span class="variable">$&#123;CA_CERT&#125;</span><span class="string">&quot;-bak，然后重新创建 \033[0m&quot;</span></span><br><span class="line">    mv <span class="variable">$&#123;CA_CERT&#125;</span> <span class="string">&quot;<span class="variable">$&#123;CA_CERT&#125;</span>&quot;</span>-bak</span><br><span class="line">    openssl req -x509 -sha256 -new -nodes -key <span class="variable">$&#123;CA_KEY&#125;</span> -days <span class="variable">$&#123;CA_DATE&#125;</span> -out <span class="variable">$&#123;CA_CERT&#125;</span> -subj <span class="string">&quot;/C=<span class="variable">$&#123;CN&#125;</span>/CN=<span class="variable">$&#123;CA_DOMAIN&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 2. 生成新的CA证书 <span class="variable">$&#123;CA_CERT&#125;</span> \033[0m&quot;</span></span><br><span class="line">    openssl req -x509 -sha256 -new -nodes -key <span class="variable">$&#123;CA_KEY&#125;</span> -days <span class="variable">$&#123;CA_DATE&#125;</span> -out <span class="variable">$&#123;CA_CERT&#125;</span> -subj <span class="string">&quot;/C=<span class="variable">$&#123;CN&#125;</span>/CN=<span class="variable">$&#123;CA_DOMAIN&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 3. 生成Openssl配置文件 <span class="variable">$&#123;SSL_CONFIG&#125;</span> \033[0m&quot;</span></span><br><span class="line">cat &gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span> &lt;&lt;<span class="string">EOM</span></span><br><span class="line"><span class="string">[req]</span></span><br><span class="line"><span class="string">req_extensions = v3_req</span></span><br><span class="line"><span class="string">distinguished_name = req_distinguished_name</span></span><br><span class="line"><span class="string">[req_distinguished_name]</span></span><br><span class="line"><span class="string">[ v3_req ]</span></span><br><span class="line"><span class="string">basicConstraints = CA:FALSE</span></span><br><span class="line"><span class="string">keyUsage = nonRepudiation, digitalSignature, keyEncipherment</span></span><br><span class="line"><span class="string">extendedKeyUsage = clientAuth, serverAuth</span></span><br><span class="line"><span class="string">EOM</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="variable">$&#123;SSL_TRUSTED_IP&#125;</span> || -n <span class="variable">$&#123;SSL_TRUSTED_DOMAIN&#125;</span> || -n <span class="variable">$&#123;SSL_DOMAIN&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">    cat &gt;&gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span> &lt;&lt;<span class="string">EOM</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string">[alt_names]</span></span><br><span class="line"><span class="string">EOM</span></span><br><span class="line">    IFS=<span class="string">&quot;,&quot;</span></span><br><span class="line">    dns=(<span class="variable">$&#123;SSL_TRUSTED_DOMAIN&#125;</span>)</span><br><span class="line">    dns+=(<span class="variable">$&#123;SSL_DOMAIN&#125;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!dns[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">      <span class="built_in">echo</span> DNS.$((i+<span class="number">1</span>)) = <span class="variable">$&#123;dns[$i]&#125;</span> &gt;&gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [[ -n <span class="variable">$&#123;SSL_TRUSTED_IP&#125;</span> ]]; <span class="keyword">then</span></span><br><span class="line">        ip=(<span class="variable">$&#123;SSL_TRUSTED_IP&#125;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;!ip[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">          <span class="built_in">echo</span> IP.$((i+<span class="number">1</span>)) = <span class="variable">$&#123;ip[$i]&#125;</span> &gt;&gt; <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 4. 生成服务SSL KEY <span class="variable">$&#123;SSL_KEY&#125;</span> \033[0m&quot;</span></span><br><span class="line">openssl genrsa -out <span class="variable">$&#123;SSL_KEY&#125;</span> <span class="variable">$&#123;SSL_SIZE&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 5. 生成服务SSL CSR <span class="variable">$&#123;SSL_CSR&#125;</span> \033[0m&quot;</span></span><br><span class="line">openssl req -sha256 -new -key <span class="variable">$&#123;SSL_KEY&#125;</span> -out <span class="variable">$&#123;SSL_CSR&#125;</span> -subj <span class="string">&quot;/C=<span class="variable">$&#123;CN&#125;</span>/CN=<span class="variable">$&#123;SSL_DOMAIN&#125;</span>&quot;</span> -config <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 6. 生成服务SSL CERT <span class="variable">$&#123;SSL_CERT&#125;</span> \033[0m&quot;</span></span><br><span class="line">openssl x509 -sha256 -req -<span class="keyword">in</span> <span class="variable">$&#123;SSL_CSR&#125;</span> -CA <span class="variable">$&#123;CA_CERT&#125;</span> \</span><br><span class="line">    -CAkey <span class="variable">$&#123;CA_KEY&#125;</span> -CAcreateserial -out <span class="variable">$&#123;SSL_CERT&#125;</span> \</span><br><span class="line">    -days <span class="variable">$&#123;SSL_DATE&#125;</span> -extensions v3_req \</span><br><span class="line">    -extfile <span class="variable">$&#123;SSL_CONFIG&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 7. 证书制作完成 \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 8. 以YAML格式输出结果 \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;----------------------------------------------------------&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ca_key: |&quot;</span></span><br><span class="line">cat <span class="variable">$CA_KEY</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ca_cert: |&quot;</span></span><br><span class="line">cat <span class="variable">$CA_CERT</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_key: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_KEY</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_csr: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_CSR</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_cert: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_CERT</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 9. 附加CA证书到Cert文件 \033[0m&quot;</span></span><br><span class="line">cat <span class="variable">$&#123;CA_CERT&#125;</span> &gt;&gt; <span class="variable">$&#123;SSL_CERT&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;ssl_cert: |&quot;</span></span><br><span class="line">cat <span class="variable">$SSL_CERT</span> | sed <span class="string">&#x27;s/^/  /&#x27;</span></span><br><span class="line"><span class="built_in">echo</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\033[32m ====&gt; 10. 重命名服务证书 \033[0m&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.key tls.key&quot;</span></span><br><span class="line">cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.key tls.key</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.crt tls.crt&quot;</span></span><br><span class="line">cp <span class="variable">$&#123;SSL_DOMAIN&#125;</span>.crt tls.crt</span><br></pre></td></tr></table></figure>

<p>使用示例如下，详细参数说明请参考<a href="https://docs.rancher.cn/docs/rancher2.5/installation/resources/advanced/self-signed-ssl/_index/#41-%E4%B8%80%E9%94%AE%E7%94%9F%E6%88%90-ssl-%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6%E8%84%9A%E6%9C%AC">Rancher一键生成自签名证书脚本</a>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x create-cert.sh</span><br><span class="line">./create-cert.sh --ssl-domain=ldap.zerchin.xyz --ssl-trusted-ip=172.16.21.12 --ssl-size=2048 --ssl-date=3650</span><br></pre></td></tr></table></figure>



<h4 id="LDAP-添加相关-TLS-配置参数"><a href="#LDAP-添加相关-TLS-配置参数" class="headerlink" title="LDAP 添加相关 TLS 配置参数"></a>LDAP 添加相关 TLS 配置参数</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2.3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">openldap:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">osixia/openldap:1.5.0</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">openldap</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_ORGANISATION=rancher</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_DOMAIN=rancherldap.com</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_ADMIN_PASSWORD=Rancher123</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_TLS_CRT_FILENAME=tls.crt</span>                   <span class="comment">## tls</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_TLS_KEY_FILENAME=tls.key</span>                   <span class="comment">## tls</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_TLS_CA_CRT_FILENAME=cacerts.pem</span>            <span class="comment">## tls</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">LDAP_TLS_VERIFY_CLIENT=try</span>                      <span class="comment">## tls</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">389</span><span class="string">:389</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">636</span><span class="string">:636</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./slapd:/etc/ldap/slapd.d</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./data:/var/lib/ldap</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./certs:/container/service/slapd/assets/certs</span>    <span class="comment">## tls</span></span><br><span class="line">  <span class="attr">phpldapadmin:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">osixia/phpldapadmin:0.9.0</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">phpldapadmin</span></span><br><span class="line">    <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">PHPLDAPADMIN_LDAP_HOSTS=openldap</span></span><br><span class="line">    <span class="attr">links:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">openldap:openldap</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">openldap</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">6443</span><span class="string">:443</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./phpldapadmin-certs:/container/service/phpldapadmin/assets/apache2/certs</span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<p><code>LDAP_TLS_CRT_FILENAME</code>：ldap证书文件名</p>
<p><code>LDAP_TLS_KEY_FILENAME</code>：ldap证书key文件名</p>
<p><code>LDAP_TLS_CA_CRT_FILENAME</code>：CA证书文件名</p>
<p><code>LDAP_TLS_VERIFY_CLIENT</code>：默认是<code>demand</code>，会对传入的 TLS 会话中的客户端证书强制执行检查，在对接的过程中会报证书相关错误，这里设置为<code>try</code>，没有证书也可以正常会话保持。可参考<a href="https://www.openldap.org/doc/admin24/tls.html">此文档</a>。</p>
<p>然后重新运行docker-compose命令即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose down -v</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>



<h4 id="Rancher对接TLS-OpenLDAP"><a href="#Rancher对接TLS-OpenLDAP" class="headerlink" title="Rancher对接TLS OpenLDAP"></a>Rancher对接TLS OpenLDAP</h4><p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/rancher-5.png" alt="rancher-5"></p>
<p>其中端口要改为636 tls端口，并将加密类型设置为TLS，其中CA证书去certs目录下查看<code>cacerts.pem</code>文件拷贝过来即可，对接成功如下：</p>
<p><img src="/images/mk/%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAOpenLDAP%E7%8E%AF%E5%A2%83%E5%B9%B6%E5%AF%B9%E6%8E%A5Rancher%E8%AE%A4%E8%AF%81.assets/rancher-6.png" alt="rancher-6"></p>
]]></content>
      <categories>
        <category>openldap</category>
      </categories>
      <tags>
        <tag>rancher</tag>
        <tag>openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>生成自签名证书脚本</title>
    <url>/2021/04/20/%E7%94%9F%E6%88%90%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>基于OpenSSL实现自动生成自签名证书</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="脚本如下"><a href="#脚本如下" class="headerlink" title="脚本如下"></a>脚本如下</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line">DOMAIN=test1.zerchin.xyz</span><br><span class="line">DOMAIN_EXT=</span><br><span class="line">IP=172.16.1.188</span><br><span class="line">DATE=3650</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate CA : cakey.pem &amp;&amp; cacerts.pem</span></span><br><span class="line"><span class="keyword">if</span> [[ ! -e <span class="string">&quot;cacerts.pem&quot;</span> || ! -e <span class="string">&quot;cakey.pem&quot;</span> ]]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  openssl genrsa -out cakey.pem 2048</span><br><span class="line">  openssl req -x509 -new -nodes -key cakey.pem -subj <span class="string">&quot;/CN=zerchin&quot;</span> -days <span class="variable">$&#123;DATE&#125;</span> -out cacerts.pem </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## generate server tls</span></span><br><span class="line">mkdir <span class="variable">$&#123;DOMAIN&#125;</span></span><br><span class="line">openssl genrsa -out <span class="variable">$&#123;DOMAIN&#125;</span>/tls.key 2048</span><br><span class="line"></span><br><span class="line">cat &gt; <span class="variable">$&#123;DOMAIN&#125;</span>/csr.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[ req ]</span></span><br><span class="line"><span class="string">default_bits = 2048</span></span><br><span class="line"><span class="string">prompt = no</span></span><br><span class="line"><span class="string">default_md = sha256</span></span><br><span class="line"><span class="string">req_extensions = req_ext</span></span><br><span class="line"><span class="string">distinguished_name = dn</span></span><br><span class="line"><span class="string">[ dn ]</span></span><br><span class="line"><span class="string">C = CN</span></span><br><span class="line"><span class="string">ST = GD</span></span><br><span class="line"><span class="string">L = SZ</span></span><br><span class="line"><span class="string">O = zerchin</span></span><br><span class="line"><span class="string">OU = zerchin</span></span><br><span class="line"><span class="string">CN = $&#123;DOMAIN&#125;</span></span><br><span class="line"><span class="string">[ req_ext ]</span></span><br><span class="line"><span class="string">subjectAltName = @alt_names</span></span><br><span class="line"><span class="string">[ alt_names ]</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="variable">$&#123;DOMAIN_EXT&#125;</span> ]]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    IFS=<span class="string">&quot;,&quot;</span></span><br><span class="line">    DNS=(<span class="variable">$&#123;DOMAIN&#125;</span>)</span><br><span class="line">    DNS+=(<span class="variable">$&#123;DOMAIN_EXT&#125;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;!DNS[@]&#125;</span> </span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> DNS.<span class="variable">$&#123;i&#125;</span> <span class="string">&quot;=&quot;</span> <span class="variable">$&#123;DNS[$i]&#125;</span> &gt;&gt; <span class="variable">$&#123;DOMAIN&#125;</span>/csr.conf</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">    <span class="built_in">echo</span> DNS.</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">if</span> [[ -n <span class="variable">$&#123;IP&#125;</span> ]]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    IFS=<span class="string">&quot;,&quot;</span></span><br><span class="line">    ip=(<span class="variable">$&#123;IP&#125;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;!ip[@]&#125;</span> </span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> IP.<span class="variable">$&#123;i&#125;</span> <span class="string">&quot;=&quot;</span> <span class="variable">$&#123;ip[$i]&#125;</span> &gt;&gt; <span class="variable">$&#123;DOMAIN&#125;</span>/csr.conf</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">    <span class="built_in">echo</span> DNS.</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">cat &gt;&gt; <span class="variable">$&#123;DOMAIN&#125;</span>/csr.conf &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">[ v3_ext ]</span></span><br><span class="line"><span class="string">authorityKeyIdentifier=keyid,issuer:always</span></span><br><span class="line"><span class="string">basicConstraints=CA:FALSE</span></span><br><span class="line"><span class="string">keyUsage=nonRepudiation,digitalSignature,keyEncipherment</span></span><br><span class="line"><span class="string">extendedKeyUsage=serverAuth,clientAuth</span></span><br><span class="line"><span class="string">subjectAltName=@alt_names</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># </span></span><br><span class="line">openssl req -new -key <span class="variable">$&#123;DOMAIN&#125;</span>/tls.key -out <span class="variable">$&#123;DOMAIN&#125;</span>/tls.csr -config <span class="variable">$&#123;DOMAIN&#125;</span>/csr.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">openssl x509 -req -<span class="keyword">in</span> <span class="variable">$&#123;DOMAIN&#125;</span>/tls.csr -CA cacerts.pem  -CAkey cakey.pem \</span><br><span class="line">  -CAcreateserial -out <span class="variable">$&#123;DOMAIN&#125;</span>/tls.crt -days <span class="variable">$&#123;DATE&#125;</span> \</span><br><span class="line">  -extensions v3_ext -extfile <span class="variable">$&#123;DOMAIN&#125;</span>/csr.conf</span><br></pre></td></tr></table></figure>

<p><strong>参数说明</strong>：</p>
<p><code>DOMAIN</code>：必填项，证书的域名</p>
<p><code>DOMAIN_EXT</code>：可选，额外的域名，多个域名以逗号隔开，没有则留空</p>
<p><code>IP</code>：可选，可信任的IP地址，多个IP地址以逗号隔开，没有则留空</p>
<p><code>DATE</code>：证书有效期，默认是10年</p>
<h3 id="生成自签名证书"><a href="#生成自签名证书" class="headerlink" title="生成自签名证书"></a>生成自签名证书</h3><p>将上述脚本保存到文件中并执行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bash auto-generate-cert.sh</span><br></pre></td></tr></table></figure>


<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># verify tls</span></span><br><span class="line">openssl x509  -noout -text -<span class="keyword">in</span> test1.zerchin.xyz/tls.crt</span><br><span class="line"><span class="comment"># verify CA</span></span><br><span class="line">openssl verify -CAfile cacerts.pem test1.zerchin.xyz/tls.crt</span><br><span class="line"><span class="comment"># verify server</span></span><br><span class="line">openssl s_client -connect test1.zerchin.xyz:443 -servername test1.zerchin.xyz</span><br><span class="line">openssl s_client -connect test1.zerchin.xyz:443 -servername test1.zerchin.xyz -CAfile cacerts.pem</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>openssl</tag>
      </tags>
  </entry>
  <entry>
    <title>自定义DDNS自动解析脚本</title>
    <url>/2022/06/27/%E8%87%AA%E5%AE%9A%E4%B9%89DDNS%E8%87%AA%E5%8A%A8%E8%A7%A3%E6%9E%90%E8%84%9A%E6%9C%AC/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在了解DDNS之前，我们先来了解一下什么DNS。在网络中，我们如果要访问一台主机或网站时，需要先获知其地址，其中IP地址获取记起来总是不那么方便。而DNS就是为了解决这种问题。DNS，也就是域名系统，记录了域名和IP之间的映射关系，主要的作用就是基于访问的域名（也就是网址中的xx.xx.xx）查出对应的IP。</p>
<p>但是在某些实际场景中，我们的IP并不一定会固定，可能会随着某些因素而发生变化，从而导致我们无法正常访问到具体应用或服务。为了解决这种问题，我们可以通过DDNS实现域名的动态解析。DDNS用来动态更新DNS服务器上域名和IP地址之间的映射关系，从而保证通过域名访问到正确的IP地址。</p>
<p>通常情况下，某些路由器或者网络设备会有DDNS功能，但是不一定支持我们域名所在的DNS服务商，所以我们可以基于DNS服务商提供的API接口，自行编写DDNS脚本。</p>
<h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><p>Linux操作系统：CentOS7</p>
<p>已开通的公网IP</p>
<h2 id="详细操作"><a href="#详细操作" class="headerlink" title="详细操作"></a>详细操作</h2><h3 id="基于腾讯云DNS域名解析实现DDNS"><a href="#基于腾讯云DNS域名解析实现DDNS" class="headerlink" title="基于腾讯云DNS域名解析实现DDNS"></a>基于腾讯云DNS域名解析实现DDNS</h3><ol>
<li><p>获取token，登录腾讯云的DNSPod账号中心控制台，右上角依次单击<strong>我的账号</strong>-&gt;<strong>API密钥</strong>，在<strong>DNSPod Token</strong>中点击创建密钥即可。（密钥只会显示一次，记得保存好）</p>
<p>然后LOGIN_TOKEN会以ID+”,”+TOKEN的方式使用，所以也要记得记录一下当前token的ID值。</p>
<p>将其保存到<code>/usr/local/dnspod-agent</code>目录下，并命名成<code>dnspod-token</code>文件。</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /usr/<span class="built_in">local</span>/dnspod-agent</span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">&quot;ID,TOKEN&quot;</span> | base64 &gt; /usr/<span class="built_in">local</span>/dnspod-agent/dnspod-token</span><br><span class="line">LOGIN_TOKEN=`base64 -d /usr/<span class="built_in">local</span>/dnspod-agent/dnspod-token`</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>获取当前主机的公网IP</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">IP=`curl ifconfig.me -s`</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>获取Domain ID</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DOMAIN_ID=`curl -s -X POST https://dnsapi.cn/Domain.List -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&quot;</span> | jq .domains[0].id`</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>获取需要解析的子域名前缀，例如demo.zerchin.xyz`，那么就填写demo</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SUB_DOMAIN=<span class="string">&quot;demo&quot;</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>获取record ID，也就是子域名记录的ID</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RECORD_ID=`curl -s -X POST https://dnsapi.cn/Record.List -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&amp;domain_id=<span class="variable">$&#123;DOMAIN_ID&#125;</span>&amp;sub_domain=<span class="variable">$&#123;SUB_DOMAIN&#125;</span>&quot;</span> | jq -r .records[0].id`</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>record type</li>
</ol>
<p>常用的记录类型：</p>
<p><code>A</code>：用来指定域名的IP地址</p>
<p><code>CNAME</code>：将域名指向到另一个域名上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RECORD_TYPE=<span class="string">&quot;A&quot;</span></span><br></pre></td></tr></table></figure>

<ol start="7">
<li>线路类型，我们选择默认就可以了，<code>默认 == &quot;0&quot;</code></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RECORD_LINE_ID=<span class="string">&quot;0&quot;</span></span><br></pre></td></tr></table></figure>

<ol start="8">
<li>原先记录的IP</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OLD_IP=`curl -s -X POST https://dnsapi.cn/Record.List -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&amp;domain_id=<span class="variable">$&#123;DOMAIN_ID&#125;</span>&amp;sub_domain=<span class="variable">$&#123;SUB_DOMAIN&#125;</span>&quot;</span> | jq -r .records[0].value`</span><br></pre></td></tr></table></figure>



<p><strong>9. 完整脚本实现如下：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"></span><br><span class="line">LOGIN_TOKEN=`base64 -d /usr/<span class="built_in">local</span>/dnspod-agent/dnspod-token`</span><br><span class="line"></span><br><span class="line">IP=`curl ifconfig.me -s`</span><br><span class="line"></span><br><span class="line">DOMAIN_ID=`curl -s -X POST https://dnsapi.cn/Domain.List -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&quot;</span> | jq .domains[0].id`</span><br><span class="line"></span><br><span class="line">SUB_DOMAIN=<span class="string">&quot;demo&quot;</span></span><br><span class="line"></span><br><span class="line">RECORD_ID=`curl -s -X POST https://dnsapi.cn/Record.List -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&amp;domain_id=<span class="variable">$&#123;DOMAIN_ID&#125;</span>&amp;sub_domain=<span class="variable">$&#123;SUB_DOMAIN&#125;</span>&quot;</span> | jq -r .records[0].id`</span><br><span class="line"></span><br><span class="line">RECORD_TYPE=<span class="string">&quot;A&quot;</span></span><br><span class="line"></span><br><span class="line">RECORD_LINE_ID=<span class="string">&quot;0&quot;</span></span><br><span class="line"></span><br><span class="line">OLD_IP=`curl -s -X POST https://dnsapi.cn/Record.List -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&amp;domain_id=<span class="variable">$&#123;DOMAIN_ID&#125;</span>&amp;sub_domain=<span class="variable">$&#123;SUB_DOMAIN&#125;</span>&quot;</span> | jq -r .records[0].value`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$OLD_IP</span> != <span class="variable">$IP</span> ]];<span class="keyword">then</span></span><br><span class="line">  <span class="comment">## modify record ip</span></span><br><span class="line">  curl -X POST https://dnsapi.cn/Record.Modify -d <span class="string">&quot;login_token=<span class="variable">$&#123;LOGIN_TOKEN&#125;</span>&amp;format=json&amp;domain_id=<span class="variable">$&#123;DOMAIN_ID&#125;</span>&amp;record_id=<span class="variable">$&#123;RECORD_ID&#125;</span>&amp;sub_domain=<span class="variable">$&#123;SUB_DOMAIN&#125;</span>&amp;value=<span class="variable">$&#123;IP&#125;</span>&amp;record_type=<span class="variable">$&#123;RECORD_TYPE&#125;</span>&amp;record_line_id=<span class="variable">$&#123;RECORD_LINE_ID&#125;</span>&quot;</span></span><br><span class="line">  <span class="built_in">echo</span> `date +<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>` <span class="variable">$IP</span> &gt;&gt; /usr/<span class="built_in">local</span>/dnspod-agent/dnspod_record_ip</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>为防止频繁访问API被禁，建议<code>DOMAIN_ID</code>、<code>RECORD_ID</code>这种不会变动的参数预先获取直接填入。</p>
</blockquote>
<p>将上述脚本保存在<code>/usr/local/dnspod-agent</code>目录下，命名为<code>dnspod-agent.sh</code>，然后添加一条每分钟执行的定时任务即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x /opt/dnspod-agent/dnspod-agent.sh</span><br><span class="line">* * * * * /opt/dnspod-agent/dnspod-agent.sh</span><br></pre></td></tr></table></figure>



<h3 id="基于公云DNS域名解析实现DDNS"><a href="#基于公云DNS域名解析实现DDNS" class="headerlink" title="基于公云DNS域名解析实现DDNS"></a>基于公云DNS域名解析实现DDNS</h3><p>公云是一个可以免费解析动态域名服务商，某些路由器集成了公云的DDNS，但是如果没有集成的话，也可以自行实现一个DDNS脚本，如下：</p>
<ol>
<li>保存用户名密码到<code>/usr/local/pubyun-agent</code>目录下，命名为<code>pubyun-token</code></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /opt/pubyun-agent</span><br><span class="line"><span class="built_in">echo</span> -n <span class="string">&quot;userName:password&quot;</span> | base64 &gt; /opt/pubyun-agent/pubyun-token</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>完整脚本实现如下：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment">## 获取当前主机IP</span></span><br><span class="line">IP=`curl ifconfig.me -s`</span><br><span class="line"></span><br><span class="line">PUBYUN_TOKEN=`base64 -d /usr/<span class="built_in">local</span>/pubyun-agent/pubyun-token`</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">record_ip</span></span>()&#123;</span><br><span class="line">    curl -X POST -u <span class="variable">$&#123;PUBYUN_TOKEN&#125;</span> <span class="string">&quot;http://members.3322.net/dyndns/update?system=dyndns&amp;hostname=zerchin.f3322.net&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> `date +<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>` <span class="variable">$IP</span> &gt;&gt; /usr/<span class="built_in">local</span>/pubyun-agent/pubyun_record_ip</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">  <span class="keyword">if</span> [[ ! -f <span class="string">&quot;/usr/local/pubyun-agent/pubyun_record_ip&quot;</span> ]];<span class="keyword">then</span></span><br><span class="line">    touch /usr/<span class="built_in">local</span>/pubyun-agent/pubyun_record_ip</span><br><span class="line">    record_ip</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">if</span> [[ `tail -n 1 /usr/<span class="built_in">local</span>/pubyun-agent/pubyun_record_ip | awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span>` != <span class="variable">$IP</span> &amp;&amp; <span class="variable">$IP</span> != <span class="string">&quot;&quot;</span> ]];<span class="keyword">then</span></span><br><span class="line">      record_ip</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">  <span class="keyword">fi</span> </span><br><span class="line">&#125;</span><br><span class="line">main</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>将上述脚本保存在<code>/usr/local/pubyun-agent</code>目录下，命名为<code>pubyun-agent.sh</code>，然后添加一条每分钟执行的定时任务即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x /opt/pubyun-agent/pubyun-agent.sh</span><br><span class="line">* * * * * /opt/pubyun-agent/pubyun-agent.sh</span><br></pre></td></tr></table></figure>



<blockquote>
<p>腾讯云 DNS API 参考：<a href="https://docs.dnspod.cn/api/modify-records/">https://docs.dnspod.cn/api/modify-records/</a></p>
<p>公云 DNS API 参考：<a href="https://www.pubyun.com/products/dyndns/download/">https://www.pubyun.com/products/dyndns/download/</a></p>
</blockquote>
]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>ddns</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次docker-compose映射2222端口的坑</title>
    <url>/2021/05/22/%E8%AE%B0%E4%B8%80%E6%AC%A1docker-compose%E6%98%A0%E5%B0%842222%E7%AB%AF%E5%8F%A3%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>使用docker-compose搭建基于gogs+MySQL的个人git仓库，在映射<code>2222:22</code>端口的时候，报如下错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ./docker-compose up -d</span></span><br><span class="line">Creating network <span class="string">&quot;gogs_default&quot;</span> with the default driver</span><br><span class="line">Creating gogs_mysql_1 ... <span class="keyword">done</span></span><br><span class="line">Creating gogs_gogs_1  ... error</span><br><span class="line"></span><br><span class="line">ERROR: <span class="keyword">for</span> gogs_gogs_1  Cannot create container <span class="keyword">for</span> service gogs: invalid port specification: <span class="string">&quot;133342&quot;</span></span><br><span class="line"></span><br><span class="line">ERROR: <span class="keyword">for</span> gogs  Cannot create container <span class="keyword">for</span> service gogs: invalid port specification: <span class="string">&quot;133342&quot;</span></span><br><span class="line">ERROR: Encountered errors <span class="keyword">while</span> bringing up the project.</span><br></pre></td></tr></table></figure>

<p>其中<code>docker-compose.yml</code>部分配置如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">gogs:</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="number">2222</span><span class="string">:22</span></span><br></pre></td></tr></table></figure>



<h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>YAML 支持所谓的“<a href="http://yaml.org/type/float.html">以60为底的浮点数</a>”，对时间计算很有用。因此<code>2222:22</code>被解释为<code>2222 * 60 + 22</code>，即133342。如果port包含大于60的数字，例如<code>3306:3306</code>或<code>8080:80</code>，就没有问题，因此不会总是发生此问题，从而使其隐蔽。</p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>使用双引号即可，如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">gogs:</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;2222:22&quot;</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次harbor数据库表异常恢复过程</title>
    <url>/2021/07/30/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="问题概述"><a href="#问题概述" class="headerlink" title="问题概述"></a>问题概述</h2><p>由于某些操作，导致客户的harbor镜像仓库无法进行镜像同步，经过排查，发现数据库异常，报如下错误：</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/error-1.png" alt="error-1"></p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/error-2.png" alt="error-2"></p>
<h2 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h2><p>查看<code>/var/log/postgresql.log</code>日志，发现数据库频繁报如下错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">STATEMENT: SELECT COUNT(1) FROM quota AS a JOIN quota_usage AS b ON a.id = b.id WHERE 1=1</span><br><span class="line">ERROR: MultiXactId 29362 has not been created yet -- apparent wraparound</span><br></pre></td></tr></table></figure>

<p>于是进入harbor的数据库进行查看。（harbor默认使用postgresql作为数据库）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it harbor-db bash</span><br><span class="line">postgres [ / ]$ psql</span><br><span class="line">psql (9.6.21)</span><br><span class="line">Type <span class="string">&quot;help&quot;</span> <span class="keyword">for</span> <span class="built_in">help</span>.</span><br><span class="line"></span><br><span class="line">postgres=<span class="comment"># </span></span><br></pre></td></tr></table></figure>

<p>进入registry数据库</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">\c registry</span><br></pre></td></tr></table></figure>

<p>看到<code>connected</code>说明已经连上了该数据库</p>
<p>查看该数据库中的所有表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">\dt</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">                 List of relations</span><br><span class="line"> Schema |           Name           | Type  |  Owner   </span><br><span class="line"><span class="comment">--------+--------------------------+-------+----------</span></span><br><span class="line">...（省略）</span><br><span class="line">public | quota                    | table | postgres</span><br><span class="line">public | quota_usage              | table | postgres</span><br><span class="line">...（省略）</span><br></pre></td></tr></table></figure>

<p>先看一下表数据还在不在</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> quota_usage;</span><br></pre></td></tr></table></figure>

<p>发现报同样的错误</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/pg-1.png" alt="pg-1"></p>
<p>那么这里就可以确定是这个表异常了导致harbor UI上显示异常，并且由于镜像同步时会去查询该表，所以导致查询的时候异常了无法进行镜像同步的操作。</p>
<h2 id="问题处理"><a href="#问题处理" class="headerlink" title="问题处理"></a>问题处理</h2><p>手动恢复该表即可</p>
<h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><p>清空<code>quota_usage</code>表数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> quota_usage;</span><br></pre></td></tr></table></figure>

<p>重新恢复数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> quota_usage (<span class="keyword">id</span>, <span class="keyword">reference</span>, reference_id, used, creation_time, update_time)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>,</span><br><span class="line">       <span class="keyword">reference</span>,</span><br><span class="line">       reference_id,</span><br><span class="line">       <span class="string">&#x27;&#123;&quot;storage&quot;: 0&#125;&#x27;</span>,</span><br><span class="line">       creation_time,</span><br><span class="line">       update_time</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">quota</span>;</span><br></pre></td></tr></table></figure>

<p>这里插入数据的命令可以参考harbor官方<a href="https://github.com/goharbor/harbor/blob/e714a8eacc5edce218ca96e6a458413f71badf0c/make/migrations/postgresql/0010_1.9.0_schema.up.sql#L99">github代码</a></p>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>如果无法清空表，可以手动删除该表重新创建</p>
<p>删除<code>quota_usage</code>表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> quota_usage;</span><br></pre></td></tr></table></figure>

<p>新建<code>quota_usage</code>表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> quota_usage</span><br><span class="line">(</span><br><span class="line">  <span class="keyword">id</span>            <span class="built_in">SERIAL</span> PRIMARY <span class="keyword">KEY</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">reference</span>     <span class="built_in">VARCHAR</span>(<span class="number">255</span>)       <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  reference_id  <span class="built_in">VARCHAR</span>(<span class="number">255</span>)       <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  used          JSONB              <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  creation_time <span class="built_in">timestamp</span> <span class="keyword">default</span> <span class="keyword">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  update_time   <span class="built_in">timestamp</span> <span class="keyword">default</span> <span class="keyword">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  <span class="keyword">UNIQUE</span> (<span class="keyword">reference</span>, reference_id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>这里创建表的命令参考<a href="https://github.com/goharbor/harbor/blob/e714a8eacc5edce218ca96e6a458413f71badf0c/make/migrations/postgresql/0010_1.9.0_schema.up.sql#L78">github代码</a></p>
<p>然后再恢复数据</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> quota_usage (<span class="keyword">id</span>, <span class="keyword">reference</span>, reference_id, used, creation_time, update_time)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>,</span><br><span class="line">       <span class="keyword">reference</span>,</span><br><span class="line">       reference_id,</span><br><span class="line">       <span class="string">&#x27;&#123;&quot;storage&quot;: 0&#125;&#x27;</span>,</span><br><span class="line">       creation_time,</span><br><span class="line">       update_time</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">quota</span>;</span><br></pre></td></tr></table></figure>

<h3 id="恢复Harbor-UI显示异常"><a href="#恢复Harbor-UI显示异常" class="headerlink" title="恢复Harbor UI显示异常"></a>恢复Harbor UI显示异常</h3><p>当这一步操作完之后，镜像同步就可以操作了，但是UI还是显示异常</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/harbor-1.png" alt="harbor-1"></p>
<p>可以看到，右侧存储显示为0Byte，此时我们需要一个操作去触发更新存储的大小</p>
<p>这里也有两种方法恢复存储的显示</p>
<h4 id="方法一（不推荐）"><a href="#方法一（不推荐）" class="headerlink" title="方法一（不推荐）"></a>方法一（不推荐）</h4><p>手动上传镜像到项目中，即可自动更新对应项目的存储大小</p>
<p>例如这里我们push一个busybox镜像到test项目中</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/docker-push.png" alt="docker-push"></p>
<p>可以看到项目的存储大小自动更新为正确的值</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/harbor-2.png" alt="harbor-2"></p>
<p>但是此方法需要对每个项目都执行push操作，比较麻烦，推荐使用方法二</p>
<h4 id="方法二（推荐）"><a href="#方法二（推荐）" class="headerlink" title="方法二（推荐）"></a>方法二（推荐）</h4><p>对harbor执行垃圾清理即可</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/gc-1.png" alt="gc-1"></p>
<p>由于垃圾清理会去扫描所有的项目，所以就能够触发存储大小的更新</p>
<p>等待垃圾清理完毕，就可以看到，项目的存储大小全都恢复正常了</p>
<p><img src="/images/mk/%E8%AE%B0%E4%B8%80%E6%AC%A1harbor%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%BC%82%E5%B8%B8%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B.assets/harbor-3.png" alt="harbor-3"></p>
<h2 id="postgresql相关使用技巧"><a href="#postgresql相关使用技巧" class="headerlink" title="postgresql相关使用技巧"></a>postgresql相关使用技巧</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入数据库</span></span><br><span class="line">psql -h IP地址 -p 端口 -U 数据库名</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据库</span></span><br><span class="line">\l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择数据库</span></span><br><span class="line">\c database</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看该某个库中的所有表</span></span><br><span class="line">\dt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某个库中的某个表结构：</span></span><br><span class="line">\d 表名</span><br><span class="line"></span><br><span class="line"><span class="comment">## 基于表1插入表2</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> quota_usage (<span class="keyword">id</span>, <span class="keyword">reference</span>, reference_id, used, creation_time, update_time)</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>,</span><br><span class="line">       <span class="keyword">reference</span>,</span><br><span class="line">       reference_id,</span><br><span class="line">       <span class="string">&#x27;&#123;&quot;storage&quot;: 0&#125;&#x27;</span>,</span><br><span class="line">       creation_time,</span><br><span class="line">       update_time</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">quota</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 基于表1 插入 表2 并筛选已存在的值</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> quota_usage (<span class="keyword">id</span>,<span class="keyword">reference</span>,reference_id,creation_time,update_time,used) <span class="keyword">select</span> q.id,q.reference,q.reference_id,q.creation_time,q.update_time,<span class="string">&#x27;&#123;&quot;storage&quot;: 0&#125;&#x27;</span> <span class="keyword">from</span> <span class="keyword">quota</span> q <span class="keyword">where</span> <span class="keyword">not</span> <span class="keyword">exists</span> (<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> quota_usage qu <span class="keyword">WHERE</span> qu.id = q.id);</span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除表</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> quota_usage;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 清空表数据</span></span><br><span class="line"><span class="keyword">truncate</span> <span class="keyword">table</span> quota_usage;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 创建表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> quota_usage</span><br><span class="line">(</span><br><span class="line">  <span class="keyword">id</span>            <span class="built_in">SERIAL</span> PRIMARY <span class="keyword">KEY</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">reference</span>     <span class="built_in">VARCHAR</span>(<span class="number">255</span>)       <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  reference_id  <span class="built_in">VARCHAR</span>(<span class="number">255</span>)       <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  used          JSONB              <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  creation_time <span class="built_in">timestamp</span> <span class="keyword">default</span> <span class="keyword">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  update_time   <span class="built_in">timestamp</span> <span class="keyword">default</span> <span class="keyword">CURRENT_TIMESTAMP</span>,</span><br><span class="line">  <span class="keyword">UNIQUE</span> (<span class="keyword">reference</span>, reference_id)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">## 更新某个字段</span></span><br><span class="line"><span class="keyword">update</span> quota_usage <span class="keyword">set</span> used=<span class="string">&#x27;&#123;&quot;storage&quot;: 0&#125;&#x27;</span> <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除某行数据</span></span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> quota_usage <span class="keyword">where</span> <span class="keyword">id</span>=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<!--参考：https://www.cnblogs.com/my-blogs-for-everone/p/10226473.html  -->]]></content>
      <categories>
        <category>harbor</category>
      </categories>
      <tags>
        <tag>harbor</tag>
        <tag>postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title>通过API操作Rancher 用户权限</title>
    <url>/2020/06/02/%E9%80%9A%E8%BF%87API%E6%93%8D%E4%BD%9CRancher-%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/</url>
    <content><![CDATA[<h2 id="1、查看用户列表"><a href="#1、查看用户列表" class="headerlink" title="1、查看用户列表"></a>1、查看用户列表</h2><p>API接口：https://<Rancher_URL>/v3/users</p>
<p>例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 环境变量，可从Rancher UI右上角 &quot;API &amp; Keys&quot; 中获取</span></span><br><span class="line">API=https://&lt;RANCHER_SERVER_URL&gt;/v3</span><br><span class="line">CATTLE_ACCESS_KEY=token-fmtvn</span><br><span class="line">CATTLE_SECRET_KEY=2kd2tlkzm5hnlnj76x26nswn7jpxrjwbd56t9nlxnt5qzd479wkb5l</span><br><span class="line"></span><br><span class="line">curl -k -s -u <span class="string">&quot;<span class="variable">$&#123;CATTLE_ACCESS_KEY&#125;</span>:<span class="variable">$&#123;CATTLE_SECRET_KEY&#125;</span>&quot;</span> -X GET \</span><br><span class="line"> -H <span class="string">&#x27;Content-Type: application/json&#x27;</span> -H <span class="string">&#x27;Accept: application/json&#x27;</span> \</span><br><span class="line">  <span class="variable">$API</span>/users/  | jq .data[].id &gt; /tmp/user_id</span><br><span class="line"></span><br><span class="line">cat /tmp/user_id</span><br></pre></td></tr></table></figure>



<h2 id="2、为所有用户添加user权限"><a href="#2、为所有用户添加user权限" class="headerlink" title="2、为所有用户添加user权限"></a>2、为所有用户添加user权限</h2><p>API接口：https://<Rancher_URL>/v3/globalrolebindings</p>
<p>例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 环境变量</span></span><br><span class="line">API=https://&lt;RANCHER_SERVER_URL&gt;/v3</span><br><span class="line">CATTLE_ACCESS_KEY=token-fmtvn</span><br><span class="line">CATTLE_SECRET_KEY=2kd2tlkzm5hnlnj76x26nswn7jpxrjwbd56t9nlxnt5qzd479wkb5l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat /tmp/user_id`</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">curl -k -s -u <span class="string">&quot;<span class="variable">$&#123;CATTLE_ACCESS_KEY&#125;</span>:<span class="variable">$&#123;CATTLE_SECRET_KEY&#125;</span>&quot;</span> \</span><br><span class="line">-X POST \</span><br><span class="line">-H <span class="string">&#x27;Accept: application/json&#x27;</span> \</span><br><span class="line">-H <span class="string">&#x27;Content-Type: application/json&#x27;</span> \</span><br><span class="line">-d <span class="string">&#x27;&#123;&quot;globalRoleId&quot;:&quot;user&quot; , &quot;name&quot;:&quot;&quot;, &quot;userId&quot;:&#x27;</span><span class="variable">$i</span><span class="string">&#x27;&#125;&#x27;</span> \</span><br><span class="line"><span class="variable">$&#123;API&#125;</span>/globalrolebindings</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>



<h2 id="3、查看拥有user权限的用户"><a href="#3、查看拥有user权限的用户" class="headerlink" title="3、查看拥有user权限的用户"></a>3、查看拥有user权限的用户</h2><p>API接口：https://<Rancher_URL>/v3/globalRoleBindings</p>
<p>例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 环境变量</span></span><br><span class="line">API=https://&lt;RANCHER_SERVER_URL&gt;/v3</span><br><span class="line">CATTLE_ACCESS_KEY=token-fmtvn</span><br><span class="line">CATTLE_SECRET_KEY=2kd2tlkzm5hnlnj76x26nswn7jpxrjwbd56t9nlxnt5qzd479wkb5l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data=`curl -k -s -u <span class="string">&quot;<span class="variable">$&#123;CATTLE_ACCESS_KEY&#125;</span>:<span class="variable">$&#123;CATTLE_SECRET_KEY&#125;</span>&quot;</span> -X GET -H <span class="string">&#x27;Accept: application/json&#x27;</span> <span class="variable">$API</span>/globalRoleBindings/ `</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$data</span> | jq <span class="string">&#x27;[foreach .data[] as $item([[],[]]; if $item.globalRoleId == &quot;user&quot; then $item.name else empty end )  ]&#x27;</span> | jq .[] &gt; /tmp/user_tmp</span><br><span class="line"></span><br><span class="line">cat /tmp/user_tmp</span><br></pre></td></tr></table></figure>



<h2 id="4、删除拥有user权限的用户"><a href="#4、删除拥有user权限的用户" class="headerlink" title="4、删除拥有user权限的用户"></a>4、删除拥有user权限的用户</h2><p>API接口：https://<Rancher_URL>/v3/globalRoleBindings</p>
<p>例如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 环境变量</span></span><br><span class="line">API=https://&lt;RANCHER_SERVER_URL&gt;/v3CATTLE_ACCESS_KEY=token-fmtvn</span><br><span class="line">CATTLE_SECRET_KEY=2kd2tlkzm5hnlnj76x26nswn7jpxrjwbd56t9nlxnt5qzd479wkb5l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> `cat /tmp/user_tmp`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">name=`<span class="built_in">echo</span> <span class="variable">$i</span>|awk -F <span class="string">&#x27;&quot;&#x27;</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>`</span><br><span class="line">curl -k -s -u <span class="string">&quot;<span class="variable">$&#123;CATTLE_ACCESS_KEY&#125;</span>:<span class="variable">$&#123;CATTLE_SECRET_KEY&#125;</span>&quot;</span> \</span><br><span class="line">-X DELETE \</span><br><span class="line">-H <span class="string">&#x27;Accept: application/json&#x27;</span> \</span><br><span class="line"><span class="string">&quot;<span class="variable">$&#123;API&#125;</span>/globalRoleBindings/<span class="variable">$&#123;name&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>rancher</category>
      </categories>
      <tags>
        <tag>rancher</tag>
      </tags>
  </entry>
</search>
